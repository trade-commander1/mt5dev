[14:08:02] NTCP initialized.
[12:47:41] NTCP initialized.
[16:32:33] NTCP initialized.
[16:44:08] NTCP initialized.
[16:49:37] NTCP initialized.
[16:59:05] NTCP initialized.
[22:37:14] NTCP initialized.
[22:51:52] Load error: 'date'
[22:56:20] Load error: 'date'
[22:59:13] Load error: 'date'
[22:59:21] Load error: 'date'
[23:02:36] NTCP initialized.
[23:02:55] Load error: 'datetime'
[23:04:26] NTCP initialized.
[23:04:47] Load error: 'datetime'
[23:05:11] Loaded 7730082 M5 bars.
[23:05:30] Training started.
[23:05:30] 
============================================================
[23:05:30] STF Factor 6 of [6..24]
[23:05:30] ============================================================
[23:05:34] Training error: 'open'
[23:05:34] Training returned no results.
[23:13:01] NTCP initialized.
[23:13:18] Loaded 7730082 M5 bars.
[23:13:24] Training started.
[23:13:24] 
============================================================
[23:13:24] STF Factor 6 of [6..24]
[23:13:24] ============================================================
[23:13:29] Building features: 0% (1/7730082)
[23:13:52] Building features: 5% (386505/7730082)
[23:14:15] Building features: 10% (773009/7730082)
[23:14:38] Building features: 15% (1159513/7730082)
[23:15:02] Building features: 20% (1546017/7730082)
[23:15:26] Building features: 25% (1932521/7730082)
[23:15:49] Building features: 30% (2319025/7730082)
[23:16:13] Building features: 35% (2705529/7730082)
[23:16:36] Building features: 40% (3092033/7730082)
[23:17:00] Building features: 45% (3478537/7730082)
[23:17:23] Building features: 50% (3865041/7730082)
[23:17:47] Building features: 55% (4251545/7730082)
[23:18:10] Building features: 60% (4638049/7730082)
[23:18:31] Building features: 65% (5024553/7730082)
[23:18:52] Building features: 70% (5411057/7730082)
[23:19:13] Building features: 75% (5797561/7730082)
[23:19:35] Building features: 80% (6184065/7730082)
[23:19:58] Building features: 85% (6570569/7730082)
[23:20:22] Building features: 90% (6957073/7730082)
[23:20:45] Building features: 95% (7343577/7730082)
[23:21:09] Building features: 100% (7730081/7730082)
[23:21:09] Computing Hurst exponent...
[23:24:52] Computing market regimes (GMM)...
[23:28:28] Factor 6: 7729960 samples, 92 features
[23:28:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:28:32] Training error: The size of tensor a (18) must match the size of tensor b (24) at non-singleton dimension 1
[23:28:32] Training returned no results.
[23:37:15] NTCP initialized.
[23:37:27] Loaded 175846 M5 bars.
[23:37:32] Training started.
[23:37:32] 
============================================================
[23:37:32] STF Factor 6 of [6..24]
[23:37:32] ============================================================
[23:37:33] Building features: 0% (1/175846)
[23:37:33] Building features: 5% (8793/175846)
[23:37:33] Building features: 10% (17585/175846)
[23:37:34] Building features: 15% (26377/175846)
[23:37:34] Building features: 20% (35169/175846)
[23:37:35] Building features: 25% (43961/175846)
[23:37:35] Building features: 30% (52753/175846)
[23:37:36] Building features: 35% (61545/175846)
[23:37:36] Building features: 40% (70337/175846)
[23:37:37] Building features: 45% (79129/175846)
[23:37:37] Building features: 50% (87921/175846)
[23:37:38] Building features: 55% (96713/175846)
[23:37:38] Building features: 60% (105505/175846)
[23:37:39] Building features: 65% (114297/175846)
[23:37:39] Building features: 70% (123089/175846)
[23:37:40] Building features: 75% (131881/175846)
[23:37:40] Building features: 80% (140673/175846)
[23:37:41] Building features: 85% (149465/175846)
[23:37:41] Building features: 90% (158257/175846)
[23:37:42] Building features: 95% (167049/175846)
[23:37:42] Building features: 100% (175841/175846)
[23:37:42] Computing Hurst exponent...
[23:37:47] Computing market regimes (GMM)...
[23:37:55] Factor 6: 175724 samples, 92 features
[23:37:55] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:38:01] Epoch 1/100 | Train: 0.000081 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:38:02] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:38:04] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:38:06] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:38:08] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:38:09] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:38:11] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:38:13] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:38:15] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:38:17] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:19] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:21] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:23] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:25] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:27] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:38:29] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 10)
[23:38:31] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:38:33] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:38:35] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:38:38] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:38:40] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:38:42] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:38:44] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:38:46] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:38:48] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:38:50] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:38:52] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:38:54] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 26)
[23:38:56] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[23:38:58] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[23:39:00] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[23:39:02] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[23:39:04] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[23:39:06] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 34)
[23:39:08] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:10] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:12] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:14] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:16] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:18] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[23:39:20] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[23:39:22] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[23:39:24] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[23:39:26] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[23:39:28] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[23:39:28] Early stopping at epoch 45 (no improvement for 10 epochs)
[23:39:29] Factor 6 done — best val loss: 0.000001 at epoch 35
[23:39:29] 
============================================================
[23:39:29] STF Factor 7 of [6..24]
[23:39:29] ============================================================
[23:39:29] Building features: 0% (1/175846)
[23:39:30] Building features: 5% (8793/175846)
[23:39:30] Building features: 10% (17585/175846)
[23:39:31] Building features: 15% (26377/175846)
[23:39:31] Building features: 20% (35169/175846)
[23:39:32] Building features: 25% (43961/175846)
[23:39:32] Building features: 30% (52753/175846)
[23:39:33] Building features: 35% (61545/175846)
[23:39:33] Building features: 40% (70337/175846)
[23:39:34] Building features: 45% (79129/175846)
[23:39:34] Building features: 50% (87921/175846)
[23:39:35] Building features: 55% (96713/175846)
[23:39:35] Building features: 60% (105505/175846)
[23:39:36] Building features: 65% (114297/175846)
[23:39:36] Building features: 70% (123089/175846)
[23:39:37] Building features: 75% (131881/175846)
[23:39:37] Building features: 80% (140673/175846)
[23:39:38] Building features: 85% (149465/175846)
[23:39:38] Building features: 90% (158257/175846)
[23:39:39] Building features: 95% (167049/175846)
[23:39:39] Building features: 100% (175841/175846)
[23:39:39] Computing Hurst exponent...
[23:39:44] Computing market regimes (GMM)...
[23:39:51] Factor 7: 175724 samples, 92 features
[23:39:51] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:39:57] Epoch 1/100 | Train: 0.000090 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:39:59] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:40:01] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:40:03] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:40:05] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:40:07] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:40:09] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:40:11] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:40:13] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:40:15] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:40:17] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:40:19] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:40:21] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:40:23] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:40:25] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 15)
[23:40:26] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 16)
[23:40:28] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:40:30] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:40:32] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:40:34] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 20)
[23:40:36] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 20)
[23:40:38] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:40:40] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:40:42] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:40:44] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[23:40:46] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[23:40:48] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:40:50] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:40:52] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:40:54] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:40:56] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:40:58] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:41:00] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:02] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:04] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:06] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:08] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:10] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 33)
[23:41:12] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:14] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:16] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:18] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:20] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:22] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 39)
[23:41:24] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:26] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:28] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:30] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:32] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:34] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 45)
[23:41:36] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:41:38] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:41:40] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:41:42] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:41:44] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:46] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:48] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:49] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:51] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:53] Epoch 60/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 55)
[23:41:55] Epoch 61/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[23:41:57] Epoch 62/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 62)
[23:41:59] Epoch 63/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 62)
[23:42:01] Epoch 64/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 62)
[23:42:03] Epoch 65/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 62)
[23:42:05] Epoch 66/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 62)
[23:42:07] Epoch 67/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:09] Epoch 68/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:11] Epoch 69/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:13] Epoch 70/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:15] Epoch 71/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:17] Epoch 72/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 67)
[23:42:19] Epoch 73/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 67)
[23:42:21] Epoch 74/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 67)
[23:42:23] Epoch 75/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 67)
[23:42:25] Epoch 76/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:27] Epoch 77/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:29] Epoch 78/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:31] Epoch 79/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:33] Epoch 80/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:35] Epoch 81/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 76)
[23:42:37] Epoch 82/100 | Train: 0.000000 | Val: 0.000001 | LR: 3.13e-05 | Best: 0.000001 (ep 76)
[23:42:39] Epoch 83/100 | Train: 0.000000 | Val: 0.000001 | LR: 3.13e-05 | Best: 0.000001 (ep 76)
[23:42:41] Epoch 84/100 | Train: 0.000000 | Val: 0.000001 | LR: 3.13e-05 | Best: 0.000001 (ep 76)
[23:42:43] Epoch 85/100 | Train: 0.000000 | Val: 0.000001 | LR: 3.13e-05 | Best: 0.000001 (ep 76)
[23:42:45] Epoch 86/100 | Train: 0.000000 | Val: 0.000001 | LR: 3.13e-05 | Best: 0.000001 (ep 76)
[23:42:45] Early stopping at epoch 86 (no improvement for 10 epochs)
[23:42:46] Factor 7 done — best val loss: 0.000001 at epoch 76
[23:42:46] 
============================================================
[23:42:46] STF Factor 8 of [6..24]
[23:42:46] ============================================================
[23:42:46] Building features: 0% (1/175846)
[23:42:47] Building features: 5% (8793/175846)
[23:42:47] Building features: 10% (17585/175846)
[23:42:48] Building features: 15% (26377/175846)
[23:42:48] Building features: 20% (35169/175846)
[23:42:49] Building features: 25% (43961/175846)
[23:42:49] Building features: 30% (52753/175846)
[23:42:50] Building features: 35% (61545/175846)
[23:42:50] Building features: 40% (70337/175846)
[23:42:51] Building features: 45% (79129/175846)
[23:42:51] Building features: 50% (87921/175846)
[23:42:52] Building features: 55% (96713/175846)
[23:42:52] Building features: 60% (105505/175846)
[23:42:53] Building features: 65% (114297/175846)
[23:42:53] Building features: 70% (123089/175846)
[23:42:54] Building features: 75% (131881/175846)
[23:42:54] Building features: 80% (140673/175846)
[23:42:55] Building features: 85% (149465/175846)
[23:42:55] Building features: 90% (158257/175846)
[23:42:56] Building features: 95% (167049/175846)
[23:42:56] Building features: 100% (175841/175846)
[23:42:56] Computing Hurst exponent...
[23:43:01] Computing market regimes (GMM)...
[23:43:08] Factor 8: 175724 samples, 92 features
[23:43:08] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:43:14] Epoch 1/100 | Train: 0.000080 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:43:16] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:43:18] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:43:20] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:43:22] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:43:24] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:43:26] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:43:28] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:43:29] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:31] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:33] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:35] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:37] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:39] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:43:41] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 9)
[23:43:43] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 16)
[23:43:45] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[23:43:47] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:43:49] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:43:51] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:43:53] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:43:55] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:43:57] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:43:59] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:44:01] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:44:03] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:44:05] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:44:07] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[23:44:09] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 23)
[23:44:11] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 30)
[23:44:13] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 30)
[23:44:15] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:17] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:19] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:21] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:23] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:25] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:44:27] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[23:44:29] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:31] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:33] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:35] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:37] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:39] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:44:41] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 39)
[23:44:43] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 39)
[23:44:45] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 39)
[23:44:47] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 39)
[23:44:48] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 39)
[23:44:48] Early stopping at epoch 49 (no improvement for 10 epochs)
[23:44:49] Factor 8 done — best val loss: 0.000001 at epoch 39
[23:44:49] 
============================================================
[23:44:49] STF Factor 9 of [6..24]
[23:44:49] ============================================================
[23:44:50] Building features: 0% (1/175846)
[23:44:50] Building features: 5% (8793/175846)
[23:44:51] Building features: 10% (17585/175846)
[23:44:51] Building features: 15% (26377/175846)
[23:44:52] Building features: 20% (35169/175846)
[23:44:52] Building features: 25% (43961/175846)
[23:44:53] Building features: 30% (52753/175846)
[23:44:53] Building features: 35% (61545/175846)
[23:44:54] Building features: 40% (70337/175846)
[23:44:54] Building features: 45% (79129/175846)
[23:44:55] Building features: 50% (87921/175846)
[23:44:55] Building features: 55% (96713/175846)
[23:44:56] Building features: 60% (105505/175846)
[23:44:56] Building features: 65% (114297/175846)
[23:44:57] Building features: 70% (123089/175846)
[23:44:57] Building features: 75% (131881/175846)
[23:44:58] Building features: 80% (140673/175846)
[23:44:58] Building features: 85% (149465/175846)
[23:44:59] Building features: 90% (158257/175846)
[23:44:59] Building features: 95% (167049/175846)
[23:45:00] Building features: 100% (175841/175846)
[23:45:00] Computing Hurst exponent...
[23:45:05] Computing market regimes (GMM)...
[23:45:11] Factor 9: 175724 samples, 92 features
[23:45:11] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:45:17] Epoch 1/100 | Train: 0.000122 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:45:19] Epoch 2/100 | Train: 0.000006 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:45:21] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:45:23] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:45:25] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:45:27] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:45:29] Epoch 7/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:45:31] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:45:33] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:45:35] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:45:36] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:39] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:41] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:42] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:44] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:46] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:45:48] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 11)
[23:45:50] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 11)
[23:45:52] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:45:54] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:45:56] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:45:58] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:46:00] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:46:02] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:46:04] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[23:46:06] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:46:08] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:46:10] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 28)
[23:46:12] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[23:46:14] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[23:46:16] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[23:46:18] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[23:46:20] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[23:46:22] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:46:24] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:46:26] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:46:28] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:46:30] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:32] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:34] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:36] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:38] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:40] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 38)
[23:46:42] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[23:46:44] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[23:46:46] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[23:46:48] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[23:46:50] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:46:52] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:46:54] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:46:56] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:46:58] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:47:00] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 48)
[23:47:02] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[23:47:04] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[23:47:06] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[23:47:08] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:10] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:12] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:14] Epoch 60/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:16] Epoch 61/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:18] Epoch 62/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 57)
[23:47:20] Epoch 63/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 57)
[23:47:22] Epoch 64/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 57)
[23:47:24] Epoch 65/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 57)
[23:47:26] Epoch 66/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 57)
[23:47:28] Epoch 67/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 57)
[23:47:28] Early stopping at epoch 67 (no improvement for 10 epochs)
[23:47:29] Factor 9 done — best val loss: 0.000001 at epoch 57
[23:47:29] 
============================================================
[23:47:29] STF Factor 10 of [6..24]
[23:47:29] ============================================================
[23:47:29] Building features: 0% (1/175846)
[23:47:29] Building features: 5% (8793/175846)
[23:47:30] Building features: 10% (17585/175846)
[23:47:30] Building features: 15% (26377/175846)
[23:47:31] Building features: 20% (35169/175846)
[23:47:31] Building features: 25% (43961/175846)
[23:47:32] Building features: 30% (52753/175846)
[23:47:32] Building features: 35% (61545/175846)
[23:47:33] Building features: 40% (70337/175846)
[23:47:33] Building features: 45% (79129/175846)
[23:47:34] Building features: 50% (87921/175846)
[23:47:34] Building features: 55% (96713/175846)
[23:47:35] Building features: 60% (105505/175846)
[23:47:35] Building features: 65% (114297/175846)
[23:47:36] Building features: 70% (123089/175846)
[23:47:36] Building features: 75% (131881/175846)
[23:47:37] Building features: 80% (140673/175846)
[23:47:37] Building features: 85% (149465/175846)
[23:47:38] Building features: 90% (158257/175846)
[23:47:38] Building features: 95% (167049/175846)
[23:47:39] Building features: 100% (175841/175846)
[23:47:39] Computing Hurst exponent...
[23:47:44] Computing market regimes (GMM)...
[23:47:50] Factor 10: 175724 samples, 92 features
[23:47:50] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:47:56] Epoch 1/100 | Train: 0.000097 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:47:58] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:48:00] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:48:02] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:48:04] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:48:06] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:48:08] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:48:10] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:48:12] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:14] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:16] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:18] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:20] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:22] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:48:24] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 9)
[23:48:26] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 9)
[23:48:28] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 9)
[23:48:30] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:48:32] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:48:34] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:48:36] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:48:38] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:48:40] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:48:41] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:48:43] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:48:45] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:48:47] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:48:49] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:48:51] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:48:53] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:48:55] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[23:48:57] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:48:59] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:49:01] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:49:03] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:49:05] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:49:07] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 32)
[23:49:09] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 32)
[23:49:11] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[23:49:13] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:15] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:17] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:19] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:21] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:23] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 40)
[23:49:25] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 40)
[23:49:27] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 40)
[23:49:29] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 40)
[23:49:31] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:33] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:35] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:37] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:39] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:41] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[23:49:43] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 49)
[23:49:45] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 49)
[23:49:47] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 49)
[23:49:49] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 49)
[23:49:51] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 49)
[23:49:51] Early stopping at epoch 59 (no improvement for 10 epochs)
[23:49:52] Factor 10 done — best val loss: 0.000001 at epoch 49
[23:49:52] 
============================================================
[23:49:52] STF Factor 11 of [6..24]
[23:49:52] ============================================================
[23:49:52] Building features: 0% (1/175846)
[23:49:52] Building features: 5% (8793/175846)
[23:49:53] Building features: 10% (17585/175846)
[23:49:53] Building features: 15% (26377/175846)
[23:49:54] Building features: 20% (35169/175846)
[23:49:54] Building features: 25% (43961/175846)
[23:49:55] Building features: 30% (52753/175846)
[23:49:55] Building features: 35% (61545/175846)
[23:49:56] Building features: 40% (70337/175846)
[23:49:56] Building features: 45% (79129/175846)
[23:49:57] Building features: 50% (87921/175846)
[23:49:57] Building features: 55% (96713/175846)
[23:49:58] Building features: 60% (105505/175846)
[23:49:58] Building features: 65% (114297/175846)
[23:49:59] Building features: 70% (123089/175846)
[23:49:59] Building features: 75% (131881/175846)
[23:50:00] Building features: 80% (140673/175846)
[23:50:00] Building features: 85% (149465/175846)
[23:50:01] Building features: 90% (158257/175846)
[23:50:01] Building features: 95% (167049/175846)
[23:50:02] Building features: 100% (175841/175846)
[23:50:02] Computing Hurst exponent...
[23:50:07] Computing market regimes (GMM)...
[23:50:13] Factor 11: 175724 samples, 92 features
[23:50:13] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:50:19] Epoch 1/100 | Train: 0.000086 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:50:21] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:50:23] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:50:25] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:50:27] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:50:29] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:50:31] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:50:33] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:50:35] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:50:37] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:50:39] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:50:41] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:50:43] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 13)
[23:50:45] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 14)
[23:50:47] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[23:50:49] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[23:50:51] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[23:50:53] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[23:50:55] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[23:50:57] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 20)
[23:50:59] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 20)
[23:51:01] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:51:03] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:51:05] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:51:07] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:51:08] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:10] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:12] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:14] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:16] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:18] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 26)
[23:51:20] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:51:22] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 26)
[23:51:24] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:26] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:28] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:30] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:32] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:34] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 34)
[23:51:36] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 34)
[23:51:38] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[23:51:40] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[23:51:42] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[23:51:44] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[23:51:46] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:48] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:50] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:52] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:54] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:56] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 45)
[23:51:58] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 45)
[23:52:00] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 45)
[23:52:02] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 45)
[23:52:04] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 45)
[23:52:06] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 45)
[23:52:06] Early stopping at epoch 55 (no improvement for 10 epochs)
[23:52:07] Factor 11 done — best val loss: 0.000001 at epoch 45
[23:52:07] 
============================================================
[23:52:07] STF Factor 12 of [6..24]
[23:52:07] ============================================================
[23:52:07] Building features: 0% (1/175846)
[23:52:08] Building features: 5% (8793/175846)
[23:52:08] Building features: 10% (17585/175846)
[23:52:09] Building features: 15% (26377/175846)
[23:52:09] Building features: 20% (35169/175846)
[23:52:10] Building features: 25% (43961/175846)
[23:52:10] Building features: 30% (52753/175846)
[23:52:11] Building features: 35% (61545/175846)
[23:52:11] Building features: 40% (70337/175846)
[23:52:11] Building features: 45% (79129/175846)
[23:52:12] Building features: 50% (87921/175846)
[23:52:12] Building features: 55% (96713/175846)
[23:52:13] Building features: 60% (105505/175846)
[23:52:13] Building features: 65% (114297/175846)
[23:52:14] Building features: 70% (123089/175846)
[23:52:14] Building features: 75% (131881/175846)
[23:52:15] Building features: 80% (140673/175846)
[23:52:15] Building features: 85% (149465/175846)
[23:52:16] Building features: 90% (158257/175846)
[23:52:16] Building features: 95% (167049/175846)
[23:52:17] Building features: 100% (175841/175846)
[23:52:17] Computing Hurst exponent...
[23:52:22] Computing market regimes (GMM)...
[23:52:28] Factor 12: 175724 samples, 92 features
[23:52:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:52:34] Epoch 1/100 | Train: 0.000087 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 1)
[23:52:36] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:52:38] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:52:40] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:52:42] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:52:44] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:52:46] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:52:48] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:52:50] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:52:52] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:52:54] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:52:56] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:52:58] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:53:00] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:53:02] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[23:53:04] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 16)
[23:53:06] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:53:08] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:53:10] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:53:12] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:53:14] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:53:16] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:53:18] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:53:20] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:53:22] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:53:24] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[23:53:26] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 27)
[23:53:28] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 28)
[23:53:30] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 28)
[23:53:32] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 28)
[23:53:34] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 31)
[23:53:36] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 31)
[23:53:38] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 31)
[23:53:40] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 31)
[23:53:42] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:43] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:45] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:47] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:49] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:51] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 35)
[23:53:53] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 35)
[23:53:55] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:53:57] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:53:59] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:54:01] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:54:03] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:54:05] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 42)
[23:54:07] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[23:54:09] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[23:54:11] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[23:54:13] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[23:54:15] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[23:54:15] Early stopping at epoch 52 (no improvement for 10 epochs)
[23:54:16] Factor 12 done — best val loss: 0.000001 at epoch 42
[23:54:16] 
============================================================
[23:54:16] STF Factor 13 of [6..24]
[23:54:16] ============================================================
[23:54:16] Building features: 0% (1/175846)
[23:54:17] Building features: 5% (8793/175846)
[23:54:17] Building features: 10% (17585/175846)
[23:54:18] Building features: 15% (26377/175846)
[23:54:18] Building features: 20% (35169/175846)
[23:54:19] Building features: 25% (43961/175846)
[23:54:19] Building features: 30% (52753/175846)
[23:54:20] Building features: 35% (61545/175846)
[23:54:20] Building features: 40% (70337/175846)
[23:54:21] Building features: 45% (79129/175846)
[23:54:22] Building features: 50% (87921/175846)
[23:54:22] Building features: 55% (96713/175846)
[23:54:23] Building features: 60% (105505/175846)
[23:54:23] Building features: 65% (114297/175846)
[23:54:24] Building features: 70% (123089/175846)
[23:54:24] Building features: 75% (131881/175846)
[23:54:25] Building features: 80% (140673/175846)
[23:54:25] Building features: 85% (149465/175846)
[23:54:26] Building features: 90% (158257/175846)
[23:54:26] Building features: 95% (167049/175846)
[23:54:27] Building features: 100% (175841/175846)
[23:54:27] Computing Hurst exponent...
[23:54:32] Computing market regimes (GMM)...
[23:54:38] Factor 13: 175724 samples, 92 features
[23:54:38] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:54:44] Epoch 1/100 | Train: 0.000087 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:54:46] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:54:48] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:54:50] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:54:52] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:54:54] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:54:56] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:54:58] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:55:00] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:55:02] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:55:04] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:55:06] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:08] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:10] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:12] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:14] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:16] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[23:55:18] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[23:55:20] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:22] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:24] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:26] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:28] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:30] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[23:55:32] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[23:55:34] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 26)
[23:55:36] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[23:55:38] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[23:55:40] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[23:55:42] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[23:55:44] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:46] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:48] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:50] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:52] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:54] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[23:55:55] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 31)
[23:55:57] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 31)
[23:55:59] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 31)
[23:56:01] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 31)
[23:56:03] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 31)
[23:56:03] Early stopping at epoch 41 (no improvement for 10 epochs)
[23:56:04] Factor 13 done — best val loss: 0.000001 at epoch 31
[23:56:04] 
============================================================
[23:56:04] STF Factor 14 of [6..24]
[23:56:04] ============================================================
[23:56:05] Building features: 0% (1/175846)
[23:56:05] Building features: 5% (8793/175846)
[23:56:06] Building features: 10% (17585/175846)
[23:56:06] Building features: 15% (26377/175846)
[23:56:07] Building features: 20% (35169/175846)
[23:56:07] Building features: 25% (43961/175846)
[23:56:08] Building features: 30% (52753/175846)
[23:56:08] Building features: 35% (61545/175846)
[23:56:09] Building features: 40% (70337/175846)
[23:56:09] Building features: 45% (79129/175846)
[23:56:10] Building features: 50% (87921/175846)
[23:56:10] Building features: 55% (96713/175846)
[23:56:11] Building features: 60% (105505/175846)
[23:56:11] Building features: 65% (114297/175846)
[23:56:12] Building features: 70% (123089/175846)
[23:56:12] Building features: 75% (131881/175846)
[23:56:13] Building features: 80% (140673/175846)
[23:56:13] Building features: 85% (149465/175846)
[23:56:14] Building features: 90% (158257/175846)
[23:56:14] Building features: 95% (167049/175846)
[23:56:15] Building features: 100% (175841/175846)
[23:56:15] Computing Hurst exponent...
[23:56:20] Computing market regimes (GMM)...
[23:56:26] Factor 14: 175724 samples, 92 features
[23:56:26] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:56:32] Epoch 1/100 | Train: 0.000103 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:56:34] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:56:36] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:56:38] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:56:40] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:56:42] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:56:44] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:56:46] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:56:48] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:56:50] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:56:52] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:56:54] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:56:56] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:56:58] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[23:57:00] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 9)
[23:57:02] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 16)
[23:57:04] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 16)
[23:57:06] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:08] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:10] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:12] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:14] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:16] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[23:57:18] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 18)
[23:57:20] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 18)
[23:57:22] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 18)
[23:57:24] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[23:57:25] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 28)
[23:57:27] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 28)
[23:57:29] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 28)
[23:57:31] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 28)
[23:57:33] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 28)
[23:57:35] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 33)
[23:57:37] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 33)
[23:57:39] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 33)
[23:57:41] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 33)
[23:57:43] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:45] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:47] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:49] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:51] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:53] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 37)
[23:57:55] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:57:57] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:57:59] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:58:01] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:58:03] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:58:05] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 43)
[23:58:07] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[23:58:09] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[23:58:11] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[23:58:13] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[23:58:15] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[23:58:15] Early stopping at epoch 53 (no improvement for 10 epochs)
[23:58:16] Factor 14 done — best val loss: 0.000001 at epoch 43
[23:58:16] 
============================================================
[23:58:16] STF Factor 15 of [6..24]
[23:58:16] ============================================================
[23:58:16] Building features: 0% (1/175846)
[23:58:17] Building features: 5% (8793/175846)
[23:58:17] Building features: 10% (17585/175846)
[23:58:18] Building features: 15% (26377/175846)
[23:58:18] Building features: 20% (35169/175846)
[23:58:19] Building features: 25% (43961/175846)
[23:58:19] Building features: 30% (52753/175846)
[23:58:20] Building features: 35% (61545/175846)
[23:58:20] Building features: 40% (70337/175846)
[23:58:21] Building features: 45% (79129/175846)
[23:58:21] Building features: 50% (87921/175846)
[23:58:22] Building features: 55% (96713/175846)
[23:58:22] Building features: 60% (105505/175846)
[23:58:23] Building features: 65% (114297/175846)
[23:58:23] Building features: 70% (123089/175846)
[23:58:24] Building features: 75% (131881/175846)
[23:58:24] Building features: 80% (140673/175846)
[23:58:25] Building features: 85% (149465/175846)
[23:58:25] Building features: 90% (158257/175846)
[23:58:26] Building features: 95% (167049/175846)
[23:58:26] Building features: 100% (175841/175846)
[23:58:26] Computing Hurst exponent...
[23:58:31] Computing market regimes (GMM)...
[23:58:38] Factor 15: 175724 samples, 92 features
[23:58:38] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[23:58:44] Epoch 1/100 | Train: 0.000093 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[23:58:46] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[23:58:48] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[23:58:50] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[23:58:52] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[23:58:53] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[23:58:55] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[23:58:57] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:58:59] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[23:59:01] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:03] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:05] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:07] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:09] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:11] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[23:59:13] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 16)
[23:59:15] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[23:59:17] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 18)
[23:59:19] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 19)
[23:59:21] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 19)
[23:59:23] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:25] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:27] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:29] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:31] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:33] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 21)
[23:59:35] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:59:37] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:59:39] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:59:41] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:59:43] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 21)
[23:59:43] Early stopping at epoch 31 (no improvement for 10 epochs)
[23:59:44] Factor 15 done — best val loss: 0.000001 at epoch 21
[23:59:44] 
============================================================
[23:59:44] STF Factor 16 of [6..24]
[23:59:44] ============================================================
[23:59:44] Building features: 0% (1/175846)
[23:59:44] Building features: 5% (8793/175846)
[23:59:45] Building features: 10% (17585/175846)
[23:59:45] Building features: 15% (26377/175846)
[23:59:46] Building features: 20% (35169/175846)
[23:59:46] Building features: 25% (43961/175846)
[23:59:47] Building features: 30% (52753/175846)
[23:59:47] Building features: 35% (61545/175846)
[23:59:48] Building features: 40% (70337/175846)
[23:59:49] Building features: 45% (79129/175846)
[23:59:49] Building features: 50% (87921/175846)
[23:59:50] Building features: 55% (96713/175846)
[23:59:50] Building features: 60% (105505/175846)
[23:59:51] Building features: 65% (114297/175846)
[23:59:51] Building features: 70% (123089/175846)
[23:59:52] Building features: 75% (131881/175846)
[23:59:52] Building features: 80% (140673/175846)
[23:59:53] Building features: 85% (149465/175846)
[23:59:53] Building features: 90% (158257/175846)
[23:59:54] Building features: 95% (167049/175846)
[23:59:54] Building features: 100% (175841/175846)
[23:59:54] Computing Hurst exponent...
[23:59:59] Computing market regimes (GMM)...
[00:00:06] Factor 16: 175724 samples, 92 features
[00:00:06] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:00:11] Epoch 1/100 | Train: 0.000085 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:00:13] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:00:15] Epoch 3/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:00:17] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:00:19] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:00:21] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:00:23] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:00:25] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:00:27] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:00:29] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[00:00:31] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:00:33] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:35] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:37] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:39] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:41] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:43] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:00:45] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[00:00:47] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[00:00:49] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[00:00:51] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[00:00:53] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:00:55] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:00:57] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:00:59] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:01:01] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:01:03] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:01:05] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 22)
[00:01:07] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:09] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:11] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:13] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:15] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:17] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 29)
[00:01:19] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:21] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:23] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:25] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:27] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:29] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 35)
[00:01:31] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 35)
[00:01:33] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 42)
[00:01:35] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[00:01:37] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[00:01:39] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[00:01:41] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[00:01:43] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 43)
[00:01:45] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:47] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:49] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:51] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:53] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:55] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 48)
[00:01:57] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 48)
[00:01:59] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 48)
[00:02:01] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 48)
[00:02:03] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 48)
[00:02:05] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 48)
[00:02:05] Early stopping at epoch 58 (no improvement for 10 epochs)
[00:02:06] Factor 16 done — best val loss: 0.000001 at epoch 48
[00:02:06] 
============================================================
[00:02:06] STF Factor 17 of [6..24]
[00:02:06] ============================================================
[00:02:06] Building features: 0% (1/175846)
[00:02:07] Building features: 5% (8793/175846)
[00:02:07] Building features: 10% (17585/175846)
[00:02:08] Building features: 15% (26377/175846)
[00:02:08] Building features: 20% (35169/175846)
[00:02:09] Building features: 25% (43961/175846)
[00:02:09] Building features: 30% (52753/175846)
[00:02:10] Building features: 35% (61545/175846)
[00:02:10] Building features: 40% (70337/175846)
[00:02:11] Building features: 45% (79129/175846)
[00:02:11] Building features: 50% (87921/175846)
[00:02:11] Building features: 55% (96713/175846)
[00:02:12] Building features: 60% (105505/175846)
[00:02:12] Building features: 65% (114297/175846)
[00:02:13] Building features: 70% (123089/175846)
[00:02:13] Building features: 75% (131881/175846)
[00:02:14] Building features: 80% (140673/175846)
[00:02:14] Building features: 85% (149465/175846)
[00:02:15] Building features: 90% (158257/175846)
[00:02:15] Building features: 95% (167049/175846)
[00:02:16] Building features: 100% (175841/175846)
[00:02:16] Computing Hurst exponent...
[00:02:21] Computing market regimes (GMM)...
[00:02:27] Factor 17: 175724 samples, 92 features
[00:02:27] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:02:33] Epoch 1/100 | Train: 0.000083 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:02:35] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:02:37] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:02:39] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:02:41] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:02:43] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:02:45] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:02:47] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[00:02:49] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:02:51] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:02:53] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:02:55] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:02:57] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 13)
[00:02:59] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 13)
[00:03:01] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[00:03:03] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[00:03:05] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[00:03:07] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[00:03:09] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 15)
[00:03:11] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 20)
[00:03:13] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 20)
[00:03:15] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:03:17] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:03:19] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:03:21] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:03:23] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:03:25] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:03:27] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:03:29] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 29)
[00:03:31] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:33] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:35] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:37] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:39] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:41] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 30)
[00:03:43] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 30)
[00:03:45] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 30)
[00:03:47] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[00:03:49] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[00:03:51] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 39)
[00:03:53] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:03:55] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:03:57] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:03:59] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:04:01] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:04:03] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 41)
[00:04:06] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 41)
[00:04:08] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 41)
[00:04:10] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 49)
[00:04:12] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 50)
[00:04:14] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 50)
[00:04:16] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 50)
[00:04:18] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 50)
[00:04:20] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 50)
[00:04:22] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:24] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:26] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:28] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:30] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:32] Epoch 60/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 55)
[00:04:34] Epoch 61/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 55)
[00:04:36] Epoch 62/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 55)
[00:04:38] Epoch 63/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 55)
[00:04:40] Epoch 64/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 55)
[00:04:42] Epoch 65/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 55)
[00:04:42] Early stopping at epoch 65 (no improvement for 10 epochs)
[00:04:43] Factor 17 done — best val loss: 0.000001 at epoch 55
[00:04:43] 
============================================================
[00:04:43] STF Factor 18 of [6..24]
[00:04:43] ============================================================
[00:04:43] Building features: 0% (1/175846)
[00:04:44] Building features: 5% (8793/175846)
[00:04:44] Building features: 10% (17585/175846)
[00:04:45] Building features: 15% (26377/175846)
[00:04:45] Building features: 20% (35169/175846)
[00:04:46] Building features: 25% (43961/175846)
[00:04:46] Building features: 30% (52753/175846)
[00:04:47] Building features: 35% (61545/175846)
[00:04:47] Building features: 40% (70337/175846)
[00:04:48] Building features: 45% (79129/175846)
[00:04:48] Building features: 50% (87921/175846)
[00:04:49] Building features: 55% (96713/175846)
[00:04:49] Building features: 60% (105505/175846)
[00:04:50] Building features: 65% (114297/175846)
[00:04:50] Building features: 70% (123089/175846)
[00:04:51] Building features: 75% (131881/175846)
[00:04:51] Building features: 80% (140673/175846)
[00:04:52] Building features: 85% (149465/175846)
[00:04:52] Building features: 90% (158257/175846)
[00:04:53] Building features: 95% (167049/175846)
[00:04:53] Building features: 100% (175841/175846)
[00:04:53] Computing Hurst exponent...
[00:04:58] Computing market regimes (GMM)...
[00:05:05] Factor 18: 175724 samples, 92 features
[00:05:05] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:05:11] Epoch 1/100 | Train: 0.000096 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:05:12] Epoch 2/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:05:14] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:05:16] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:05:18] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:05:20] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:05:22] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:05:24] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:05:26] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:05:28] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:05:30] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:05:32] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:05:34] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:05:36] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 14)
[00:05:38] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 14)
[00:05:40] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 14)
[00:05:42] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:44] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:46] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:48] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:50] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:52] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:05:54] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[00:05:56] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 24)
[00:05:58] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:06:00] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:06:02] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:04] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:06] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:08] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:10] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:12] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 27)
[00:06:14] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[00:06:16] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[00:06:18] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[00:06:20] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[00:06:22] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 27)
[00:06:22] Early stopping at epoch 37 (no improvement for 10 epochs)
[00:06:23] Factor 18 done — best val loss: 0.000001 at epoch 27
[00:06:23] 
============================================================
[00:06:23] STF Factor 19 of [6..24]
[00:06:23] ============================================================
[00:06:23] Building features: 0% (1/175846)
[00:06:23] Building features: 5% (8793/175846)
[00:06:24] Building features: 10% (17585/175846)
[00:06:24] Building features: 15% (26377/175846)
[00:06:25] Building features: 20% (35169/175846)
[00:06:25] Building features: 25% (43961/175846)
[00:06:26] Building features: 30% (52753/175846)
[00:06:26] Building features: 35% (61545/175846)
[00:06:27] Building features: 40% (70337/175846)
[00:06:27] Building features: 45% (79129/175846)
[00:06:28] Building features: 50% (87921/175846)
[00:06:28] Building features: 55% (96713/175846)
[00:06:29] Building features: 60% (105505/175846)
[00:06:29] Building features: 65% (114297/175846)
[00:06:30] Building features: 70% (123089/175846)
[00:06:31] Building features: 75% (131881/175846)
[00:06:31] Building features: 80% (140673/175846)
[00:06:32] Building features: 85% (149465/175846)
[00:06:32] Building features: 90% (158257/175846)
[00:06:33] Building features: 95% (167049/175846)
[00:06:33] Building features: 100% (175841/175846)
[00:06:33] Computing Hurst exponent...
[00:06:38] Computing market regimes (GMM)...
[00:06:45] Factor 19: 175724 samples, 92 features
[00:06:45] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:06:50] Epoch 1/100 | Train: 0.000094 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:06:52] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:06:54] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:06:56] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:06:58] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:07:00] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:07:02] Epoch 7/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:04] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:06] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:08] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:10] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:12] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:07:14] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 7)
[00:07:16] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 14)
[00:07:18] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 14)
[00:07:20] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 14)
[00:07:22] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[00:07:24] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 17)
[00:07:26] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:07:28] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:07:30] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:07:32] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:07:34] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 23)
[00:07:36] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 24)
[00:07:38] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:40] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:42] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:44] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:46] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:48] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 25)
[00:07:50] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:07:52] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:07:54] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:07:56] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:07:58] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:08:00] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 31)
[00:08:02] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 31)
[00:08:03] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[00:08:05] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[00:08:07] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[00:08:09] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 38)
[00:08:11] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[00:08:13] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[00:08:15] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[00:08:17] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[00:08:19] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 42)
[00:08:21] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:23] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:25] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:27] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:29] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:31] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 47)
[00:08:33] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 47)
[00:08:35] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 54)
[00:08:37] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 54)
[00:08:39] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 54)
[00:08:41] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 54)
[00:08:43] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 54)
[00:08:45] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:47] Epoch 60/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:49] Epoch 61/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:51] Epoch 62/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:53] Epoch 63/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:55] Epoch 64/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.25e-04 | Best: 0.000001 (ep 59)
[00:08:57] Epoch 65/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 59)
[00:08:59] Epoch 66/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 59)
[00:09:01] Epoch 67/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 59)
[00:09:03] Epoch 68/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 59)
[00:09:05] Epoch 69/100 | Train: 0.000000 | Val: 0.000001 | LR: 6.25e-05 | Best: 0.000001 (ep 59)
[00:09:05] Early stopping at epoch 69 (no improvement for 10 epochs)
[00:09:06] Factor 19 done — best val loss: 0.000001 at epoch 59
[00:09:06] 
============================================================
[00:09:06] STF Factor 20 of [6..24]
[00:09:06] ============================================================
[00:09:06] Building features: 0% (1/175846)
[00:09:07] Building features: 5% (8793/175846)
[00:09:07] Building features: 10% (17585/175846)
[00:09:08] Building features: 15% (26377/175846)
[00:09:08] Building features: 20% (35169/175846)
[00:09:09] Building features: 25% (43961/175846)
[00:09:09] Building features: 30% (52753/175846)
[00:09:10] Building features: 35% (61545/175846)
[00:09:10] Building features: 40% (70337/175846)
[00:09:11] Building features: 45% (79129/175846)
[00:09:11] Building features: 50% (87921/175846)
[00:09:12] Building features: 55% (96713/175846)
[00:09:12] Building features: 60% (105505/175846)
[00:09:13] Building features: 65% (114297/175846)
[00:09:13] Building features: 70% (123089/175846)
[00:09:14] Building features: 75% (131881/175846)
[00:09:14] Building features: 80% (140673/175846)
[00:09:15] Building features: 85% (149465/175846)
[00:09:15] Building features: 90% (158257/175846)
[00:09:16] Building features: 95% (167049/175846)
[00:09:16] Building features: 100% (175841/175846)
[00:09:16] Computing Hurst exponent...
[00:09:21] Computing market regimes (GMM)...
[00:09:28] Factor 20: 175724 samples, 92 features
[00:09:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:09:34] Epoch 1/100 | Train: 0.000109 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:09:36] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:09:37] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:09:39] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:09:41] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:09:43] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:09:45] Epoch 7/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:09:47] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:09:49] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:09:51] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:09:53] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:09:55] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:09:57] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:09:59] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:10:01] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:10:03] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 16)
[00:10:05] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:10:07] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:10:09] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:10:11] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:10:13] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 17)
[00:10:15] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:17] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:19] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:21] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:23] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:25] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 22)
[00:10:27] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:10:29] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:10:31] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:10:33] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:10:35] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 22)
[00:10:35] Early stopping at epoch 32 (no improvement for 10 epochs)
[00:10:36] Factor 20 done — best val loss: 0.000001 at epoch 22
[00:10:36] 
============================================================
[00:10:36] STF Factor 21 of [6..24]
[00:10:36] ============================================================
[00:10:36] Building features: 0% (1/175846)
[00:10:36] Building features: 5% (8793/175846)
[00:10:37] Building features: 10% (17585/175846)
[00:10:38] Building features: 15% (26377/175846)
[00:10:38] Building features: 20% (35169/175846)
[00:10:39] Building features: 25% (43961/175846)
[00:10:39] Building features: 30% (52753/175846)
[00:10:40] Building features: 35% (61545/175846)
[00:10:40] Building features: 40% (70337/175846)
[00:10:41] Building features: 45% (79129/175846)
[00:10:41] Building features: 50% (87921/175846)
[00:10:42] Building features: 55% (96713/175846)
[00:10:42] Building features: 60% (105505/175846)
[00:10:43] Building features: 65% (114297/175846)
[00:10:43] Building features: 70% (123089/175846)
[00:10:44] Building features: 75% (131881/175846)
[00:10:44] Building features: 80% (140673/175846)
[00:10:45] Building features: 85% (149465/175846)
[00:10:45] Building features: 90% (158257/175846)
[00:10:46] Building features: 95% (167049/175846)
[00:10:46] Building features: 100% (175841/175846)
[00:10:46] Computing Hurst exponent...
[00:10:51] Computing market regimes (GMM)...
[00:10:58] Factor 21: 175724 samples, 92 features
[00:10:58] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:11:03] Epoch 1/100 | Train: 0.000113 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:11:05] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:11:07] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:11:09] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:11:11] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:11:13] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:11:15] Epoch 7/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:11:17] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:11:19] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:11:21] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:11:23] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:11:25] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:27] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:29] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:31] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:33] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:35] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 12)
[00:11:37] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 12)
[00:11:39] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:41] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:43] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:45] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:47] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:49] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 19)
[00:11:51] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[00:11:53] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[00:11:55] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[00:11:57] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[00:11:59] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-04 | Best: 0.000001 (ep 19)
[00:11:59] Early stopping at epoch 29 (no improvement for 10 epochs)
[00:12:00] Factor 21 done — best val loss: 0.000001 at epoch 19
[00:12:00] 
============================================================
[00:12:00] STF Factor 22 of [6..24]
[00:12:00] ============================================================
[00:12:00] Building features: 0% (1/175846)
[00:12:01] Building features: 5% (8793/175846)
[00:12:01] Building features: 10% (17585/175846)
[00:12:02] Building features: 15% (26377/175846)
[00:12:02] Building features: 20% (35169/175846)
[00:12:03] Building features: 25% (43961/175846)
[00:12:03] Building features: 30% (52753/175846)
[00:12:04] Building features: 35% (61545/175846)
[00:12:04] Building features: 40% (70337/175846)
[00:12:05] Building features: 45% (79129/175846)
[00:12:05] Building features: 50% (87921/175846)
[00:12:06] Building features: 55% (96713/175846)
[00:12:06] Building features: 60% (105505/175846)
[00:12:07] Building features: 65% (114297/175846)
[00:12:07] Building features: 70% (123089/175846)
[00:12:08] Building features: 75% (131881/175846)
[00:12:08] Building features: 80% (140673/175846)
[00:12:09] Building features: 85% (149465/175846)
[00:12:09] Building features: 90% (158257/175846)
[00:12:10] Building features: 95% (167049/175846)
[00:12:10] Building features: 100% (175841/175846)
[00:12:10] Computing Hurst exponent...
[00:12:15] Computing market regimes (GMM)...
[00:12:22] Factor 22: 175724 samples, 92 features
[00:12:22] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:12:28] Epoch 1/100 | Train: 0.000120 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:12:30] Epoch 2/100 | Train: 0.000006 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:12:32] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:12:34] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:12:36] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:12:37] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:12:39] Epoch 7/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:12:41] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[00:12:44] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 8)
[00:12:46] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[00:12:48] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:50] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:52] Epoch 13/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:54] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:56] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:58] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:12:59] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 11)
[00:13:01] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[00:13:03] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 18)
[00:13:04] Stop requested...
[00:13:05] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-04 | Best: 0.000001 (ep 20)
[00:13:05] Training stopped by user.
[00:13:05] Factor 22 done — best val loss: 0.000001 at epoch 20
[00:13:05] 
Best factor: 19 (val loss 0.000001)
[00:13:05] Training done. Best factor=19, val_loss=0.000001
[00:13:14] Training started.
[00:13:14] 
============================================================
[00:13:14] STF Factor 6 of [6..24]
[00:13:14] ============================================================
[00:13:15] Building features: 0% (1/175846)
[00:13:15] Building features: 5% (8793/175846)
[00:13:16] Building features: 10% (17585/175846)
[00:13:16] Building features: 15% (26377/175846)
[00:13:17] Building features: 20% (35169/175846)
[00:13:17] Building features: 25% (43961/175846)
[00:13:18] Building features: 30% (52753/175846)
[00:13:18] Building features: 35% (61545/175846)
[00:13:19] Building features: 40% (70337/175846)
[00:13:19] Building features: 45% (79129/175846)
[00:13:20] Building features: 50% (87921/175846)
[00:13:20] Building features: 55% (96713/175846)
[00:13:21] Building features: 60% (105505/175846)
[00:13:21] Building features: 65% (114297/175846)
[00:13:22] Building features: 70% (123089/175846)
[00:13:22] Building features: 75% (131881/175846)
[00:13:23] Building features: 80% (140673/175846)
[00:13:23] Building features: 85% (149465/175846)
[00:13:24] Building features: 90% (158257/175846)
[00:13:24] Building features: 95% (167049/175846)
[00:13:25] Building features: 100% (175841/175846)
[00:13:25] Computing Hurst exponent...
[00:13:30] Computing market regimes (GMM)...
[00:13:37] Factor 6: 175724 samples, 92 features
[00:13:37] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:13:42] Epoch 1/100 | Train: 0.000337 | Val: 0.000025 | LR: 2.00e-04 | Best: 0.000025 (ep 1)
[00:13:44] Epoch 2/100 | Train: 0.000040 | Val: 0.000004 | LR: 2.00e-04 | Best: 0.000004 (ep 2)
[00:13:46] Epoch 3/100 | Train: 0.000017 | Val: 0.000002 | LR: 2.00e-04 | Best: 0.000002 (ep 3)
[00:13:48] Epoch 4/100 | Train: 0.000009 | Val: 0.000002 | LR: 2.00e-04 | Best: 0.000002 (ep 4)
[00:13:50] Epoch 5/100 | Train: 0.000005 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 5)
[00:13:52] Epoch 6/100 | Train: 0.000003 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 6)
[00:13:54] Epoch 7/100 | Train: 0.000002 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 7)
[00:13:56] Epoch 8/100 | Train: 0.000002 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 8)
[00:13:58] Epoch 9/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 9)
[00:14:00] Epoch 10/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 10)
[00:14:02] Epoch 11/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 11)
[00:14:03] Epoch 12/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 12)
[00:14:05] Epoch 13/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 13)
[00:14:07] Epoch 14/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 13)
[00:14:09] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 15)
[00:14:10] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 15)
[00:14:12] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 17)
[00:14:14] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 18)
[00:14:15] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:14:17] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:14:19] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:14:20] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:22] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:24] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:26] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:28] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:30] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 22)
[00:14:32] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 28)
[00:14:34] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 28)
[00:14:36] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 28)
[00:14:38] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 31)
[00:14:40] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 31)
[00:14:42] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 33)
[00:14:44] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 33)
[00:14:46] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 33)
[00:14:48] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:14:50] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:14:52] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:14:54] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:14:56] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:14:58] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 36)
[00:15:00] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 36)
[00:15:02] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:15:04] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:15:06] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:15:08] Epoch 46/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 46)
[00:15:10] Epoch 47/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 46)
[00:15:12] Epoch 48/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 48)
[00:15:14] Epoch 49/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 48)
[00:15:16] Epoch 50/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 48)
[00:15:18] Epoch 51/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 48)
[00:15:20] Epoch 52/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 52)
[00:15:22] Epoch 53/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:24] Epoch 54/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:26] Epoch 55/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:28] Epoch 56/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:30] Epoch 57/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:32] Epoch 58/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 53)
[00:15:34] Epoch 59/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 53)
[00:15:36] Epoch 60/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 53)
[00:15:38] Epoch 61/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:40] Epoch 62/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:42] Epoch 63/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:43] Epoch 64/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:45] Epoch 65/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:47] Epoch 66/100 | Train: 0.000000 | Val: 0.000001 | LR: 5.00e-05 | Best: 0.000001 (ep 61)
[00:15:49] Epoch 67/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-05 | Best: 0.000001 (ep 61)
[00:15:51] Epoch 68/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-05 | Best: 0.000001 (ep 61)
[00:15:53] Epoch 69/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-05 | Best: 0.000001 (ep 61)
[00:15:55] Epoch 70/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-05 | Best: 0.000001 (ep 61)
[00:15:57] Epoch 71/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.50e-05 | Best: 0.000001 (ep 61)
[00:15:57] Early stopping at epoch 71 (no improvement for 10 epochs)
[00:15:58] Factor 6 done — best val loss: 0.000001 at epoch 61
[00:15:58] 
============================================================
[00:15:58] STF Factor 7 of [6..24]
[00:15:58] ============================================================
[00:15:58] Building features: 0% (1/175846)
[00:15:59] Building features: 5% (8793/175846)
[00:15:59] Building features: 10% (17585/175846)
[00:16:00] Building features: 15% (26377/175846)
[00:16:01] Building features: 20% (35169/175846)
[00:16:01] Building features: 25% (43961/175846)
[00:16:02] Building features: 30% (52753/175846)
[00:16:02] Building features: 35% (61545/175846)
[00:16:03] Building features: 40% (70337/175846)
[00:16:03] Building features: 45% (79129/175846)
[00:16:04] Building features: 50% (87921/175846)
[00:16:04] Building features: 55% (96713/175846)
[00:16:05] Building features: 60% (105505/175846)
[00:16:05] Building features: 65% (114297/175846)
[00:16:06] Building features: 70% (123089/175846)
[00:16:06] Building features: 75% (131881/175846)
[00:16:07] Building features: 80% (140673/175846)
[00:16:07] Building features: 85% (149465/175846)
[00:16:08] Building features: 90% (158257/175846)
[00:16:08] Building features: 95% (167049/175846)
[00:16:09] Building features: 100% (175841/175846)
[00:16:09] Computing Hurst exponent...
[00:16:14] Computing market regimes (GMM)...
[00:16:21] Factor 7: 175724 samples, 92 features
[00:16:21] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:16:27] Epoch 1/100 | Train: 0.000269 | Val: 0.000005 | LR: 2.00e-04 | Best: 0.000005 (ep 1)
[00:16:29] Epoch 2/100 | Train: 0.000032 | Val: 0.000002 | LR: 2.00e-04 | Best: 0.000002 (ep 2)
[00:16:31] Epoch 3/100 | Train: 0.000013 | Val: 0.000002 | LR: 2.00e-04 | Best: 0.000002 (ep 3)
[00:16:33] Epoch 4/100 | Train: 0.000007 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 4)
[00:16:35] Epoch 5/100 | Train: 0.000004 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 5)
[00:16:37] Epoch 6/100 | Train: 0.000003 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 6)
[00:16:38] Epoch 7/100 | Train: 0.000002 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 7)
[00:16:40] Epoch 8/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 8)
[00:16:42] Epoch 9/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 9)
[00:16:44] Epoch 10/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 10)
[00:16:46] Epoch 11/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 11)
[00:16:48] Epoch 12/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 12)
[00:16:50] Epoch 13/100 | Train: 0.000001 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 13)
[00:16:52] Epoch 14/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 14)
[00:16:54] Epoch 15/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 15)
[00:16:56] Epoch 16/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 16)
[00:16:58] Epoch 17/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 17)
[00:17:00] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 17)
[00:17:02] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:04] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:06] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:08] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:10] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:12] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 2.00e-04 | Best: 0.000001 (ep 19)
[00:17:14] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 19)
[00:17:16] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 26)
[00:17:18] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 27)
[00:17:20] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 27)
[00:17:21] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 29)
[00:17:23] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 29)
[00:17:25] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 31)
[00:17:27] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 31)
[00:17:29] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:31] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:33] Epoch 35/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:35] Epoch 36/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:37] Epoch 37/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:39] Epoch 38/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 33)
[00:17:41] Epoch 39/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 39)
[00:17:43] Epoch 40/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 39)
[00:17:45] Epoch 41/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 39)
[00:17:47] Epoch 42/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 39)
[00:17:49] Epoch 43/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:17:50] Epoch 44/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:17:52] Stop requested...
[00:17:52] Epoch 45/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 43)
[00:17:52] Training stopped by user.
[00:17:53] Factor 7 done — best val loss: 0.000001 at epoch 43
[00:17:53] 
Best factor: 6 (val loss 0.000001)
[00:17:53] Training done. Best factor=6, val_loss=0.000001
[00:17:57] Training started.
[00:17:57] 
============================================================
[00:17:57] STF Factor 6 of [6..24]
[00:17:57] ============================================================
[00:17:58] Building features: 0% (1/175846)
[00:17:58] Building features: 5% (8793/175846)
[00:17:59] Building features: 10% (17585/175846)
[00:17:59] Building features: 15% (26377/175846)
[00:18:00] Building features: 20% (35169/175846)
[00:18:00] Building features: 25% (43961/175846)
[00:18:01] Building features: 30% (52753/175846)
[00:18:01] Building features: 35% (61545/175846)
[00:18:02] Building features: 40% (70337/175846)
[00:18:02] Building features: 45% (79129/175846)
[00:18:03] Building features: 50% (87921/175846)
[00:18:03] Building features: 55% (96713/175846)
[00:18:04] Building features: 60% (105505/175846)
[00:18:05] Building features: 65% (114297/175846)
[00:18:05] Building features: 70% (123089/175846)
[00:18:06] Building features: 75% (131881/175846)
[00:18:06] Building features: 80% (140673/175846)
[00:18:07] Building features: 85% (149465/175846)
[00:18:07] Building features: 90% (158257/175846)
[00:18:08] Building features: 95% (167049/175846)
[00:18:08] Building features: 100% (175841/175846)
[00:18:08] Computing Hurst exponent...
[00:18:14] Computing market regimes (GMM)...
[00:18:20] Factor 6: 175724 samples, 92 features
[00:18:20] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:18:26] Epoch 1/100 | Train: 0.000521 | Val: 0.000034 | LR: 1.00e-04 | Best: 0.000034 (ep 1)
[00:18:28] Epoch 2/100 | Train: 0.000092 | Val: 0.000010 | LR: 1.00e-04 | Best: 0.000010 (ep 2)
[00:18:30] Epoch 3/100 | Train: 0.000045 | Val: 0.000004 | LR: 1.00e-04 | Best: 0.000004 (ep 3)
[00:18:31] Epoch 4/100 | Train: 0.000025 | Val: 0.000002 | LR: 1.00e-04 | Best: 0.000002 (ep 4)
[00:18:33] Epoch 5/100 | Train: 0.000016 | Val: 0.000002 | LR: 1.00e-04 | Best: 0.000002 (ep 5)
[00:18:35] Epoch 6/100 | Train: 0.000010 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 6)
[00:18:37] Epoch 7/100 | Train: 0.000007 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 7)
[00:18:39] Epoch 8/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 8)
[00:18:41] Epoch 9/100 | Train: 0.000003 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 9)
[00:18:43] Epoch 10/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 10)
[00:18:45] Epoch 11/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 11)
[00:18:47] Epoch 12/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 12)
[00:18:49] Epoch 13/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 13)
[00:18:51] Epoch 14/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 13)
[00:18:53] Epoch 15/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 15)
[00:18:55] Epoch 16/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 16)
[00:18:57] Epoch 17/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 17)
[00:18:59] Epoch 18/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 18)
[00:19:01] Epoch 19/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 19)
[00:19:03] Epoch 20/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 19)
[00:19:05] Epoch 21/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 19)
[00:19:06] Epoch 22/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 22)
[00:19:08] Epoch 23/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 22)
[00:19:10] Epoch 24/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 22)
[00:19:12] Epoch 25/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 25)
[00:19:14] Epoch 26/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 25)
[00:19:16] Epoch 27/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 25)
[00:19:18] Epoch 28/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 25)
[00:19:20] Epoch 29/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 29)
[00:19:22] Epoch 30/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 29)
[00:19:25] Epoch 31/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 29)
[00:19:26] Epoch 32/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 32)
[00:19:28] Epoch 33/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 32)
[00:19:29] Stop requested...
[00:19:30] Epoch 34/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-04 | Best: 0.000001 (ep 32)
[00:19:30] Training stopped by user.
[00:19:31] Factor 6 done — best val loss: 0.000001 at epoch 32
[00:19:31] 
Best factor: 6 (val loss 0.000001)
[00:19:31] Training done. Best factor=6, val_loss=0.000001
[00:19:34] Training started.
[00:19:34] 
============================================================
[00:19:34] STF Factor 6 of [6..24]
[00:19:34] ============================================================
[00:19:34] Building features: 0% (1/175846)
[00:19:34] Building features: 5% (8793/175846)
[00:19:35] Building features: 10% (17585/175846)
[00:19:35] Building features: 15% (26377/175846)
[00:19:36] Building features: 20% (35169/175846)
[00:19:36] Building features: 25% (43961/175846)
[00:19:37] Building features: 30% (52753/175846)
[00:19:37] Building features: 35% (61545/175846)
[00:19:38] Building features: 40% (70337/175846)
[00:19:38] Building features: 45% (79129/175846)
[00:19:39] Building features: 50% (87921/175846)
[00:19:39] Building features: 55% (96713/175846)
[00:19:39] Building features: 60% (105505/175846)
[00:19:40] Building features: 65% (114297/175846)
[00:19:40] Building features: 70% (123089/175846)
[00:19:41] Building features: 75% (131881/175846)
[00:19:41] Building features: 80% (140673/175846)
[00:19:42] Building features: 85% (149465/175846)
[00:19:42] Building features: 90% (158257/175846)
[00:19:43] Building features: 95% (167049/175846)
[00:19:44] Building features: 100% (175841/175846)
[00:19:44] Computing Hurst exponent...
[00:19:49] Computing market regimes (GMM)...
[00:19:56] Factor 6: 175724 samples, 92 features
[00:19:56] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:20:02] Epoch 1/100 | Train: 0.002115 | Val: 0.000260 | LR: 1.00e-05 | Best: 0.000260 (ep 1)
[00:20:04] Epoch 2/100 | Train: 0.000631 | Val: 0.000159 | LR: 1.00e-05 | Best: 0.000159 (ep 2)
[00:20:06] Epoch 3/100 | Train: 0.000424 | Val: 0.000124 | LR: 1.00e-05 | Best: 0.000124 (ep 3)
[00:20:07] Epoch 4/100 | Train: 0.000315 | Val: 0.000097 | LR: 1.00e-05 | Best: 0.000097 (ep 4)
[00:20:09] Epoch 5/100 | Train: 0.000242 | Val: 0.000076 | LR: 1.00e-05 | Best: 0.000076 (ep 5)
[00:20:10] Epoch 6/100 | Train: 0.000192 | Val: 0.000060 | LR: 1.00e-05 | Best: 0.000060 (ep 6)
[00:20:12] Epoch 7/100 | Train: 0.000154 | Val: 0.000046 | LR: 1.00e-05 | Best: 0.000046 (ep 7)
[00:20:14] Epoch 8/100 | Train: 0.000124 | Val: 0.000036 | LR: 1.00e-05 | Best: 0.000036 (ep 8)
[00:20:15] Epoch 9/100 | Train: 0.000100 | Val: 0.000027 | LR: 1.00e-05 | Best: 0.000027 (ep 9)
[00:20:17] Epoch 10/100 | Train: 0.000081 | Val: 0.000021 | LR: 1.00e-05 | Best: 0.000021 (ep 10)
[00:20:19] Epoch 11/100 | Train: 0.000066 | Val: 0.000016 | LR: 1.00e-05 | Best: 0.000016 (ep 11)
[00:20:20] Epoch 12/100 | Train: 0.000053 | Val: 0.000013 | LR: 1.00e-05 | Best: 0.000013 (ep 12)
[00:20:22] Epoch 13/100 | Train: 0.000043 | Val: 0.000010 | LR: 1.00e-05 | Best: 0.000010 (ep 13)
[00:20:24] Epoch 14/100 | Train: 0.000035 | Val: 0.000008 | LR: 1.00e-05 | Best: 0.000008 (ep 14)
[00:20:25] Epoch 15/100 | Train: 0.000028 | Val: 0.000006 | LR: 1.00e-05 | Best: 0.000006 (ep 15)
[00:20:27] Epoch 16/100 | Train: 0.000023 | Val: 0.000005 | LR: 1.00e-05 | Best: 0.000005 (ep 16)
[00:20:29] Epoch 17/100 | Train: 0.000019 | Val: 0.000004 | LR: 1.00e-05 | Best: 0.000004 (ep 17)
[00:20:31] Epoch 18/100 | Train: 0.000015 | Val: 0.000003 | LR: 1.00e-05 | Best: 0.000003 (ep 18)
[00:20:33] Epoch 19/100 | Train: 0.000012 | Val: 0.000003 | LR: 1.00e-05 | Best: 0.000003 (ep 19)
[00:20:35] Epoch 20/100 | Train: 0.000010 | Val: 0.000002 | LR: 1.00e-05 | Best: 0.000002 (ep 20)
[00:20:37] Epoch 21/100 | Train: 0.000008 | Val: 0.000002 | LR: 1.00e-05 | Best: 0.000002 (ep 21)
[00:20:39] Epoch 22/100 | Train: 0.000007 | Val: 0.000002 | LR: 1.00e-05 | Best: 0.000002 (ep 22)
[00:20:41] Epoch 23/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-05 | Best: 0.000001 (ep 23)
[00:20:43] Epoch 24/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-05 | Best: 0.000001 (ep 24)
[00:20:45] Epoch 25/100 | Train: 0.000004 | Val: 0.000001 | LR: 1.00e-05 | Best: 0.000001 (ep 25)
[00:20:47] Epoch 26/100 | Train: 0.000003 | Val: 0.000001 | LR: 1.00e-05 | Best: 0.000001 (ep 26)
[00:20:47] Stop requested...
[00:23:10] NTCP initialized.
[00:23:26] Loaded 175846 M5 bars.
[00:23:30] Training started.
[00:23:30] 
============================================================
[00:23:30] STF Factor 6 of [6..24]
[00:23:30] ============================================================
[00:23:30] Building features: 0% (1/175846)
[00:23:31] Building features: 5% (8793/175846)
[00:23:31] Building features: 10% (17585/175846)
[00:23:32] Building features: 15% (26377/175846)
[00:23:32] Building features: 20% (35169/175846)
[00:23:33] Building features: 25% (43961/175846)
[00:23:33] Building features: 30% (52753/175846)
[00:23:34] Building features: 35% (61545/175846)
[00:23:34] Building features: 40% (70337/175846)
[00:23:35] Building features: 45% (79129/175846)
[00:23:35] Building features: 50% (87921/175846)
[00:23:36] Building features: 55% (96713/175846)
[00:23:36] Building features: 60% (105505/175846)
[00:23:37] Building features: 65% (114297/175846)
[00:23:37] Building features: 70% (123089/175846)
[00:23:38] Building features: 75% (131881/175846)
[00:23:38] Building features: 80% (140673/175846)
[00:23:38] Building features: 85% (149465/175846)
[00:23:39] Building features: 90% (158257/175846)
[00:23:39] Building features: 95% (167049/175846)
[00:23:40] Building features: 100% (175841/175846)
[00:23:40] Computing Hurst exponent...
[00:23:46] Computing market regimes (GMM)...
[00:23:55] Factor 6: 175724 samples, 92 features
[00:23:55] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[00:24:00] Epoch 1/100 | Train: 0.000101 | Val: 0.000002 | LR: 1.00e-03 | Best: 0.000002 (ep 1)
[00:24:02] Epoch 2/100 | Train: 0.000005 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 2)
[00:24:04] Epoch 3/100 | Train: 0.000002 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 3)
[00:24:06] Epoch 4/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 4)
[00:24:07] Epoch 5/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 5)
[00:24:09] Epoch 6/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 6)
[00:24:11] Epoch 7/100 | Train: 0.000001 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:24:12] Epoch 8/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 7)
[00:24:14] Epoch 9/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 9)
[00:24:16] Epoch 10/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 10)
[00:24:18] Epoch 11/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:24:18] Stop requested...
[00:24:19] Epoch 12/100 | Train: 0.000000 | Val: 0.000001 | LR: 1.00e-03 | Best: 0.000001 (ep 11)
[00:24:19] Training stopped by user.
[00:24:20] Factor 6 done — best val loss: 0.000001 at epoch 11
[00:24:20] 
Best factor: 6 (val loss 0.000001)
[00:24:20] Training done. Best factor=6, val_loss=0.000001
[02:21:23] NTCP initialized.
[02:21:42] Loaded 175846 M5 bars.
[02:21:54] Training started.
[02:21:54] 
============================================================
[02:21:54] STF Factor 6 of [6..8]
[02:21:54] ============================================================
[02:21:55] Building features: 0% (1/175846)
[02:21:55] Building features: 5% (8793/175846)
[02:21:56] Building features: 10% (17585/175846)
[02:21:56] Building features: 15% (26377/175846)
[02:21:57] Building features: 20% (35169/175846)
[02:21:57] Building features: 25% (43961/175846)
[02:21:58] Building features: 30% (52753/175846)
[02:21:58] Building features: 35% (61545/175846)
[02:21:58] Building features: 40% (70337/175846)
[02:21:59] Building features: 45% (79129/175846)
[02:21:59] Building features: 50% (87921/175846)
[02:22:00] Building features: 55% (96713/175846)
[02:22:00] Building features: 60% (105505/175846)
[02:22:01] Building features: 65% (114297/175846)
[02:22:01] Building features: 70% (123089/175846)
[02:22:02] Building features: 75% (131881/175846)
[02:22:02] Building features: 80% (140673/175846)
[02:22:03] Building features: 85% (149465/175846)
[02:22:03] Building features: 90% (158257/175846)
[02:22:04] Building features: 95% (167049/175846)
[02:22:04] Building features: 100% (175841/175846)
[02:22:04] Computing Hurst exponent...
[02:22:09] Computing market regimes (GMM)...
[02:22:17] Factor 6: 175724 samples, 92 features
[02:22:19] Batch stats — Input:  mean=0.0544 std=0.2694 min=-4.8553 max=6.1356
[02:22:19] Batch stats — Target: mean=0.0024 std=0.0663 min=-0.4184 max=0.4134
[02:22:19] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:22:24] Epoch 1/100 | Train: 0.003886 | Val: 0.010666 | LR: 1.00e-04 | Best: 0.010666 (ep 1)
[02:22:26] Epoch 2/100 | Train: 0.003108 | Val: 0.009408 | LR: 1.00e-04 | Best: 0.009408 (ep 2)
[02:22:27] Epoch 3/100 | Train: 0.003050 | Val: 0.009191 | LR: 1.00e-04 | Best: 0.009191 (ep 3)
[02:22:29] Epoch 4/100 | Train: 0.003013 | Val: 0.009172 | LR: 1.00e-04 | Best: 0.009172 (ep 4)
[02:22:31] Epoch 5/100 | Train: 0.002985 | Val: 0.009059 | LR: 1.00e-04 | Best: 0.009059 (ep 5)
[02:22:33] Epoch 6/100 | Train: 0.002964 | Val: 0.009051 | LR: 1.00e-04 | Best: 0.009051 (ep 6)
[02:22:35] Epoch 7/100 | Train: 0.002950 | Val: 0.008951 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:37] Epoch 8/100 | Train: 0.002937 | Val: 0.009054 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:39] Epoch 9/100 | Train: 0.002930 | Val: 0.008990 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:40] Epoch 10/100 | Train: 0.002922 | Val: 0.008988 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:42] Epoch 11/100 | Train: 0.002911 | Val: 0.008994 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:44] Epoch 12/100 | Train: 0.002905 | Val: 0.009072 | LR: 1.00e-04 | Best: 0.008951 (ep 7)
[02:22:46] Epoch 13/100 | Train: 0.002899 | Val: 0.009065 | LR: 5.00e-05 | Best: 0.008951 (ep 7)
[02:22:48] Epoch 14/100 | Train: 0.002888 | Val: 0.009055 | LR: 5.00e-05 | Best: 0.008951 (ep 7)
[02:22:50] Epoch 15/100 | Train: 0.002885 | Val: 0.009151 | LR: 5.00e-05 | Best: 0.008951 (ep 7)
[02:22:52] Epoch 16/100 | Train: 0.002880 | Val: 0.009157 | LR: 5.00e-05 | Best: 0.008951 (ep 7)
[02:22:54] Epoch 17/100 | Train: 0.002879 | Val: 0.009043 | LR: 5.00e-05 | Best: 0.008951 (ep 7)
[02:22:54] Early stopping at epoch 17 (no improvement for 10 epochs)
[02:22:55] Factor 6 done — best val loss: 0.008951 at epoch 7
[02:22:55] 
============================================================
[02:22:55] STF Factor 7 of [6..8]
[02:22:55] ============================================================
[02:22:55] Building features: 0% (1/175846)
[02:22:56] Building features: 5% (8793/175846)
[02:22:56] Building features: 10% (17585/175846)
[02:22:57] Building features: 15% (26377/175846)
[02:22:57] Building features: 20% (35169/175846)
[02:22:58] Building features: 25% (43961/175846)
[02:22:58] Building features: 30% (52753/175846)
[02:22:59] Building features: 35% (61545/175846)
[02:22:59] Building features: 40% (70337/175846)
[02:23:00] Building features: 45% (79129/175846)
[02:23:00] Building features: 50% (87921/175846)
[02:23:01] Building features: 55% (96713/175846)
[02:23:01] Building features: 60% (105505/175846)
[02:23:02] Building features: 65% (114297/175846)
[02:23:02] Building features: 70% (123089/175846)
[02:23:03] Building features: 75% (131881/175846)
[02:23:03] Building features: 80% (140673/175846)
[02:23:04] Building features: 85% (149465/175846)
[02:23:05] Building features: 90% (158257/175846)
[02:23:05] Building features: 95% (167049/175846)
[02:23:06] Building features: 100% (175841/175846)
[02:23:06] Computing Hurst exponent...
[02:23:11] Computing market regimes (GMM)...
[02:23:18] Factor 7: 175724 samples, 92 features
[02:23:20] Batch stats — Input:  mean=0.0528 std=0.2687 min=-3.8209 max=22.9822
[02:23:20] Batch stats — Target: mean=0.0048 std=0.0652 min=-0.4720 max=0.4134
[02:23:20] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:23:24] Epoch 1/100 | Train: 0.003927 | Val: 0.010590 | LR: 1.00e-04 | Best: 0.010590 (ep 1)
[02:23:26] Epoch 2/100 | Train: 0.003113 | Val: 0.009582 | LR: 1.00e-04 | Best: 0.009582 (ep 2)
[02:23:28] Epoch 3/100 | Train: 0.003054 | Val: 0.009350 | LR: 1.00e-04 | Best: 0.009350 (ep 3)
[02:23:30] Epoch 4/100 | Train: 0.003018 | Val: 0.009178 | LR: 1.00e-04 | Best: 0.009178 (ep 4)
[02:23:33] Epoch 5/100 | Train: 0.002988 | Val: 0.009284 | LR: 1.00e-04 | Best: 0.009178 (ep 4)
[02:23:35] Epoch 6/100 | Train: 0.002968 | Val: 0.009095 | LR: 1.00e-04 | Best: 0.009095 (ep 6)
[02:23:37] Epoch 7/100 | Train: 0.002952 | Val: 0.009231 | LR: 1.00e-04 | Best: 0.009095 (ep 6)
[02:23:39] Epoch 8/100 | Train: 0.002941 | Val: 0.009021 | LR: 1.00e-04 | Best: 0.009021 (ep 8)
[02:23:41] Epoch 9/100 | Train: 0.002930 | Val: 0.009002 | LR: 1.00e-04 | Best: 0.009002 (ep 9)
[02:23:44] Epoch 10/100 | Train: 0.002918 | Val: 0.009060 | LR: 1.00e-04 | Best: 0.009002 (ep 9)
[02:23:46] Epoch 11/100 | Train: 0.002914 | Val: 0.008914 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:48] Epoch 12/100 | Train: 0.002906 | Val: 0.009037 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:50] Epoch 13/100 | Train: 0.002901 | Val: 0.009015 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:52] Epoch 14/100 | Train: 0.002894 | Val: 0.008994 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:54] Epoch 15/100 | Train: 0.002886 | Val: 0.009173 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:57] Epoch 16/100 | Train: 0.002884 | Val: 0.009072 | LR: 1.00e-04 | Best: 0.008914 (ep 11)
[02:23:59] Epoch 17/100 | Train: 0.002881 | Val: 0.009359 | LR: 5.00e-05 | Best: 0.008914 (ep 11)
[02:24:01] Epoch 18/100 | Train: 0.002868 | Val: 0.009289 | LR: 5.00e-05 | Best: 0.008914 (ep 11)
[02:24:03] Epoch 19/100 | Train: 0.002866 | Val: 0.009214 | LR: 5.00e-05 | Best: 0.008914 (ep 11)
[02:24:05] Epoch 20/100 | Train: 0.002863 | Val: 0.009157 | LR: 5.00e-05 | Best: 0.008914 (ep 11)
[02:24:08] Epoch 21/100 | Train: 0.002859 | Val: 0.009262 | LR: 5.00e-05 | Best: 0.008914 (ep 11)
[02:24:08] Early stopping at epoch 21 (no improvement for 10 epochs)
[02:24:09] Factor 7 done — best val loss: 0.008914 at epoch 11
[02:24:09] 
============================================================
[02:24:09] STF Factor 8 of [6..8]
[02:24:09] ============================================================
[02:24:09] Building features: 0% (1/175846)
[02:24:09] Building features: 5% (8793/175846)
[02:24:10] Building features: 10% (17585/175846)
[02:24:10] Building features: 15% (26377/175846)
[02:24:11] Building features: 20% (35169/175846)
[02:24:11] Building features: 25% (43961/175846)
[02:24:12] Building features: 30% (52753/175846)
[02:24:12] Building features: 35% (61545/175846)
[02:24:13] Building features: 40% (70337/175846)
[02:24:13] Building features: 45% (79129/175846)
[02:24:14] Building features: 50% (87921/175846)
[02:24:14] Building features: 55% (96713/175846)
[02:24:15] Building features: 60% (105505/175846)
[02:24:15] Building features: 65% (114297/175846)
[02:24:16] Building features: 70% (123089/175846)
[02:24:16] Building features: 75% (131881/175846)
[02:24:17] Building features: 80% (140673/175846)
[02:24:17] Building features: 85% (149465/175846)
[02:24:18] Building features: 90% (158257/175846)
[02:24:18] Building features: 95% (167049/175846)
[02:24:19] Building features: 100% (175841/175846)
[02:24:19] Computing Hurst exponent...
[02:24:24] Computing market regimes (GMM)...
[02:24:31] Factor 8: 175724 samples, 92 features
[02:24:33] Batch stats — Input:  mean=0.0541 std=0.2703 min=-4.7575 max=12.2195
[02:24:33] Batch stats — Target: mean=-0.0008 std=0.0651 min=-0.4484 max=0.4134
[02:24:33] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:24:37] Epoch 1/100 | Train: 0.003657 | Val: 0.010926 | LR: 1.00e-04 | Best: 0.010926 (ep 1)
[02:24:39] Epoch 2/100 | Train: 0.003102 | Val: 0.009359 | LR: 1.00e-04 | Best: 0.009359 (ep 2)
[02:24:42] Epoch 3/100 | Train: 0.003051 | Val: 0.009195 | LR: 1.00e-04 | Best: 0.009195 (ep 3)
[02:24:44] Epoch 4/100 | Train: 0.003010 | Val: 0.009069 | LR: 1.00e-04 | Best: 0.009069 (ep 4)
[02:24:46] Epoch 5/100 | Train: 0.002983 | Val: 0.009080 | LR: 1.00e-04 | Best: 0.009069 (ep 4)
[02:24:48] Epoch 6/100 | Train: 0.002967 | Val: 0.008963 | LR: 1.00e-04 | Best: 0.008963 (ep 6)
[02:24:50] Epoch 7/100 | Train: 0.002949 | Val: 0.008940 | LR: 1.00e-04 | Best: 0.008940 (ep 7)
[02:24:53] Epoch 8/100 | Train: 0.002940 | Val: 0.008935 | LR: 1.00e-04 | Best: 0.008935 (ep 8)
[02:24:55] Epoch 9/100 | Train: 0.002931 | Val: 0.008963 | LR: 1.00e-04 | Best: 0.008935 (ep 8)
[02:24:57] Epoch 10/100 | Train: 0.002920 | Val: 0.008963 | LR: 1.00e-04 | Best: 0.008935 (ep 8)
[02:24:59] Epoch 11/100 | Train: 0.002912 | Val: 0.009021 | LR: 1.00e-04 | Best: 0.008935 (ep 8)
[02:25:01] Epoch 12/100 | Train: 0.002903 | Val: 0.008977 | LR: 1.00e-04 | Best: 0.008935 (ep 8)
[02:25:03] Epoch 13/100 | Train: 0.002895 | Val: 0.008928 | LR: 1.00e-04 | Best: 0.008928 (ep 13)
[02:25:05] Epoch 14/100 | Train: 0.002890 | Val: 0.008889 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:07] Epoch 15/100 | Train: 0.002886 | Val: 0.008955 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:09] Epoch 16/100 | Train: 0.002881 | Val: 0.009038 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:11] Epoch 17/100 | Train: 0.002872 | Val: 0.009041 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:13] Epoch 18/100 | Train: 0.002871 | Val: 0.009180 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:14] Epoch 19/100 | Train: 0.002865 | Val: 0.009074 | LR: 1.00e-04 | Best: 0.008889 (ep 14)
[02:25:16] Epoch 20/100 | Train: 0.002863 | Val: 0.009155 | LR: 5.00e-05 | Best: 0.008889 (ep 14)
[02:25:18] Epoch 21/100 | Train: 0.002852 | Val: 0.009111 | LR: 5.00e-05 | Best: 0.008889 (ep 14)
[02:25:20] Epoch 22/100 | Train: 0.002847 | Val: 0.009079 | LR: 5.00e-05 | Best: 0.008889 (ep 14)
[02:25:22] Epoch 23/100 | Train: 0.002845 | Val: 0.009080 | LR: 5.00e-05 | Best: 0.008889 (ep 14)
[02:25:24] Epoch 24/100 | Train: 0.002841 | Val: 0.009061 | LR: 5.00e-05 | Best: 0.008889 (ep 14)
[02:25:24] Early stopping at epoch 24 (no improvement for 10 epochs)
[02:25:25] Factor 8 done — best val loss: 0.008889 at epoch 14
[02:25:25] 
Best factor: 8 (val loss 0.008889)
[02:25:25] Training done. Best factor=8, val_loss=0.008889
[02:27:15] Building validation dataset...
[02:27:15] Building features: 0% (1/175846)
[02:27:16] Building features: 5% (8793/175846)
[02:27:16] Building features: 10% (17585/175846)
[02:27:17] Building features: 15% (26377/175846)
[02:27:17] Building features: 20% (35169/175846)
[02:27:18] Building features: 25% (43961/175846)
[02:27:18] Building features: 30% (52753/175846)
[02:27:19] Building features: 35% (61545/175846)
[02:27:19] Building features: 40% (70337/175846)
[02:27:20] Building features: 45% (79129/175846)
[02:27:20] Building features: 50% (87921/175846)
[02:27:21] Building features: 55% (96713/175846)
[02:27:21] Building features: 60% (105505/175846)
[02:27:22] Building features: 65% (114297/175846)
[02:27:22] Building features: 70% (123089/175846)
[02:27:23] Building features: 75% (131881/175846)
[02:27:23] Building features: 80% (140673/175846)
[02:27:24] Building features: 85% (149465/175846)
[02:27:24] Building features: 90% (158257/175846)
[02:27:25] Building features: 95% (167049/175846)
[02:27:25] Building features: 100% (175841/175846)
[02:27:25] Computing Hurst exponent...
[02:27:31] Computing market regimes (GMM)...
[02:27:37] Running backtest...
[02:27:38] Backtest complete: 27 trades, WR=44.4%, PF=0.61
[02:29:39] Training started.
[02:29:39] 
============================================================
[02:29:39] STF Factor 6 of [6..8]
[02:29:39] ============================================================
[02:29:39] Building features: 0% (1/175846)
[02:29:39] Building features: 5% (8793/175846)
[02:29:40] Building features: 10% (17585/175846)
[02:29:40] Building features: 15% (26377/175846)
[02:29:41] Building features: 20% (35169/175846)
[02:29:41] Building features: 25% (43961/175846)
[02:29:42] Building features: 30% (52753/175846)
[02:29:42] Building features: 35% (61545/175846)
[02:29:43] Building features: 40% (70337/175846)
[02:29:43] Building features: 45% (79129/175846)
[02:29:44] Building features: 50% (87921/175846)
[02:29:44] Building features: 55% (96713/175846)
[02:29:45] Building features: 60% (105505/175846)
[02:29:45] Building features: 65% (114297/175846)
[02:29:46] Building features: 70% (123089/175846)
[02:29:46] Building features: 75% (131881/175846)
[02:29:47] Building features: 80% (140673/175846)
[02:29:47] Building features: 85% (149465/175846)
[02:29:48] Building features: 90% (158257/175846)
[02:29:48] Building features: 95% (167049/175846)
[02:29:49] Building features: 100% (175841/175846)
[02:29:49] Computing Hurst exponent...
[02:29:54] Computing market regimes (GMM)...
[02:30:01] Factor 6: 175704 samples, 92 features
[02:30:03] Batch stats — Input:  mean=0.0536 std=0.2722 min=-4.0884 max=60.4783
[02:30:03] Batch stats — Target: mean=0.0040 std=0.0667 min=-0.4001 max=0.4134
[02:30:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:30:07] Epoch 1/100 | Train: 0.003585 | Val: 0.010929 | LR: 1.00e-04 | Best: 0.010929 (ep 1)
[02:30:10] Epoch 2/100 | Train: 0.003089 | Val: 0.009666 | LR: 1.00e-04 | Best: 0.009666 (ep 2)
[02:30:12] Epoch 3/100 | Train: 0.003036 | Val: 0.009210 | LR: 1.00e-04 | Best: 0.009210 (ep 3)
[02:30:14] Epoch 4/100 | Train: 0.002997 | Val: 0.009154 | LR: 1.00e-04 | Best: 0.009154 (ep 4)
[02:30:16] Epoch 5/100 | Train: 0.002971 | Val: 0.009000 | LR: 1.00e-04 | Best: 0.009000 (ep 5)
[02:30:18] Epoch 6/100 | Train: 0.002950 | Val: 0.008971 | LR: 1.00e-04 | Best: 0.008971 (ep 6)
[02:30:20] Epoch 7/100 | Train: 0.002936 | Val: 0.008908 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:22] Epoch 8/100 | Train: 0.002925 | Val: 0.008957 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:24] Epoch 9/100 | Train: 0.002916 | Val: 0.009080 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:26] Epoch 10/100 | Train: 0.002905 | Val: 0.008983 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:28] Epoch 11/100 | Train: 0.002900 | Val: 0.008988 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:30] Epoch 12/100 | Train: 0.002892 | Val: 0.008973 | LR: 1.00e-04 | Best: 0.008908 (ep 7)
[02:30:32] Epoch 13/100 | Train: 0.002887 | Val: 0.008947 | LR: 5.00e-05 | Best: 0.008908 (ep 7)
[02:30:34] Epoch 14/100 | Train: 0.002875 | Val: 0.009010 | LR: 5.00e-05 | Best: 0.008908 (ep 7)
[02:30:36] Epoch 15/100 | Train: 0.002871 | Val: 0.008997 | LR: 5.00e-05 | Best: 0.008908 (ep 7)
[02:30:38] Epoch 16/100 | Train: 0.002868 | Val: 0.008947 | LR: 5.00e-05 | Best: 0.008908 (ep 7)
[02:30:40] Epoch 17/100 | Train: 0.002868 | Val: 0.008911 | LR: 5.00e-05 | Best: 0.008908 (ep 7)
[02:30:40] Early stopping at epoch 17 (no improvement for 10 epochs)
[02:30:40] Factor 6 done — best val loss: 0.008908 at epoch 7
[02:30:40] 
============================================================
[02:30:40] STF Factor 7 of [6..8]
[02:30:40] ============================================================
[02:30:41] Building features: 0% (1/175846)
[02:30:41] Building features: 5% (8793/175846)
[02:30:41] Building features: 10% (17585/175846)
[02:30:42] Building features: 15% (26377/175846)
[02:30:42] Building features: 20% (35169/175846)
[02:30:43] Building features: 25% (43961/175846)
[02:30:43] Building features: 30% (52753/175846)
[02:30:44] Building features: 35% (61545/175846)
[02:30:44] Building features: 40% (70337/175846)
[02:30:45] Building features: 45% (79129/175846)
[02:30:45] Building features: 50% (87921/175846)
[02:30:46] Building features: 55% (96713/175846)
[02:30:46] Building features: 60% (105505/175846)
[02:30:47] Building features: 65% (114297/175846)
[02:30:47] Building features: 70% (123089/175846)
[02:30:48] Building features: 75% (131881/175846)
[02:30:48] Building features: 80% (140673/175846)
[02:30:49] Building features: 85% (149465/175846)
[02:30:49] Building features: 90% (158257/175846)
[02:30:50] Building features: 95% (167049/175846)
[02:30:50] Building features: 100% (175841/175846)
[02:30:50] Computing Hurst exponent...
[02:30:55] Computing market regimes (GMM)...
[02:31:02] Factor 7: 175704 samples, 92 features
[02:31:03] Batch stats — Input:  mean=0.0521 std=0.2680 min=-6.3561 max=9.5638
[02:31:03] Batch stats — Target: mean=-0.0007 std=0.0689 min=-0.4470 max=0.4134
[02:31:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:31:07] Epoch 1/100 | Train: 0.003727 | Val: 0.010198 | LR: 1.00e-04 | Best: 0.010198 (ep 1)
[02:31:09] Epoch 2/100 | Train: 0.003091 | Val: 0.009405 | LR: 1.00e-04 | Best: 0.009405 (ep 2)
[02:31:11] Epoch 3/100 | Train: 0.003041 | Val: 0.009293 | LR: 1.00e-04 | Best: 0.009293 (ep 3)
[02:31:13] Epoch 4/100 | Train: 0.003006 | Val: 0.009104 | LR: 1.00e-04 | Best: 0.009104 (ep 4)
[02:31:14] Epoch 5/100 | Train: 0.002977 | Val: 0.009134 | LR: 1.00e-04 | Best: 0.009104 (ep 4)
[02:31:16] Epoch 6/100 | Train: 0.002961 | Val: 0.009097 | LR: 1.00e-04 | Best: 0.009097 (ep 6)
[02:31:18] Epoch 7/100 | Train: 0.002945 | Val: 0.008984 | LR: 1.00e-04 | Best: 0.008984 (ep 7)
[02:31:20] Epoch 8/100 | Train: 0.002930 | Val: 0.008964 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:22] Epoch 9/100 | Train: 0.002923 | Val: 0.009063 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:24] Epoch 10/100 | Train: 0.002914 | Val: 0.009145 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:26] Epoch 11/100 | Train: 0.002903 | Val: 0.009090 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:28] Epoch 12/100 | Train: 0.002899 | Val: 0.009333 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:30] Epoch 13/100 | Train: 0.002892 | Val: 0.009165 | LR: 1.00e-04 | Best: 0.008964 (ep 8)
[02:31:32] Epoch 14/100 | Train: 0.002889 | Val: 0.009336 | LR: 5.00e-05 | Best: 0.008964 (ep 8)
[02:31:34] Epoch 15/100 | Train: 0.002876 | Val: 0.009225 | LR: 5.00e-05 | Best: 0.008964 (ep 8)
[02:31:36] Epoch 16/100 | Train: 0.002871 | Val: 0.009273 | LR: 5.00e-05 | Best: 0.008964 (ep 8)
[02:31:38] Epoch 17/100 | Train: 0.002870 | Val: 0.009158 | LR: 5.00e-05 | Best: 0.008964 (ep 8)
[02:31:40] Epoch 18/100 | Train: 0.002864 | Val: 0.009297 | LR: 5.00e-05 | Best: 0.008964 (ep 8)
[02:31:40] Early stopping at epoch 18 (no improvement for 10 epochs)
[02:31:41] Factor 7 done — best val loss: 0.008964 at epoch 8
[02:31:41] 
============================================================
[02:31:41] STF Factor 8 of [6..8]
[02:31:41] ============================================================
[02:31:41] Building features: 0% (1/175846)
[02:31:41] Building features: 5% (8793/175846)
[02:31:42] Building features: 10% (17585/175846)
[02:31:42] Building features: 15% (26377/175846)
[02:31:43] Building features: 20% (35169/175846)
[02:31:43] Building features: 25% (43961/175846)
[02:31:44] Building features: 30% (52753/175846)
[02:31:44] Building features: 35% (61545/175846)
[02:31:45] Building features: 40% (70337/175846)
[02:31:45] Building features: 45% (79129/175846)
[02:31:46] Building features: 50% (87921/175846)
[02:31:46] Building features: 55% (96713/175846)
[02:31:47] Building features: 60% (105505/175846)
[02:31:47] Building features: 65% (114297/175846)
[02:31:48] Building features: 70% (123089/175846)
[02:31:48] Building features: 75% (131881/175846)
[02:31:49] Building features: 80% (140673/175846)
[02:31:49] Building features: 85% (149465/175846)
[02:31:50] Building features: 90% (158257/175846)
[02:31:50] Building features: 95% (167049/175846)
[02:31:51] Building features: 100% (175841/175846)
[02:31:51] Computing Hurst exponent...
[02:31:55] Computing market regimes (GMM)...
[02:32:02] Factor 8: 175704 samples, 92 features
[02:32:03] Batch stats — Input:  mean=0.0539 std=0.2742 min=-7.0610 max=22.9822
[02:32:03] Batch stats — Target: mean=0.0004 std=0.0573 min=-0.2714 max=0.4134
[02:32:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:32:07] Epoch 1/100 | Train: 0.003816 | Val: 0.010169 | LR: 1.00e-04 | Best: 0.010169 (ep 1)
[02:32:09] Epoch 2/100 | Train: 0.003101 | Val: 0.009410 | LR: 1.00e-04 | Best: 0.009410 (ep 2)
[02:32:11] Epoch 3/100 | Train: 0.003048 | Val: 0.009258 | LR: 1.00e-04 | Best: 0.009258 (ep 3)
[02:32:13] Epoch 4/100 | Train: 0.003014 | Val: 0.009106 | LR: 1.00e-04 | Best: 0.009106 (ep 4)
[02:32:15] Epoch 5/100 | Train: 0.002984 | Val: 0.009147 | LR: 1.00e-04 | Best: 0.009106 (ep 4)
[02:32:18] Epoch 6/100 | Train: 0.002965 | Val: 0.008990 | LR: 1.00e-04 | Best: 0.008990 (ep 6)
[02:32:20] Epoch 7/100 | Train: 0.002948 | Val: 0.008934 | LR: 1.00e-04 | Best: 0.008934 (ep 7)
[02:32:22] Epoch 8/100 | Train: 0.002936 | Val: 0.008947 | LR: 1.00e-04 | Best: 0.008934 (ep 7)
[02:32:25] Epoch 9/100 | Train: 0.002925 | Val: 0.009013 | LR: 1.00e-04 | Best: 0.008934 (ep 7)
[02:32:27] Epoch 10/100 | Train: 0.002915 | Val: 0.009017 | LR: 1.00e-04 | Best: 0.008934 (ep 7)
[02:32:30] Epoch 11/100 | Train: 0.002905 | Val: 0.008968 | LR: 1.00e-04 | Best: 0.008934 (ep 7)
[02:32:32] Epoch 12/100 | Train: 0.002900 | Val: 0.008930 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:34] Epoch 13/100 | Train: 0.002895 | Val: 0.008979 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:36] Epoch 14/100 | Train: 0.002886 | Val: 0.008995 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:38] Epoch 15/100 | Train: 0.002882 | Val: 0.008962 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:40] Epoch 16/100 | Train: 0.002877 | Val: 0.009074 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:42] Epoch 17/100 | Train: 0.002872 | Val: 0.009075 | LR: 1.00e-04 | Best: 0.008930 (ep 12)
[02:32:44] Epoch 18/100 | Train: 0.002868 | Val: 0.009121 | LR: 5.00e-05 | Best: 0.008930 (ep 12)
[02:32:46] Epoch 19/100 | Train: 0.002855 | Val: 0.009311 | LR: 5.00e-05 | Best: 0.008930 (ep 12)
[02:32:48] Epoch 20/100 | Train: 0.002853 | Val: 0.009167 | LR: 5.00e-05 | Best: 0.008930 (ep 12)
[02:32:50] Epoch 21/100 | Train: 0.002852 | Val: 0.009023 | LR: 5.00e-05 | Best: 0.008930 (ep 12)
[02:32:52] Epoch 22/100 | Train: 0.002851 | Val: 0.009131 | LR: 5.00e-05 | Best: 0.008930 (ep 12)
[02:32:52] Early stopping at epoch 22 (no improvement for 10 epochs)
[02:32:53] Factor 8 done — best val loss: 0.008930 at epoch 12
[02:32:53] 
Best factor: 6 (val loss 0.008908)
[02:32:53] Training done. Best factor=6, val_loss=0.008908
[02:33:14] Building validation dataset...
[02:33:15] Building features: 0% (1/175846)
[02:33:15] Building features: 5% (8793/175846)
[02:33:16] Building features: 10% (17585/175846)
[02:33:16] Building features: 15% (26377/175846)
[02:33:16] Building features: 20% (35169/175846)
[02:33:17] Building features: 25% (43961/175846)
[02:33:17] Building features: 30% (52753/175846)
[02:33:18] Building features: 35% (61545/175846)
[02:33:18] Building features: 40% (70337/175846)
[02:33:19] Building features: 45% (79129/175846)
[02:33:19] Building features: 50% (87921/175846)
[02:33:20] Building features: 55% (96713/175846)
[02:33:20] Building features: 60% (105505/175846)
[02:33:21] Building features: 65% (114297/175846)
[02:33:21] Building features: 70% (123089/175846)
[02:33:22] Building features: 75% (131881/175846)
[02:33:23] Building features: 80% (140673/175846)
[02:33:23] Building features: 85% (149465/175846)
[02:33:24] Building features: 90% (158257/175846)
[02:33:24] Building features: 95% (167049/175846)
[02:33:25] Building features: 100% (175841/175846)
[02:33:25] Computing Hurst exponent...
[02:33:30] Computing market regimes (GMM)...
[02:33:37] Running backtest...
[02:33:37] Backtest complete: 256 trades, WR=57.4%, PF=1.41
[02:34:28] Training started.
[02:34:28] 
============================================================
[02:34:28] STF Factor 6 of [6..8]
[02:34:28] ============================================================
[02:34:28] Building features: 0% (1/175846)
[02:34:28] Building features: 5% (8793/175846)
[02:34:29] Building features: 10% (17585/175846)
[02:34:29] Building features: 15% (26377/175846)
[02:34:30] Building features: 20% (35169/175846)
[02:34:30] Building features: 25% (43961/175846)
[02:34:31] Building features: 30% (52753/175846)
[02:34:31] Building features: 35% (61545/175846)
[02:34:32] Building features: 40% (70337/175846)
[02:34:32] Building features: 45% (79129/175846)
[02:34:33] Building features: 50% (87921/175846)
[02:34:34] Building features: 55% (96713/175846)
[02:34:34] Building features: 60% (105505/175846)
[02:34:35] Building features: 65% (114297/175846)
[02:34:35] Building features: 70% (123089/175846)
[02:34:36] Building features: 75% (131881/175846)
[02:34:36] Building features: 80% (140673/175846)
[02:34:37] Building features: 85% (149465/175846)
[02:34:37] Building features: 90% (158257/175846)
[02:34:38] Building features: 95% (167049/175846)
[02:34:38] Building features: 100% (175841/175846)
[02:34:38] Computing Hurst exponent...
[02:34:43] Computing market regimes (GMM)...
[02:34:50] Factor 6: 175644 samples, 92 features
[02:34:52] Batch stats — Input:  mean=0.0528 std=0.2690 min=-6.3561 max=10.0671
[02:34:52] Batch stats — Target: mean=0.0048 std=0.0693 min=-0.4720 max=0.4134
[02:34:52] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:34:57] Epoch 1/100 | Train: 0.003940 | Val: 0.010304 | LR: 1.00e-04 | Best: 0.010304 (ep 1)
[02:35:01] Epoch 2/100 | Train: 0.003108 | Val: 0.009364 | LR: 1.00e-04 | Best: 0.009364 (ep 2)
[02:35:04] Epoch 3/100 | Train: 0.003044 | Val: 0.009214 | LR: 1.00e-04 | Best: 0.009214 (ep 3)
[02:35:07] Epoch 4/100 | Train: 0.003008 | Val: 0.009064 | LR: 1.00e-04 | Best: 0.009064 (ep 4)
[02:35:10] Epoch 5/100 | Train: 0.002981 | Val: 0.009032 | LR: 1.00e-04 | Best: 0.009032 (ep 5)
[02:35:13] Epoch 6/100 | Train: 0.002961 | Val: 0.008968 | LR: 1.00e-04 | Best: 0.008968 (ep 6)
[02:35:16] Epoch 7/100 | Train: 0.002951 | Val: 0.008912 | LR: 1.00e-04 | Best: 0.008912 (ep 7)
[02:35:19] Epoch 8/100 | Train: 0.002939 | Val: 0.008987 | LR: 1.00e-04 | Best: 0.008912 (ep 7)
[02:35:22] Epoch 9/100 | Train: 0.002925 | Val: 0.008888 | LR: 1.00e-04 | Best: 0.008888 (ep 9)
[02:35:25] Epoch 10/100 | Train: 0.002919 | Val: 0.008873 | LR: 1.00e-04 | Best: 0.008873 (ep 10)
[02:35:28] Epoch 11/100 | Train: 0.002910 | Val: 0.008864 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:31] Epoch 12/100 | Train: 0.002908 | Val: 0.008912 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:34] Epoch 13/100 | Train: 0.002898 | Val: 0.008908 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:37] Epoch 14/100 | Train: 0.002892 | Val: 0.008883 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:40] Epoch 15/100 | Train: 0.002890 | Val: 0.008892 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:43] Epoch 16/100 | Train: 0.002881 | Val: 0.008879 | LR: 1.00e-04 | Best: 0.008864 (ep 11)
[02:35:46] Epoch 17/100 | Train: 0.002877 | Val: 0.008974 | LR: 5.00e-05 | Best: 0.008864 (ep 11)
[02:35:49] Epoch 18/100 | Train: 0.002867 | Val: 0.009004 | LR: 5.00e-05 | Best: 0.008864 (ep 11)
[02:35:52] Epoch 19/100 | Train: 0.002864 | Val: 0.009135 | LR: 5.00e-05 | Best: 0.008864 (ep 11)
[02:35:55] Epoch 20/100 | Train: 0.002860 | Val: 0.009186 | LR: 5.00e-05 | Best: 0.008864 (ep 11)
[02:35:59] Epoch 21/100 | Train: 0.002857 | Val: 0.009097 | LR: 5.00e-05 | Best: 0.008864 (ep 11)
[02:35:59] Early stopping at epoch 21 (no improvement for 10 epochs)
[02:36:00] Factor 6 done — best val loss: 0.008864 at epoch 11
[02:36:00] 
============================================================
[02:36:00] STF Factor 7 of [6..8]
[02:36:00] ============================================================
[02:36:00] Building features: 0% (1/175846)
[02:36:00] Building features: 5% (8793/175846)
[02:36:01] Building features: 10% (17585/175846)
[02:36:01] Building features: 15% (26377/175846)
[02:36:02] Building features: 20% (35169/175846)
[02:36:02] Building features: 25% (43961/175846)
[02:36:03] Building features: 30% (52753/175846)
[02:36:03] Building features: 35% (61545/175846)
[02:36:04] Building features: 40% (70337/175846)
[02:36:04] Building features: 45% (79129/175846)
[02:36:05] Building features: 50% (87921/175846)
[02:36:05] Building features: 55% (96713/175846)
[02:36:06] Building features: 60% (105505/175846)
[02:36:07] Building features: 65% (114297/175846)
[02:36:07] Building features: 70% (123089/175846)
[02:36:08] Building features: 75% (131881/175846)
[02:36:08] Building features: 80% (140673/175846)
[02:36:09] Building features: 85% (149465/175846)
[02:36:09] Building features: 90% (158257/175846)
[02:36:10] Building features: 95% (167049/175846)
[02:36:10] Building features: 100% (175841/175846)
[02:36:10] Computing Hurst exponent...
[02:36:15] Computing market regimes (GMM)...
[02:36:22] Factor 7: 175644 samples, 92 features
[02:36:24] Batch stats — Input:  mean=0.0542 std=0.2683 min=-5.5995 max=13.1528
[02:36:24] Batch stats — Target: mean=-0.0057 std=0.0730 min=-0.4720 max=0.4134
[02:36:24] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:36:29] Epoch 1/100 | Train: 0.003560 | Val: 0.011237 | LR: 1.00e-04 | Best: 0.011237 (ep 1)
[02:36:32] Epoch 2/100 | Train: 0.003082 | Val: 0.009491 | LR: 1.00e-04 | Best: 0.009491 (ep 2)
[02:36:35] Epoch 3/100 | Train: 0.003027 | Val: 0.009199 | LR: 1.00e-04 | Best: 0.009199 (ep 3)
[02:36:38] Epoch 4/100 | Train: 0.002994 | Val: 0.009096 | LR: 1.00e-04 | Best: 0.009096 (ep 4)
[02:36:41] Epoch 5/100 | Train: 0.002969 | Val: 0.008997 | LR: 1.00e-04 | Best: 0.008997 (ep 5)
[02:36:44] Epoch 6/100 | Train: 0.002953 | Val: 0.008982 | LR: 1.00e-04 | Best: 0.008982 (ep 6)
[02:36:48] Epoch 7/100 | Train: 0.002939 | Val: 0.008962 | LR: 1.00e-04 | Best: 0.008962 (ep 7)
[02:36:51] Epoch 8/100 | Train: 0.002926 | Val: 0.008897 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:36:54] Epoch 9/100 | Train: 0.002917 | Val: 0.008945 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:36:57] Epoch 10/100 | Train: 0.002905 | Val: 0.008910 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:37:00] Epoch 11/100 | Train: 0.002900 | Val: 0.009081 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:37:03] Epoch 12/100 | Train: 0.002896 | Val: 0.008920 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:37:06] Epoch 13/100 | Train: 0.002888 | Val: 0.009034 | LR: 1.00e-04 | Best: 0.008897 (ep 8)
[02:37:09] Epoch 14/100 | Train: 0.002879 | Val: 0.009040 | LR: 5.00e-05 | Best: 0.008897 (ep 8)
[02:37:12] Epoch 15/100 | Train: 0.002870 | Val: 0.009016 | LR: 5.00e-05 | Best: 0.008897 (ep 8)
[02:37:15] Epoch 16/100 | Train: 0.002864 | Val: 0.009056 | LR: 5.00e-05 | Best: 0.008897 (ep 8)
[02:37:18] Epoch 17/100 | Train: 0.002865 | Val: 0.009066 | LR: 5.00e-05 | Best: 0.008897 (ep 8)
[02:37:21] Epoch 18/100 | Train: 0.002859 | Val: 0.009028 | LR: 5.00e-05 | Best: 0.008897 (ep 8)
[02:37:21] Early stopping at epoch 18 (no improvement for 10 epochs)
[02:37:22] Factor 7 done — best val loss: 0.008897 at epoch 8
[02:37:22] 
============================================================
[02:37:22] STF Factor 8 of [6..8]
[02:37:22] ============================================================
[02:37:22] Building features: 0% (1/175846)
[02:37:22] Building features: 5% (8793/175846)
[02:37:23] Building features: 10% (17585/175846)
[02:37:23] Building features: 15% (26377/175846)
[02:37:24] Building features: 20% (35169/175846)
[02:37:24] Building features: 25% (43961/175846)
[02:37:25] Building features: 30% (52753/175846)
[02:37:26] Building features: 35% (61545/175846)
[02:37:26] Building features: 40% (70337/175846)
[02:37:27] Building features: 45% (79129/175846)
[02:37:27] Building features: 50% (87921/175846)
[02:37:28] Building features: 55% (96713/175846)
[02:37:28] Building features: 60% (105505/175846)
[02:37:29] Building features: 65% (114297/175846)
[02:37:29] Building features: 70% (123089/175846)
[02:37:30] Building features: 75% (131881/175846)
[02:37:30] Building features: 80% (140673/175846)
[02:37:31] Building features: 85% (149465/175846)
[02:37:31] Building features: 90% (158257/175846)
[02:37:32] Building features: 95% (167049/175846)
[02:37:32] Building features: 100% (175841/175846)
[02:37:32] Computing Hurst exponent...
[02:37:37] Computing market regimes (GMM)...
[02:37:44] Factor 8: 175644 samples, 92 features
[02:37:46] Batch stats — Input:  mean=0.0536 std=0.2666 min=-3.8425 max=60.4783
[02:37:46] Batch stats — Target: mean=0.0025 std=0.0693 min=-0.4595 max=0.4134
[02:37:46] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:37:51] Epoch 1/100 | Train: 0.003692 | Val: 0.010606 | LR: 1.00e-04 | Best: 0.010606 (ep 1)
[02:37:54] Epoch 2/100 | Train: 0.003103 | Val: 0.009515 | LR: 1.00e-04 | Best: 0.009515 (ep 2)
[02:37:57] Epoch 3/100 | Train: 0.003047 | Val: 0.009433 | LR: 1.00e-04 | Best: 0.009433 (ep 3)
[02:38:00] Epoch 4/100 | Train: 0.003012 | Val: 0.009246 | LR: 1.00e-04 | Best: 0.009246 (ep 4)
[02:38:03] Epoch 5/100 | Train: 0.002979 | Val: 0.009167 | LR: 1.00e-04 | Best: 0.009167 (ep 5)
[02:38:06] Epoch 6/100 | Train: 0.002962 | Val: 0.009131 | LR: 1.00e-04 | Best: 0.009131 (ep 6)
[02:38:09] Epoch 7/100 | Train: 0.002950 | Val: 0.008917 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:12] Epoch 8/100 | Train: 0.002936 | Val: 0.008921 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:15] Epoch 9/100 | Train: 0.002926 | Val: 0.008925 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:18] Epoch 10/100 | Train: 0.002916 | Val: 0.008936 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:20] Epoch 11/100 | Train: 0.002907 | Val: 0.008956 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:23] Epoch 12/100 | Train: 0.002900 | Val: 0.008965 | LR: 1.00e-04 | Best: 0.008917 (ep 7)
[02:38:26] Epoch 13/100 | Train: 0.002894 | Val: 0.009005 | LR: 5.00e-05 | Best: 0.008917 (ep 7)
[02:38:28] Epoch 14/100 | Train: 0.002885 | Val: 0.008995 | LR: 5.00e-05 | Best: 0.008917 (ep 7)
[02:38:31] Epoch 15/100 | Train: 0.002879 | Val: 0.009032 | LR: 5.00e-05 | Best: 0.008917 (ep 7)
[02:38:33] Epoch 16/100 | Train: 0.002875 | Val: 0.009060 | LR: 5.00e-05 | Best: 0.008917 (ep 7)
[02:38:36] Epoch 17/100 | Train: 0.002873 | Val: 0.009088 | LR: 5.00e-05 | Best: 0.008917 (ep 7)
[02:38:36] Early stopping at epoch 17 (no improvement for 10 epochs)
[02:38:37] Factor 8 done — best val loss: 0.008917 at epoch 7
[02:38:37] 
Best factor: 6 (val loss 0.008864)
[02:38:37] Training done. Best factor=6, val_loss=0.008864
[02:38:55] Building validation dataset...
[02:38:56] Building features: 0% (1/175846)
[02:38:56] Building features: 5% (8793/175846)
[02:38:57] Building features: 10% (17585/175846)
[02:38:57] Building features: 15% (26377/175846)
[02:38:57] Building features: 20% (35169/175846)
[02:38:58] Building features: 25% (43961/175846)
[02:38:58] Building features: 30% (52753/175846)
[02:38:59] Building features: 35% (61545/175846)
[02:38:59] Building features: 40% (70337/175846)
[02:39:00] Building features: 45% (79129/175846)
[02:39:00] Building features: 50% (87921/175846)
[02:39:01] Building features: 55% (96713/175846)
[02:39:01] Building features: 60% (105505/175846)
[02:39:02] Building features: 65% (114297/175846)
[02:39:02] Building features: 70% (123089/175846)
[02:39:03] Building features: 75% (131881/175846)
[02:39:04] Building features: 80% (140673/175846)
[02:39:04] Building features: 85% (149465/175846)
[02:39:05] Building features: 90% (158257/175846)
[02:39:05] Building features: 95% (167049/175846)
[02:39:06] Building features: 100% (175841/175846)
[02:39:06] Computing Hurst exponent...
[02:39:11] Computing market regimes (GMM)...
[02:39:18] Running backtest...
[02:39:18] Backtest complete: 664 trades, WR=50.6%, PF=1.05
[02:40:18] Building validation dataset...
[02:40:18] Building features: 0% (1/175846)
[02:40:18] Building features: 5% (8793/175846)
[02:40:19] Building features: 10% (17585/175846)
[02:40:19] Building features: 15% (26377/175846)
[02:40:20] Building features: 20% (35169/175846)
[02:40:20] Building features: 25% (43961/175846)
[02:40:21] Building features: 30% (52753/175846)
[02:40:21] Building features: 35% (61545/175846)
[02:40:22] Building features: 40% (70337/175846)
[02:40:22] Building features: 45% (79129/175846)
[02:40:23] Building features: 50% (87921/175846)
[02:40:23] Building features: 55% (96713/175846)
[02:40:24] Building features: 60% (105505/175846)
[02:40:24] Building features: 65% (114297/175846)
[02:40:25] Building features: 70% (123089/175846)
[02:40:25] Building features: 75% (131881/175846)
[02:40:26] Building features: 80% (140673/175846)
[02:40:26] Building features: 85% (149465/175846)
[02:40:27] Building features: 90% (158257/175846)
[02:40:27] Building features: 95% (167049/175846)
[02:40:28] Building features: 100% (175841/175846)
[02:40:28] Computing Hurst exponent...
[02:40:33] Computing market regimes (GMM)...
[02:40:40] Running backtest...
[02:40:40] Backtest complete: 5 trades, WR=60.0%, PF=1.11
[02:40:54] Building validation dataset...
[02:40:54] Building features: 0% (1/175846)
[02:40:54] Building features: 5% (8793/175846)
[02:40:55] Building features: 10% (17585/175846)
[02:40:55] Building features: 15% (26377/175846)
[02:40:56] Building features: 20% (35169/175846)
[02:40:56] Building features: 25% (43961/175846)
[02:40:57] Building features: 30% (52753/175846)
[02:40:57] Building features: 35% (61545/175846)
[02:40:58] Building features: 40% (70337/175846)
[02:40:58] Building features: 45% (79129/175846)
[02:40:59] Building features: 50% (87921/175846)
[02:41:00] Building features: 55% (96713/175846)
[02:41:00] Building features: 60% (105505/175846)
[02:41:01] Building features: 65% (114297/175846)
[02:41:01] Building features: 70% (123089/175846)
[02:41:02] Building features: 75% (131881/175846)
[02:41:02] Building features: 80% (140673/175846)
[02:41:03] Building features: 85% (149465/175846)
[02:41:03] Building features: 90% (158257/175846)
[02:41:04] Building features: 95% (167049/175846)
[02:41:04] Building features: 100% (175841/175846)
[02:41:04] Computing Hurst exponent...
[02:41:10] Computing market regimes (GMM)...
[02:41:17] Running backtest...
[02:41:17] Backtest complete: 3 trades, WR=33.3%, PF=0.47
[02:41:46] Training started.
[02:41:46] 
============================================================
[02:41:46] STF Factor 10 of [10..14]
[02:41:46] ============================================================
[02:41:46] Building features: 0% (1/175846)
[02:41:47] Building features: 5% (8793/175846)
[02:41:47] Building features: 10% (17585/175846)
[02:41:48] Building features: 15% (26377/175846)
[02:41:48] Building features: 20% (35169/175846)
[02:41:49] Building features: 25% (43961/175846)
[02:41:49] Building features: 30% (52753/175846)
[02:41:50] Building features: 35% (61545/175846)
[02:41:50] Building features: 40% (70337/175846)
[02:41:51] Building features: 45% (79129/175846)
[02:41:51] Building features: 50% (87921/175846)
[02:41:52] Building features: 55% (96713/175846)
[02:41:52] Building features: 60% (105505/175846)
[02:41:53] Building features: 65% (114297/175846)
[02:41:53] Building features: 70% (123089/175846)
[02:41:54] Building features: 75% (131881/175846)
[02:41:54] Building features: 80% (140673/175846)
[02:41:55] Building features: 85% (149465/175846)
[02:41:56] Building features: 90% (158257/175846)
[02:41:56] Building features: 95% (167049/175846)
[02:41:57] Building features: 100% (175841/175846)
[02:41:57] Computing Hurst exponent...
[02:42:02] Computing market regimes (GMM)...
[02:42:09] Factor 10: 175694 samples, 92 features
[02:42:11] Batch stats — Input:  mean=0.0559 std=0.2652 min=-4.1165 max=7.1903
[02:42:11] Batch stats — Target: mean=-0.0002 std=0.0682 min=-0.4720 max=0.4134
[02:42:11] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:42:15] Epoch 1/100 | Train: 0.004120 | Val: 0.010347 | LR: 1.00e-04 | Best: 0.010347 (ep 1)
[02:42:17] Epoch 2/100 | Train: 0.003122 | Val: 0.009447 | LR: 1.00e-04 | Best: 0.009447 (ep 2)
[02:42:20] Epoch 3/100 | Train: 0.003054 | Val: 0.009210 | LR: 1.00e-04 | Best: 0.009210 (ep 3)
[02:42:22] Epoch 4/100 | Train: 0.003011 | Val: 0.009111 | LR: 1.00e-04 | Best: 0.009111 (ep 4)
[02:42:25] Epoch 5/100 | Train: 0.002985 | Val: 0.009006 | LR: 1.00e-04 | Best: 0.009006 (ep 5)
[02:42:27] Epoch 6/100 | Train: 0.002967 | Val: 0.008961 | LR: 1.00e-04 | Best: 0.008961 (ep 6)
[02:42:29] Epoch 7/100 | Train: 0.002949 | Val: 0.008880 | LR: 1.00e-04 | Best: 0.008880 (ep 7)
[02:42:32] Epoch 8/100 | Train: 0.002941 | Val: 0.008823 | LR: 1.00e-04 | Best: 0.008823 (ep 8)
[02:42:34] Epoch 9/100 | Train: 0.002930 | Val: 0.008850 | LR: 1.00e-04 | Best: 0.008823 (ep 8)
[02:42:37] Epoch 10/100 | Train: 0.002920 | Val: 0.008836 | LR: 1.00e-04 | Best: 0.008823 (ep 8)
[02:42:39] Epoch 11/100 | Train: 0.002912 | Val: 0.008793 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:41] Epoch 12/100 | Train: 0.002902 | Val: 0.008817 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:44] Epoch 13/100 | Train: 0.002898 | Val: 0.008815 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:46] Epoch 14/100 | Train: 0.002892 | Val: 0.008848 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:48] Epoch 15/100 | Train: 0.002886 | Val: 0.008813 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:51] Epoch 16/100 | Train: 0.002880 | Val: 0.008860 | LR: 1.00e-04 | Best: 0.008793 (ep 11)
[02:42:53] Epoch 17/100 | Train: 0.002873 | Val: 0.008820 | LR: 5.00e-05 | Best: 0.008793 (ep 11)
[02:42:56] Epoch 18/100 | Train: 0.002859 | Val: 0.008883 | LR: 5.00e-05 | Best: 0.008793 (ep 11)
[02:42:58] Epoch 19/100 | Train: 0.002860 | Val: 0.008855 | LR: 5.00e-05 | Best: 0.008793 (ep 11)
[02:43:00] Epoch 20/100 | Train: 0.002855 | Val: 0.008896 | LR: 5.00e-05 | Best: 0.008793 (ep 11)
[02:43:03] Epoch 21/100 | Train: 0.002851 | Val: 0.008894 | LR: 5.00e-05 | Best: 0.008793 (ep 11)
[02:43:03] Early stopping at epoch 21 (no improvement for 10 epochs)
[02:43:04] Factor 10 done — best val loss: 0.008793 at epoch 11
[02:43:04] 
============================================================
[02:43:04] STF Factor 11 of [10..14]
[02:43:04] ============================================================
[02:43:04] Building features: 0% (1/175846)
[02:43:05] Building features: 5% (8793/175846)
[02:43:05] Building features: 10% (17585/175846)
[02:43:06] Building features: 15% (26377/175846)
[02:43:06] Building features: 20% (35169/175846)
[02:43:07] Building features: 25% (43961/175846)
[02:43:07] Building features: 30% (52753/175846)
[02:43:08] Building features: 35% (61545/175846)
[02:43:08] Building features: 40% (70337/175846)
[02:43:09] Building features: 45% (79129/175846)
[02:43:09] Building features: 50% (87921/175846)
[02:43:10] Building features: 55% (96713/175846)
[02:43:10] Building features: 60% (105505/175846)
[02:43:11] Building features: 65% (114297/175846)
[02:43:11] Building features: 70% (123089/175846)
[02:43:12] Building features: 75% (131881/175846)
[02:43:12] Building features: 80% (140673/175846)
[02:43:13] Building features: 85% (149465/175846)
[02:43:13] Building features: 90% (158257/175846)
[02:43:14] Building features: 95% (167049/175846)
[02:43:14] Building features: 100% (175841/175846)
[02:43:14] Computing Hurst exponent...
[02:43:19] Computing market regimes (GMM)...
[02:43:26] Factor 11: 175694 samples, 92 features
[02:43:28] Batch stats — Input:  mean=0.0524 std=0.2734 min=-5.4479 max=60.4783
[02:43:28] Batch stats — Target: mean=0.0027 std=0.0677 min=-0.4720 max=0.4134
[02:43:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:43:32] Epoch 1/100 | Train: 0.003843 | Val: 0.010580 | LR: 1.00e-04 | Best: 0.010580 (ep 1)
[02:43:35] Epoch 2/100 | Train: 0.003104 | Val: 0.009494 | LR: 1.00e-04 | Best: 0.009494 (ep 2)
[02:43:37] Epoch 3/100 | Train: 0.003046 | Val: 0.009171 | LR: 1.00e-04 | Best: 0.009171 (ep 3)
[02:43:40] Epoch 4/100 | Train: 0.003011 | Val: 0.009160 | LR: 1.00e-04 | Best: 0.009160 (ep 4)
[02:43:42] Epoch 5/100 | Train: 0.002985 | Val: 0.009034 | LR: 1.00e-04 | Best: 0.009034 (ep 5)
[02:43:44] Epoch 6/100 | Train: 0.002967 | Val: 0.009005 | LR: 1.00e-04 | Best: 0.009005 (ep 6)
[02:43:47] Epoch 7/100 | Train: 0.002953 | Val: 0.008968 | LR: 1.00e-04 | Best: 0.008968 (ep 7)
[02:43:49] Epoch 8/100 | Train: 0.002939 | Val: 0.009068 | LR: 1.00e-04 | Best: 0.008968 (ep 7)
[02:43:51] Epoch 9/100 | Train: 0.002931 | Val: 0.008922 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:43:54] Epoch 10/100 | Train: 0.002922 | Val: 0.009088 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:43:56] Epoch 11/100 | Train: 0.002913 | Val: 0.009202 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:43:59] Epoch 12/100 | Train: 0.002906 | Val: 0.009043 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:44:01] Epoch 13/100 | Train: 0.002901 | Val: 0.009324 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:44:03] Epoch 14/100 | Train: 0.002900 | Val: 0.009216 | LR: 1.00e-04 | Best: 0.008922 (ep 9)
[02:44:06] Epoch 15/100 | Train: 0.002889 | Val: 0.009373 | LR: 5.00e-05 | Best: 0.008922 (ep 9)
[02:44:08] Epoch 16/100 | Train: 0.002880 | Val: 0.009703 | LR: 5.00e-05 | Best: 0.008922 (ep 9)
[02:44:11] Epoch 17/100 | Train: 0.002879 | Val: 0.009421 | LR: 5.00e-05 | Best: 0.008922 (ep 9)
[02:44:13] Epoch 18/100 | Train: 0.002874 | Val: 0.009726 | LR: 5.00e-05 | Best: 0.008922 (ep 9)
[02:44:15] Epoch 19/100 | Train: 0.002871 | Val: 0.009521 | LR: 5.00e-05 | Best: 0.008922 (ep 9)
[02:44:15] Early stopping at epoch 19 (no improvement for 10 epochs)
[02:44:16] Factor 11 done — best val loss: 0.008922 at epoch 9
[02:44:16] 
============================================================
[02:44:16] STF Factor 12 of [10..14]
[02:44:16] ============================================================
[02:44:17] Building features: 0% (1/175846)
[02:44:17] Building features: 5% (8793/175846)
[02:44:18] Building features: 10% (17585/175846)
[02:44:18] Building features: 15% (26377/175846)
[02:44:19] Building features: 20% (35169/175846)
[02:44:19] Building features: 25% (43961/175846)
[02:44:20] Building features: 30% (52753/175846)
[02:44:20] Building features: 35% (61545/175846)
[02:44:21] Building features: 40% (70337/175846)
[02:44:21] Building features: 45% (79129/175846)
[02:44:22] Building features: 50% (87921/175846)
[02:44:22] Building features: 55% (96713/175846)
[02:44:23] Building features: 60% (105505/175846)
[02:44:23] Building features: 65% (114297/175846)
[02:44:24] Building features: 70% (123089/175846)
[02:44:24] Building features: 75% (131881/175846)
[02:44:25] Building features: 80% (140673/175846)
[02:44:25] Building features: 85% (149465/175846)
[02:44:26] Building features: 90% (158257/175846)
[02:44:26] Building features: 95% (167049/175846)
[02:44:27] Building features: 100% (175841/175846)
[02:44:27] Computing Hurst exponent...
[02:44:32] Computing market regimes (GMM)...
[02:44:39] Factor 12: 175694 samples, 92 features
[02:44:41] Batch stats — Input:  mean=0.0532 std=0.2690 min=-4.7113 max=13.1528
[02:44:41] Batch stats — Target: mean=0.0016 std=0.0672 min=-0.4630 max=0.3897
[02:44:41] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:44:45] Epoch 1/100 | Train: 0.003844 | Val: 0.011436 | LR: 1.00e-04 | Best: 0.011436 (ep 1)
[02:44:47] Epoch 2/100 | Train: 0.003111 | Val: 0.009733 | LR: 1.00e-04 | Best: 0.009733 (ep 2)
[02:44:50] Epoch 3/100 | Train: 0.003056 | Val: 0.009362 | LR: 1.00e-04 | Best: 0.009362 (ep 3)
[02:44:52] Epoch 4/100 | Train: 0.003025 | Val: 0.009243 | LR: 1.00e-04 | Best: 0.009243 (ep 4)
[02:44:55] Epoch 5/100 | Train: 0.002996 | Val: 0.009141 | LR: 1.00e-04 | Best: 0.009141 (ep 5)
[02:44:57] Epoch 6/100 | Train: 0.002971 | Val: 0.009042 | LR: 1.00e-04 | Best: 0.009042 (ep 6)
[02:44:59] Epoch 7/100 | Train: 0.002957 | Val: 0.009053 | LR: 1.00e-04 | Best: 0.009042 (ep 6)
[02:45:02] Epoch 8/100 | Train: 0.002937 | Val: 0.008963 | LR: 1.00e-04 | Best: 0.008963 (ep 8)
[02:45:04] Epoch 9/100 | Train: 0.002932 | Val: 0.008982 | LR: 1.00e-04 | Best: 0.008963 (ep 8)
[02:45:06] Epoch 10/100 | Train: 0.002923 | Val: 0.008974 | LR: 1.00e-04 | Best: 0.008963 (ep 8)
[02:45:09] Epoch 11/100 | Train: 0.002917 | Val: 0.009000 | LR: 1.00e-04 | Best: 0.008963 (ep 8)
[02:45:11] Epoch 12/100 | Train: 0.002911 | Val: 0.008897 | LR: 1.00e-04 | Best: 0.008897 (ep 12)
[02:45:13] Epoch 13/100 | Train: 0.002902 | Val: 0.008831 | LR: 1.00e-04 | Best: 0.008831 (ep 13)
[02:45:16] Epoch 14/100 | Train: 0.002894 | Val: 0.008945 | LR: 1.00e-04 | Best: 0.008831 (ep 13)
[02:45:18] Epoch 15/100 | Train: 0.002890 | Val: 0.008804 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:20] Epoch 16/100 | Train: 0.002886 | Val: 0.009004 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:23] Epoch 17/100 | Train: 0.002881 | Val: 0.008921 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:25] Epoch 18/100 | Train: 0.002877 | Val: 0.008949 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:28] Epoch 19/100 | Train: 0.002875 | Val: 0.008960 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:30] Epoch 20/100 | Train: 0.002867 | Val: 0.008877 | LR: 1.00e-04 | Best: 0.008804 (ep 15)
[02:45:32] Epoch 21/100 | Train: 0.002862 | Val: 0.008956 | LR: 5.00e-05 | Best: 0.008804 (ep 15)
[02:45:35] Epoch 22/100 | Train: 0.002853 | Val: 0.008950 | LR: 5.00e-05 | Best: 0.008804 (ep 15)
[02:45:37] Epoch 23/100 | Train: 0.002851 | Val: 0.008925 | LR: 5.00e-05 | Best: 0.008804 (ep 15)
[02:45:40] Epoch 24/100 | Train: 0.002847 | Val: 0.009008 | LR: 5.00e-05 | Best: 0.008804 (ep 15)
[02:45:42] Epoch 25/100 | Train: 0.002846 | Val: 0.009076 | LR: 5.00e-05 | Best: 0.008804 (ep 15)
[02:45:42] Early stopping at epoch 25 (no improvement for 10 epochs)
[02:45:43] Factor 12 done — best val loss: 0.008804 at epoch 15
[02:45:43] 
============================================================
[02:45:43] STF Factor 13 of [10..14]
[02:45:43] ============================================================
[02:45:43] Building features: 0% (1/175846)
[02:45:44] Building features: 5% (8793/175846)
[02:45:44] Building features: 10% (17585/175846)
[02:45:45] Building features: 15% (26377/175846)
[02:45:45] Building features: 20% (35169/175846)
[02:45:46] Building features: 25% (43961/175846)
[02:45:46] Building features: 30% (52753/175846)
[02:45:47] Building features: 35% (61545/175846)
[02:45:47] Building features: 40% (70337/175846)
[02:45:48] Building features: 45% (79129/175846)
[02:45:48] Building features: 50% (87921/175846)
[02:45:49] Building features: 55% (96713/175846)
[02:45:49] Building features: 60% (105505/175846)
[02:45:50] Building features: 65% (114297/175846)
[02:45:50] Building features: 70% (123089/175846)
[02:45:51] Building features: 75% (131881/175846)
[02:45:51] Building features: 80% (140673/175846)
[02:45:52] Building features: 85% (149465/175846)
[02:45:52] Building features: 90% (158257/175846)
[02:45:53] Building features: 95% (167049/175846)
[02:45:53] Building features: 100% (175841/175846)
[02:45:53] Computing Hurst exponent...
[02:45:58] Computing market regimes (GMM)...
[02:46:05] Factor 13: 175694 samples, 92 features
[02:46:07] Batch stats — Input:  mean=0.0556 std=0.2688 min=-6.9094 max=22.9822
[02:46:07] Batch stats — Target: mean=0.0018 std=0.0624 min=-0.4720 max=0.3745
[02:46:07] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:46:12] Epoch 1/100 | Train: 0.003557 | Val: 0.010328 | LR: 1.00e-04 | Best: 0.010328 (ep 1)
[02:46:14] Epoch 2/100 | Train: 0.003082 | Val: 0.009320 | LR: 1.00e-04 | Best: 0.009320 (ep 2)
[02:46:16] Epoch 3/100 | Train: 0.003029 | Val: 0.009231 | LR: 1.00e-04 | Best: 0.009231 (ep 3)
[02:46:18] Epoch 4/100 | Train: 0.002993 | Val: 0.009111 | LR: 1.00e-04 | Best: 0.009111 (ep 4)
[02:46:20] Epoch 5/100 | Train: 0.002971 | Val: 0.008980 | LR: 1.00e-04 | Best: 0.008980 (ep 5)
[02:46:23] Epoch 6/100 | Train: 0.002954 | Val: 0.008976 | LR: 1.00e-04 | Best: 0.008976 (ep 6)
[02:46:25] Epoch 7/100 | Train: 0.002939 | Val: 0.009006 | LR: 1.00e-04 | Best: 0.008976 (ep 6)
[02:46:27] Epoch 8/100 | Train: 0.002928 | Val: 0.008950 | LR: 1.00e-04 | Best: 0.008950 (ep 8)
[02:46:30] Epoch 9/100 | Train: 0.002919 | Val: 0.008931 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:32] Epoch 10/100 | Train: 0.002910 | Val: 0.008967 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:35] Epoch 11/100 | Train: 0.002901 | Val: 0.008936 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:37] Epoch 12/100 | Train: 0.002897 | Val: 0.009041 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:38] Epoch 13/100 | Train: 0.002891 | Val: 0.009460 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:40] Epoch 14/100 | Train: 0.002885 | Val: 0.009429 | LR: 1.00e-04 | Best: 0.008931 (ep 9)
[02:46:42] Epoch 15/100 | Train: 0.002880 | Val: 0.009371 | LR: 5.00e-05 | Best: 0.008931 (ep 9)
[02:46:44] Epoch 16/100 | Train: 0.002868 | Val: 0.009599 | LR: 5.00e-05 | Best: 0.008931 (ep 9)
[02:46:47] Epoch 17/100 | Train: 0.002865 | Val: 0.009427 | LR: 5.00e-05 | Best: 0.008931 (ep 9)
[02:46:49] Epoch 18/100 | Train: 0.002861 | Val: 0.009689 | LR: 5.00e-05 | Best: 0.008931 (ep 9)
[02:46:52] Epoch 19/100 | Train: 0.002858 | Val: 0.009993 | LR: 5.00e-05 | Best: 0.008931 (ep 9)
[02:46:52] Early stopping at epoch 19 (no improvement for 10 epochs)
[02:46:53] Factor 13 done — best val loss: 0.008931 at epoch 9
[02:46:53] 
============================================================
[02:46:53] STF Factor 14 of [10..14]
[02:46:53] ============================================================
[02:46:53] Building features: 0% (1/175846)
[02:46:53] Building features: 5% (8793/175846)
[02:46:54] Building features: 10% (17585/175846)
[02:46:54] Building features: 15% (26377/175846)
[02:46:55] Building features: 20% (35169/175846)
[02:46:55] Building features: 25% (43961/175846)
[02:46:56] Building features: 30% (52753/175846)
[02:46:56] Building features: 35% (61545/175846)
[02:46:57] Building features: 40% (70337/175846)
[02:46:57] Building features: 45% (79129/175846)
[02:46:58] Building features: 50% (87921/175846)
[02:46:58] Building features: 55% (96713/175846)
[02:46:59] Building features: 60% (105505/175846)
[02:47:00] Building features: 65% (114297/175846)
[02:47:00] Building features: 70% (123089/175846)
[02:47:01] Building features: 75% (131881/175846)
[02:47:01] Building features: 80% (140673/175846)
[02:47:02] Building features: 85% (149465/175846)
[02:47:02] Building features: 90% (158257/175846)
[02:47:03] Building features: 95% (167049/175846)
[02:47:03] Building features: 100% (175841/175846)
[02:47:03] Computing Hurst exponent...
[02:47:09] Computing market regimes (GMM)...
[02:47:15] Factor 14: 175694 samples, 92 features
[02:47:17] Batch stats — Input:  mean=0.0529 std=0.2695 min=-4.1165 max=7.8302
[02:47:17] Batch stats — Target: mean=0.0041 std=0.0733 min=-0.4545 max=0.4134
[02:47:17] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:47:22] Epoch 1/100 | Train: 0.003960 | Val: 0.011556 | LR: 1.00e-04 | Best: 0.011556 (ep 1)
[02:47:24] Epoch 2/100 | Train: 0.003107 | Val: 0.009816 | LR: 1.00e-04 | Best: 0.009816 (ep 2)
[02:47:26] Epoch 3/100 | Train: 0.003048 | Val: 0.009286 | LR: 1.00e-04 | Best: 0.009286 (ep 3)
[02:47:29] Epoch 4/100 | Train: 0.003012 | Val: 0.009149 | LR: 1.00e-04 | Best: 0.009149 (ep 4)
[02:47:31] Epoch 5/100 | Train: 0.002984 | Val: 0.009125 | LR: 1.00e-04 | Best: 0.009125 (ep 5)
[02:47:33] Epoch 6/100 | Train: 0.002960 | Val: 0.009032 | LR: 1.00e-04 | Best: 0.009032 (ep 6)
[02:47:34] Epoch 7/100 | Train: 0.002945 | Val: 0.008978 | LR: 1.00e-04 | Best: 0.008978 (ep 7)
[02:47:36] Epoch 8/100 | Train: 0.002930 | Val: 0.008948 | LR: 1.00e-04 | Best: 0.008948 (ep 8)
[02:47:38] Epoch 9/100 | Train: 0.002922 | Val: 0.008889 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:40] Epoch 10/100 | Train: 0.002915 | Val: 0.008909 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:42] Epoch 11/100 | Train: 0.002910 | Val: 0.008934 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:44] Epoch 12/100 | Train: 0.002897 | Val: 0.008957 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:46] Epoch 13/100 | Train: 0.002892 | Val: 0.009014 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:48] Epoch 14/100 | Train: 0.002888 | Val: 0.009196 | LR: 1.00e-04 | Best: 0.008889 (ep 9)
[02:47:50] Epoch 15/100 | Train: 0.002882 | Val: 0.009129 | LR: 5.00e-05 | Best: 0.008889 (ep 9)
[02:47:52] Epoch 16/100 | Train: 0.002871 | Val: 0.009161 | LR: 5.00e-05 | Best: 0.008889 (ep 9)
[02:47:54] Epoch 17/100 | Train: 0.002869 | Val: 0.009240 | LR: 5.00e-05 | Best: 0.008889 (ep 9)
[02:47:56] Epoch 18/100 | Train: 0.002863 | Val: 0.009333 | LR: 5.00e-05 | Best: 0.008889 (ep 9)
[02:47:58] Epoch 19/100 | Train: 0.002861 | Val: 0.009364 | LR: 5.00e-05 | Best: 0.008889 (ep 9)
[02:47:58] Early stopping at epoch 19 (no improvement for 10 epochs)
[02:47:59] Factor 14 done — best val loss: 0.008889 at epoch 9
[02:47:59] 
Best factor: 10 (val loss 0.008793)
[02:47:59] Training done. Best factor=10, val_loss=0.008793
[02:48:45] Building validation dataset...
[02:48:45] Building features: 0% (1/175846)
[02:48:46] Building features: 5% (8793/175846)
[02:48:46] Building features: 10% (17585/175846)
[02:48:47] Building features: 15% (26377/175846)
[02:48:47] Building features: 20% (35169/175846)
[02:48:48] Building features: 25% (43961/175846)
[02:48:48] Building features: 30% (52753/175846)
[02:48:49] Building features: 35% (61545/175846)
[02:48:49] Building features: 40% (70337/175846)
[02:48:50] Building features: 45% (79129/175846)
[02:48:50] Building features: 50% (87921/175846)
[02:48:51] Building features: 55% (96713/175846)
[02:48:51] Building features: 60% (105505/175846)
[02:48:52] Building features: 65% (114297/175846)
[02:48:52] Building features: 70% (123089/175846)
[02:48:53] Building features: 75% (131881/175846)
[02:48:53] Building features: 80% (140673/175846)
[02:48:54] Building features: 85% (149465/175846)
[02:48:54] Building features: 90% (158257/175846)
[02:48:55] Building features: 95% (167049/175846)
[02:48:55] Building features: 100% (175841/175846)
[02:48:55] Computing Hurst exponent...
[02:49:00] Computing market regimes (GMM)...
[02:49:07] Running backtest...
[02:49:07] Backtest complete: 12 trades, WR=50.0%, PF=1.48
[02:50:08] Training started.
[02:50:08] 
============================================================
[02:50:08] STF Factor 2 of [2..5]
[02:50:08] ============================================================
[02:50:08] Building features: 0% (1/175846)
[02:50:09] Building features: 5% (8793/175846)
[02:50:09] Building features: 10% (17585/175846)
[02:50:10] Building features: 15% (26377/175846)
[02:50:10] Building features: 20% (35169/175846)
[02:50:11] Building features: 25% (43961/175846)
[02:50:11] Building features: 30% (52753/175846)
[02:50:12] Building features: 35% (61545/175846)
[02:50:12] Building features: 40% (70337/175846)
[02:50:13] Building features: 45% (79129/175846)
[02:50:14] Building features: 50% (87921/175846)
[02:50:14] Building features: 55% (96713/175846)
[02:50:15] Building features: 60% (105505/175846)
[02:50:15] Building features: 65% (114297/175846)
[02:50:16] Building features: 70% (123089/175846)
[02:50:16] Building features: 75% (131881/175846)
[02:50:17] Building features: 80% (140673/175846)
[02:50:17] Building features: 85% (149465/175846)
[02:50:18] Building features: 90% (158257/175846)
[02:50:18] Building features: 95% (167049/175846)
[02:50:19] Building features: 100% (175841/175846)
[02:50:19] Computing Hurst exponent...
[02:50:24] Computing market regimes (GMM)...
[02:50:31] Factor 2: 175694 samples, 92 features
[02:50:33] Batch stats — Input:  mean=0.0549 std=0.2608 min=-7.0610 max=15.9549
[02:50:33] Batch stats — Target: mean=0.0049 std=0.0638 min=-0.4180 max=0.4134
[02:50:33] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:50:37] Epoch 1/100 | Train: 0.003740 | Val: 0.010940 | LR: 1.00e-04 | Best: 0.010940 (ep 1)
[02:50:40] Epoch 2/100 | Train: 0.003096 | Val: 0.009535 | LR: 1.00e-04 | Best: 0.009535 (ep 2)
[02:50:42] Epoch 3/100 | Train: 0.003040 | Val: 0.009207 | LR: 1.00e-04 | Best: 0.009207 (ep 3)
[02:50:44] Epoch 4/100 | Train: 0.003006 | Val: 0.009178 | LR: 1.00e-04 | Best: 0.009178 (ep 4)
[02:50:47] Epoch 5/100 | Train: 0.002979 | Val: 0.009099 | LR: 1.00e-04 | Best: 0.009099 (ep 5)
[02:50:49] Epoch 6/100 | Train: 0.002957 | Val: 0.008996 | LR: 1.00e-04 | Best: 0.008996 (ep 6)
[02:50:52] Epoch 7/100 | Train: 0.002944 | Val: 0.009005 | LR: 1.00e-04 | Best: 0.008996 (ep 6)
[02:50:54] Epoch 8/100 | Train: 0.002933 | Val: 0.009017 | LR: 1.00e-04 | Best: 0.008996 (ep 6)
[02:50:56] Epoch 9/100 | Train: 0.002921 | Val: 0.008924 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:50:59] Epoch 10/100 | Train: 0.002913 | Val: 0.009031 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:51:01] Epoch 11/100 | Train: 0.002905 | Val: 0.009100 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:51:03] Epoch 12/100 | Train: 0.002902 | Val: 0.009005 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:51:05] Epoch 13/100 | Train: 0.002894 | Val: 0.008998 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:51:07] Epoch 14/100 | Train: 0.002886 | Val: 0.009076 | LR: 1.00e-04 | Best: 0.008924 (ep 9)
[02:51:09] Epoch 15/100 | Train: 0.002885 | Val: 0.009028 | LR: 5.00e-05 | Best: 0.008924 (ep 9)
[02:51:11] Epoch 16/100 | Train: 0.002870 | Val: 0.009073 | LR: 5.00e-05 | Best: 0.008924 (ep 9)
[02:51:13] Epoch 17/100 | Train: 0.002867 | Val: 0.008964 | LR: 5.00e-05 | Best: 0.008924 (ep 9)
[02:51:15] Epoch 18/100 | Train: 0.002865 | Val: 0.009060 | LR: 5.00e-05 | Best: 0.008924 (ep 9)
[02:51:17] Epoch 19/100 | Train: 0.002860 | Val: 0.008997 | LR: 5.00e-05 | Best: 0.008924 (ep 9)
[02:51:17] Early stopping at epoch 19 (no improvement for 10 epochs)
[02:51:18] Factor 2 done — best val loss: 0.008924 at epoch 9
[02:51:18] 
============================================================
[02:51:18] STF Factor 3 of [2..5]
[02:51:18] ============================================================
[02:51:18] Building features: 0% (1/175846)
[02:51:18] Building features: 5% (8793/175846)
[02:51:19] Building features: 10% (17585/175846)
[02:51:19] Building features: 15% (26377/175846)
[02:51:20] Building features: 20% (35169/175846)
[02:51:20] Building features: 25% (43961/175846)
[02:51:21] Building features: 30% (52753/175846)
[02:51:21] Building features: 35% (61545/175846)
[02:51:22] Building features: 40% (70337/175846)
[02:51:22] Building features: 45% (79129/175846)
[02:51:23] Building features: 50% (87921/175846)
[02:51:23] Building features: 55% (96713/175846)
[02:51:24] Building features: 60% (105505/175846)
[02:51:24] Building features: 65% (114297/175846)
[02:51:25] Building features: 70% (123089/175846)
[02:51:25] Building features: 75% (131881/175846)
[02:51:26] Building features: 80% (140673/175846)
[02:51:26] Building features: 85% (149465/175846)
[02:51:27] Building features: 90% (158257/175846)
[02:51:27] Building features: 95% (167049/175846)
[02:51:27] Building features: 100% (175841/175846)
[02:51:28] Computing Hurst exponent...
[02:51:32] Computing market regimes (GMM)...
[02:51:39] Factor 3: 175694 samples, 92 features
[02:51:40] Batch stats — Input:  mean=0.0546 std=0.2623 min=-5.3639 max=9.5638
[02:51:40] Batch stats — Target: mean=-0.0006 std=0.0664 min=-0.4720 max=0.4134
[02:51:40] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:51:44] Epoch 1/100 | Train: 0.003807 | Val: 0.010774 | LR: 1.00e-04 | Best: 0.010774 (ep 1)
[02:51:46] Epoch 2/100 | Train: 0.003095 | Val: 0.009491 | LR: 1.00e-04 | Best: 0.009491 (ep 2)
[02:51:48] Epoch 3/100 | Train: 0.003043 | Val: 0.009184 | LR: 1.00e-04 | Best: 0.009184 (ep 3)
[02:51:50] Epoch 4/100 | Train: 0.003006 | Val: 0.009033 | LR: 1.00e-04 | Best: 0.009033 (ep 4)
[02:51:51] Epoch 5/100 | Train: 0.002979 | Val: 0.008977 | LR: 1.00e-04 | Best: 0.008977 (ep 5)
[02:51:53] Epoch 6/100 | Train: 0.002960 | Val: 0.009016 | LR: 1.00e-04 | Best: 0.008977 (ep 5)
[02:51:55] Epoch 7/100 | Train: 0.002944 | Val: 0.008933 | LR: 1.00e-04 | Best: 0.008933 (ep 7)
[02:51:57] Epoch 8/100 | Train: 0.002934 | Val: 0.008905 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:51:59] Epoch 9/100 | Train: 0.002923 | Val: 0.008920 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:52:01] Epoch 10/100 | Train: 0.002916 | Val: 0.009003 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:52:03] Epoch 11/100 | Train: 0.002906 | Val: 0.009071 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:52:05] Epoch 12/100 | Train: 0.002900 | Val: 0.009043 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:52:07] Epoch 13/100 | Train: 0.002893 | Val: 0.009209 | LR: 1.00e-04 | Best: 0.008905 (ep 8)
[02:52:09] Epoch 14/100 | Train: 0.002886 | Val: 0.009158 | LR: 5.00e-05 | Best: 0.008905 (ep 8)
[02:52:11] Epoch 15/100 | Train: 0.002877 | Val: 0.009125 | LR: 5.00e-05 | Best: 0.008905 (ep 8)
[02:52:13] Epoch 16/100 | Train: 0.002873 | Val: 0.009155 | LR: 5.00e-05 | Best: 0.008905 (ep 8)
[02:52:14] Epoch 17/100 | Train: 0.002868 | Val: 0.009158 | LR: 5.00e-05 | Best: 0.008905 (ep 8)
[02:52:16] Epoch 18/100 | Train: 0.002870 | Val: 0.009162 | LR: 5.00e-05 | Best: 0.008905 (ep 8)
[02:52:16] Early stopping at epoch 18 (no improvement for 10 epochs)
[02:52:17] Factor 3 done — best val loss: 0.008905 at epoch 8
[02:52:17] 
============================================================
[02:52:17] STF Factor 4 of [2..5]
[02:52:17] ============================================================
[02:52:17] Building features: 0% (1/175846)
[02:52:18] Building features: 5% (8793/175846)
[02:52:18] Building features: 10% (17585/175846)
[02:52:19] Building features: 15% (26377/175846)
[02:52:19] Building features: 20% (35169/175846)
[02:52:20] Building features: 25% (43961/175846)
[02:52:20] Building features: 30% (52753/175846)
[02:52:21] Building features: 35% (61545/175846)
[02:52:21] Building features: 40% (70337/175846)
[02:52:22] Building features: 45% (79129/175846)
[02:52:22] Building features: 50% (87921/175846)
[02:52:23] Building features: 55% (96713/175846)
[02:52:23] Building features: 60% (105505/175846)
[02:52:24] Building features: 65% (114297/175846)
[02:52:24] Building features: 70% (123089/175846)
[02:52:25] Building features: 75% (131881/175846)
[02:52:25] Building features: 80% (140673/175846)
[02:52:26] Building features: 85% (149465/175846)
[02:52:26] Building features: 90% (158257/175846)
[02:52:27] Building features: 95% (167049/175846)
[02:52:27] Building features: 100% (175841/175846)
[02:52:27] Computing Hurst exponent...
[02:52:32] Computing market regimes (GMM)...
[02:52:38] Factor 4: 175694 samples, 92 features
[02:52:40] Batch stats — Input:  mean=0.0536 std=0.2644 min=-4.2128 max=13.1528
[02:52:40] Batch stats — Target: mean=-0.0047 std=0.0757 min=-0.4720 max=0.3260
[02:52:40] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:52:44] Epoch 1/100 | Train: 0.003876 | Val: 0.011051 | LR: 1.00e-04 | Best: 0.011051 (ep 1)
[02:52:46] Epoch 2/100 | Train: 0.003118 | Val: 0.009527 | LR: 1.00e-04 | Best: 0.009527 (ep 2)
[02:52:47] Epoch 3/100 | Train: 0.003057 | Val: 0.009238 | LR: 1.00e-04 | Best: 0.009238 (ep 3)
[02:52:49] Epoch 4/100 | Train: 0.003019 | Val: 0.009124 | LR: 1.00e-04 | Best: 0.009124 (ep 4)
[02:52:51] Epoch 5/100 | Train: 0.002989 | Val: 0.009092 | LR: 1.00e-04 | Best: 0.009092 (ep 5)
[02:52:53] Epoch 6/100 | Train: 0.002966 | Val: 0.008915 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:52:55] Epoch 7/100 | Train: 0.002949 | Val: 0.008919 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:52:57] Epoch 8/100 | Train: 0.002938 | Val: 0.008971 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:52:59] Epoch 9/100 | Train: 0.002928 | Val: 0.009025 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:53:01] Epoch 10/100 | Train: 0.002918 | Val: 0.009047 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:53:03] Epoch 11/100 | Train: 0.002910 | Val: 0.009150 | LR: 1.00e-04 | Best: 0.008915 (ep 6)
[02:53:05] Epoch 12/100 | Train: 0.002903 | Val: 0.008928 | LR: 5.00e-05 | Best: 0.008915 (ep 6)
[02:53:07] Epoch 13/100 | Train: 0.002892 | Val: 0.009063 | LR: 5.00e-05 | Best: 0.008915 (ep 6)
[02:53:09] Epoch 14/100 | Train: 0.002890 | Val: 0.008991 | LR: 5.00e-05 | Best: 0.008915 (ep 6)
[02:53:11] Epoch 15/100 | Train: 0.002883 | Val: 0.008961 | LR: 5.00e-05 | Best: 0.008915 (ep 6)
[02:53:13] Epoch 16/100 | Train: 0.002882 | Val: 0.009040 | LR: 5.00e-05 | Best: 0.008915 (ep 6)
[02:53:13] Early stopping at epoch 16 (no improvement for 10 epochs)
[02:53:13] Factor 4 done — best val loss: 0.008915 at epoch 6
[02:53:13] 
============================================================
[02:53:13] STF Factor 5 of [2..5]
[02:53:13] ============================================================
[02:53:14] Building features: 0% (1/175846)
[02:53:14] Building features: 5% (8793/175846)
[02:53:15] Building features: 10% (17585/175846)
[02:53:15] Building features: 15% (26377/175846)
[02:53:15] Building features: 20% (35169/175846)
[02:53:16] Building features: 25% (43961/175846)
[02:53:16] Building features: 30% (52753/175846)
[02:53:17] Building features: 35% (61545/175846)
[02:53:17] Building features: 40% (70337/175846)
[02:53:18] Building features: 45% (79129/175846)
[02:53:18] Building features: 50% (87921/175846)
[02:53:19] Building features: 55% (96713/175846)
[02:53:19] Building features: 60% (105505/175846)
[02:53:20] Building features: 65% (114297/175846)
[02:53:20] Building features: 70% (123089/175846)
[02:53:21] Building features: 75% (131881/175846)
[02:53:21] Building features: 80% (140673/175846)
[02:53:22] Building features: 85% (149465/175846)
[02:53:22] Building features: 90% (158257/175846)
[02:53:23] Building features: 95% (167049/175846)
[02:53:23] Building features: 100% (175841/175846)
[02:53:23] Computing Hurst exponent...
[02:53:28] Computing market regimes (GMM)...
[02:53:34] Factor 5: 175694 samples, 92 features
[02:53:36] Batch stats — Input:  mean=0.0554 std=0.2740 min=-7.0610 max=22.9822
[02:53:36] Batch stats — Target: mean=-0.0007 std=0.0643 min=-0.4247 max=0.4134
[02:53:36] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[02:53:40] Epoch 1/100 | Train: 0.003803 | Val: 0.010487 | LR: 1.00e-04 | Best: 0.010487 (ep 1)
[02:53:41] Epoch 2/100 | Train: 0.003099 | Val: 0.009554 | LR: 1.00e-04 | Best: 0.009554 (ep 2)
[02:53:43] Epoch 3/100 | Train: 0.003045 | Val: 0.009443 | LR: 1.00e-04 | Best: 0.009443 (ep 3)
[02:53:45] Epoch 4/100 | Train: 0.003009 | Val: 0.009285 | LR: 1.00e-04 | Best: 0.009285 (ep 4)
[02:53:47] Epoch 5/100 | Train: 0.002982 | Val: 0.009112 | LR: 1.00e-04 | Best: 0.009112 (ep 5)
[02:53:49] Epoch 6/100 | Train: 0.002963 | Val: 0.009033 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:53:51] Epoch 7/100 | Train: 0.002949 | Val: 0.009036 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:53:53] Epoch 8/100 | Train: 0.002937 | Val: 0.009205 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:53:55] Epoch 9/100 | Train: 0.002926 | Val: 0.009443 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:53:57] Epoch 10/100 | Train: 0.002914 | Val: 0.009384 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:53:59] Epoch 11/100 | Train: 0.002910 | Val: 0.009214 | LR: 1.00e-04 | Best: 0.009033 (ep 6)
[02:54:01] Epoch 12/100 | Train: 0.002902 | Val: 0.009143 | LR: 5.00e-05 | Best: 0.009033 (ep 6)
[02:54:03] Epoch 13/100 | Train: 0.002893 | Val: 0.009314 | LR: 5.00e-05 | Best: 0.009033 (ep 6)
[02:54:04] Epoch 14/100 | Train: 0.002889 | Val: 0.009342 | LR: 5.00e-05 | Best: 0.009033 (ep 6)
[02:54:06] Epoch 15/100 | Train: 0.002884 | Val: 0.009234 | LR: 5.00e-05 | Best: 0.009033 (ep 6)
[02:54:08] Epoch 16/100 | Train: 0.002881 | Val: 0.009368 | LR: 5.00e-05 | Best: 0.009033 (ep 6)
[02:54:08] Early stopping at epoch 16 (no improvement for 10 epochs)
[02:54:09] Factor 5 done — best val loss: 0.009033 at epoch 6
[02:54:09] 
Best factor: 3 (val loss 0.008905)
[02:54:09] Training done. Best factor=3, val_loss=0.008905
[02:55:53] Building validation dataset...
[02:55:53] Building features: 0% (1/175846)
[02:55:54] Building features: 5% (8793/175846)
[02:55:54] Building features: 10% (17585/175846)
[02:55:55] Building features: 15% (26377/175846)
[02:55:55] Building features: 20% (35169/175846)
[02:55:56] Building features: 25% (43961/175846)
[02:55:56] Building features: 30% (52753/175846)
[02:55:57] Building features: 35% (61545/175846)
[02:55:57] Building features: 40% (70337/175846)
[02:55:58] Building features: 45% (79129/175846)
[02:55:58] Building features: 50% (87921/175846)
[02:55:59] Building features: 55% (96713/175846)
[02:56:00] Building features: 60% (105505/175846)
[02:56:00] Building features: 65% (114297/175846)
[02:56:01] Building features: 70% (123089/175846)
[02:56:01] Building features: 75% (131881/175846)
[02:56:02] Building features: 80% (140673/175846)
[02:56:02] Building features: 85% (149465/175846)
[02:56:03] Building features: 90% (158257/175846)
[02:56:03] Building features: 95% (167049/175846)
[02:56:04] Building features: 100% (175841/175846)
[02:56:04] Computing Hurst exponent...
[02:56:09] Computing market regimes (GMM)...
[02:56:16] Running backtest...
[02:56:17] Backtest complete: 22 trades, WR=59.1%, PF=1.73
[02:56:50] Building validation dataset...
[02:56:50] Building features: 0% (1/175846)
[02:56:51] Building features: 5% (8793/175846)
[02:56:51] Building features: 10% (17585/175846)
[02:56:52] Building features: 15% (26377/175846)
[02:56:52] Building features: 20% (35169/175846)
[02:56:53] Building features: 25% (43961/175846)
[02:56:53] Building features: 30% (52753/175846)
[02:56:54] Building features: 35% (61545/175846)
[02:56:54] Building features: 40% (70337/175846)
[02:56:55] Building features: 45% (79129/175846)
[02:56:55] Building features: 50% (87921/175846)
[02:56:56] Building features: 55% (96713/175846)
[02:56:56] Building features: 60% (105505/175846)
[02:56:57] Building features: 65% (114297/175846)
[02:56:57] Building features: 70% (123089/175846)
[02:56:58] Building features: 75% (131881/175846)
[02:56:58] Building features: 80% (140673/175846)
[02:56:59] Building features: 85% (149465/175846)
[02:57:00] Building features: 90% (158257/175846)
[02:57:00] Building features: 95% (167049/175846)
[02:57:01] Building features: 100% (175841/175846)
[02:57:01] Computing Hurst exponent...
[02:57:06] Computing market regimes (GMM)...
[02:57:13] Running backtest...
[02:57:13] Backtest complete: 0 trades, WR=0.0%, PF=0.00
[02:58:20] Building validation dataset...
[02:58:20] Building features: 0% (1/175846)
[02:58:20] Building features: 5% (8793/175846)
[02:58:21] Building features: 10% (17585/175846)
[02:58:21] Building features: 15% (26377/175846)
[02:58:22] Building features: 20% (35169/175846)
[02:58:22] Building features: 25% (43961/175846)
[02:58:23] Building features: 30% (52753/175846)
[02:58:23] Building features: 35% (61545/175846)
[02:58:24] Building features: 40% (70337/175846)
[02:58:24] Building features: 45% (79129/175846)
[02:58:25] Building features: 50% (87921/175846)
[02:58:25] Building features: 55% (96713/175846)
[02:58:26] Building features: 60% (105505/175846)
[02:58:26] Building features: 65% (114297/175846)
[02:58:27] Building features: 70% (123089/175846)
[02:58:28] Building features: 75% (131881/175846)
[02:58:28] Building features: 80% (140673/175846)
[02:58:29] Building features: 85% (149465/175846)
[02:58:29] Building features: 90% (158257/175846)
[02:58:30] Building features: 95% (167049/175846)
[02:58:30] Building features: 100% (175841/175846)
[02:58:30] Computing Hurst exponent...
[02:58:36] Computing market regimes (GMM)...
[02:58:42] Running backtest...
[02:58:43] Backtest complete: 1 trades, WR=0.0%, PF=0.00
[02:59:08] Building validation dataset...
[02:59:08] Building features: 0% (1/175846)
[02:59:09] Building features: 5% (8793/175846)
[02:59:09] Building features: 10% (17585/175846)
[02:59:10] Building features: 15% (26377/175846)
[02:59:10] Building features: 20% (35169/175846)
[02:59:11] Building features: 25% (43961/175846)
[02:59:11] Building features: 30% (52753/175846)
[02:59:12] Building features: 35% (61545/175846)
[02:59:12] Building features: 40% (70337/175846)
[02:59:13] Building features: 45% (79129/175846)
[02:59:13] Building features: 50% (87921/175846)
[02:59:14] Building features: 55% (96713/175846)
[02:59:14] Building features: 60% (105505/175846)
[02:59:15] Building features: 65% (114297/175846)
[02:59:15] Building features: 70% (123089/175846)
[02:59:16] Building features: 75% (131881/175846)
[02:59:16] Building features: 80% (140673/175846)
[02:59:17] Building features: 85% (149465/175846)
[02:59:17] Building features: 90% (158257/175846)
[02:59:18] Building features: 95% (167049/175846)
[02:59:19] Building features: 100% (175841/175846)
[02:59:19] Computing Hurst exponent...
[02:59:24] Computing market regimes (GMM)...
[02:59:31] Running backtest...
[02:59:32] Backtest complete: 8116 trades, WR=49.9%, PF=0.98
[03:00:23] Building validation dataset...
[03:00:23] Building features: 0% (1/175846)
[03:00:24] Building features: 5% (8793/175846)
[03:00:24] Building features: 10% (17585/175846)
[03:00:25] Building features: 15% (26377/175846)
[03:00:25] Building features: 20% (35169/175846)
[03:00:26] Building features: 25% (43961/175846)
[03:00:26] Building features: 30% (52753/175846)
[03:00:27] Building features: 35% (61545/175846)
[03:00:27] Building features: 40% (70337/175846)
[03:00:28] Building features: 45% (79129/175846)
[03:00:28] Building features: 50% (87921/175846)
[03:00:29] Building features: 55% (96713/175846)
[03:00:29] Building features: 60% (105505/175846)
[03:00:30] Building features: 65% (114297/175846)
[03:00:30] Building features: 70% (123089/175846)
[03:00:31] Building features: 75% (131881/175846)
[03:00:32] Building features: 80% (140673/175846)
[03:00:32] Building features: 85% (149465/175846)
[03:00:33] Building features: 90% (158257/175846)
[03:00:33] Building features: 95% (167049/175846)
[03:00:34] Building features: 100% (175841/175846)
[03:00:34] Computing Hurst exponent...
[03:00:39] Computing market regimes (GMM)...
[03:00:46] Running backtest...
[03:00:46] Backtest complete: 22 trades, WR=59.1%, PF=1.73
[03:05:28] Training started.
[03:05:28] 
============================================================
[03:05:28] STF Factor 2 of [2..5]
[03:05:28] ============================================================
[03:05:28] Building features: 0% (1/175846)
[03:05:29] Building features: 5% (8793/175846)
[03:05:29] Building features: 10% (17585/175846)
[03:05:30] Building features: 15% (26377/175846)
[03:05:30] Building features: 20% (35169/175846)
[03:05:31] Building features: 25% (43961/175846)
[03:05:31] Building features: 30% (52753/175846)
[03:05:32] Building features: 35% (61545/175846)
[03:05:32] Building features: 40% (70337/175846)
[03:05:32] Building features: 45% (79129/175846)
[03:05:33] Building features: 50% (87921/175846)
[03:05:33] Building features: 55% (96713/175846)
[03:05:34] Building features: 60% (105505/175846)
[03:05:34] Building features: 65% (114297/175846)
[03:05:35] Building features: 70% (123089/175846)
[03:05:35] Building features: 75% (131881/175846)
[03:05:36] Building features: 80% (140673/175846)
[03:05:36] Building features: 85% (149465/175846)
[03:05:37] Building features: 90% (158257/175846)
[03:05:37] Building features: 95% (167049/175846)
[03:05:38] Building features: 100% (175841/175846)
[03:05:38] Computing Hurst exponent...
[03:05:43] Computing market regimes (GMM)...
[03:05:50] Factor 2: 175714 samples, 92 features
[03:05:52] Batch stats — Input:  mean=0.0569 std=0.2594 min=-4.1411 max=9.5638
[03:05:52] Batch stats — Target: mean=0.0021 std=0.0639 min=-0.3559 max=0.3380
[03:05:52] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:05:56] Epoch 1/100 | Train: 0.003795 | Val: 0.010673 | LR: 1.00e-04 | Best: 0.010673 (ep 1)
[03:05:58] Epoch 2/100 | Train: 0.003093 | Val: 0.009436 | LR: 1.00e-04 | Best: 0.009436 (ep 2)
[03:06:00] Epoch 3/100 | Train: 0.003029 | Val: 0.009107 | LR: 1.00e-04 | Best: 0.009107 (ep 3)
[03:06:02] Epoch 4/100 | Train: 0.002995 | Val: 0.009022 | LR: 1.00e-04 | Best: 0.009022 (ep 4)
[03:06:04] Epoch 5/100 | Train: 0.002969 | Val: 0.008949 | LR: 1.00e-04 | Best: 0.008949 (ep 5)
[03:06:06] Epoch 6/100 | Train: 0.002951 | Val: 0.008927 | LR: 1.00e-04 | Best: 0.008927 (ep 6)
[03:06:08] Epoch 7/100 | Train: 0.002942 | Val: 0.008935 | LR: 1.00e-04 | Best: 0.008927 (ep 6)
[03:06:11] Epoch 8/100 | Train: 0.002931 | Val: 0.008898 | LR: 1.00e-04 | Best: 0.008898 (ep 8)
[03:06:13] Epoch 9/100 | Train: 0.002921 | Val: 0.008872 | LR: 1.00e-04 | Best: 0.008872 (ep 9)
[03:06:15] Epoch 10/100 | Train: 0.002914 | Val: 0.008902 | LR: 1.00e-04 | Best: 0.008872 (ep 9)
[03:06:17] Epoch 11/100 | Train: 0.002907 | Val: 0.008959 | LR: 1.00e-04 | Best: 0.008872 (ep 9)
[03:06:19] Epoch 12/100 | Train: 0.002905 | Val: 0.009002 | LR: 1.00e-04 | Best: 0.008872 (ep 9)
[03:06:21] Epoch 13/100 | Train: 0.002899 | Val: 0.008907 | LR: 1.00e-04 | Best: 0.008872 (ep 9)
[03:06:24] Epoch 14/100 | Train: 0.002890 | Val: 0.008864 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:26] Epoch 15/100 | Train: 0.002886 | Val: 0.008941 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:28] Epoch 16/100 | Train: 0.002881 | Val: 0.008985 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:30] Epoch 17/100 | Train: 0.002879 | Val: 0.008901 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:32] Epoch 18/100 | Train: 0.002869 | Val: 0.008866 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:35] Epoch 19/100 | Train: 0.002870 | Val: 0.008949 | LR: 1.00e-04 | Best: 0.008864 (ep 14)
[03:06:37] Epoch 20/100 | Train: 0.002862 | Val: 0.009074 | LR: 5.00e-05 | Best: 0.008864 (ep 14)
[03:06:39] Epoch 21/100 | Train: 0.002853 | Val: 0.008971 | LR: 5.00e-05 | Best: 0.008864 (ep 14)
[03:06:41] Epoch 22/100 | Train: 0.002847 | Val: 0.009034 | LR: 5.00e-05 | Best: 0.008864 (ep 14)
[03:06:43] Epoch 23/100 | Train: 0.002845 | Val: 0.009021 | LR: 5.00e-05 | Best: 0.008864 (ep 14)
[03:06:45] Epoch 24/100 | Train: 0.002840 | Val: 0.009029 | LR: 5.00e-05 | Best: 0.008864 (ep 14)
[03:06:45] Early stopping at epoch 24 (no improvement for 10 epochs)
[03:06:46] Factor 2 done — best val loss: 0.008864 at epoch 14
[03:06:46] 
============================================================
[03:06:46] STF Factor 3 of [2..5]
[03:06:46] ============================================================
[03:06:46] Building features: 0% (1/175846)
[03:06:47] Building features: 5% (8793/175846)
[03:06:47] Building features: 10% (17585/175846)
[03:06:48] Building features: 15% (26377/175846)
[03:06:48] Building features: 20% (35169/175846)
[03:06:49] Building features: 25% (43961/175846)
[03:06:49] Building features: 30% (52753/175846)
[03:06:50] Building features: 35% (61545/175846)
[03:06:50] Building features: 40% (70337/175846)
[03:06:51] Building features: 45% (79129/175846)
[03:06:51] Building features: 50% (87921/175846)
[03:06:52] Building features: 55% (96713/175846)
[03:06:52] Building features: 60% (105505/175846)
[03:06:53] Building features: 65% (114297/175846)
[03:06:53] Building features: 70% (123089/175846)
[03:06:54] Building features: 75% (131881/175846)
[03:06:54] Building features: 80% (140673/175846)
[03:06:55] Building features: 85% (149465/175846)
[03:06:55] Building features: 90% (158257/175846)
[03:06:56] Building features: 95% (167049/175846)
[03:06:56] Building features: 100% (175841/175846)
[03:06:56] Computing Hurst exponent...
[03:07:02] Computing market regimes (GMM)...
[03:07:08] Factor 3: 175714 samples, 92 features
[03:07:10] Batch stats — Input:  mean=0.0561 std=0.2641 min=-6.3561 max=9.5638
[03:07:10] Batch stats — Target: mean=-0.0069 std=0.0727 min=-0.4720 max=0.4134
[03:07:10] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:07:14] Epoch 1/100 | Train: 0.003799 | Val: 0.010244 | LR: 1.00e-04 | Best: 0.010244 (ep 1)
[03:07:16] Epoch 2/100 | Train: 0.003096 | Val: 0.009267 | LR: 1.00e-04 | Best: 0.009267 (ep 2)
[03:07:18] Epoch 3/100 | Train: 0.003035 | Val: 0.009092 | LR: 1.00e-04 | Best: 0.009092 (ep 3)
[03:07:21] Epoch 4/100 | Train: 0.002998 | Val: 0.008991 | LR: 1.00e-04 | Best: 0.008991 (ep 4)
[03:07:23] Epoch 5/100 | Train: 0.002977 | Val: 0.008955 | LR: 1.00e-04 | Best: 0.008955 (ep 5)
[03:07:25] Epoch 6/100 | Train: 0.002960 | Val: 0.008878 | LR: 1.00e-04 | Best: 0.008878 (ep 6)
[03:07:27] Epoch 7/100 | Train: 0.002945 | Val: 0.008837 | LR: 1.00e-04 | Best: 0.008837 (ep 7)
[03:07:29] Epoch 8/100 | Train: 0.002935 | Val: 0.008923 | LR: 1.00e-04 | Best: 0.008837 (ep 7)
[03:07:31] Epoch 9/100 | Train: 0.002925 | Val: 0.008820 | LR: 1.00e-04 | Best: 0.008820 (ep 9)
[03:07:33] Epoch 10/100 | Train: 0.002915 | Val: 0.008818 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:36] Epoch 11/100 | Train: 0.002910 | Val: 0.008855 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:38] Epoch 12/100 | Train: 0.002902 | Val: 0.008876 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:40] Epoch 13/100 | Train: 0.002897 | Val: 0.008909 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:42] Epoch 14/100 | Train: 0.002887 | Val: 0.008908 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:44] Epoch 15/100 | Train: 0.002882 | Val: 0.009136 | LR: 1.00e-04 | Best: 0.008818 (ep 10)
[03:07:45] Epoch 16/100 | Train: 0.002879 | Val: 0.008974 | LR: 5.00e-05 | Best: 0.008818 (ep 10)
[03:07:47] Epoch 17/100 | Train: 0.002870 | Val: 0.009107 | LR: 5.00e-05 | Best: 0.008818 (ep 10)
[03:07:49] Epoch 18/100 | Train: 0.002866 | Val: 0.009330 | LR: 5.00e-05 | Best: 0.008818 (ep 10)
[03:07:51] Epoch 19/100 | Train: 0.002861 | Val: 0.009484 | LR: 5.00e-05 | Best: 0.008818 (ep 10)
[03:07:53] Epoch 20/100 | Train: 0.002860 | Val: 0.009517 | LR: 5.00e-05 | Best: 0.008818 (ep 10)
[03:07:53] Early stopping at epoch 20 (no improvement for 10 epochs)
[03:07:53] Factor 3 done — best val loss: 0.008818 at epoch 10
[03:07:53] 
============================================================
[03:07:53] STF Factor 4 of [2..5]
[03:07:53] ============================================================
[03:07:54] Building features: 0% (1/175846)
[03:07:54] Building features: 5% (8793/175846)
[03:07:54] Building features: 10% (17585/175846)
[03:07:55] Building features: 15% (26377/175846)
[03:07:55] Building features: 20% (35169/175846)
[03:07:56] Building features: 25% (43961/175846)
[03:07:56] Building features: 30% (52753/175846)
[03:07:57] Building features: 35% (61545/175846)
[03:07:57] Building features: 40% (70337/175846)
[03:07:58] Building features: 45% (79129/175846)
[03:07:58] Building features: 50% (87921/175846)
[03:07:59] Building features: 55% (96713/175846)
[03:07:59] Building features: 60% (105505/175846)
[03:08:00] Building features: 65% (114297/175846)
[03:08:00] Building features: 70% (123089/175846)
[03:08:01] Building features: 75% (131881/175846)
[03:08:01] Building features: 80% (140673/175846)
[03:08:02] Building features: 85% (149465/175846)
[03:08:02] Building features: 90% (158257/175846)
[03:08:03] Building features: 95% (167049/175846)
[03:08:03] Building features: 100% (175841/175846)
[03:08:03] Computing Hurst exponent...
[03:08:09] Computing market regimes (GMM)...
[03:08:16] Factor 4: 175714 samples, 92 features
[03:08:17] Batch stats — Input:  mean=0.0526 std=0.2596 min=-4.1889 max=9.5561
[03:08:17] Batch stats — Target: mean=-0.0009 std=0.0676 min=-0.4720 max=0.4134
[03:08:17] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:08:20] Epoch 1/100 | Train: 0.003846 | Val: 0.010334 | LR: 1.00e-04 | Best: 0.010334 (ep 1)
[03:08:22] Epoch 2/100 | Train: 0.003095 | Val: 0.009439 | LR: 1.00e-04 | Best: 0.009439 (ep 2)
[03:08:24] Epoch 3/100 | Train: 0.003048 | Val: 0.009224 | LR: 1.00e-04 | Best: 0.009224 (ep 3)
[03:08:26] Epoch 4/100 | Train: 0.003014 | Val: 0.009295 | LR: 1.00e-04 | Best: 0.009224 (ep 3)
[03:08:28] Epoch 5/100 | Train: 0.002991 | Val: 0.009115 | LR: 1.00e-04 | Best: 0.009115 (ep 5)
[03:08:29] Epoch 6/100 | Train: 0.002969 | Val: 0.009083 | LR: 1.00e-04 | Best: 0.009083 (ep 6)
[03:08:31] Epoch 7/100 | Train: 0.002955 | Val: 0.009049 | LR: 1.00e-04 | Best: 0.009049 (ep 7)
[03:08:33] Epoch 8/100 | Train: 0.002942 | Val: 0.009169 | LR: 1.00e-04 | Best: 0.009049 (ep 7)
[03:08:35] Epoch 9/100 | Train: 0.002930 | Val: 0.008985 | LR: 1.00e-04 | Best: 0.008985 (ep 9)
[03:08:37] Epoch 10/100 | Train: 0.002922 | Val: 0.008989 | LR: 1.00e-04 | Best: 0.008985 (ep 9)
[03:08:38] Epoch 11/100 | Train: 0.002912 | Val: 0.009052 | LR: 1.00e-04 | Best: 0.008985 (ep 9)
[03:08:40] Epoch 12/100 | Train: 0.002903 | Val: 0.008972 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:42] Epoch 13/100 | Train: 0.002900 | Val: 0.009125 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:44] Epoch 14/100 | Train: 0.002889 | Val: 0.009163 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:47] Epoch 15/100 | Train: 0.002884 | Val: 0.009168 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:49] Epoch 16/100 | Train: 0.002877 | Val: 0.009698 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:51] Epoch 17/100 | Train: 0.002870 | Val: 0.009902 | LR: 1.00e-04 | Best: 0.008972 (ep 12)
[03:08:53] Epoch 18/100 | Train: 0.002865 | Val: 0.009722 | LR: 5.00e-05 | Best: 0.008972 (ep 12)
[03:08:56] Epoch 19/100 | Train: 0.002857 | Val: 0.009885 | LR: 5.00e-05 | Best: 0.008972 (ep 12)
[03:08:58] Epoch 20/100 | Train: 0.002852 | Val: 0.010206 | LR: 5.00e-05 | Best: 0.008972 (ep 12)
[03:09:00] Epoch 21/100 | Train: 0.002847 | Val: 0.009945 | LR: 5.00e-05 | Best: 0.008972 (ep 12)
[03:09:02] Epoch 22/100 | Train: 0.002842 | Val: 0.010055 | LR: 5.00e-05 | Best: 0.008972 (ep 12)
[03:09:02] Early stopping at epoch 22 (no improvement for 10 epochs)
[03:09:03] Factor 4 done — best val loss: 0.008972 at epoch 12
[03:09:03] 
============================================================
[03:09:03] STF Factor 5 of [2..5]
[03:09:03] ============================================================
[03:09:03] Building features: 0% (1/175846)
[03:09:04] Building features: 5% (8793/175846)
[03:09:04] Building features: 10% (17585/175846)
[03:09:05] Building features: 15% (26377/175846)
[03:09:05] Building features: 20% (35169/175846)
[03:09:06] Building features: 25% (43961/175846)
[03:09:07] Building features: 30% (52753/175846)
[03:09:07] Building features: 35% (61545/175846)
[03:09:08] Building features: 40% (70337/175846)
[03:09:08] Building features: 45% (79129/175846)
[03:09:09] Building features: 50% (87921/175846)
[03:09:09] Building features: 55% (96713/175846)
[03:09:10] Building features: 60% (105505/175846)
[03:09:10] Building features: 65% (114297/175846)
[03:09:11] Building features: 70% (123089/175846)
[03:09:11] Building features: 75% (131881/175846)
[03:09:12] Building features: 80% (140673/175846)
[03:09:12] Building features: 85% (149465/175846)
[03:09:13] Building features: 90% (158257/175846)
[03:09:13] Building features: 95% (167049/175846)
[03:09:14] Building features: 100% (175841/175846)
[03:09:14] Computing Hurst exponent...
[03:09:19] Computing market regimes (GMM)...
[03:09:26] Factor 5: 175714 samples, 92 features
[03:09:28] Batch stats — Input:  mean=0.0550 std=0.2637 min=-5.5995 max=8.3752
[03:09:28] Batch stats — Target: mean=0.0015 std=0.0651 min=-0.4720 max=0.4134
[03:09:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:09:32] Epoch 1/100 | Train: 0.003872 | Val: 0.011358 | LR: 1.00e-04 | Best: 0.011358 (ep 1)
[03:09:34] Epoch 2/100 | Train: 0.003115 | Val: 0.009948 | LR: 1.00e-04 | Best: 0.009948 (ep 2)
[03:09:37] Epoch 3/100 | Train: 0.003049 | Val: 0.009515 | LR: 1.00e-04 | Best: 0.009515 (ep 3)
[03:09:39] Epoch 4/100 | Train: 0.003008 | Val: 0.009182 | LR: 1.00e-04 | Best: 0.009182 (ep 4)
[03:09:41] Epoch 5/100 | Train: 0.002980 | Val: 0.009051 | LR: 1.00e-04 | Best: 0.009051 (ep 5)
[03:09:43] Epoch 6/100 | Train: 0.002962 | Val: 0.008925 | LR: 1.00e-04 | Best: 0.008925 (ep 6)
[03:09:45] Epoch 7/100 | Train: 0.002948 | Val: 0.008942 | LR: 1.00e-04 | Best: 0.008925 (ep 6)
[03:09:47] Epoch 8/100 | Train: 0.002937 | Val: 0.008940 | LR: 1.00e-04 | Best: 0.008925 (ep 6)
[03:09:50] Epoch 9/100 | Train: 0.002924 | Val: 0.008856 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:09:52] Epoch 10/100 | Train: 0.002918 | Val: 0.008912 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:09:54] Epoch 11/100 | Train: 0.002909 | Val: 0.008943 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:09:56] Epoch 12/100 | Train: 0.002905 | Val: 0.008919 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:09:58] Epoch 13/100 | Train: 0.002899 | Val: 0.009122 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:10:00] Epoch 14/100 | Train: 0.002894 | Val: 0.008965 | LR: 1.00e-04 | Best: 0.008856 (ep 9)
[03:10:01] Epoch 15/100 | Train: 0.002885 | Val: 0.009091 | LR: 5.00e-05 | Best: 0.008856 (ep 9)
[03:10:03] Epoch 16/100 | Train: 0.002875 | Val: 0.009103 | LR: 5.00e-05 | Best: 0.008856 (ep 9)
[03:10:05] Epoch 17/100 | Train: 0.002873 | Val: 0.009156 | LR: 5.00e-05 | Best: 0.008856 (ep 9)
[03:10:07] Epoch 18/100 | Train: 0.002868 | Val: 0.009188 | LR: 5.00e-05 | Best: 0.008856 (ep 9)
[03:10:09] Epoch 19/100 | Train: 0.002867 | Val: 0.009120 | LR: 5.00e-05 | Best: 0.008856 (ep 9)
[03:10:09] Early stopping at epoch 19 (no improvement for 10 epochs)
[03:10:09] Factor 5 done — best val loss: 0.008856 at epoch 9
[03:10:09] 
Best factor: 3 (val loss 0.008818)
[03:10:09] Training done. Best factor=3, val_loss=0.008818
[03:11:08] Building validation dataset...
[03:11:08] Building features: 0% (1/175846)
[03:11:09] Building features: 5% (8793/175846)
[03:11:09] Building features: 10% (17585/175846)
[03:11:10] Building features: 15% (26377/175846)
[03:11:10] Building features: 20% (35169/175846)
[03:11:11] Building features: 25% (43961/175846)
[03:11:11] Building features: 30% (52753/175846)
[03:11:12] Building features: 35% (61545/175846)
[03:11:12] Building features: 40% (70337/175846)
[03:11:13] Building features: 45% (79129/175846)
[03:11:13] Building features: 50% (87921/175846)
[03:11:13] Building features: 55% (96713/175846)
[03:11:14] Building features: 60% (105505/175846)
[03:11:14] Building features: 65% (114297/175846)
[03:11:15] Building features: 70% (123089/175846)
[03:11:16] Building features: 75% (131881/175846)
[03:11:16] Building features: 80% (140673/175846)
[03:11:17] Building features: 85% (149465/175846)
[03:11:17] Building features: 90% (158257/175846)
[03:11:18] Building features: 95% (167049/175846)
[03:11:18] Building features: 100% (175841/175846)
[03:11:18] Computing Hurst exponent...
[03:11:24] Computing market regimes (GMM)...
[03:11:31] Running backtest...
[03:11:31] Backtest complete: 0 trades, WR=0.0%, PF=0.00
[03:12:37] Building validation dataset...
[03:12:37] Building features: 0% (1/175846)
[03:12:37] Building features: 5% (8793/175846)
[03:12:38] Building features: 10% (17585/175846)
[03:12:38] Building features: 15% (26377/175846)
[03:12:39] Building features: 20% (35169/175846)
[03:12:39] Building features: 25% (43961/175846)
[03:12:40] Building features: 30% (52753/175846)
[03:12:40] Building features: 35% (61545/175846)
[03:12:41] Building features: 40% (70337/175846)
[03:12:41] Building features: 45% (79129/175846)
[03:12:42] Building features: 50% (87921/175846)
[03:12:42] Building features: 55% (96713/175846)
[03:12:43] Building features: 60% (105505/175846)
[03:12:43] Building features: 65% (114297/175846)
[03:12:44] Building features: 70% (123089/175846)
[03:12:44] Building features: 75% (131881/175846)
[03:12:45] Building features: 80% (140673/175846)
[03:12:46] Building features: 85% (149465/175846)
[03:12:46] Building features: 90% (158257/175846)
[03:12:47] Building features: 95% (167049/175846)
[03:12:47] Building features: 100% (175841/175846)
[03:12:47] Computing Hurst exponent...
[03:12:53] Computing market regimes (GMM)...
[03:12:59] Running backtest...
[03:13:00] Backtest complete: 0 trades, WR=0.0%, PF=0.00
[03:14:14] Training started.
[03:14:14] 
============================================================
[03:14:14] STF Factor 3 of [3..6]
[03:14:14] ============================================================
[03:14:14] Building features: 0% (1/175846)
[03:14:15] Building features: 5% (8793/175846)
[03:14:15] Building features: 10% (17585/175846)
[03:14:16] Building features: 15% (26377/175846)
[03:14:16] Building features: 20% (35169/175846)
[03:14:17] Building features: 25% (43961/175846)
[03:14:17] Building features: 30% (52753/175846)
[03:14:18] Building features: 35% (61545/175846)
[03:14:18] Building features: 40% (70337/175846)
[03:14:18] Building features: 45% (79129/175846)
[03:14:19] Building features: 50% (87921/175846)
[03:14:19] Building features: 55% (96713/175846)
[03:14:20] Building features: 60% (105505/175846)
[03:14:20] Building features: 65% (114297/175846)
[03:14:21] Building features: 70% (123089/175846)
[03:14:21] Building features: 75% (131881/175846)
[03:14:22] Building features: 80% (140673/175846)
[03:14:22] Building features: 85% (149465/175846)
[03:14:23] Building features: 90% (158257/175846)
[03:14:23] Building features: 95% (167049/175846)
[03:14:24] Building features: 100% (175841/175846)
[03:14:24] Computing Hurst exponent...
[03:14:29] Computing market regimes (GMM)...
[03:14:36] Factor 3: 175644 samples, 92 features
[03:14:37] Batch stats — Input:  mean=0.0546 std=0.2646 min=-5.3639 max=27.8570
[03:14:37] Batch stats — Target: mean=0.0036 std=0.0656 min=-0.4720 max=0.4134
[03:14:37] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:14:43] Epoch 1/100 | Train: 0.003885 | Val: 0.010987 | LR: 1.00e-04 | Best: 0.010987 (ep 1)
[03:14:45] Epoch 2/100 | Train: 0.003111 | Val: 0.009648 | LR: 1.00e-04 | Best: 0.009648 (ep 2)
[03:14:48] Epoch 3/100 | Train: 0.003049 | Val: 0.009335 | LR: 1.00e-04 | Best: 0.009335 (ep 3)
[03:14:51] Epoch 4/100 | Train: 0.003013 | Val: 0.009113 | LR: 1.00e-04 | Best: 0.009113 (ep 4)
[03:14:54] Epoch 5/100 | Train: 0.002984 | Val: 0.009152 | LR: 1.00e-04 | Best: 0.009113 (ep 4)
[03:14:57] Epoch 6/100 | Train: 0.002966 | Val: 0.009075 | LR: 1.00e-04 | Best: 0.009075 (ep 6)
[03:15:00] Epoch 7/100 | Train: 0.002945 | Val: 0.009004 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:03] Epoch 8/100 | Train: 0.002935 | Val: 0.009196 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:05] Epoch 9/100 | Train: 0.002926 | Val: 0.009088 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:08] Epoch 10/100 | Train: 0.002918 | Val: 0.009038 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:11] Epoch 11/100 | Train: 0.002910 | Val: 0.009062 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:14] Epoch 12/100 | Train: 0.002900 | Val: 0.009145 | LR: 1.00e-04 | Best: 0.009004 (ep 7)
[03:15:17] Epoch 13/100 | Train: 0.002893 | Val: 0.009235 | LR: 5.00e-05 | Best: 0.009004 (ep 7)
[03:15:20] Epoch 14/100 | Train: 0.002884 | Val: 0.009233 | LR: 5.00e-05 | Best: 0.009004 (ep 7)
[03:15:23] Epoch 15/100 | Train: 0.002882 | Val: 0.009240 | LR: 5.00e-05 | Best: 0.009004 (ep 7)
[03:15:26] Epoch 16/100 | Train: 0.002879 | Val: 0.009193 | LR: 5.00e-05 | Best: 0.009004 (ep 7)
[03:15:28] Epoch 17/100 | Train: 0.002874 | Val: 0.009249 | LR: 5.00e-05 | Best: 0.009004 (ep 7)
[03:15:28] Early stopping at epoch 17 (no improvement for 10 epochs)
[03:15:29] Factor 3 done — best val loss: 0.009004 at epoch 7
[03:15:29] 
============================================================
[03:15:29] STF Factor 4 of [3..6]
[03:15:29] ============================================================
[03:15:29] Building features: 0% (1/175846)
[03:15:30] Building features: 5% (8793/175846)
[03:15:30] Building features: 10% (17585/175846)
[03:15:31] Building features: 15% (26377/175846)
[03:15:31] Building features: 20% (35169/175846)
[03:15:32] Building features: 25% (43961/175846)
[03:15:32] Building features: 30% (52753/175846)
[03:15:33] Building features: 35% (61545/175846)
[03:15:33] Building features: 40% (70337/175846)
[03:15:34] Building features: 45% (79129/175846)
[03:15:34] Building features: 50% (87921/175846)
[03:15:35] Building features: 55% (96713/175846)
[03:15:36] Building features: 60% (105505/175846)
[03:15:36] Building features: 65% (114297/175846)
[03:15:37] Building features: 70% (123089/175846)
[03:15:37] Building features: 75% (131881/175846)
[03:15:38] Building features: 80% (140673/175846)
[03:15:38] Building features: 85% (149465/175846)
[03:15:39] Building features: 90% (158257/175846)
[03:15:39] Building features: 95% (167049/175846)
[03:15:40] Building features: 100% (175841/175846)
[03:15:40] Computing Hurst exponent...
[03:15:45] Computing market regimes (GMM)...
[03:15:51] Factor 4: 175644 samples, 92 features
[03:15:53] Batch stats — Input:  mean=0.0543 std=0.2644 min=-5.2415 max=13.1528
[03:15:53] Batch stats — Target: mean=0.0021 std=0.0680 min=-0.4720 max=0.3571
[03:15:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:15:58] Epoch 1/100 | Train: 0.003855 | Val: 0.010128 | LR: 1.00e-04 | Best: 0.010128 (ep 1)
[03:16:01] Epoch 2/100 | Train: 0.003109 | Val: 0.009404 | LR: 1.00e-04 | Best: 0.009404 (ep 2)
[03:16:04] Epoch 3/100 | Train: 0.003052 | Val: 0.009192 | LR: 1.00e-04 | Best: 0.009192 (ep 3)
[03:16:07] Epoch 4/100 | Train: 0.003013 | Val: 0.009044 | LR: 1.00e-04 | Best: 0.009044 (ep 4)
[03:16:10] Epoch 5/100 | Train: 0.002982 | Val: 0.008993 | LR: 1.00e-04 | Best: 0.008993 (ep 5)
[03:16:12] Epoch 6/100 | Train: 0.002961 | Val: 0.008871 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:15] Epoch 7/100 | Train: 0.002943 | Val: 0.008882 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:18] Epoch 8/100 | Train: 0.002933 | Val: 0.009021 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:21] Epoch 9/100 | Train: 0.002924 | Val: 0.008964 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:24] Epoch 10/100 | Train: 0.002914 | Val: 0.009035 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:27] Epoch 11/100 | Train: 0.002907 | Val: 0.009026 | LR: 1.00e-04 | Best: 0.008871 (ep 6)
[03:16:29] Epoch 12/100 | Train: 0.002899 | Val: 0.009179 | LR: 5.00e-05 | Best: 0.008871 (ep 6)
[03:16:32] Epoch 13/100 | Train: 0.002888 | Val: 0.009227 | LR: 5.00e-05 | Best: 0.008871 (ep 6)
[03:16:35] Epoch 14/100 | Train: 0.002882 | Val: 0.009049 | LR: 5.00e-05 | Best: 0.008871 (ep 6)
[03:16:38] Epoch 15/100 | Train: 0.002883 | Val: 0.009154 | LR: 5.00e-05 | Best: 0.008871 (ep 6)
[03:16:41] Epoch 16/100 | Train: 0.002881 | Val: 0.009165 | LR: 5.00e-05 | Best: 0.008871 (ep 6)
[03:16:41] Early stopping at epoch 16 (no improvement for 10 epochs)
[03:16:42] Factor 4 done — best val loss: 0.008871 at epoch 6
[03:16:42] 
============================================================
[03:16:42] STF Factor 5 of [3..6]
[03:16:42] ============================================================
[03:16:42] Building features: 0% (1/175846)
[03:16:43] Building features: 5% (8793/175846)
[03:16:43] Building features: 10% (17585/175846)
[03:16:44] Building features: 15% (26377/175846)
[03:16:44] Building features: 20% (35169/175846)
[03:16:45] Building features: 25% (43961/175846)
[03:16:45] Building features: 30% (52753/175846)
[03:16:46] Building features: 35% (61545/175846)
[03:16:46] Building features: 40% (70337/175846)
[03:16:47] Building features: 45% (79129/175846)
[03:16:47] Building features: 50% (87921/175846)
[03:16:48] Building features: 55% (96713/175846)
[03:16:48] Building features: 60% (105505/175846)
[03:16:49] Building features: 65% (114297/175846)
[03:16:49] Building features: 70% (123089/175846)
[03:16:50] Building features: 75% (131881/175846)
[03:16:50] Building features: 80% (140673/175846)
[03:16:51] Building features: 85% (149465/175846)
[03:16:51] Building features: 90% (158257/175846)
[03:16:52] Building features: 95% (167049/175846)
[03:16:52] Building features: 100% (175841/175846)
[03:16:52] Computing Hurst exponent...
[03:16:57] Computing market regimes (GMM)...
[03:17:04] Factor 5: 175644 samples, 92 features
[03:17:06] Batch stats — Input:  mean=0.0545 std=0.2713 min=-7.0610 max=27.8570
[03:17:06] Batch stats — Target: mean=0.0059 std=0.0633 min=-0.2635 max=0.4134
[03:17:06] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:17:11] Epoch 1/100 | Train: 0.003783 | Val: 0.010427 | LR: 1.00e-04 | Best: 0.010427 (ep 1)
[03:17:14] Epoch 2/100 | Train: 0.003108 | Val: 0.009479 | LR: 1.00e-04 | Best: 0.009479 (ep 2)
[03:17:17] Epoch 3/100 | Train: 0.003051 | Val: 0.009180 | LR: 1.00e-04 | Best: 0.009180 (ep 3)
[03:17:20] Epoch 4/100 | Train: 0.003014 | Val: 0.009085 | LR: 1.00e-04 | Best: 0.009085 (ep 4)
[03:17:22] Epoch 5/100 | Train: 0.002991 | Val: 0.008938 | LR: 1.00e-04 | Best: 0.008938 (ep 5)
[03:17:25] Epoch 6/100 | Train: 0.002962 | Val: 0.008931 | LR: 1.00e-04 | Best: 0.008931 (ep 6)
[03:17:28] Epoch 7/100 | Train: 0.002948 | Val: 0.008858 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:31] Epoch 8/100 | Train: 0.002937 | Val: 0.008886 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:34] Epoch 9/100 | Train: 0.002923 | Val: 0.008955 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:37] Epoch 10/100 | Train: 0.002913 | Val: 0.008946 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:40] Epoch 11/100 | Train: 0.002906 | Val: 0.009162 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:42] Epoch 12/100 | Train: 0.002897 | Val: 0.009033 | LR: 1.00e-04 | Best: 0.008858 (ep 7)
[03:17:45] Epoch 13/100 | Train: 0.002890 | Val: 0.009243 | LR: 5.00e-05 | Best: 0.008858 (ep 7)
[03:17:48] Epoch 14/100 | Train: 0.002877 | Val: 0.009317 | LR: 5.00e-05 | Best: 0.008858 (ep 7)
[03:17:51] Epoch 15/100 | Train: 0.002874 | Val: 0.009095 | LR: 5.00e-05 | Best: 0.008858 (ep 7)
[03:17:54] Epoch 16/100 | Train: 0.002872 | Val: 0.009190 | LR: 5.00e-05 | Best: 0.008858 (ep 7)
[03:17:57] Epoch 17/100 | Train: 0.002868 | Val: 0.009294 | LR: 5.00e-05 | Best: 0.008858 (ep 7)
[03:17:57] Early stopping at epoch 17 (no improvement for 10 epochs)
[03:17:58] Factor 5 done — best val loss: 0.008858 at epoch 7
[03:17:58] 
============================================================
[03:17:58] STF Factor 6 of [3..6]
[03:17:58] ============================================================
[03:17:58] Building features: 0% (1/175846)
[03:17:59] Building features: 5% (8793/175846)
[03:17:59] Building features: 10% (17585/175846)
[03:18:00] Building features: 15% (26377/175846)
[03:18:00] Building features: 20% (35169/175846)
[03:18:01] Building features: 25% (43961/175846)
[03:18:01] Building features: 30% (52753/175846)
[03:18:02] Building features: 35% (61545/175846)
[03:18:02] Building features: 40% (70337/175846)
[03:18:03] Building features: 45% (79129/175846)
[03:18:03] Building features: 50% (87921/175846)
[03:18:04] Building features: 55% (96713/175846)
[03:18:04] Building features: 60% (105505/175846)
[03:18:05] Building features: 65% (114297/175846)
[03:18:05] Building features: 70% (123089/175846)
[03:18:06] Building features: 75% (131881/175846)
[03:18:06] Building features: 80% (140673/175846)
[03:18:07] Building features: 85% (149465/175846)
[03:18:07] Building features: 90% (158257/175846)
[03:18:08] Building features: 95% (167049/175846)
[03:18:08] Building features: 100% (175841/175846)
[03:18:08] Computing Hurst exponent...
[03:18:14] Computing market regimes (GMM)...
[03:18:20] Factor 6: 175644 samples, 92 features
[03:18:22] Batch stats — Input:  mean=0.0539 std=0.2664 min=-6.3561 max=9.5638
[03:18:22] Batch stats — Target: mean=0.0034 std=0.0699 min=-0.4720 max=0.4134
[03:18:22] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:18:27] Epoch 1/100 | Train: 0.003777 | Val: 0.010545 | LR: 1.00e-04 | Best: 0.010545 (ep 1)
[03:18:30] Epoch 2/100 | Train: 0.003107 | Val: 0.009430 | LR: 1.00e-04 | Best: 0.009430 (ep 2)
[03:18:33] Epoch 3/100 | Train: 0.003046 | Val: 0.009256 | LR: 1.00e-04 | Best: 0.009256 (ep 3)
[03:18:36] Epoch 4/100 | Train: 0.003004 | Val: 0.009062 | LR: 1.00e-04 | Best: 0.009062 (ep 4)
[03:18:39] Epoch 5/100 | Train: 0.002976 | Val: 0.009014 | LR: 1.00e-04 | Best: 0.009014 (ep 5)
[03:18:42] Epoch 6/100 | Train: 0.002955 | Val: 0.008929 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:45] Epoch 7/100 | Train: 0.002939 | Val: 0.008962 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:48] Epoch 8/100 | Train: 0.002931 | Val: 0.008997 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:51] Epoch 9/100 | Train: 0.002916 | Val: 0.009013 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:54] Epoch 10/100 | Train: 0.002911 | Val: 0.009079 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:56] Epoch 11/100 | Train: 0.002901 | Val: 0.009188 | LR: 1.00e-04 | Best: 0.008929 (ep 6)
[03:18:59] Epoch 12/100 | Train: 0.002897 | Val: 0.009302 | LR: 5.00e-05 | Best: 0.008929 (ep 6)
[03:19:02] Epoch 13/100 | Train: 0.002884 | Val: 0.009394 | LR: 5.00e-05 | Best: 0.008929 (ep 6)
[03:19:05] Epoch 14/100 | Train: 0.002882 | Val: 0.009405 | LR: 5.00e-05 | Best: 0.008929 (ep 6)
[03:19:08] Epoch 15/100 | Train: 0.002884 | Val: 0.009247 | LR: 5.00e-05 | Best: 0.008929 (ep 6)
[03:19:11] Epoch 16/100 | Train: 0.002877 | Val: 0.009230 | LR: 5.00e-05 | Best: 0.008929 (ep 6)
[03:19:11] Early stopping at epoch 16 (no improvement for 10 epochs)
[03:19:12] Factor 6 done — best val loss: 0.008929 at epoch 6
[03:19:12] 
Best factor: 5 (val loss 0.008858)
[03:19:12] Training done. Best factor=5, val_loss=0.008858
[03:19:48] Building validation dataset...
[03:19:48] Building features: 0% (1/175846)
[03:19:49] Building features: 5% (8793/175846)
[03:19:49] Building features: 10% (17585/175846)
[03:19:50] Building features: 15% (26377/175846)
[03:19:50] Building features: 20% (35169/175846)
[03:19:51] Building features: 25% (43961/175846)
[03:19:51] Building features: 30% (52753/175846)
[03:19:52] Building features: 35% (61545/175846)
[03:19:52] Building features: 40% (70337/175846)
[03:19:53] Building features: 45% (79129/175846)
[03:19:53] Building features: 50% (87921/175846)
[03:19:54] Building features: 55% (96713/175846)
[03:19:54] Building features: 60% (105505/175846)
[03:19:55] Building features: 65% (114297/175846)
[03:19:55] Building features: 70% (123089/175846)
[03:19:56] Building features: 75% (131881/175846)
[03:19:56] Building features: 80% (140673/175846)
[03:19:57] Building features: 85% (149465/175846)
[03:19:57] Building features: 90% (158257/175846)
[03:19:58] Building features: 95% (167049/175846)
[03:19:58] Building features: 100% (175841/175846)
[03:19:58] Computing Hurst exponent...
[03:20:03] Computing market regimes (GMM)...
[03:20:10] Running backtest...
[03:20:10] Backtest complete: 0 trades, WR=0.0%, PF=0.00
[03:21:07] Building validation dataset...
[03:21:07] Building features: 0% (1/175846)
[03:21:07] Building features: 5% (8793/175846)
[03:21:08] Building features: 10% (17585/175846)
[03:21:08] Building features: 15% (26377/175846)
[03:21:09] Building features: 20% (35169/175846)
[03:21:09] Building features: 25% (43961/175846)
[03:21:10] Building features: 30% (52753/175846)
[03:21:10] Building features: 35% (61545/175846)
[03:21:11] Building features: 40% (70337/175846)
[03:21:11] Building features: 45% (79129/175846)
[03:21:12] Building features: 50% (87921/175846)
[03:21:12] Building features: 55% (96713/175846)
[03:21:13] Building features: 60% (105505/175846)
[03:21:13] Building features: 65% (114297/175846)
[03:21:14] Building features: 70% (123089/175846)
[03:21:14] Building features: 75% (131881/175846)
[03:21:15] Building features: 80% (140673/175846)
[03:21:15] Building features: 85% (149465/175846)
[03:21:16] Building features: 90% (158257/175846)
[03:21:16] Building features: 95% (167049/175846)
[03:21:17] Building features: 100% (175841/175846)
[03:21:17] Computing Hurst exponent...
[03:21:22] Computing market regimes (GMM)...
[03:21:29] Running backtest...
[03:21:30] Backtest complete: 7 trades, WR=14.3%, PF=0.28
[03:22:23] Training started.
[03:22:23] 
============================================================
[03:22:23] STF Factor 3 of [3..6]
[03:22:23] ============================================================
[03:22:23] Building features: 0% (1/175846)
[03:22:24] Building features: 5% (8793/175846)
[03:22:24] Building features: 10% (17585/175846)
[03:22:25] Building features: 15% (26377/175846)
[03:22:25] Building features: 20% (35169/175846)
[03:22:26] Building features: 25% (43961/175846)
[03:22:26] Building features: 30% (52753/175846)
[03:22:27] Building features: 35% (61545/175846)
[03:22:27] Building features: 40% (70337/175846)
[03:22:28] Building features: 45% (79129/175846)
[03:22:28] Building features: 50% (87921/175846)
[03:22:29] Building features: 55% (96713/175846)
[03:22:30] Building features: 60% (105505/175846)
[03:22:30] Building features: 65% (114297/175846)
[03:22:31] Building features: 70% (123089/175846)
[03:22:31] Building features: 75% (131881/175846)
[03:22:32] Building features: 80% (140673/175846)
[03:22:32] Building features: 85% (149465/175846)
[03:22:33] Building features: 90% (158257/175846)
[03:22:33] Building features: 95% (167049/175846)
[03:22:34] Building features: 100% (175841/175846)
[03:22:34] Computing Hurst exponent...
[03:22:39] Computing market regimes (GMM)...
[03:22:46] Factor 3: 175704 samples, 92 features
[03:22:48] Batch stats — Input:  mean=0.0556 std=0.2591 min=-3.5438 max=7.6216
[03:22:48] Batch stats — Target: mean=-0.0036 std=0.0624 min=-0.4720 max=0.3386
[03:22:48] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:22:52] Epoch 1/100 | Train: 0.003819 | Val: 0.010448 | LR: 1.00e-04 | Best: 0.010448 (ep 1)
[03:22:54] Epoch 2/100 | Train: 0.003112 | Val: 0.009422 | LR: 1.00e-04 | Best: 0.009422 (ep 2)
[03:22:56] Epoch 3/100 | Train: 0.003048 | Val: 0.009226 | LR: 1.00e-04 | Best: 0.009226 (ep 3)
[03:22:59] Epoch 4/100 | Train: 0.003003 | Val: 0.009085 | LR: 1.00e-04 | Best: 0.009085 (ep 4)
[03:23:01] Epoch 5/100 | Train: 0.002977 | Val: 0.008894 | LR: 1.00e-04 | Best: 0.008894 (ep 5)
[03:23:03] Epoch 6/100 | Train: 0.002956 | Val: 0.008856 | LR: 1.00e-04 | Best: 0.008856 (ep 6)
[03:23:06] Epoch 7/100 | Train: 0.002944 | Val: 0.008920 | LR: 1.00e-04 | Best: 0.008856 (ep 6)
[03:23:08] Epoch 8/100 | Train: 0.002931 | Val: 0.008852 | LR: 1.00e-04 | Best: 0.008852 (ep 8)
[03:23:10] Epoch 9/100 | Train: 0.002925 | Val: 0.008849 | LR: 1.00e-04 | Best: 0.008849 (ep 9)
[03:23:12] Epoch 10/100 | Train: 0.002911 | Val: 0.008823 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:14] Epoch 11/100 | Train: 0.002908 | Val: 0.008831 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:16] Epoch 12/100 | Train: 0.002901 | Val: 0.008971 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:18] Epoch 13/100 | Train: 0.002897 | Val: 0.008917 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:20] Epoch 14/100 | Train: 0.002891 | Val: 0.008918 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:23] Epoch 15/100 | Train: 0.002886 | Val: 0.009057 | LR: 1.00e-04 | Best: 0.008823 (ep 10)
[03:23:25] Epoch 16/100 | Train: 0.002882 | Val: 0.009084 | LR: 5.00e-05 | Best: 0.008823 (ep 10)
[03:23:27] Epoch 17/100 | Train: 0.002871 | Val: 0.009120 | LR: 5.00e-05 | Best: 0.008823 (ep 10)
[03:23:29] Epoch 18/100 | Train: 0.002868 | Val: 0.009026 | LR: 5.00e-05 | Best: 0.008823 (ep 10)
[03:23:32] Epoch 19/100 | Train: 0.002866 | Val: 0.009253 | LR: 5.00e-05 | Best: 0.008823 (ep 10)
[03:23:34] Epoch 20/100 | Train: 0.002862 | Val: 0.009144 | LR: 5.00e-05 | Best: 0.008823 (ep 10)
[03:23:34] Early stopping at epoch 20 (no improvement for 10 epochs)
[03:23:35] Factor 3 done — best val loss: 0.008823 at epoch 10
[03:23:35] 
============================================================
[03:23:35] STF Factor 4 of [3..6]
[03:23:35] ============================================================
[03:23:35] Building features: 0% (1/175846)
[03:23:36] Building features: 5% (8793/175846)
[03:23:36] Building features: 10% (17585/175846)
[03:23:37] Building features: 15% (26377/175846)
[03:23:37] Building features: 20% (35169/175846)
[03:23:38] Building features: 25% (43961/175846)
[03:23:38] Building features: 30% (52753/175846)
[03:23:39] Building features: 35% (61545/175846)
[03:23:39] Building features: 40% (70337/175846)
[03:23:40] Building features: 45% (79129/175846)
[03:23:40] Building features: 50% (87921/175846)
[03:23:41] Building features: 55% (96713/175846)
[03:23:41] Building features: 60% (105505/175846)
[03:23:42] Building features: 65% (114297/175846)
[03:23:42] Building features: 70% (123089/175846)
[03:23:43] Building features: 75% (131881/175846)
[03:23:43] Building features: 80% (140673/175846)
[03:23:44] Building features: 85% (149465/175846)
[03:23:44] Building features: 90% (158257/175846)
[03:23:45] Building features: 95% (167049/175846)
[03:23:45] Building features: 100% (175841/175846)
[03:23:45] Computing Hurst exponent...
[03:23:50] Computing market regimes (GMM)...
[03:23:57] Factor 4: 175704 samples, 92 features
[03:23:59] Batch stats — Input:  mean=0.0540 std=0.2689 min=-7.0610 max=22.9822
[03:23:59] Batch stats — Target: mean=0.0005 std=0.0626 min=-0.4720 max=0.3010
[03:23:59] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:24:03] Epoch 1/100 | Train: 0.003901 | Val: 0.011158 | LR: 1.00e-04 | Best: 0.011158 (ep 1)
[03:24:05] Epoch 2/100 | Train: 0.003111 | Val: 0.009483 | LR: 1.00e-04 | Best: 0.009483 (ep 2)
[03:24:07] Epoch 3/100 | Train: 0.003054 | Val: 0.009248 | LR: 1.00e-04 | Best: 0.009248 (ep 3)
[03:24:10] Epoch 4/100 | Train: 0.003016 | Val: 0.009100 | LR: 1.00e-04 | Best: 0.009100 (ep 4)
[03:24:12] Epoch 5/100 | Train: 0.002990 | Val: 0.009013 | LR: 1.00e-04 | Best: 0.009013 (ep 5)
[03:24:14] Epoch 6/100 | Train: 0.002971 | Val: 0.008944 | LR: 1.00e-04 | Best: 0.008944 (ep 6)
[03:24:17] Epoch 7/100 | Train: 0.002953 | Val: 0.008911 | LR: 1.00e-04 | Best: 0.008911 (ep 7)
[03:24:19] Epoch 8/100 | Train: 0.002942 | Val: 0.008934 | LR: 1.00e-04 | Best: 0.008911 (ep 7)
[03:24:21] Epoch 9/100 | Train: 0.002932 | Val: 0.009007 | LR: 1.00e-04 | Best: 0.008911 (ep 7)
[03:24:23] Epoch 10/100 | Train: 0.002925 | Val: 0.008964 | LR: 1.00e-04 | Best: 0.008911 (ep 7)
[03:24:26] Epoch 11/100 | Train: 0.002913 | Val: 0.009086 | LR: 1.00e-04 | Best: 0.008911 (ep 7)
[03:24:28] Epoch 12/100 | Train: 0.002907 | Val: 0.008888 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:30] Epoch 13/100 | Train: 0.002900 | Val: 0.009046 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:32] Epoch 14/100 | Train: 0.002894 | Val: 0.009115 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:34] Epoch 15/100 | Train: 0.002892 | Val: 0.009129 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:37] Epoch 16/100 | Train: 0.002883 | Val: 0.009153 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:39] Epoch 17/100 | Train: 0.002881 | Val: 0.009454 | LR: 1.00e-04 | Best: 0.008888 (ep 12)
[03:24:41] Epoch 18/100 | Train: 0.002873 | Val: 0.009253 | LR: 5.00e-05 | Best: 0.008888 (ep 12)
[03:24:43] Epoch 19/100 | Train: 0.002863 | Val: 0.009566 | LR: 5.00e-05 | Best: 0.008888 (ep 12)
[03:24:46] Epoch 20/100 | Train: 0.002857 | Val: 0.009615 | LR: 5.00e-05 | Best: 0.008888 (ep 12)
[03:24:48] Epoch 21/100 | Train: 0.002856 | Val: 0.009522 | LR: 5.00e-05 | Best: 0.008888 (ep 12)
[03:24:50] Epoch 22/100 | Train: 0.002851 | Val: 0.009711 | LR: 5.00e-05 | Best: 0.008888 (ep 12)
[03:24:50] Early stopping at epoch 22 (no improvement for 10 epochs)
[03:24:51] Factor 4 done — best val loss: 0.008888 at epoch 12
[03:24:51] 
============================================================
[03:24:51] STF Factor 5 of [3..6]
[03:24:51] ============================================================
[03:24:51] Building features: 0% (1/175846)
[03:24:52] Building features: 5% (8793/175846)
[03:24:52] Building features: 10% (17585/175846)
[03:24:53] Building features: 15% (26377/175846)
[03:24:53] Building features: 20% (35169/175846)
[03:24:54] Building features: 25% (43961/175846)
[03:24:55] Building features: 30% (52753/175846)
[03:24:55] Building features: 35% (61545/175846)
[03:24:56] Building features: 40% (70337/175846)
[03:24:56] Building features: 45% (79129/175846)
[03:24:57] Building features: 50% (87921/175846)
[03:24:57] Building features: 55% (96713/175846)
[03:24:58] Building features: 60% (105505/175846)
[03:24:58] Building features: 65% (114297/175846)
[03:24:59] Building features: 70% (123089/175846)
[03:24:59] Building features: 75% (131881/175846)
[03:25:00] Building features: 80% (140673/175846)
[03:25:00] Building features: 85% (149465/175846)
[03:25:01] Building features: 90% (158257/175846)
[03:25:01] Building features: 95% (167049/175846)
[03:25:02] Building features: 100% (175841/175846)
[03:25:02] Computing Hurst exponent...
[03:25:07] Computing market regimes (GMM)...
[03:25:13] Factor 5: 175704 samples, 92 features
[03:25:15] Batch stats — Input:  mean=0.0558 std=0.2637 min=-5.3639 max=9.5561
[03:25:15] Batch stats — Target: mean=-0.0020 std=0.0697 min=-0.4720 max=0.4134
[03:25:15] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:25:20] Epoch 1/100 | Train: 0.003917 | Val: 0.011523 | LR: 1.00e-04 | Best: 0.011523 (ep 1)
[03:25:22] Epoch 2/100 | Train: 0.003111 | Val: 0.009750 | LR: 1.00e-04 | Best: 0.009750 (ep 2)
[03:25:24] Epoch 3/100 | Train: 0.003053 | Val: 0.009269 | LR: 1.00e-04 | Best: 0.009269 (ep 3)
[03:25:26] Epoch 4/100 | Train: 0.003016 | Val: 0.009115 | LR: 1.00e-04 | Best: 0.009115 (ep 4)
[03:25:29] Epoch 5/100 | Train: 0.002982 | Val: 0.009041 | LR: 1.00e-04 | Best: 0.009041 (ep 5)
[03:25:31] Epoch 6/100 | Train: 0.002967 | Val: 0.008994 | LR: 1.00e-04 | Best: 0.008994 (ep 6)
[03:25:33] Epoch 7/100 | Train: 0.002951 | Val: 0.009000 | LR: 1.00e-04 | Best: 0.008994 (ep 6)
[03:25:35] Epoch 8/100 | Train: 0.002941 | Val: 0.008924 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:38] Epoch 9/100 | Train: 0.002932 | Val: 0.008960 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:40] Epoch 10/100 | Train: 0.002919 | Val: 0.008938 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:42] Epoch 11/100 | Train: 0.002913 | Val: 0.009046 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:44] Epoch 12/100 | Train: 0.002907 | Val: 0.009101 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:47] Epoch 13/100 | Train: 0.002903 | Val: 0.008946 | LR: 1.00e-04 | Best: 0.008924 (ep 8)
[03:25:49] Epoch 14/100 | Train: 0.002895 | Val: 0.009233 | LR: 5.00e-05 | Best: 0.008924 (ep 8)
[03:25:51] Epoch 15/100 | Train: 0.002885 | Val: 0.009169 | LR: 5.00e-05 | Best: 0.008924 (ep 8)
[03:25:53] Epoch 16/100 | Train: 0.002884 | Val: 0.009268 | LR: 5.00e-05 | Best: 0.008924 (ep 8)
[03:25:55] Epoch 17/100 | Train: 0.002879 | Val: 0.009596 | LR: 5.00e-05 | Best: 0.008924 (ep 8)
[03:25:58] Epoch 18/100 | Train: 0.002874 | Val: 0.009577 | LR: 5.00e-05 | Best: 0.008924 (ep 8)
[03:25:58] Early stopping at epoch 18 (no improvement for 10 epochs)
[03:25:59] Factor 5 done — best val loss: 0.008924 at epoch 8
[03:25:59] 
============================================================
[03:25:59] STF Factor 6 of [3..6]
[03:25:59] ============================================================
[03:25:59] Building features: 0% (1/175846)
[03:25:59] Building features: 5% (8793/175846)
[03:26:00] Building features: 10% (17585/175846)
[03:26:00] Building features: 15% (26377/175846)
[03:26:01] Building features: 20% (35169/175846)
[03:26:01] Building features: 25% (43961/175846)
[03:26:02] Building features: 30% (52753/175846)
[03:26:03] Building features: 35% (61545/175846)
[03:26:03] Building features: 40% (70337/175846)
[03:26:04] Building features: 45% (79129/175846)
[03:26:04] Building features: 50% (87921/175846)
[03:26:05] Building features: 55% (96713/175846)
[03:26:05] Building features: 60% (105505/175846)
[03:26:06] Building features: 65% (114297/175846)
[03:26:06] Building features: 70% (123089/175846)
[03:26:07] Building features: 75% (131881/175846)
[03:26:07] Building features: 80% (140673/175846)
[03:26:08] Building features: 85% (149465/175846)
[03:26:08] Building features: 90% (158257/175846)
[03:26:09] Building features: 95% (167049/175846)
[03:26:09] Building features: 100% (175841/175846)
[03:26:09] Computing Hurst exponent...
[03:26:14] Computing market regimes (GMM)...
[03:26:20] Factor 6: 175704 samples, 92 features
[03:26:22] Batch stats — Input:  mean=0.0530 std=0.2677 min=-4.0254 max=12.2195
[03:26:22] Batch stats — Target: mean=-0.0022 std=0.0666 min=-0.4720 max=0.3501
[03:26:22] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:26:25] Epoch 1/100 | Train: 0.003830 | Val: 0.010635 | LR: 1.00e-04 | Best: 0.010635 (ep 1)
[03:26:27] Epoch 2/100 | Train: 0.003107 | Val: 0.009567 | LR: 1.00e-04 | Best: 0.009567 (ep 2)
[03:26:29] Epoch 3/100 | Train: 0.003044 | Val: 0.009162 | LR: 1.00e-04 | Best: 0.009162 (ep 3)
[03:26:31] Epoch 4/100 | Train: 0.003006 | Val: 0.009057 | LR: 1.00e-04 | Best: 0.009057 (ep 4)
[03:26:33] Epoch 5/100 | Train: 0.002976 | Val: 0.008972 | LR: 1.00e-04 | Best: 0.008972 (ep 5)
[03:26:35] Epoch 6/100 | Train: 0.002955 | Val: 0.009032 | LR: 1.00e-04 | Best: 0.008972 (ep 5)
[03:26:37] Epoch 7/100 | Train: 0.002944 | Val: 0.008928 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:40] Epoch 8/100 | Train: 0.002932 | Val: 0.009014 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:42] Epoch 9/100 | Train: 0.002924 | Val: 0.009004 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:44] Epoch 10/100 | Train: 0.002915 | Val: 0.009018 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:47] Epoch 11/100 | Train: 0.002906 | Val: 0.009092 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:49] Epoch 12/100 | Train: 0.002901 | Val: 0.009109 | LR: 1.00e-04 | Best: 0.008928 (ep 7)
[03:26:51] Epoch 13/100 | Train: 0.002897 | Val: 0.009054 | LR: 5.00e-05 | Best: 0.008928 (ep 7)
[03:26:53] Epoch 14/100 | Train: 0.002886 | Val: 0.009151 | LR: 5.00e-05 | Best: 0.008928 (ep 7)
[03:26:56] Epoch 15/100 | Train: 0.002882 | Val: 0.009155 | LR: 5.00e-05 | Best: 0.008928 (ep 7)
[03:26:58] Epoch 16/100 | Train: 0.002878 | Val: 0.009168 | LR: 5.00e-05 | Best: 0.008928 (ep 7)
[03:27:00] Epoch 17/100 | Train: 0.002878 | Val: 0.009347 | LR: 5.00e-05 | Best: 0.008928 (ep 7)
[03:27:00] Early stopping at epoch 17 (no improvement for 10 epochs)
[03:27:01] Factor 6 done — best val loss: 0.008928 at epoch 7
[03:27:01] 
Best factor: 3 (val loss 0.008823)
[03:27:01] Training done. Best factor=3, val_loss=0.008823
[03:27:20] Building validation dataset...
[03:27:20] Building features: 0% (1/175846)
[03:27:20] Building features: 5% (8793/175846)
[03:27:21] Building features: 10% (17585/175846)
[03:27:21] Building features: 15% (26377/175846)
[03:27:22] Building features: 20% (35169/175846)
[03:27:22] Building features: 25% (43961/175846)
[03:27:23] Building features: 30% (52753/175846)
[03:27:23] Building features: 35% (61545/175846)
[03:27:24] Building features: 40% (70337/175846)
[03:27:24] Building features: 45% (79129/175846)
[03:27:25] Building features: 50% (87921/175846)
[03:27:25] Building features: 55% (96713/175846)
[03:27:26] Building features: 60% (105505/175846)
[03:27:26] Building features: 65% (114297/175846)
[03:27:27] Building features: 70% (123089/175846)
[03:27:27] Building features: 75% (131881/175846)
[03:27:28] Building features: 80% (140673/175846)
[03:27:28] Building features: 85% (149465/175846)
[03:27:29] Building features: 90% (158257/175846)
[03:27:29] Building features: 95% (167049/175846)
[03:27:30] Building features: 100% (175841/175846)
[03:27:30] Computing Hurst exponent...
[03:27:35] Computing market regimes (GMM)...
[03:27:42] Running backtest...
[03:27:42] Backtest complete: 0 trades, WR=0.0%, PF=0.00
[03:28:54] Training started.
[03:28:54] 
============================================================
[03:28:54] STF Factor 10 of [10..11]
[03:28:54] ============================================================
[03:28:54] Building features: 0% (1/175846)
[03:28:55] Building features: 5% (8793/175846)
[03:28:55] Building features: 10% (17585/175846)
[03:28:56] Building features: 15% (26377/175846)
[03:28:56] Building features: 20% (35169/175846)
[03:28:57] Building features: 25% (43961/175846)
[03:28:57] Building features: 30% (52753/175846)
[03:28:57] Building features: 35% (61545/175846)
[03:28:58] Building features: 40% (70337/175846)
[03:28:58] Building features: 45% (79129/175846)
[03:28:59] Building features: 50% (87921/175846)
[03:28:59] Building features: 55% (96713/175846)
[03:29:00] Building features: 60% (105505/175846)
[03:29:00] Building features: 65% (114297/175846)
[03:29:01] Building features: 70% (123089/175846)
[03:29:01] Building features: 75% (131881/175846)
[03:29:02] Building features: 80% (140673/175846)
[03:29:02] Building features: 85% (149465/175846)
[03:29:03] Building features: 90% (158257/175846)
[03:29:03] Building features: 95% (167049/175846)
[03:29:04] Building features: 100% (175841/175846)
[03:29:04] Computing Hurst exponent...
[03:29:09] Computing market regimes (GMM)...
[03:29:16] Factor 10: 175644 samples, 92 features
[03:29:18] Batch stats — Input:  mean=0.0546 std=0.2647 min=-6.3104 max=9.9344
[03:29:18] Batch stats — Target: mean=-0.0019 std=0.0574 min=-0.4720 max=0.2442
[03:29:18] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:29:23] Epoch 1/100 | Train: 0.003852 | Val: 0.010706 | LR: 1.00e-04 | Best: 0.010706 (ep 1)
[03:29:25] Epoch 2/100 | Train: 0.003114 | Val: 0.009526 | LR: 1.00e-04 | Best: 0.009526 (ep 2)
[03:29:28] Epoch 3/100 | Train: 0.003062 | Val: 0.009345 | LR: 1.00e-04 | Best: 0.009345 (ep 3)
[03:29:31] Epoch 4/100 | Train: 0.003031 | Val: 0.009157 | LR: 1.00e-04 | Best: 0.009157 (ep 4)
[03:29:34] Epoch 5/100 | Train: 0.002998 | Val: 0.009091 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:37] Epoch 6/100 | Train: 0.002975 | Val: 0.009103 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:40] Epoch 7/100 | Train: 0.002958 | Val: 0.009105 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:43] Epoch 8/100 | Train: 0.002944 | Val: 0.009151 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:47] Epoch 9/100 | Train: 0.002932 | Val: 0.009233 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:50] Epoch 10/100 | Train: 0.002923 | Val: 0.009195 | LR: 1.00e-04 | Best: 0.009091 (ep 5)
[03:29:53] Epoch 11/100 | Train: 0.002916 | Val: 0.009268 | LR: 5.00e-05 | Best: 0.009091 (ep 5)
[03:29:56] Epoch 12/100 | Train: 0.002900 | Val: 0.009312 | LR: 5.00e-05 | Best: 0.009091 (ep 5)
[03:29:59] Epoch 13/100 | Train: 0.002898 | Val: 0.009323 | LR: 5.00e-05 | Best: 0.009091 (ep 5)
[03:30:02] Epoch 14/100 | Train: 0.002895 | Val: 0.009395 | LR: 5.00e-05 | Best: 0.009091 (ep 5)
[03:30:05] Epoch 15/100 | Train: 0.002891 | Val: 0.009511 | LR: 5.00e-05 | Best: 0.009091 (ep 5)
[03:30:05] Early stopping at epoch 15 (no improvement for 10 epochs)
[03:30:06] Factor 10 done — best val loss: 0.009091 at epoch 5
[03:30:06] 
============================================================
[03:30:06] STF Factor 11 of [10..11]
[03:30:06] ============================================================
[03:30:06] Building features: 0% (1/175846)
[03:30:07] Building features: 5% (8793/175846)
[03:30:07] Building features: 10% (17585/175846)
[03:30:08] Building features: 15% (26377/175846)
[03:30:08] Building features: 20% (35169/175846)
[03:30:09] Building features: 25% (43961/175846)
[03:30:09] Building features: 30% (52753/175846)
[03:30:10] Building features: 35% (61545/175846)
[03:30:10] Building features: 40% (70337/175846)
[03:30:11] Building features: 45% (79129/175846)
[03:30:11] Building features: 50% (87921/175846)
[03:30:12] Building features: 55% (96713/175846)
[03:30:12] Building features: 60% (105505/175846)
[03:30:13] Building features: 65% (114297/175846)
[03:30:14] Building features: 70% (123089/175846)
[03:30:14] Building features: 75% (131881/175846)
[03:30:15] Building features: 80% (140673/175846)
[03:30:15] Building features: 85% (149465/175846)
[03:30:16] Building features: 90% (158257/175846)
[03:30:16] Building features: 95% (167049/175846)
[03:30:17] Building features: 100% (175841/175846)
[03:30:17] Computing Hurst exponent...
[03:30:22] Computing market regimes (GMM)...
[03:30:29] Factor 11: 175644 samples, 92 features
[03:30:30] Batch stats — Input:  mean=0.0498 std=0.2723 min=-6.3561 max=12.7797
[03:30:30] Batch stats — Target: mean=-0.0028 std=0.0645 min=-0.4720 max=0.4134
[03:30:30] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[03:30:35] Epoch 1/100 | Train: 0.003781 | Val: 0.010715 | LR: 1.00e-04 | Best: 0.010715 (ep 1)
[03:30:38] Epoch 2/100 | Train: 0.003100 | Val: 0.009553 | LR: 1.00e-04 | Best: 0.009553 (ep 2)
[03:30:41] Epoch 3/100 | Train: 0.003047 | Val: 0.009366 | LR: 1.00e-04 | Best: 0.009366 (ep 3)
[03:30:44] Epoch 4/100 | Train: 0.003011 | Val: 0.009169 | LR: 1.00e-04 | Best: 0.009169 (ep 4)
[03:30:47] Epoch 5/100 | Train: 0.002983 | Val: 0.009118 | LR: 1.00e-04 | Best: 0.009118 (ep 5)
[03:30:50] Epoch 6/100 | Train: 0.002968 | Val: 0.008926 | LR: 1.00e-04 | Best: 0.008926 (ep 6)
[03:30:52] Epoch 7/100 | Train: 0.002948 | Val: 0.009045 | LR: 1.00e-04 | Best: 0.008926 (ep 6)
[03:30:55] Epoch 8/100 | Train: 0.002934 | Val: 0.008909 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:30:58] Epoch 9/100 | Train: 0.002930 | Val: 0.009017 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:31:01] Epoch 10/100 | Train: 0.002918 | Val: 0.008997 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:31:04] Epoch 11/100 | Train: 0.002908 | Val: 0.009100 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:31:07] Epoch 12/100 | Train: 0.002905 | Val: 0.009045 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:31:10] Epoch 13/100 | Train: 0.002901 | Val: 0.008983 | LR: 1.00e-04 | Best: 0.008909 (ep 8)
[03:31:13] Epoch 14/100 | Train: 0.002894 | Val: 0.008982 | LR: 5.00e-05 | Best: 0.008909 (ep 8)
[03:31:16] Epoch 15/100 | Train: 0.002882 | Val: 0.009128 | LR: 5.00e-05 | Best: 0.008909 (ep 8)
[03:31:19] Epoch 16/100 | Train: 0.002880 | Val: 0.009309 | LR: 5.00e-05 | Best: 0.008909 (ep 8)
[03:31:22] Epoch 17/100 | Train: 0.002876 | Val: 0.009160 | LR: 5.00e-05 | Best: 0.008909 (ep 8)
[03:31:25] Epoch 18/100 | Train: 0.002872 | Val: 0.009319 | LR: 5.00e-05 | Best: 0.008909 (ep 8)
[03:31:25] Early stopping at epoch 18 (no improvement for 10 epochs)
[03:31:26] Factor 11 done — best val loss: 0.008909 at epoch 8
[03:31:26] 
Best factor: 11 (val loss 0.008909)
[03:31:26] Training done. Best factor=11, val_loss=0.008909
[03:31:43] Building validation dataset...
[03:31:44] Building features: 0% (1/175846)
[03:31:44] Building features: 5% (8793/175846)
[03:31:45] Building features: 10% (17585/175846)
[03:31:45] Building features: 15% (26377/175846)
[03:31:45] Building features: 20% (35169/175846)
[03:31:46] Building features: 25% (43961/175846)
[03:31:46] Building features: 30% (52753/175846)
[03:31:47] Building features: 35% (61545/175846)
[03:31:47] Building features: 40% (70337/175846)
[03:31:48] Building features: 45% (79129/175846)
[03:31:48] Building features: 50% (87921/175846)
[03:31:49] Building features: 55% (96713/175846)
[03:31:49] Building features: 60% (105505/175846)
[03:31:50] Building features: 65% (114297/175846)
[03:31:50] Building features: 70% (123089/175846)
[03:31:51] Building features: 75% (131881/175846)
[03:31:51] Building features: 80% (140673/175846)
[03:31:52] Building features: 85% (149465/175846)
[03:31:52] Building features: 90% (158257/175846)
[03:31:53] Building features: 95% (167049/175846)
[03:31:53] Building features: 100% (175841/175846)
[03:31:53] Computing Hurst exponent...
[03:31:59] Computing market regimes (GMM)...
[03:32:05] Running backtest...
[03:32:06] Backtest complete: 271 trades, WR=63.8%, PF=1.97
[04:33:17] NTCP initialized.
[04:33:39] Loaded 175846 M5 bars.
[04:34:14] Training started.
[04:34:14] 
============================================================
[04:34:14] STF Factor 2 of [2..15]
[04:34:14] ============================================================
[04:34:14] Building features: 0% (1/175846)
[04:34:15] Building features: 5% (8793/175846)
[04:34:15] Building features: 10% (17585/175846)
[04:34:16] Building features: 15% (26377/175846)
[04:34:16] Building features: 20% (35169/175846)
[04:34:17] Building features: 25% (43961/175846)
[04:34:17] Building features: 30% (52753/175846)
[04:34:18] Building features: 35% (61545/175846)
[04:34:18] Building features: 40% (70337/175846)
[04:34:19] Building features: 45% (79129/175846)
[04:34:19] Building features: 50% (87921/175846)
[04:34:20] Building features: 55% (96713/175846)
[04:34:20] Building features: 60% (105505/175846)
[04:34:21] Building features: 65% (114297/175846)
[04:34:21] Building features: 70% (123089/175846)
[04:34:22] Building features: 75% (131881/175846)
[04:34:22] Building features: 80% (140673/175846)
[04:34:23] Building features: 85% (149465/175846)
[04:34:24] Building features: 90% (158257/175846)
[04:34:24] Building features: 95% (167049/175846)
[04:34:25] Building features: 100% (175841/175846)
[04:34:25] Computing Hurst exponent...
[04:34:30] Computing market regimes (GMM)...
[04:34:44] Factor 2: 175704 samples, 92 features
[04:34:45] Batch stats — Input:  mean=0.0571 std=0.2712 min=-5.4479 max=60.4783
[04:34:45] Batch stats — Target: mean=0.0019 std=0.0620 min=-0.4680 max=0.3762
[04:34:45] Batch stats — Cls:    pos_long=111/256 pos_short=102/256
[04:34:45] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:34:50] Epoch 1/100 | Train: 0.666520 | Val: 0.679154 | LR: 1.00e-04 | Best: 0.679154 (ep 1)
[04:34:53] Epoch 2/100 | Train: 0.664551 | Val: 0.678133 | LR: 1.00e-04 | Best: 0.678133 (ep 2)
[04:34:55] Epoch 3/100 | Train: 0.664340 | Val: 0.678296 | LR: 1.00e-04 | Best: 0.678133 (ep 2)
[04:34:58] Epoch 4/100 | Train: 0.664134 | Val: 0.677763 | LR: 1.00e-04 | Best: 0.677763 (ep 4)
[04:35:00] Epoch 5/100 | Train: 0.664079 | Val: 0.677153 | LR: 1.00e-04 | Best: 0.677153 (ep 5)
[04:35:03] Epoch 6/100 | Train: 0.663824 | Val: 0.676773 | LR: 1.00e-04 | Best: 0.676773 (ep 6)
[04:35:05] Epoch 7/100 | Train: 0.663831 | Val: 0.676527 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:08] Epoch 8/100 | Train: 0.663755 | Val: 0.676760 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:10] Epoch 9/100 | Train: 0.663635 | Val: 0.676836 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:13] Epoch 10/100 | Train: 0.663525 | Val: 0.676685 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:15] Epoch 11/100 | Train: 0.663535 | Val: 0.676575 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:18] Epoch 12/100 | Train: 0.663450 | Val: 0.676597 | LR: 1.00e-04 | Best: 0.676527 (ep 7)
[04:35:20] Epoch 13/100 | Train: 0.663368 | Val: 0.676525 | LR: 5.00e-05 | Best: 0.676525 (ep 13)
[04:35:23] Epoch 14/100 | Train: 0.663224 | Val: 0.676902 | LR: 5.00e-05 | Best: 0.676525 (ep 13)
[04:35:26] Epoch 15/100 | Train: 0.663049 | Val: 0.676540 | LR: 5.00e-05 | Best: 0.676525 (ep 13)
[04:35:29] Epoch 16/100 | Train: 0.663134 | Val: 0.676400 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:32] Epoch 17/100 | Train: 0.663081 | Val: 0.676574 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:35] Epoch 18/100 | Train: 0.663106 | Val: 0.676808 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:38] Epoch 19/100 | Train: 0.663024 | Val: 0.676541 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:40] Epoch 20/100 | Train: 0.662938 | Val: 0.676494 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:43] Epoch 21/100 | Train: 0.663014 | Val: 0.676497 | LR: 5.00e-05 | Best: 0.676400 (ep 16)
[04:35:45] Epoch 22/100 | Train: 0.662942 | Val: 0.677088 | LR: 2.50e-05 | Best: 0.676400 (ep 16)
[04:35:48] Epoch 23/100 | Train: 0.662879 | Val: 0.676880 | LR: 2.50e-05 | Best: 0.676400 (ep 16)
[04:35:50] Epoch 24/100 | Train: 0.662803 | Val: 0.676716 | LR: 2.50e-05 | Best: 0.676400 (ep 16)
[04:35:53] Epoch 25/100 | Train: 0.662812 | Val: 0.677164 | LR: 2.50e-05 | Best: 0.676400 (ep 16)
[04:35:55] Epoch 26/100 | Train: 0.662731 | Val: 0.676767 | LR: 2.50e-05 | Best: 0.676400 (ep 16)
[04:35:55] Early stopping at epoch 26 (no improvement for 10 epochs)
[04:35:56] Factor 2 done — best val loss: 0.676400 at epoch 16
[04:35:56] 
============================================================
[04:35:56] STF Factor 3 of [2..15]
[04:35:56] ============================================================
[04:35:56] Building features: 0% (1/175846)
[04:35:57] Building features: 5% (8793/175846)
[04:35:57] Building features: 10% (17585/175846)
[04:35:58] Building features: 15% (26377/175846)
[04:35:58] Building features: 20% (35169/175846)
[04:35:59] Building features: 25% (43961/175846)
[04:35:59] Building features: 30% (52753/175846)
[04:36:00] Building features: 35% (61545/175846)
[04:36:00] Building features: 40% (70337/175846)
[04:36:01] Building features: 45% (79129/175846)
[04:36:01] Building features: 50% (87921/175846)
[04:36:02] Building features: 55% (96713/175846)
[04:36:02] Building features: 60% (105505/175846)
[04:36:03] Building features: 65% (114297/175846)
[04:36:03] Building features: 70% (123089/175846)
[04:36:04] Building features: 75% (131881/175846)
[04:36:04] Building features: 80% (140673/175846)
[04:36:05] Building features: 85% (149465/175846)
[04:36:05] Building features: 90% (158257/175846)
[04:36:06] Building features: 95% (167049/175846)
[04:36:06] Building features: 100% (175841/175846)
[04:36:06] Computing Hurst exponent...
[04:36:11] Computing market regimes (GMM)...
[04:36:18] Factor 3: 175704 samples, 92 features
[04:36:20] Batch stats — Input:  mean=0.0566 std=0.2569 min=-3.3103 max=6.0399
[04:36:20] Batch stats — Target: mean=-0.0018 std=0.0635 min=-0.4720 max=0.2924
[04:36:20] Batch stats — Cls:    pos_long=106/256 pos_short=89/256
[04:36:20] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:36:25] Epoch 1/100 | Train: 0.666839 | Val: 0.679484 | LR: 1.00e-04 | Best: 0.679484 (ep 1)
[04:36:28] Epoch 2/100 | Train: 0.664538 | Val: 0.677906 | LR: 1.00e-04 | Best: 0.677906 (ep 2)
[04:36:31] Epoch 3/100 | Train: 0.664394 | Val: 0.677538 | LR: 1.00e-04 | Best: 0.677538 (ep 3)
[04:36:34] Epoch 4/100 | Train: 0.664190 | Val: 0.677231 | LR: 1.00e-04 | Best: 0.677231 (ep 4)
[04:36:37] Epoch 5/100 | Train: 0.663989 | Val: 0.677312 | LR: 1.00e-04 | Best: 0.677231 (ep 4)
[04:36:40] Epoch 6/100 | Train: 0.663903 | Val: 0.676711 | LR: 1.00e-04 | Best: 0.676711 (ep 6)
[04:36:43] Epoch 7/100 | Train: 0.663757 | Val: 0.676827 | LR: 1.00e-04 | Best: 0.676711 (ep 6)
[04:36:46] Epoch 8/100 | Train: 0.663732 | Val: 0.676766 | LR: 1.00e-04 | Best: 0.676711 (ep 6)
[04:36:49] Epoch 9/100 | Train: 0.663713 | Val: 0.676351 | LR: 1.00e-04 | Best: 0.676351 (ep 9)
[04:36:52] Epoch 10/100 | Train: 0.663543 | Val: 0.676464 | LR: 1.00e-04 | Best: 0.676351 (ep 9)
[04:36:55] Epoch 11/100 | Train: 0.663401 | Val: 0.676294 | LR: 1.00e-04 | Best: 0.676294 (ep 11)
[04:36:58] Epoch 12/100 | Train: 0.663409 | Val: 0.676402 | LR: 1.00e-04 | Best: 0.676294 (ep 11)
[04:37:01] Epoch 13/100 | Train: 0.663398 | Val: 0.676391 | LR: 1.00e-04 | Best: 0.676294 (ep 11)
[04:37:04] Epoch 14/100 | Train: 0.663336 | Val: 0.676441 | LR: 1.00e-04 | Best: 0.676294 (ep 11)
[04:37:07] Epoch 15/100 | Train: 0.663230 | Val: 0.676875 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:10] Epoch 16/100 | Train: 0.663036 | Val: 0.676540 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:13] Epoch 17/100 | Train: 0.662975 | Val: 0.676470 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:16] Epoch 18/100 | Train: 0.662969 | Val: 0.676729 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:19] Epoch 19/100 | Train: 0.662838 | Val: 0.676445 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:22] Epoch 20/100 | Train: 0.662853 | Val: 0.676481 | LR: 5.00e-05 | Best: 0.676294 (ep 11)
[04:37:25] Epoch 21/100 | Train: 0.662853 | Val: 0.676890 | LR: 2.50e-05 | Best: 0.676294 (ep 11)
[04:37:25] Early stopping at epoch 21 (no improvement for 10 epochs)
[04:37:26] Factor 3 done — best val loss: 0.676294 at epoch 11
[04:37:26] 
============================================================
[04:37:26] STF Factor 4 of [2..15]
[04:37:26] ============================================================
[04:37:27] Building features: 0% (1/175846)
[04:37:27] Building features: 5% (8793/175846)
[04:37:28] Building features: 10% (17585/175846)
[04:37:28] Building features: 15% (26377/175846)
[04:37:29] Building features: 20% (35169/175846)
[04:37:29] Building features: 25% (43961/175846)
[04:37:30] Building features: 30% (52753/175846)
[04:37:30] Building features: 35% (61545/175846)
[04:37:31] Building features: 40% (70337/175846)
[04:37:31] Building features: 45% (79129/175846)
[04:37:32] Building features: 50% (87921/175846)
[04:37:32] Building features: 55% (96713/175846)
[04:37:33] Building features: 60% (105505/175846)
[04:37:33] Building features: 65% (114297/175846)
[04:37:34] Building features: 70% (123089/175846)
[04:37:34] Building features: 75% (131881/175846)
[04:37:35] Building features: 80% (140673/175846)
[04:37:36] Building features: 85% (149465/175846)
[04:37:36] Building features: 90% (158257/175846)
[04:37:37] Building features: 95% (167049/175846)
[04:37:37] Building features: 100% (175841/175846)
[04:37:37] Computing Hurst exponent...
[04:37:42] Computing market regimes (GMM)...
[04:37:50] Factor 4: 175704 samples, 92 features
[04:37:52] Batch stats — Input:  mean=0.0527 std=0.2641 min=-5.4705 max=12.2195
[04:37:52] Batch stats — Target: mean=-0.0055 std=0.0726 min=-0.4720 max=0.2308
[04:37:52] Batch stats — Cls:    pos_long=97/256 pos_short=109/256
[04:37:52] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:37:57] Epoch 1/100 | Train: 0.667898 | Val: 0.678564 | LR: 1.00e-04 | Best: 0.678564 (ep 1)
[04:38:00] Epoch 2/100 | Train: 0.664887 | Val: 0.677745 | LR: 1.00e-04 | Best: 0.677745 (ep 2)
[04:38:03] Epoch 3/100 | Train: 0.664403 | Val: 0.677612 | LR: 1.00e-04 | Best: 0.677612 (ep 3)
[04:38:06] Epoch 4/100 | Train: 0.664297 | Val: 0.676529 | LR: 1.00e-04 | Best: 0.676529 (ep 4)
[04:38:08] Epoch 5/100 | Train: 0.664176 | Val: 0.676300 | LR: 1.00e-04 | Best: 0.676300 (ep 5)
[04:38:11] Epoch 6/100 | Train: 0.664091 | Val: 0.676125 | LR: 1.00e-04 | Best: 0.676125 (ep 6)
[04:38:14] Epoch 7/100 | Train: 0.663932 | Val: 0.675983 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:17] Epoch 8/100 | Train: 0.663888 | Val: 0.676078 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:20] Epoch 9/100 | Train: 0.663865 | Val: 0.676248 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:23] Epoch 10/100 | Train: 0.663690 | Val: 0.676185 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:26] Epoch 11/100 | Train: 0.663619 | Val: 0.676146 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:29] Epoch 12/100 | Train: 0.663555 | Val: 0.676273 | LR: 1.00e-04 | Best: 0.675983 (ep 7)
[04:38:32] Epoch 13/100 | Train: 0.663456 | Val: 0.676247 | LR: 5.00e-05 | Best: 0.675983 (ep 7)
[04:38:35] Epoch 14/100 | Train: 0.663347 | Val: 0.676501 | LR: 5.00e-05 | Best: 0.675983 (ep 7)
[04:38:38] Epoch 15/100 | Train: 0.663224 | Val: 0.676426 | LR: 5.00e-05 | Best: 0.675983 (ep 7)
[04:38:41] Epoch 16/100 | Train: 0.663191 | Val: 0.676649 | LR: 5.00e-05 | Best: 0.675983 (ep 7)
[04:38:44] Epoch 17/100 | Train: 0.663164 | Val: 0.676242 | LR: 5.00e-05 | Best: 0.675983 (ep 7)
[04:38:44] Early stopping at epoch 17 (no improvement for 10 epochs)
[04:38:45] Factor 4 done — best val loss: 0.675983 at epoch 7
[04:38:45] 
============================================================
[04:38:45] STF Factor 5 of [2..15]
[04:38:45] ============================================================
[04:38:46] Building features: 0% (1/175846)
[04:38:46] Building features: 5% (8793/175846)
[04:38:47] Building features: 10% (17585/175846)
[04:38:47] Building features: 15% (26377/175846)
[04:38:48] Building features: 20% (35169/175846)
[04:38:48] Building features: 25% (43961/175846)
[04:38:49] Building features: 30% (52753/175846)
[04:38:49] Building features: 35% (61545/175846)
[04:38:50] Building features: 40% (70337/175846)
[04:38:50] Building features: 45% (79129/175846)
[04:38:51] Building features: 50% (87921/175846)
[04:38:51] Building features: 55% (96713/175846)
[04:38:52] Building features: 60% (105505/175846)
[04:38:52] Building features: 65% (114297/175846)
[04:38:53] Building features: 70% (123089/175846)
[04:38:53] Building features: 75% (131881/175846)
[04:38:54] Building features: 80% (140673/175846)
[04:38:55] Building features: 85% (149465/175846)
[04:38:55] Building features: 90% (158257/175846)
[04:38:56] Building features: 95% (167049/175846)
[04:38:56] Building features: 100% (175841/175846)
[04:38:56] Computing Hurst exponent...
[04:39:01] Computing market regimes (GMM)...
[04:39:09] Factor 5: 175704 samples, 92 features
[04:39:10] Batch stats — Input:  mean=0.0540 std=0.2632 min=-4.1600 max=7.9674
[04:39:10] Batch stats — Target: mean=0.0051 std=0.0622 min=-0.2203 max=0.4134
[04:39:10] Batch stats — Cls:    pos_long=103/256 pos_short=91/256
[04:39:10] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:39:15] Epoch 1/100 | Train: 0.667085 | Val: 0.679080 | LR: 1.00e-04 | Best: 0.679080 (ep 1)
[04:39:18] Epoch 2/100 | Train: 0.664744 | Val: 0.678395 | LR: 1.00e-04 | Best: 0.678395 (ep 2)
[04:39:21] Epoch 3/100 | Train: 0.664382 | Val: 0.678022 | LR: 1.00e-04 | Best: 0.678022 (ep 3)
[04:39:24] Epoch 4/100 | Train: 0.664297 | Val: 0.677798 | LR: 1.00e-04 | Best: 0.677798 (ep 4)
[04:39:27] Epoch 5/100 | Train: 0.664180 | Val: 0.677296 | LR: 1.00e-04 | Best: 0.677296 (ep 5)
[04:39:30] Epoch 6/100 | Train: 0.664009 | Val: 0.677340 | LR: 1.00e-04 | Best: 0.677296 (ep 5)
[04:39:33] Epoch 7/100 | Train: 0.663889 | Val: 0.676739 | LR: 1.00e-04 | Best: 0.676739 (ep 7)
[04:39:36] Epoch 8/100 | Train: 0.663805 | Val: 0.676648 | LR: 1.00e-04 | Best: 0.676648 (ep 8)
[04:39:39] Epoch 9/100 | Train: 0.663658 | Val: 0.677316 | LR: 1.00e-04 | Best: 0.676648 (ep 8)
[04:39:42] Epoch 10/100 | Train: 0.663758 | Val: 0.676585 | LR: 1.00e-04 | Best: 0.676585 (ep 10)
[04:39:45] Epoch 11/100 | Train: 0.663511 | Val: 0.676449 | LR: 1.00e-04 | Best: 0.676449 (ep 11)
[04:39:48] Epoch 12/100 | Train: 0.663517 | Val: 0.676369 | LR: 1.00e-04 | Best: 0.676369 (ep 12)
[04:39:51] Epoch 13/100 | Train: 0.663429 | Val: 0.676354 | LR: 1.00e-04 | Best: 0.676354 (ep 13)
[04:39:54] Epoch 14/100 | Train: 0.663301 | Val: 0.676116 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:39:57] Epoch 15/100 | Train: 0.663350 | Val: 0.676580 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:40:00] Epoch 16/100 | Train: 0.663254 | Val: 0.676916 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:40:03] Epoch 17/100 | Train: 0.663181 | Val: 0.676345 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:40:06] Epoch 18/100 | Train: 0.663030 | Val: 0.676601 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:40:09] Epoch 19/100 | Train: 0.662987 | Val: 0.677498 | LR: 1.00e-04 | Best: 0.676116 (ep 14)
[04:40:12] Epoch 20/100 | Train: 0.662983 | Val: 0.676828 | LR: 5.00e-05 | Best: 0.676116 (ep 14)
[04:40:15] Epoch 21/100 | Train: 0.662729 | Val: 0.677147 | LR: 5.00e-05 | Best: 0.676116 (ep 14)
[04:40:18] Epoch 22/100 | Train: 0.662706 | Val: 0.677133 | LR: 5.00e-05 | Best: 0.676116 (ep 14)
[04:40:21] Epoch 23/100 | Train: 0.662618 | Val: 0.677206 | LR: 5.00e-05 | Best: 0.676116 (ep 14)
[04:40:24] Epoch 24/100 | Train: 0.662659 | Val: 0.677965 | LR: 5.00e-05 | Best: 0.676116 (ep 14)
[04:40:24] Early stopping at epoch 24 (no improvement for 10 epochs)
[04:40:25] Factor 5 done — best val loss: 0.676116 at epoch 14
[04:40:25] 
============================================================
[04:40:25] STF Factor 6 of [2..15]
[04:40:25] ============================================================
[04:40:25] Building features: 0% (1/175846)
[04:40:26] Building features: 5% (8793/175846)
[04:40:26] Building features: 10% (17585/175846)
[04:40:27] Building features: 15% (26377/175846)
[04:40:27] Building features: 20% (35169/175846)
[04:40:28] Building features: 25% (43961/175846)
[04:40:28] Building features: 30% (52753/175846)
[04:40:29] Building features: 35% (61545/175846)
[04:40:30] Building features: 40% (70337/175846)
[04:40:30] Building features: 45% (79129/175846)
[04:40:31] Building features: 50% (87921/175846)
[04:40:31] Building features: 55% (96713/175846)
[04:40:32] Building features: 60% (105505/175846)
[04:40:32] Building features: 65% (114297/175846)
[04:40:33] Building features: 70% (123089/175846)
[04:40:33] Building features: 75% (131881/175846)
[04:40:34] Building features: 80% (140673/175846)
[04:40:34] Building features: 85% (149465/175846)
[04:40:35] Building features: 90% (158257/175846)
[04:40:35] Building features: 95% (167049/175846)
[04:40:36] Building features: 100% (175841/175846)
[04:40:36] Computing Hurst exponent...
[04:40:41] Computing market regimes (GMM)...
[04:40:48] Factor 6: 175704 samples, 92 features
[04:40:50] Batch stats — Input:  mean=0.0521 std=0.2650 min=-6.3561 max=13.1528
[04:40:50] Batch stats — Target: mean=-0.0025 std=0.0654 min=-0.4720 max=0.3916
[04:40:50] Batch stats — Cls:    pos_long=90/256 pos_short=102/256
[04:40:50] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:40:55] Epoch 1/100 | Train: 0.667104 | Val: 0.678501 | LR: 1.00e-04 | Best: 0.678501 (ep 1)
[04:40:58] Epoch 2/100 | Train: 0.664727 | Val: 0.678161 | LR: 1.00e-04 | Best: 0.678161 (ep 2)
[04:41:01] Epoch 3/100 | Train: 0.664404 | Val: 0.677331 | LR: 1.00e-04 | Best: 0.677331 (ep 3)
[04:41:04] Epoch 4/100 | Train: 0.664266 | Val: 0.677296 | LR: 1.00e-04 | Best: 0.677296 (ep 4)
[04:41:07] Epoch 5/100 | Train: 0.664072 | Val: 0.676578 | LR: 1.00e-04 | Best: 0.676578 (ep 5)
[04:41:10] Epoch 6/100 | Train: 0.664102 | Val: 0.676694 | LR: 1.00e-04 | Best: 0.676578 (ep 5)
[04:41:13] Epoch 7/100 | Train: 0.663942 | Val: 0.676446 | LR: 1.00e-04 | Best: 0.676446 (ep 7)
[04:41:15] Epoch 8/100 | Train: 0.663907 | Val: 0.676541 | LR: 1.00e-04 | Best: 0.676446 (ep 7)
[04:41:18] Epoch 9/100 | Train: 0.663771 | Val: 0.676200 | LR: 1.00e-04 | Best: 0.676200 (ep 9)
[04:41:20] Epoch 10/100 | Train: 0.663732 | Val: 0.675894 | LR: 1.00e-04 | Best: 0.675894 (ep 10)
[04:41:23] Epoch 11/100 | Train: 0.663643 | Val: 0.676332 | LR: 1.00e-04 | Best: 0.675894 (ep 10)
[04:41:25] Epoch 12/100 | Train: 0.663588 | Val: 0.676542 | LR: 1.00e-04 | Best: 0.675894 (ep 10)
[04:41:28] Epoch 13/100 | Train: 0.663478 | Val: 0.675838 | LR: 1.00e-04 | Best: 0.675838 (ep 13)
[04:41:30] Epoch 14/100 | Train: 0.663520 | Val: 0.676796 | LR: 1.00e-04 | Best: 0.675838 (ep 13)
[04:41:33] Epoch 15/100 | Train: 0.663371 | Val: 0.676726 | LR: 1.00e-04 | Best: 0.675838 (ep 13)
[04:41:35] Epoch 16/100 | Train: 0.663384 | Val: 0.676547 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:38] Epoch 17/100 | Train: 0.663076 | Val: 0.676612 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:41] Epoch 18/100 | Train: 0.663065 | Val: 0.676961 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:44] Epoch 19/100 | Train: 0.663011 | Val: 0.677585 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:47] Epoch 20/100 | Train: 0.662959 | Val: 0.677349 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:50] Epoch 21/100 | Train: 0.662915 | Val: 0.677502 | LR: 5.00e-05 | Best: 0.675838 (ep 13)
[04:41:53] Epoch 22/100 | Train: 0.662986 | Val: 0.677577 | LR: 2.50e-05 | Best: 0.675838 (ep 13)
[04:41:56] Epoch 23/100 | Train: 0.662867 | Val: 0.677351 | LR: 2.50e-05 | Best: 0.675838 (ep 13)
[04:41:56] Early stopping at epoch 23 (no improvement for 10 epochs)
[04:41:57] Factor 6 done — best val loss: 0.675838 at epoch 13
[04:41:57] 
============================================================
[04:41:57] STF Factor 7 of [2..15]
[04:41:57] ============================================================
[04:41:57] Building features: 0% (1/175846)
[04:41:58] Building features: 5% (8793/175846)
[04:41:58] Building features: 10% (17585/175846)
[04:41:59] Building features: 15% (26377/175846)
[04:41:59] Building features: 20% (35169/175846)
[04:42:00] Building features: 25% (43961/175846)
[04:42:00] Building features: 30% (52753/175846)
[04:42:01] Building features: 35% (61545/175846)
[04:42:01] Building features: 40% (70337/175846)
[04:42:02] Building features: 45% (79129/175846)
[04:42:02] Building features: 50% (87921/175846)
[04:42:03] Building features: 55% (96713/175846)
[04:42:04] Building features: 60% (105505/175846)
[04:42:04] Building features: 65% (114297/175846)
[04:42:05] Building features: 70% (123089/175846)
[04:42:05] Building features: 75% (131881/175846)
[04:42:06] Building features: 80% (140673/175846)
[04:42:06] Building features: 85% (149465/175846)
[04:42:07] Building features: 90% (158257/175846)
[04:42:07] Building features: 95% (167049/175846)
[04:42:08] Building features: 100% (175841/175846)
[04:42:08] Computing Hurst exponent...
[04:42:13] Computing market regimes (GMM)...
[04:42:20] Factor 7: 175704 samples, 92 features
[04:42:22] Batch stats — Input:  mean=0.0548 std=0.2746 min=-5.6524 max=60.4783
[04:42:22] Batch stats — Target: mean=-0.0039 std=0.0809 min=-0.4720 max=0.4134
[04:42:22] Batch stats — Cls:    pos_long=107/256 pos_short=93/256
[04:42:22] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:42:26] Epoch 1/100 | Train: 0.668011 | Val: 0.678646 | LR: 1.00e-04 | Best: 0.678646 (ep 1)
[04:42:28] Epoch 2/100 | Train: 0.664901 | Val: 0.677790 | LR: 1.00e-04 | Best: 0.677790 (ep 2)
[04:42:31] Epoch 3/100 | Train: 0.664572 | Val: 0.677307 | LR: 1.00e-04 | Best: 0.677307 (ep 3)
[04:42:33] Epoch 4/100 | Train: 0.664393 | Val: 0.676905 | LR: 1.00e-04 | Best: 0.676905 (ep 4)
[04:42:36] Epoch 5/100 | Train: 0.664083 | Val: 0.676422 | LR: 1.00e-04 | Best: 0.676422 (ep 5)
[04:42:38] Epoch 6/100 | Train: 0.663994 | Val: 0.676202 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:41] Epoch 7/100 | Train: 0.663981 | Val: 0.676237 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:43] Epoch 8/100 | Train: 0.663866 | Val: 0.676497 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:46] Epoch 9/100 | Train: 0.663811 | Val: 0.676616 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:48] Epoch 10/100 | Train: 0.663626 | Val: 0.676729 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:51] Epoch 11/100 | Train: 0.663665 | Val: 0.677041 | LR: 1.00e-04 | Best: 0.676202 (ep 6)
[04:42:54] Epoch 12/100 | Train: 0.663591 | Val: 0.676805 | LR: 5.00e-05 | Best: 0.676202 (ep 6)
[04:42:57] Epoch 13/100 | Train: 0.663347 | Val: 0.676536 | LR: 5.00e-05 | Best: 0.676202 (ep 6)
[04:43:00] Epoch 14/100 | Train: 0.663342 | Val: 0.676658 | LR: 5.00e-05 | Best: 0.676202 (ep 6)
[04:43:03] Epoch 15/100 | Train: 0.663230 | Val: 0.676678 | LR: 5.00e-05 | Best: 0.676202 (ep 6)
[04:43:06] Epoch 16/100 | Train: 0.663157 | Val: 0.676818 | LR: 5.00e-05 | Best: 0.676202 (ep 6)
[04:43:06] Early stopping at epoch 16 (no improvement for 10 epochs)
[04:43:07] Factor 7 done — best val loss: 0.676202 at epoch 6
[04:43:07] 
============================================================
[04:43:07] STF Factor 8 of [2..15]
[04:43:07] ============================================================
[04:43:07] Building features: 0% (1/175846)
[04:43:08] Building features: 5% (8793/175846)
[04:43:09] Building features: 10% (17585/175846)
[04:43:09] Building features: 15% (26377/175846)
[04:43:10] Building features: 20% (35169/175846)
[04:43:10] Building features: 25% (43961/175846)
[04:43:11] Building features: 30% (52753/175846)
[04:43:11] Building features: 35% (61545/175846)
[04:43:12] Building features: 40% (70337/175846)
[04:43:12] Building features: 45% (79129/175846)
[04:43:13] Building features: 50% (87921/175846)
[04:43:13] Building features: 55% (96713/175846)
[04:43:14] Building features: 60% (105505/175846)
[04:43:14] Building features: 65% (114297/175846)
[04:43:15] Building features: 70% (123089/175846)
[04:43:16] Building features: 75% (131881/175846)
[04:43:16] Building features: 80% (140673/175846)
[04:43:17] Building features: 85% (149465/175846)
[04:43:17] Building features: 90% (158257/175846)
[04:43:18] Building features: 95% (167049/175846)
[04:43:18] Building features: 100% (175841/175846)
[04:43:18] Computing Hurst exponent...
[04:43:23] Computing market regimes (GMM)...
[04:43:31] Factor 8: 175704 samples, 92 features
[04:43:33] Batch stats — Input:  mean=0.0547 std=0.2687 min=-4.1165 max=8.0413
[04:43:33] Batch stats — Target: mean=0.0006 std=0.0655 min=-0.3885 max=0.4134
[04:43:33] Batch stats — Cls:    pos_long=95/256 pos_short=97/256
[04:43:33] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:43:38] Epoch 1/100 | Train: 0.667587 | Val: 0.679347 | LR: 1.00e-04 | Best: 0.679347 (ep 1)
[04:43:40] Epoch 2/100 | Train: 0.664765 | Val: 0.678408 | LR: 1.00e-04 | Best: 0.678408 (ep 2)
[04:43:43] Epoch 3/100 | Train: 0.664450 | Val: 0.678031 | LR: 1.00e-04 | Best: 0.678031 (ep 3)
[04:43:45] Epoch 4/100 | Train: 0.664335 | Val: 0.677582 | LR: 1.00e-04 | Best: 0.677582 (ep 4)
[04:43:48] Epoch 5/100 | Train: 0.664090 | Val: 0.677580 | LR: 1.00e-04 | Best: 0.677580 (ep 5)
[04:43:50] Epoch 6/100 | Train: 0.664037 | Val: 0.677240 | LR: 1.00e-04 | Best: 0.677240 (ep 6)
[04:43:53] Epoch 7/100 | Train: 0.663942 | Val: 0.677827 | LR: 1.00e-04 | Best: 0.677240 (ep 6)
[04:43:55] Epoch 8/100 | Train: 0.663803 | Val: 0.676632 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:43:58] Epoch 9/100 | Train: 0.663738 | Val: 0.677165 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:44:01] Epoch 10/100 | Train: 0.663672 | Val: 0.676976 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:44:04] Epoch 11/100 | Train: 0.663505 | Val: 0.677395 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:44:07] Epoch 12/100 | Train: 0.663542 | Val: 0.677005 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:44:10] Epoch 13/100 | Train: 0.663401 | Val: 0.676979 | LR: 1.00e-04 | Best: 0.676632 (ep 8)
[04:44:13] Epoch 14/100 | Train: 0.663357 | Val: 0.677243 | LR: 5.00e-05 | Best: 0.676632 (ep 8)
[04:44:16] Epoch 15/100 | Train: 0.663258 | Val: 0.677332 | LR: 5.00e-05 | Best: 0.676632 (ep 8)
[04:44:19] Epoch 16/100 | Train: 0.663159 | Val: 0.677877 | LR: 5.00e-05 | Best: 0.676632 (ep 8)
[04:44:20] Stop requested...
[04:44:21] Epoch 17/100 | Train: 0.663112 | Val: 0.677239 | LR: 5.00e-05 | Best: 0.676632 (ep 8)
[04:44:21] Training stopped by user.
[04:44:22] Factor 8 done — best val loss: 0.676632 at epoch 8
[04:44:22] 
Best factor: 6 (val loss 0.675838)
[04:44:22] Training done. Best factor=6, val_loss=0.675838
[04:44:46] Training started.
[04:44:46] 
============================================================
[04:44:46] STF Factor 29 of [29..30]
[04:44:46] ============================================================
[04:44:47] Building features: 0% (1/175846)
[04:44:47] Building features: 5% (8793/175846)
[04:44:47] Building features: 10% (17585/175846)
[04:44:48] Building features: 15% (26377/175846)
[04:44:48] Building features: 20% (35169/175846)
[04:44:49] Building features: 25% (43961/175846)
[04:44:49] Building features: 30% (52753/175846)
[04:44:50] Building features: 35% (61545/175846)
[04:44:50] Building features: 40% (70337/175846)
[04:44:51] Building features: 45% (79129/175846)
[04:44:51] Building features: 50% (87921/175846)
[04:44:52] Building features: 55% (96713/175846)
[04:44:52] Building features: 60% (105505/175846)
[04:44:53] Building features: 65% (114297/175846)
[04:44:53] Building features: 70% (123089/175846)
[04:44:54] Building features: 75% (131881/175846)
[04:44:54] Building features: 80% (140673/175846)
[04:44:55] Building features: 85% (149465/175846)
[04:44:55] Building features: 90% (158257/175846)
[04:44:56] Building features: 95% (167049/175846)
[04:44:57] Building features: 100% (175841/175846)
[04:44:57] Computing Hurst exponent...
[04:45:02] Computing market regimes (GMM)...
[04:45:09] Factor 29: 175704 samples, 92 features
[04:45:11] Batch stats — Input:  mean=0.0521 std=0.2715 min=-3.7681 max=12.2195
[04:45:11] Batch stats — Target: mean=0.0029 std=0.0635 min=-0.4720 max=0.4134
[04:45:11] Batch stats — Cls:    pos_long=119/256 pos_short=87/256
[04:45:11] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:45:16] Epoch 1/100 | Train: 0.667142 | Val: 0.679117 | LR: 1.00e-04 | Best: 0.679117 (ep 1)
[04:45:19] Epoch 2/100 | Train: 0.664803 | Val: 0.678424 | LR: 1.00e-04 | Best: 0.678424 (ep 2)
[04:45:22] Epoch 3/100 | Train: 0.664418 | Val: 0.677642 | LR: 1.00e-04 | Best: 0.677642 (ep 3)
[04:45:25] Epoch 4/100 | Train: 0.664090 | Val: 0.677516 | LR: 1.00e-04 | Best: 0.677516 (ep 4)
[04:45:28] Epoch 5/100 | Train: 0.664096 | Val: 0.676969 | LR: 1.00e-04 | Best: 0.676969 (ep 5)
[04:45:31] Epoch 6/100 | Train: 0.663992 | Val: 0.676328 | LR: 1.00e-04 | Best: 0.676328 (ep 6)
[04:45:34] Epoch 7/100 | Train: 0.663895 | Val: 0.676433 | LR: 1.00e-04 | Best: 0.676328 (ep 6)
[04:45:37] Epoch 8/100 | Train: 0.663788 | Val: 0.676214 | LR: 1.00e-04 | Best: 0.676214 (ep 8)
[04:45:40] Epoch 9/100 | Train: 0.663736 | Val: 0.675964 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:43] Epoch 10/100 | Train: 0.663567 | Val: 0.676228 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:46] Epoch 11/100 | Train: 0.663612 | Val: 0.676152 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:49] Epoch 12/100 | Train: 0.663432 | Val: 0.676228 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:52] Epoch 13/100 | Train: 0.663357 | Val: 0.676746 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:55] Epoch 14/100 | Train: 0.663285 | Val: 0.676344 | LR: 1.00e-04 | Best: 0.675964 (ep 9)
[04:45:57] Epoch 15/100 | Train: 0.663324 | Val: 0.676634 | LR: 5.00e-05 | Best: 0.675964 (ep 9)
[04:46:00] Epoch 16/100 | Train: 0.663099 | Val: 0.676740 | LR: 5.00e-05 | Best: 0.675964 (ep 9)
[04:46:02] Epoch 17/100 | Train: 0.662927 | Val: 0.676773 | LR: 5.00e-05 | Best: 0.675964 (ep 9)
[04:46:05] Epoch 18/100 | Train: 0.663075 | Val: 0.677462 | LR: 5.00e-05 | Best: 0.675964 (ep 9)
[04:46:08] Epoch 19/100 | Train: 0.662853 | Val: 0.676935 | LR: 5.00e-05 | Best: 0.675964 (ep 9)
[04:46:08] Early stopping at epoch 19 (no improvement for 10 epochs)
[04:46:09] Factor 29 done — best val loss: 0.675964 at epoch 9
[04:46:09] 
============================================================
[04:46:09] STF Factor 30 of [29..30]
[04:46:09] ============================================================
[04:46:09] Building features: 0% (1/175846)
[04:46:10] Building features: 5% (8793/175846)
[04:46:10] Building features: 10% (17585/175846)
[04:46:11] Building features: 15% (26377/175846)
[04:46:11] Building features: 20% (35169/175846)
[04:46:12] Building features: 25% (43961/175846)
[04:46:12] Building features: 30% (52753/175846)
[04:46:13] Building features: 35% (61545/175846)
[04:46:13] Building features: 40% (70337/175846)
[04:46:14] Building features: 45% (79129/175846)
[04:46:14] Building features: 50% (87921/175846)
[04:46:15] Building features: 55% (96713/175846)
[04:46:15] Building features: 60% (105505/175846)
[04:46:15] Building features: 65% (114297/175846)
[04:46:16] Building features: 70% (123089/175846)
[04:46:16] Building features: 75% (131881/175846)
[04:46:17] Building features: 80% (140673/175846)
[04:46:17] Building features: 85% (149465/175846)
[04:46:18] Building features: 90% (158257/175846)
[04:46:18] Building features: 95% (167049/175846)
[04:46:19] Building features: 100% (175841/175846)
[04:46:19] Computing Hurst exponent...
[04:46:24] Computing market regimes (GMM)...
[04:46:30] Factor 30: 175704 samples, 92 features
[04:46:32] Batch stats — Input:  mean=0.0505 std=0.2737 min=-5.3639 max=8.4920
[04:46:32] Batch stats — Target: mean=-0.0027 std=0.0709 min=-0.4720 max=0.4134
[04:46:32] Batch stats — Cls:    pos_long=104/256 pos_short=80/256
[04:46:32] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:46:36] Epoch 1/100 | Train: 0.668166 | Val: 0.679492 | LR: 1.00e-04 | Best: 0.679492 (ep 1)
[04:46:38] Epoch 2/100 | Train: 0.664882 | Val: 0.678466 | LR: 1.00e-04 | Best: 0.678466 (ep 2)
[04:46:41] Epoch 3/100 | Train: 0.664526 | Val: 0.677810 | LR: 1.00e-04 | Best: 0.677810 (ep 3)
[04:46:43] Epoch 4/100 | Train: 0.664336 | Val: 0.676930 | LR: 1.00e-04 | Best: 0.676930 (ep 4)
[04:46:46] Epoch 5/100 | Train: 0.664083 | Val: 0.677547 | LR: 1.00e-04 | Best: 0.676930 (ep 4)
[04:46:48] Epoch 6/100 | Train: 0.664015 | Val: 0.676468 | LR: 1.00e-04 | Best: 0.676468 (ep 6)
[04:46:51] Epoch 7/100 | Train: 0.663888 | Val: 0.676257 | LR: 1.00e-04 | Best: 0.676257 (ep 7)
[04:46:53] Epoch 8/100 | Train: 0.663762 | Val: 0.676232 | LR: 1.00e-04 | Best: 0.676232 (ep 8)
[04:46:56] Epoch 9/100 | Train: 0.663637 | Val: 0.676388 | LR: 1.00e-04 | Best: 0.676232 (ep 8)
[04:46:58] Epoch 10/100 | Train: 0.663535 | Val: 0.676046 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:00] Epoch 11/100 | Train: 0.663498 | Val: 0.676311 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:03] Epoch 12/100 | Train: 0.663309 | Val: 0.676599 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:05] Epoch 13/100 | Train: 0.663291 | Val: 0.676947 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:08] Epoch 14/100 | Train: 0.663201 | Val: 0.676975 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:10] Epoch 15/100 | Train: 0.663185 | Val: 0.677342 | LR: 1.00e-04 | Best: 0.676046 (ep 10)
[04:47:13] Epoch 16/100 | Train: 0.662997 | Val: 0.677942 | LR: 5.00e-05 | Best: 0.676046 (ep 10)
[04:47:15] Epoch 17/100 | Train: 0.662799 | Val: 0.677152 | LR: 5.00e-05 | Best: 0.676046 (ep 10)
[04:47:17] Epoch 18/100 | Train: 0.662740 | Val: 0.677531 | LR: 5.00e-05 | Best: 0.676046 (ep 10)
[04:47:20] Epoch 19/100 | Train: 0.662813 | Val: 0.678200 | LR: 5.00e-05 | Best: 0.676046 (ep 10)
[04:47:23] Epoch 20/100 | Train: 0.662740 | Val: 0.678198 | LR: 5.00e-05 | Best: 0.676046 (ep 10)
[04:47:23] Early stopping at epoch 20 (no improvement for 10 epochs)
[04:47:24] Factor 30 done — best val loss: 0.676046 at epoch 10
[04:47:24] 
Best factor: 29 (val loss 0.675964)
[04:47:24] Training done. Best factor=29, val_loss=0.675964
[04:48:12] Building validation dataset...
[04:48:13] Building features: 0% (1/175846)
[04:48:13] Building features: 5% (8793/175846)
[04:48:13] Building features: 10% (17585/175846)
[04:48:14] Building features: 15% (26377/175846)
[04:48:14] Building features: 20% (35169/175846)
[04:48:15] Building features: 25% (43961/175846)
[04:48:15] Building features: 30% (52753/175846)
[04:48:16] Building features: 35% (61545/175846)
[04:48:16] Building features: 40% (70337/175846)
[04:48:17] Building features: 45% (79129/175846)
[04:48:17] Building features: 50% (87921/175846)
[04:48:18] Building features: 55% (96713/175846)
[04:48:18] Building features: 60% (105505/175846)
[04:48:19] Building features: 65% (114297/175846)
[04:48:19] Building features: 70% (123089/175846)
[04:48:20] Building features: 75% (131881/175846)
[04:48:20] Building features: 80% (140673/175846)
[04:48:21] Building features: 85% (149465/175846)
[04:48:22] Building features: 90% (158257/175846)
[04:48:22] Building features: 95% (167049/175846)
[04:48:23] Building features: 100% (175841/175846)
[04:48:23] Computing Hurst exponent...
[04:48:28] Computing market regimes (GMM)...
[04:48:35] Running backtest...
[04:48:36] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[04:50:46] Training started.
[04:50:46] Training returned no results.
[04:50:59] Training started.
[04:50:59] Training returned no results.
[04:51:15] Training started.
[04:51:15] 
============================================================
[04:51:15] STF Factor 2 of [2..5]
[04:51:15] ============================================================
[04:51:15] Building features: 0% (1/175846)
[04:51:15] Building features: 5% (8793/175846)
[04:51:16] Building features: 10% (17585/175846)
[04:51:16] Building features: 15% (26377/175846)
[04:51:17] Building features: 20% (35169/175846)
[04:51:17] Building features: 25% (43961/175846)
[04:51:18] Building features: 30% (52753/175846)
[04:51:18] Building features: 35% (61545/175846)
[04:51:19] Building features: 40% (70337/175846)
[04:51:19] Building features: 45% (79129/175846)
[04:51:20] Building features: 50% (87921/175846)
[04:51:20] Building features: 55% (96713/175846)
[04:51:20] Building features: 60% (105505/175846)
[04:51:21] Building features: 65% (114297/175846)
[04:51:21] Building features: 70% (123089/175846)
[04:51:22] Building features: 75% (131881/175846)
[04:51:22] Building features: 80% (140673/175846)
[04:51:23] Building features: 85% (149465/175846)
[04:51:24] Building features: 90% (158257/175846)
[04:51:24] Building features: 95% (167049/175846)
[04:51:25] Building features: 100% (175841/175846)
[04:51:25] Computing Hurst exponent...
[04:51:30] Computing market regimes (GMM)...
[04:51:37] Factor 2: 175704 samples, 92 features
[04:51:39] Batch stats — Input:  mean=0.0558 std=0.2580 min=-3.5438 max=8.3960
[04:51:39] Batch stats — Target: mean=-0.0019 std=0.0616 min=-0.4600 max=0.2992
[04:51:39] Batch stats — Cls:    pos_long=99/256 pos_short=93/256
[04:51:39] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:51:43] Epoch 1/100 | Train: 0.667508 | Val: 0.678560 | LR: 1.00e-04 | Best: 0.678560 (ep 1)
[04:51:45] Epoch 2/100 | Train: 0.664745 | Val: 0.677762 | LR: 1.00e-04 | Best: 0.677762 (ep 2)
[04:51:48] Epoch 3/100 | Train: 0.664424 | Val: 0.677111 | LR: 1.00e-04 | Best: 0.677111 (ep 3)
[04:51:50] Epoch 4/100 | Train: 0.664306 | Val: 0.677168 | LR: 1.00e-04 | Best: 0.677111 (ep 3)
[04:51:53] Epoch 5/100 | Train: 0.664031 | Val: 0.676487 | LR: 1.00e-04 | Best: 0.676487 (ep 5)
[04:51:55] Epoch 6/100 | Train: 0.663953 | Val: 0.676646 | LR: 1.00e-04 | Best: 0.676487 (ep 5)
[04:51:58] Epoch 7/100 | Train: 0.663899 | Val: 0.676445 | LR: 1.00e-04 | Best: 0.676445 (ep 7)
[04:52:00] Epoch 8/100 | Train: 0.663795 | Val: 0.677163 | LR: 1.00e-04 | Best: 0.676445 (ep 7)
[04:52:03] Epoch 9/100 | Train: 0.663799 | Val: 0.676632 | LR: 1.00e-04 | Best: 0.676445 (ep 7)
[04:52:06] Epoch 10/100 | Train: 0.663652 | Val: 0.677149 | LR: 1.00e-04 | Best: 0.676445 (ep 7)
[04:52:09] Epoch 11/100 | Train: 0.663585 | Val: 0.676948 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:11] Epoch 12/100 | Train: 0.663491 | Val: 0.676928 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:14] Epoch 13/100 | Train: 0.663382 | Val: 0.677300 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:17] Epoch 14/100 | Train: 0.663306 | Val: 0.676898 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:20] Epoch 15/100 | Train: 0.663347 | Val: 0.676779 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:20] Stop requested...
[04:52:22] Epoch 16/100 | Train: 0.663197 | Val: 0.677153 | LR: 5.00e-05 | Best: 0.676445 (ep 7)
[04:52:22] Training stopped by user.
[04:52:23] Factor 2 done — best val loss: 0.676445 at epoch 7
[04:52:23] 
Best factor: 2 (val loss 0.676445)
[04:52:23] Training done. Best factor=2, val_loss=0.676445
[04:52:58] NTCP initialized.
[04:53:17] Set CSV path first.
[04:54:06] Loaded 175846 M5 bars.
[04:54:09] Training started.
[04:54:09] 
============================================================
[04:54:09] STF Factor 2 of [2..5]
[04:54:09] ============================================================
[04:54:09] Building features: 0% (1/175846)
[04:54:10] Building features: 5% (8793/175846)
[04:54:10] Building features: 10% (17585/175846)
[04:54:11] Building features: 15% (26377/175846)
[04:54:11] Building features: 20% (35169/175846)
[04:54:12] Building features: 25% (43961/175846)
[04:54:12] Building features: 30% (52753/175846)
[04:54:13] Building features: 35% (61545/175846)
[04:54:13] Building features: 40% (70337/175846)
[04:54:14] Building features: 45% (79129/175846)
[04:54:15] Building features: 50% (87921/175846)
[04:54:15] Building features: 55% (96713/175846)
[04:54:16] Building features: 60% (105505/175846)
[04:54:16] Building features: 65% (114297/175846)
[04:54:17] Building features: 70% (123089/175846)
[04:54:17] Building features: 75% (131881/175846)
[04:54:18] Building features: 80% (140673/175846)
[04:54:19] Building features: 85% (149465/175846)
[04:54:19] Building features: 90% (158257/175846)
[04:54:20] Building features: 95% (167049/175846)
[04:54:20] Building features: 100% (175841/175846)
[04:54:20] Computing Hurst exponent...
[04:54:26] Computing market regimes (GMM)...
[04:54:34] Factor 2: 175724 samples, 92 features
[04:54:36] Batch stats — Input:  mean=0.0564 std=0.2590 min=-5.5995 max=12.2195
[04:54:36] Batch stats — Target: mean=0.0026 std=0.0612 min=-0.4720 max=0.4134
[04:54:36] Batch stats — Cls:    pos_long=96/256 pos_short=99/256
[04:54:36] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:54:41] Epoch 1/100 | Train: 0.037167 (MSE=0.003935 BCE=0.6646) | Val: 0.044717 (MSE=0.011375 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044717 (ep 1)
[04:54:44] Epoch 2/100 | Train: 0.036212 (MSE=0.003128 BCE=0.6617) | Val: 0.043212 (MSE=0.009878 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043212 (ep 2)
[04:54:47] Epoch 3/100 | Train: 0.036148 (MSE=0.003074 BCE=0.6615) | Val: 0.042728 (MSE=0.009386 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042728 (ep 3)
[04:54:49] Epoch 4/100 | Train: 0.036097 (MSE=0.003037 BCE=0.6612) | Val: 0.042527 (MSE=0.009204 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042527 (ep 4)
[04:54:52] Epoch 5/100 | Train: 0.036064 (MSE=0.003007 BCE=0.6611) | Val: 0.042452 (MSE=0.009115 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042452 (ep 5)
[04:54:55] Epoch 6/100 | Train: 0.036040 (MSE=0.002986 BCE=0.6611) | Val: 0.042374 (MSE=0.009033 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042374 (ep 6)
[04:54:58] Epoch 7/100 | Train: 0.036017 (MSE=0.002968 BCE=0.6610) | Val: 0.042333 (MSE=0.008998 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042333 (ep 7)
[04:55:00] Epoch 8/100 | Train: 0.036002 (MSE=0.002957 BCE=0.6609) | Val: 0.042251 (MSE=0.008918 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:03] Epoch 9/100 | Train: 0.035987 (MSE=0.002946 BCE=0.6608) | Val: 0.042263 (MSE=0.008937 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:06] Epoch 10/100 | Train: 0.035976 (MSE=0.002936 BCE=0.6608) | Val: 0.042292 (MSE=0.008941 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:09] Epoch 11/100 | Train: 0.035960 (MSE=0.002928 BCE=0.6606) | Val: 0.042413 (MSE=0.009071 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:12] Epoch 12/100 | Train: 0.035946 (MSE=0.002919 BCE=0.6605) | Val: 0.042397 (MSE=0.009030 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:14] Epoch 13/100 | Train: 0.035945 (MSE=0.002914 BCE=0.6606) | Val: 0.042398 (MSE=0.009073 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042251 (ep 8)
[04:55:17] Epoch 14/100 | Train: 0.035930 (MSE=0.002907 BCE=0.6605) | Val: 0.042458 (MSE=0.009116 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042251 (ep 8)
[04:55:20] Epoch 15/100 | Train: 0.035916 (MSE=0.002900 BCE=0.6603) | Val: 0.042530 (MSE=0.009183 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042251 (ep 8)
[04:55:23] Epoch 16/100 | Train: 0.035913 (MSE=0.002896 BCE=0.6603) | Val: 0.042581 (MSE=0.009219 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042251 (ep 8)
[04:55:25] Epoch 17/100 | Train: 0.035908 (MSE=0.002893 BCE=0.6603) | Val: 0.042594 (MSE=0.009256 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042251 (ep 8)
[04:55:28] Epoch 18/100 | Train: 0.035899 (MSE=0.002889 BCE=0.6602) | Val: 0.042617 (MSE=0.009258 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042251 (ep 8)
[04:55:28] Early stopping at epoch 18 (no improvement for 10 epochs)
[04:55:29] Factor 2 done — best val loss: 0.042251 at epoch 8
[04:55:29] 
============================================================
[04:55:29] STF Factor 3 of [2..5]
[04:55:29] ============================================================
[04:55:29] Building features: 0% (1/175846)
[04:55:30] Building features: 5% (8793/175846)
[04:55:30] Building features: 10% (17585/175846)
[04:55:31] Building features: 15% (26377/175846)
[04:55:32] Building features: 20% (35169/175846)
[04:55:32] Building features: 25% (43961/175846)
[04:55:33] Building features: 30% (52753/175846)
[04:55:33] Building features: 35% (61545/175846)
[04:55:34] Building features: 40% (70337/175846)
[04:55:34] Building features: 45% (79129/175846)
[04:55:35] Building features: 50% (87921/175846)
[04:55:35] Building features: 55% (96713/175846)
[04:55:36] Building features: 60% (105505/175846)
[04:55:36] Building features: 65% (114297/175846)
[04:55:37] Building features: 70% (123089/175846)
[04:55:37] Building features: 75% (131881/175846)
[04:55:38] Building features: 80% (140673/175846)
[04:55:38] Building features: 85% (149465/175846)
[04:55:39] Building features: 90% (158257/175846)
[04:55:39] Building features: 95% (167049/175846)
[04:55:40] Building features: 100% (175841/175846)
[04:55:40] Computing Hurst exponent...
[04:55:45] Computing market regimes (GMM)...
[04:55:52] Factor 3: 175724 samples, 92 features
[04:55:53] Batch stats — Input:  mean=0.0538 std=0.2617 min=-4.1138 max=7.1652
[04:55:53] Batch stats — Target: mean=-0.0011 std=0.0619 min=-0.4394 max=0.4134
[04:55:53] Batch stats — Cls:    pos_long=99/256 pos_short=99/256
[04:55:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:55:58] Epoch 1/100 | Train: 0.036871 (MSE=0.003709 BCE=0.6632) | Val: 0.043811 (MSE=0.010456 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043811 (ep 1)
[04:56:00] Epoch 2/100 | Train: 0.036190 (MSE=0.003112 BCE=0.6615) | Val: 0.042976 (MSE=0.009598 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042976 (ep 2)
[04:56:02] Epoch 3/100 | Train: 0.036134 (MSE=0.003069 BCE=0.6613) | Val: 0.042657 (MSE=0.009311 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042657 (ep 3)
[04:56:05] Epoch 4/100 | Train: 0.036093 (MSE=0.003035 BCE=0.6612) | Val: 0.042603 (MSE=0.009256 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042603 (ep 4)
[04:56:07] Epoch 5/100 | Train: 0.036047 (MSE=0.003000 BCE=0.6609) | Val: 0.042484 (MSE=0.009152 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042484 (ep 5)
[04:56:09] Epoch 6/100 | Train: 0.036025 (MSE=0.002978 BCE=0.6609) | Val: 0.042406 (MSE=0.009077 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042406 (ep 6)
[04:56:12] Epoch 7/100 | Train: 0.036002 (MSE=0.002958 BCE=0.6609) | Val: 0.042306 (MSE=0.008955 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042306 (ep 7)
[04:56:14] Epoch 8/100 | Train: 0.035984 (MSE=0.002946 BCE=0.6608) | Val: 0.042275 (MSE=0.008937 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:16] Epoch 9/100 | Train: 0.035970 (MSE=0.002936 BCE=0.6607) | Val: 0.042441 (MSE=0.009115 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:19] Epoch 10/100 | Train: 0.035958 (MSE=0.002928 BCE=0.6606) | Val: 0.042410 (MSE=0.009052 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:21] Epoch 11/100 | Train: 0.035946 (MSE=0.002921 BCE=0.6605) | Val: 0.042486 (MSE=0.009134 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:23] Epoch 12/100 | Train: 0.035940 (MSE=0.002912 BCE=0.6605) | Val: 0.042480 (MSE=0.009127 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:26] Epoch 13/100 | Train: 0.035929 (MSE=0.002907 BCE=0.6604) | Val: 0.042458 (MSE=0.009117 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042275 (ep 8)
[04:56:28] Epoch 14/100 | Train: 0.035919 (MSE=0.002901 BCE=0.6604) | Val: 0.042469 (MSE=0.009121 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042275 (ep 8)
[04:56:30] Epoch 15/100 | Train: 0.035906 (MSE=0.002892 BCE=0.6603) | Val: 0.042415 (MSE=0.009074 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042275 (ep 8)
[04:56:33] Epoch 16/100 | Train: 0.035897 (MSE=0.002887 BCE=0.6602) | Val: 0.042573 (MSE=0.009214 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042275 (ep 8)
[04:56:35] Epoch 17/100 | Train: 0.035892 (MSE=0.002884 BCE=0.6602) | Val: 0.042633 (MSE=0.009275 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042275 (ep 8)
[04:56:37] Epoch 18/100 | Train: 0.035886 (MSE=0.002880 BCE=0.6601) | Val: 0.042631 (MSE=0.009268 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042275 (ep 8)
[04:56:37] Early stopping at epoch 18 (no improvement for 10 epochs)
[04:56:38] Factor 3 done — best val loss: 0.042275 at epoch 8
[04:56:38] 
============================================================
[04:56:38] STF Factor 4 of [2..5]
[04:56:38] ============================================================
[04:56:38] Building features: 0% (1/175846)
[04:56:39] Building features: 5% (8793/175846)
[04:56:39] Building features: 10% (17585/175846)
[04:56:40] Building features: 15% (26377/175846)
[04:56:40] Building features: 20% (35169/175846)
[04:56:41] Building features: 25% (43961/175846)
[04:56:41] Building features: 30% (52753/175846)
[04:56:42] Building features: 35% (61545/175846)
[04:56:42] Building features: 40% (70337/175846)
[04:56:43] Building features: 45% (79129/175846)
[04:56:43] Building features: 50% (87921/175846)
[04:56:44] Building features: 55% (96713/175846)
[04:56:44] Building features: 60% (105505/175846)
[04:56:45] Building features: 65% (114297/175846)
[04:56:45] Building features: 70% (123089/175846)
[04:56:46] Building features: 75% (131881/175846)
[04:56:46] Building features: 80% (140673/175846)
[04:56:47] Building features: 85% (149465/175846)
[04:56:47] Building features: 90% (158257/175846)
[04:56:48] Building features: 95% (167049/175846)
[04:56:48] Building features: 100% (175841/175846)
[04:56:48] Computing Hurst exponent...
[04:56:54] Computing market regimes (GMM)...
[04:57:01] Factor 4: 175724 samples, 92 features
[04:57:03] Batch stats — Input:  mean=0.0536 std=0.2579 min=-3.0157 max=5.6854
[04:57:03] Batch stats — Target: mean=0.0016 std=0.0650 min=-0.4720 max=0.4134
[04:57:03] Batch stats — Cls:    pos_long=101/256 pos_short=88/256
[04:57:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:57:08] Epoch 1/100 | Train: 0.037011 (MSE=0.003842 BCE=0.6634) | Val: 0.044603 (MSE=0.011270 BCE=0.6667) | LR: 1.00e-04 | Best: 0.044603 (ep 1)
[04:57:11] Epoch 2/100 | Train: 0.036191 (MSE=0.003113 BCE=0.6616) | Val: 0.043158 (MSE=0.009826 BCE=0.6666) | LR: 1.00e-04 | Best: 0.043158 (ep 2)
[04:57:13] Epoch 3/100 | Train: 0.036120 (MSE=0.003051 BCE=0.6614) | Val: 0.042753 (MSE=0.009424 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042753 (ep 3)
[04:57:16] Epoch 4/100 | Train: 0.036078 (MSE=0.003019 BCE=0.6612) | Val: 0.042585 (MSE=0.009258 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042585 (ep 4)
[04:57:19] Epoch 5/100 | Train: 0.036045 (MSE=0.002994 BCE=0.6610) | Val: 0.042451 (MSE=0.009123 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042451 (ep 5)
[04:57:22] Epoch 6/100 | Train: 0.036022 (MSE=0.002975 BCE=0.6609) | Val: 0.042347 (MSE=0.009009 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042347 (ep 6)
[04:57:25] Epoch 7/100 | Train: 0.036003 (MSE=0.002960 BCE=0.6609) | Val: 0.042342 (MSE=0.008991 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042342 (ep 7)
[04:57:28] Epoch 8/100 | Train: 0.035989 (MSE=0.002950 BCE=0.6608) | Val: 0.042269 (MSE=0.008940 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042269 (ep 8)
[04:57:30] Epoch 9/100 | Train: 0.035973 (MSE=0.002935 BCE=0.6607) | Val: 0.042251 (MSE=0.008927 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042251 (ep 9)
[04:57:33] Epoch 10/100 | Train: 0.035962 (MSE=0.002931 BCE=0.6606) | Val: 0.042286 (MSE=0.008942 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042251 (ep 9)
[04:57:36] Epoch 11/100 | Train: 0.035957 (MSE=0.002922 BCE=0.6607) | Val: 0.042240 (MSE=0.008890 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042240 (ep 11)
[04:57:39] Epoch 12/100 | Train: 0.035945 (MSE=0.002916 BCE=0.6606) | Val: 0.042227 (MSE=0.008867 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:42] Epoch 13/100 | Train: 0.035934 (MSE=0.002909 BCE=0.6605) | Val: 0.042277 (MSE=0.008929 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:44] Epoch 14/100 | Train: 0.035921 (MSE=0.002903 BCE=0.6604) | Val: 0.042331 (MSE=0.008984 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:46] Epoch 15/100 | Train: 0.035915 (MSE=0.002895 BCE=0.6604) | Val: 0.042336 (MSE=0.008991 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:49] Epoch 16/100 | Train: 0.035913 (MSE=0.002892 BCE=0.6604) | Val: 0.042394 (MSE=0.009042 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:51] Epoch 17/100 | Train: 0.035895 (MSE=0.002884 BCE=0.6602) | Val: 0.042443 (MSE=0.009084 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042227 (ep 12)
[04:57:53] Epoch 18/100 | Train: 0.035893 (MSE=0.002881 BCE=0.6602) | Val: 0.042615 (MSE=0.009251 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042227 (ep 12)
[04:57:55] Epoch 19/100 | Train: 0.035880 (MSE=0.002872 BCE=0.6602) | Val: 0.042513 (MSE=0.009155 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042227 (ep 12)
[04:57:58] Epoch 20/100 | Train: 0.035869 (MSE=0.002867 BCE=0.6600) | Val: 0.042600 (MSE=0.009253 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042227 (ep 12)
[04:58:00] Epoch 21/100 | Train: 0.035860 (MSE=0.002866 BCE=0.6599) | Val: 0.042576 (MSE=0.009217 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042227 (ep 12)
[04:58:02] Epoch 22/100 | Train: 0.035863 (MSE=0.002863 BCE=0.6600) | Val: 0.042828 (MSE=0.009469 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042227 (ep 12)
[04:58:02] Early stopping at epoch 22 (no improvement for 10 epochs)
[04:58:03] Factor 4 done — best val loss: 0.042227 at epoch 12
[04:58:03] 
============================================================
[04:58:03] STF Factor 5 of [2..5]
[04:58:03] ============================================================
[04:58:04] Building features: 0% (1/175846)
[04:58:04] Building features: 5% (8793/175846)
[04:58:04] Building features: 10% (17585/175846)
[04:58:05] Building features: 15% (26377/175846)
[04:58:05] Building features: 20% (35169/175846)
[04:58:06] Building features: 25% (43961/175846)
[04:58:06] Building features: 30% (52753/175846)
[04:58:07] Building features: 35% (61545/175846)
[04:58:07] Building features: 40% (70337/175846)
[04:58:08] Building features: 45% (79129/175846)
[04:58:08] Building features: 50% (87921/175846)
[04:58:09] Building features: 55% (96713/175846)
[04:58:09] Building features: 60% (105505/175846)
[04:58:10] Building features: 65% (114297/175846)
[04:58:10] Building features: 70% (123089/175846)
[04:58:11] Building features: 75% (131881/175846)
[04:58:11] Building features: 80% (140673/175846)
[04:58:12] Building features: 85% (149465/175846)
[04:58:12] Building features: 90% (158257/175846)
[04:58:12] Building features: 95% (167049/175846)
[04:58:13] Building features: 100% (175841/175846)
[04:58:13] Computing Hurst exponent...
[04:58:18] Computing market regimes (GMM)...
[04:58:25] Factor 5: 175724 samples, 92 features
[04:58:27] Batch stats — Input:  mean=0.0534 std=0.2624 min=-3.8771 max=5.1139
[04:58:27] Batch stats — Target: mean=-0.0003 std=0.0680 min=-0.4720 max=0.4134
[04:58:27] Batch stats — Cls:    pos_long=92/256 pos_short=83/256
[04:58:27] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[04:58:32] Epoch 1/100 | Train: 0.036951 (MSE=0.003749 BCE=0.6640) | Val: 0.044458 (MSE=0.011083 BCE=0.6675) | LR: 1.00e-04 | Best: 0.044458 (ep 1)
[04:58:35] Epoch 2/100 | Train: 0.036181 (MSE=0.003104 BCE=0.6615) | Val: 0.042969 (MSE=0.009633 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042969 (ep 2)
[04:58:37] Epoch 3/100 | Train: 0.036122 (MSE=0.003055 BCE=0.6613) | Val: 0.042509 (MSE=0.009179 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042509 (ep 3)
[04:58:40] Epoch 4/100 | Train: 0.036079 (MSE=0.003018 BCE=0.6612) | Val: 0.042416 (MSE=0.009090 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042416 (ep 4)
[04:58:42] Epoch 5/100 | Train: 0.036048 (MSE=0.002991 BCE=0.6611) | Val: 0.042336 (MSE=0.009003 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042336 (ep 5)
[04:58:45] Epoch 6/100 | Train: 0.036022 (MSE=0.002969 BCE=0.6611) | Val: 0.042277 (MSE=0.008945 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042277 (ep 6)
[04:58:47] Epoch 7/100 | Train: 0.036000 (MSE=0.002955 BCE=0.6609) | Val: 0.042233 (MSE=0.008896 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042233 (ep 7)
[04:58:49] Epoch 8/100 | Train: 0.035987 (MSE=0.002946 BCE=0.6608) | Val: 0.042219 (MSE=0.008884 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:58:52] Epoch 9/100 | Train: 0.035974 (MSE=0.002935 BCE=0.6608) | Val: 0.042316 (MSE=0.008976 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:58:54] Epoch 10/100 | Train: 0.035961 (MSE=0.002926 BCE=0.6607) | Val: 0.042297 (MSE=0.008942 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:58:56] Epoch 11/100 | Train: 0.035954 (MSE=0.002919 BCE=0.6607) | Val: 0.042374 (MSE=0.009028 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:58:59] Epoch 12/100 | Train: 0.035946 (MSE=0.002913 BCE=0.6607) | Val: 0.042394 (MSE=0.009041 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:59:01] Epoch 13/100 | Train: 0.035931 (MSE=0.002906 BCE=0.6605) | Val: 0.042292 (MSE=0.008927 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042219 (ep 8)
[04:59:03] Epoch 14/100 | Train: 0.035923 (MSE=0.002899 BCE=0.6605) | Val: 0.042535 (MSE=0.009181 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042219 (ep 8)
[04:59:06] Epoch 15/100 | Train: 0.035909 (MSE=0.002890 BCE=0.6604) | Val: 0.042642 (MSE=0.009282 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042219 (ep 8)
[04:59:08] Epoch 16/100 | Train: 0.035908 (MSE=0.002891 BCE=0.6603) | Val: 0.042572 (MSE=0.009220 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042219 (ep 8)
[04:59:10] Epoch 17/100 | Train: 0.035894 (MSE=0.002883 BCE=0.6602) | Val: 0.042725 (MSE=0.009372 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042219 (ep 8)
[04:59:13] Epoch 18/100 | Train: 0.035894 (MSE=0.002880 BCE=0.6603) | Val: 0.042913 (MSE=0.009559 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042219 (ep 8)
[04:59:13] Early stopping at epoch 18 (no improvement for 10 epochs)
[04:59:13] Factor 5 done — best val loss: 0.042219 at epoch 8
[04:59:13] 
Best factor: 5 (val loss 0.042219)
[04:59:13] Training done. Best factor=5, val_loss=0.042219
[04:59:24] Building validation dataset...
[04:59:24] Building features: 0% (1/175846)
[04:59:25] Building features: 5% (8793/175846)
[04:59:25] Building features: 10% (17585/175846)
[04:59:25] Building features: 15% (26377/175846)
[04:59:26] Building features: 20% (35169/175846)
[04:59:26] Building features: 25% (43961/175846)
[04:59:27] Building features: 30% (52753/175846)
[04:59:27] Building features: 35% (61545/175846)
[04:59:28] Building features: 40% (70337/175846)
[04:59:28] Building features: 45% (79129/175846)
[04:59:29] Building features: 50% (87921/175846)
[04:59:30] Building features: 55% (96713/175846)
[04:59:30] Building features: 60% (105505/175846)
[04:59:31] Building features: 65% (114297/175846)
[04:59:32] Building features: 70% (123089/175846)
[04:59:32] Building features: 75% (131881/175846)
[04:59:33] Building features: 80% (140673/175846)
[04:59:33] Building features: 85% (149465/175846)
[04:59:34] Building features: 90% (158257/175846)
[04:59:34] Building features: 95% (167049/175846)
[04:59:35] Building features: 100% (175841/175846)
[04:59:35] Computing Hurst exponent...
[04:59:41] Computing market regimes (GMM)...
[04:59:48] Running backtest...
[04:59:49] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[12:34:18] NTCP initialized.
[12:34:30] Loaded 175846 M5 bars.
[12:35:13] Training started.
[12:35:13] 
============================================================
[12:35:13] STF Factor 5 of [5..10]
[12:35:13] ============================================================
[12:35:13] Building features: 0% (1/175846)
[12:35:14] Building features: 5% (8793/175846)
[12:35:14] Building features: 10% (17585/175846)
[12:35:15] Building features: 15% (26377/175846)
[12:35:15] Building features: 20% (35169/175846)
[12:35:16] Building features: 25% (43961/175846)
[12:35:16] Building features: 30% (52753/175846)
[12:35:17] Building features: 35% (61545/175846)
[12:35:17] Building features: 40% (70337/175846)
[12:35:18] Building features: 45% (79129/175846)
[12:35:19] Building features: 50% (87921/175846)
[12:35:19] Building features: 55% (96713/175846)
[12:35:20] Building features: 60% (105505/175846)
[12:35:20] Building features: 65% (114297/175846)
[12:35:21] Building features: 70% (123089/175846)
[12:35:21] Building features: 75% (131881/175846)
[12:35:22] Building features: 80% (140673/175846)
[12:35:23] Building features: 85% (149465/175846)
[12:35:23] Building features: 90% (158257/175846)
[12:35:24] Building features: 95% (167049/175846)
[12:35:24] Building features: 100% (175841/175846)
[12:35:24] Computing Hurst exponent...
[12:35:30] Computing market regimes (GMM)...
[12:35:44] Factor 5: 175724 samples, 92 features
[12:35:46] Batch stats — Input:  mean=0.0552 std=0.2631 min=-3.7395 max=13.1528
[12:35:46] Batch stats — Target: mean=0.0009 std=0.0635 min=-0.4391 max=0.4134
[12:35:46] Batch stats — Cls:    pos_long=113/256 pos_short=82/256
[12:35:46] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:35:53] Epoch 1/100 | Train: 0.036982 (MSE=0.003773 BCE=0.6642) | Val: 0.044569 (MSE=0.011199 BCE=0.6674) | LR: 1.00e-04 | Best: 0.044569 (ep 1)
[12:35:56] Epoch 2/100 | Train: 0.036188 (MSE=0.003103 BCE=0.6617) | Val: 0.042903 (MSE=0.009556 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042903 (ep 2)
[12:35:59] Epoch 3/100 | Train: 0.036119 (MSE=0.003048 BCE=0.6614) | Val: 0.042511 (MSE=0.009157 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042511 (ep 3)
[12:36:01] Epoch 4/100 | Train: 0.036081 (MSE=0.003016 BCE=0.6613) | Val: 0.042402 (MSE=0.009059 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042402 (ep 4)
[12:36:04] Epoch 5/100 | Train: 0.036050 (MSE=0.002987 BCE=0.6613) | Val: 0.042325 (MSE=0.009006 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042325 (ep 5)
[12:36:07] Epoch 6/100 | Train: 0.036023 (MSE=0.002970 BCE=0.6611) | Val: 0.042304 (MSE=0.008968 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042304 (ep 6)
[12:36:10] Epoch 7/100 | Train: 0.036002 (MSE=0.002955 BCE=0.6610) | Val: 0.042287 (MSE=0.008960 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:13] Epoch 8/100 | Train: 0.035986 (MSE=0.002943 BCE=0.6609) | Val: 0.042367 (MSE=0.009013 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:16] Epoch 9/100 | Train: 0.035973 (MSE=0.002933 BCE=0.6608) | Val: 0.042417 (MSE=0.009082 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:19] Epoch 10/100 | Train: 0.035966 (MSE=0.002927 BCE=0.6608) | Val: 0.042500 (MSE=0.009152 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:22] Epoch 11/100 | Train: 0.035955 (MSE=0.002919 BCE=0.6607) | Val: 0.042474 (MSE=0.009114 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:24] Epoch 12/100 | Train: 0.035950 (MSE=0.002915 BCE=0.6607) | Val: 0.042511 (MSE=0.009133 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042287 (ep 7)
[12:36:27] Epoch 13/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6605) | Val: 0.042514 (MSE=0.009178 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042287 (ep 7)
[12:36:30] Epoch 14/100 | Train: 0.035917 (MSE=0.002898 BCE=0.6604) | Val: 0.042552 (MSE=0.009203 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042287 (ep 7)
[12:36:33] Epoch 15/100 | Train: 0.035916 (MSE=0.002896 BCE=0.6604) | Val: 0.042553 (MSE=0.009199 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042287 (ep 7)
[12:36:36] Epoch 16/100 | Train: 0.035908 (MSE=0.002893 BCE=0.6603) | Val: 0.042652 (MSE=0.009292 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042287 (ep 7)
[12:36:39] Epoch 17/100 | Train: 0.035903 (MSE=0.002890 BCE=0.6603) | Val: 0.042760 (MSE=0.009404 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042287 (ep 7)
[12:36:39] Early stopping at epoch 17 (no improvement for 10 epochs)
[12:36:40] Factor 5 done — best val loss: 0.042287 at epoch 7
[12:36:40] 
============================================================
[12:36:40] STF Factor 6 of [5..10]
[12:36:40] ============================================================
[12:36:40] Building features: 0% (1/175846)
[12:36:41] Building features: 5% (8793/175846)
[12:36:41] Building features: 10% (17585/175846)
[12:36:42] Building features: 15% (26377/175846)
[12:36:43] Building features: 20% (35169/175846)
[12:36:43] Building features: 25% (43961/175846)
[12:36:44] Building features: 30% (52753/175846)
[12:36:45] Building features: 35% (61545/175846)
[12:36:45] Building features: 40% (70337/175846)
[12:36:46] Building features: 45% (79129/175846)
[12:36:46] Building features: 50% (87921/175846)
[12:36:47] Building features: 55% (96713/175846)
[12:36:48] Building features: 60% (105505/175846)
[12:36:48] Building features: 65% (114297/175846)
[12:36:49] Building features: 70% (123089/175846)
[12:36:50] Building features: 75% (131881/175846)
[12:36:50] Building features: 80% (140673/175846)
[12:36:51] Building features: 85% (149465/175846)
[12:36:52] Building features: 90% (158257/175846)
[12:36:52] Building features: 95% (167049/175846)
[12:36:53] Building features: 100% (175841/175846)
[12:36:53] Computing Hurst exponent...
[12:36:59] Computing market regimes (GMM)...
[12:37:07] Factor 6: 175724 samples, 92 features
[12:37:09] Batch stats — Input:  mean=0.0560 std=0.2687 min=-5.7028 max=22.9822
[12:37:09] Batch stats — Target: mean=0.0010 std=0.0653 min=-0.4720 max=0.4020
[12:37:09] Batch stats — Cls:    pos_long=114/256 pos_short=93/256
[12:37:09] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:37:13] Epoch 1/100 | Train: 0.037006 (MSE=0.003790 BCE=0.6643) | Val: 0.044010 (MSE=0.010632 BCE=0.6676) | LR: 1.00e-04 | Best: 0.044010 (ep 1)
[12:37:16] Epoch 2/100 | Train: 0.036188 (MSE=0.003102 BCE=0.6617) | Val: 0.042870 (MSE=0.009506 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042870 (ep 2)
[12:37:19] Epoch 3/100 | Train: 0.036118 (MSE=0.003051 BCE=0.6614) | Val: 0.042580 (MSE=0.009216 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042580 (ep 3)
[12:37:22] Epoch 4/100 | Train: 0.036084 (MSE=0.003022 BCE=0.6613) | Val: 0.042457 (MSE=0.009116 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042457 (ep 4)
[12:37:25] Epoch 5/100 | Train: 0.036052 (MSE=0.002994 BCE=0.6611) | Val: 0.042395 (MSE=0.009058 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042395 (ep 5)
[12:37:28] Epoch 6/100 | Train: 0.036029 (MSE=0.002975 BCE=0.6611) | Val: 0.042305 (MSE=0.008972 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042305 (ep 6)
[12:37:31] Epoch 7/100 | Train: 0.036010 (MSE=0.002961 BCE=0.6610) | Val: 0.042285 (MSE=0.008961 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:34] Epoch 8/100 | Train: 0.035997 (MSE=0.002948 BCE=0.6610) | Val: 0.042336 (MSE=0.008998 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:37] Epoch 9/100 | Train: 0.035982 (MSE=0.002938 BCE=0.6609) | Val: 0.042301 (MSE=0.008973 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:40] Epoch 10/100 | Train: 0.035974 (MSE=0.002930 BCE=0.6609) | Val: 0.042302 (MSE=0.008966 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:43] Epoch 11/100 | Train: 0.035958 (MSE=0.002924 BCE=0.6607) | Val: 0.042313 (MSE=0.008982 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:47] Epoch 12/100 | Train: 0.035948 (MSE=0.002918 BCE=0.6606) | Val: 0.042470 (MSE=0.009132 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042285 (ep 7)
[12:37:50] Epoch 13/100 | Train: 0.035940 (MSE=0.002909 BCE=0.6606) | Val: 0.042359 (MSE=0.009019 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042285 (ep 7)
[12:37:53] Epoch 14/100 | Train: 0.035924 (MSE=0.002901 BCE=0.6605) | Val: 0.042324 (MSE=0.008993 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042285 (ep 7)
[12:37:56] Epoch 15/100 | Train: 0.035919 (MSE=0.002898 BCE=0.6604) | Val: 0.042361 (MSE=0.009029 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042285 (ep 7)
[12:37:58] Epoch 16/100 | Train: 0.035910 (MSE=0.002892 BCE=0.6604) | Val: 0.042383 (MSE=0.009051 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042285 (ep 7)
[12:38:01] Epoch 17/100 | Train: 0.035908 (MSE=0.002892 BCE=0.6603) | Val: 0.042455 (MSE=0.009117 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042285 (ep 7)
[12:38:01] Early stopping at epoch 17 (no improvement for 10 epochs)
[12:38:02] Factor 6 done — best val loss: 0.042285 at epoch 7
[12:38:02] 
============================================================
[12:38:02] STF Factor 7 of [5..10]
[12:38:02] ============================================================
[12:38:02] Building features: 0% (1/175846)
[12:38:03] Building features: 5% (8793/175846)
[12:38:03] Building features: 10% (17585/175846)
[12:38:04] Building features: 15% (26377/175846)
[12:38:04] Building features: 20% (35169/175846)
[12:38:05] Building features: 25% (43961/175846)
[12:38:06] Building features: 30% (52753/175846)
[12:38:06] Building features: 35% (61545/175846)
[12:38:07] Building features: 40% (70337/175846)
[12:38:08] Building features: 45% (79129/175846)
[12:38:08] Building features: 50% (87921/175846)
[12:38:09] Building features: 55% (96713/175846)
[12:38:10] Building features: 60% (105505/175846)
[12:38:10] Building features: 65% (114297/175846)
[12:38:11] Building features: 70% (123089/175846)
[12:38:11] Building features: 75% (131881/175846)
[12:38:12] Building features: 80% (140673/175846)
[12:38:13] Building features: 85% (149465/175846)
[12:38:13] Building features: 90% (158257/175846)
[12:38:14] Building features: 95% (167049/175846)
[12:38:15] Building features: 100% (175841/175846)
[12:38:15] Computing Hurst exponent...
[12:38:20] Computing market regimes (GMM)...
[12:38:28] Factor 7: 175724 samples, 92 features
[12:38:30] Batch stats — Input:  mean=0.0541 std=0.2633 min=-3.4467 max=6.4057
[12:38:30] Batch stats — Target: mean=0.0002 std=0.0696 min=-0.4720 max=0.4134
[12:38:30] Batch stats — Cls:    pos_long=103/256 pos_short=90/256
[12:38:30] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:38:35] Epoch 1/100 | Train: 0.036960 (MSE=0.003762 BCE=0.6640) | Val: 0.044256 (MSE=0.010914 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044256 (ep 1)
[12:38:38] Epoch 2/100 | Train: 0.036189 (MSE=0.003111 BCE=0.6616) | Val: 0.043238 (MSE=0.009901 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043238 (ep 2)
[12:38:40] Epoch 3/100 | Train: 0.036127 (MSE=0.003060 BCE=0.6614) | Val: 0.042799 (MSE=0.009471 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042799 (ep 3)
[12:38:43] Epoch 4/100 | Train: 0.036089 (MSE=0.003027 BCE=0.6612) | Val: 0.042633 (MSE=0.009312 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042633 (ep 4)
[12:38:46] Epoch 5/100 | Train: 0.036046 (MSE=0.002998 BCE=0.6610) | Val: 0.042541 (MSE=0.009220 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042541 (ep 5)
[12:38:48] Epoch 6/100 | Train: 0.036027 (MSE=0.002975 BCE=0.6610) | Val: 0.042555 (MSE=0.009222 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042541 (ep 5)
[12:38:51] Epoch 7/100 | Train: 0.036009 (MSE=0.002958 BCE=0.6610) | Val: 0.042474 (MSE=0.009142 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042474 (ep 7)
[12:38:54] Epoch 8/100 | Train: 0.035988 (MSE=0.002945 BCE=0.6609) | Val: 0.042317 (MSE=0.008986 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:38:57] Epoch 9/100 | Train: 0.035973 (MSE=0.002935 BCE=0.6608) | Val: 0.042331 (MSE=0.008989 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:38:59] Epoch 10/100 | Train: 0.035965 (MSE=0.002927 BCE=0.6608) | Val: 0.042332 (MSE=0.009012 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:39:02] Epoch 11/100 | Train: 0.035951 (MSE=0.002918 BCE=0.6607) | Val: 0.042334 (MSE=0.008997 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:39:05] Epoch 12/100 | Train: 0.035941 (MSE=0.002911 BCE=0.6606) | Val: 0.042436 (MSE=0.009106 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:39:08] Epoch 13/100 | Train: 0.035933 (MSE=0.002908 BCE=0.6605) | Val: 0.042485 (MSE=0.009118 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042317 (ep 8)
[12:39:11] Epoch 14/100 | Train: 0.035922 (MSE=0.002897 BCE=0.6605) | Val: 0.042409 (MSE=0.009064 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042317 (ep 8)
[12:39:14] Epoch 15/100 | Train: 0.035909 (MSE=0.002890 BCE=0.6604) | Val: 0.042459 (MSE=0.009115 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042317 (ep 8)
[12:39:16] Epoch 16/100 | Train: 0.035898 (MSE=0.002886 BCE=0.6602) | Val: 0.042481 (MSE=0.009118 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042317 (ep 8)
[12:39:19] Epoch 17/100 | Train: 0.035900 (MSE=0.002883 BCE=0.6604) | Val: 0.042637 (MSE=0.009263 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042317 (ep 8)
[12:39:22] Epoch 18/100 | Train: 0.035891 (MSE=0.002878 BCE=0.6603) | Val: 0.042571 (MSE=0.009182 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042317 (ep 8)
[12:39:22] Early stopping at epoch 18 (no improvement for 10 epochs)
[12:39:23] Factor 7 done — best val loss: 0.042317 at epoch 8
[12:39:23] 
============================================================
[12:39:23] STF Factor 8 of [5..10]
[12:39:23] ============================================================
[12:39:23] Building features: 0% (1/175846)
[12:39:24] Building features: 5% (8793/175846)
[12:39:24] Building features: 10% (17585/175846)
[12:39:25] Building features: 15% (26377/175846)
[12:39:26] Building features: 20% (35169/175846)
[12:39:26] Building features: 25% (43961/175846)
[12:39:27] Building features: 30% (52753/175846)
[12:39:27] Building features: 35% (61545/175846)
[12:39:28] Building features: 40% (70337/175846)
[12:39:29] Building features: 45% (79129/175846)
[12:39:29] Building features: 50% (87921/175846)
[12:39:30] Building features: 55% (96713/175846)
[12:39:30] Building features: 60% (105505/175846)
[12:39:31] Building features: 65% (114297/175846)
[12:39:32] Building features: 70% (123089/175846)
[12:39:32] Building features: 75% (131881/175846)
[12:39:33] Building features: 80% (140673/175846)
[12:39:33] Building features: 85% (149465/175846)
[12:39:34] Building features: 90% (158257/175846)
[12:39:35] Building features: 95% (167049/175846)
[12:39:35] Building features: 100% (175841/175846)
[12:39:35] Computing Hurst exponent...
[12:39:41] Computing market regimes (GMM)...
[12:39:49] Factor 8: 175724 samples, 92 features
[12:39:51] Batch stats — Input:  mean=0.0543 std=0.2641 min=-3.4919 max=13.1528
[12:39:51] Batch stats — Target: mean=0.0016 std=0.0590 min=-0.3334 max=0.4134
[12:39:51] Batch stats — Cls:    pos_long=96/256 pos_short=102/256
[12:39:51] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:39:56] Epoch 1/100 | Train: 0.037117 (MSE=0.003908 BCE=0.6642) | Val: 0.044021 (MSE=0.010663 BCE=0.6672) | LR: 1.00e-04 | Best: 0.044021 (ep 1)
[12:39:59] Epoch 2/100 | Train: 0.036187 (MSE=0.003107 BCE=0.6616) | Val: 0.042925 (MSE=0.009585 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042925 (ep 2)
[12:40:02] Epoch 3/100 | Train: 0.036114 (MSE=0.003052 BCE=0.6612) | Val: 0.042683 (MSE=0.009335 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042683 (ep 3)
[12:40:05] Epoch 4/100 | Train: 0.036078 (MSE=0.003022 BCE=0.6611) | Val: 0.042590 (MSE=0.009239 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042590 (ep 4)
[12:40:08] Epoch 5/100 | Train: 0.036058 (MSE=0.002997 BCE=0.6612) | Val: 0.042469 (MSE=0.009130 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042469 (ep 5)
[12:40:10] Epoch 6/100 | Train: 0.036020 (MSE=0.002975 BCE=0.6609) | Val: 0.042415 (MSE=0.009086 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042415 (ep 6)
[12:40:13] Epoch 7/100 | Train: 0.036010 (MSE=0.002963 BCE=0.6609) | Val: 0.042295 (MSE=0.008966 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042295 (ep 7)
[12:40:16] Epoch 8/100 | Train: 0.035992 (MSE=0.002951 BCE=0.6608) | Val: 0.042270 (MSE=0.008942 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:19] Epoch 9/100 | Train: 0.035977 (MSE=0.002937 BCE=0.6608) | Val: 0.042278 (MSE=0.008940 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:21] Epoch 10/100 | Train: 0.035966 (MSE=0.002930 BCE=0.6607) | Val: 0.042298 (MSE=0.008960 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:24] Epoch 11/100 | Train: 0.035956 (MSE=0.002923 BCE=0.6607) | Val: 0.042301 (MSE=0.008967 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:27] Epoch 12/100 | Train: 0.035946 (MSE=0.002914 BCE=0.6607) | Val: 0.042363 (MSE=0.009013 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:30] Epoch 13/100 | Train: 0.035934 (MSE=0.002908 BCE=0.6605) | Val: 0.042345 (MSE=0.009010 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042270 (ep 8)
[12:40:32] Epoch 14/100 | Train: 0.035929 (MSE=0.002899 BCE=0.6606) | Val: 0.042338 (MSE=0.008997 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042270 (ep 8)
[12:40:35] Epoch 15/100 | Train: 0.035903 (MSE=0.002890 BCE=0.6603) | Val: 0.042295 (MSE=0.008945 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042270 (ep 8)
[12:40:38] Epoch 16/100 | Train: 0.035903 (MSE=0.002886 BCE=0.6603) | Val: 0.042319 (MSE=0.008967 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042270 (ep 8)
[12:40:41] Epoch 17/100 | Train: 0.035901 (MSE=0.002885 BCE=0.6603) | Val: 0.042420 (MSE=0.009065 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042270 (ep 8)
[12:40:43] Epoch 18/100 | Train: 0.035888 (MSE=0.002881 BCE=0.6601) | Val: 0.042405 (MSE=0.009054 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042270 (ep 8)
[12:40:43] Early stopping at epoch 18 (no improvement for 10 epochs)
[12:40:44] Factor 8 done — best val loss: 0.042270 at epoch 8
[12:40:44] 
============================================================
[12:40:44] STF Factor 9 of [5..10]
[12:40:44] ============================================================
[12:40:44] Building features: 0% (1/175846)
[12:40:45] Building features: 5% (8793/175846)
[12:40:46] Building features: 10% (17585/175846)
[12:40:46] Building features: 15% (26377/175846)
[12:40:47] Building features: 20% (35169/175846)
[12:40:47] Building features: 25% (43961/175846)
[12:40:48] Building features: 30% (52753/175846)
[12:40:49] Building features: 35% (61545/175846)
[12:40:49] Building features: 40% (70337/175846)
[12:40:50] Building features: 45% (79129/175846)
[12:40:50] Building features: 50% (87921/175846)
[12:40:51] Building features: 55% (96713/175846)
[12:40:52] Building features: 60% (105505/175846)
[12:40:52] Building features: 65% (114297/175846)
[12:40:53] Building features: 70% (123089/175846)
[12:40:53] Building features: 75% (131881/175846)
[12:40:54] Building features: 80% (140673/175846)
[12:40:55] Building features: 85% (149465/175846)
[12:40:55] Building features: 90% (158257/175846)
[12:40:56] Building features: 95% (167049/175846)
[12:40:56] Building features: 100% (175841/175846)
[12:40:56] Computing Hurst exponent...
[12:41:02] Computing market regimes (GMM)...
[12:41:10] Factor 9: 175724 samples, 92 features
[12:41:12] Batch stats — Input:  mean=0.0541 std=0.2666 min=-4.6594 max=6.8647
[12:41:12] Batch stats — Target: mean=0.0013 std=0.0734 min=-0.4720 max=0.4134
[12:41:12] Batch stats — Cls:    pos_long=103/256 pos_short=98/256
[12:41:12] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:41:17] Epoch 1/100 | Train: 0.036943 (MSE=0.003771 BCE=0.6634) | Val: 0.044466 (MSE=0.011095 BCE=0.6674) | LR: 1.00e-04 | Best: 0.044466 (ep 1)
[12:41:19] Epoch 2/100 | Train: 0.036176 (MSE=0.003096 BCE=0.6616) | Val: 0.043024 (MSE=0.009665 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043024 (ep 2)
[12:41:22] Epoch 3/100 | Train: 0.036114 (MSE=0.003047 BCE=0.6613) | Val: 0.042735 (MSE=0.009401 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042735 (ep 3)
[12:41:25] Epoch 4/100 | Train: 0.036073 (MSE=0.003020 BCE=0.6611) | Val: 0.042487 (MSE=0.009153 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042487 (ep 4)
[12:41:28] Epoch 5/100 | Train: 0.036047 (MSE=0.002991 BCE=0.6611) | Val: 0.042448 (MSE=0.009120 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042448 (ep 5)
[12:41:31] Epoch 6/100 | Train: 0.036009 (MSE=0.002969 BCE=0.6608) | Val: 0.042378 (MSE=0.009055 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042378 (ep 6)
[12:41:34] Epoch 7/100 | Train: 0.036000 (MSE=0.002954 BCE=0.6609) | Val: 0.042520 (MSE=0.009192 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042378 (ep 6)
[12:41:36] Epoch 8/100 | Train: 0.035986 (MSE=0.002943 BCE=0.6609) | Val: 0.042276 (MSE=0.008947 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042276 (ep 8)
[12:41:39] Epoch 9/100 | Train: 0.035971 (MSE=0.002932 BCE=0.6608) | Val: 0.042286 (MSE=0.008946 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042276 (ep 8)
[12:41:42] Epoch 10/100 | Train: 0.035964 (MSE=0.002926 BCE=0.6608) | Val: 0.042255 (MSE=0.008922 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:45] Epoch 11/100 | Train: 0.035948 (MSE=0.002918 BCE=0.6606) | Val: 0.042351 (MSE=0.009021 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:47] Epoch 12/100 | Train: 0.035939 (MSE=0.002910 BCE=0.6606) | Val: 0.042437 (MSE=0.009099 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:50] Epoch 13/100 | Train: 0.035931 (MSE=0.002908 BCE=0.6605) | Val: 0.042624 (MSE=0.009284 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:53] Epoch 14/100 | Train: 0.035919 (MSE=0.002898 BCE=0.6604) | Val: 0.042537 (MSE=0.009200 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:56] Epoch 15/100 | Train: 0.035911 (MSE=0.002893 BCE=0.6604) | Val: 0.042603 (MSE=0.009263 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042255 (ep 10)
[12:41:59] Epoch 16/100 | Train: 0.035904 (MSE=0.002891 BCE=0.6603) | Val: 0.042855 (MSE=0.009504 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042255 (ep 10)
[12:42:01] Epoch 17/100 | Train: 0.035887 (MSE=0.002879 BCE=0.6602) | Val: 0.043185 (MSE=0.009834 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042255 (ep 10)
[12:42:04] Epoch 18/100 | Train: 0.035883 (MSE=0.002878 BCE=0.6601) | Val: 0.043099 (MSE=0.009750 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042255 (ep 10)
[12:42:07] Epoch 19/100 | Train: 0.035876 (MSE=0.002873 BCE=0.6601) | Val: 0.043170 (MSE=0.009818 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042255 (ep 10)
[12:42:10] Epoch 20/100 | Train: 0.035874 (MSE=0.002873 BCE=0.6600) | Val: 0.043257 (MSE=0.009897 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042255 (ep 10)
[12:42:10] Early stopping at epoch 20 (no improvement for 10 epochs)
[12:42:11] Factor 9 done — best val loss: 0.042255 at epoch 10
[12:42:11] 
============================================================
[12:42:11] STF Factor 10 of [5..10]
[12:42:11] ============================================================
[12:42:11] Building features: 0% (1/175846)
[12:42:12] Building features: 5% (8793/175846)
[12:42:12] Building features: 10% (17585/175846)
[12:42:13] Building features: 15% (26377/175846)
[12:42:13] Building features: 20% (35169/175846)
[12:42:14] Building features: 25% (43961/175846)
[12:42:15] Building features: 30% (52753/175846)
[12:42:15] Building features: 35% (61545/175846)
[12:42:16] Building features: 40% (70337/175846)
[12:42:16] Building features: 45% (79129/175846)
[12:42:17] Building features: 50% (87921/175846)
[12:42:18] Building features: 55% (96713/175846)
[12:42:18] Building features: 60% (105505/175846)
[12:42:19] Building features: 65% (114297/175846)
[12:42:19] Building features: 70% (123089/175846)
[12:42:20] Building features: 75% (131881/175846)
[12:42:21] Building features: 80% (140673/175846)
[12:42:21] Building features: 85% (149465/175846)
[12:42:22] Building features: 90% (158257/175846)
[12:42:23] Building features: 95% (167049/175846)
[12:42:23] Building features: 100% (175841/175846)
[12:42:23] Computing Hurst exponent...
[12:42:29] Computing market regimes (GMM)...
[12:42:37] Factor 10: 175724 samples, 92 features
[12:42:39] Batch stats — Input:  mean=0.0513 std=0.2649 min=-4.2128 max=5.6871
[12:42:39] Batch stats — Target: mean=0.0050 std=0.0642 min=-0.2798 max=0.4134
[12:42:39] Batch stats — Cls:    pos_long=92/256 pos_short=85/256
[12:42:39] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[12:42:44] Epoch 1/100 | Train: 0.037243 (MSE=0.004012 BCE=0.6646) | Val: 0.043784 (MSE=0.010428 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043784 (ep 1)
[12:42:47] Epoch 2/100 | Train: 0.036205 (MSE=0.003119 BCE=0.6617) | Val: 0.042823 (MSE=0.009467 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042823 (ep 2)
[12:42:50] Epoch 3/100 | Train: 0.036133 (MSE=0.003061 BCE=0.6614) | Val: 0.042604 (MSE=0.009251 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042604 (ep 3)
[12:42:53] Epoch 4/100 | Train: 0.036093 (MSE=0.003025 BCE=0.6614) | Val: 0.042474 (MSE=0.009148 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042474 (ep 4)
[12:42:55] Epoch 5/100 | Train: 0.036051 (MSE=0.002997 BCE=0.6611) | Val: 0.042373 (MSE=0.009042 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042373 (ep 5)
[12:42:58] Epoch 6/100 | Train: 0.036031 (MSE=0.002978 BCE=0.6611) | Val: 0.042415 (MSE=0.009075 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042373 (ep 5)
[12:43:01] Epoch 7/100 | Train: 0.036008 (MSE=0.002960 BCE=0.6610) | Val: 0.042311 (MSE=0.008971 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042311 (ep 7)
[12:43:04] Epoch 8/100 | Train: 0.035993 (MSE=0.002949 BCE=0.6609) | Val: 0.042281 (MSE=0.008937 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042281 (ep 8)
[12:43:07] Epoch 9/100 | Train: 0.035981 (MSE=0.002938 BCE=0.6609) | Val: 0.042283 (MSE=0.008935 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042281 (ep 8)
[12:43:09] Epoch 10/100 | Train: 0.035971 (MSE=0.002931 BCE=0.6608) | Val: 0.042294 (MSE=0.008961 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042281 (ep 8)
[12:43:12] Epoch 11/100 | Train: 0.035957 (MSE=0.002923 BCE=0.6607) | Val: 0.042269 (MSE=0.008938 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:15] Epoch 12/100 | Train: 0.035941 (MSE=0.002913 BCE=0.6606) | Val: 0.042353 (MSE=0.009006 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:18] Epoch 13/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6605) | Val: 0.042389 (MSE=0.009049 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:20] Epoch 14/100 | Train: 0.035924 (MSE=0.002901 BCE=0.6604) | Val: 0.042464 (MSE=0.009122 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:23] Epoch 15/100 | Train: 0.035916 (MSE=0.002896 BCE=0.6604) | Val: 0.042398 (MSE=0.009055 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:26] Epoch 16/100 | Train: 0.035907 (MSE=0.002892 BCE=0.6603) | Val: 0.042492 (MSE=0.009107 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042269 (ep 11)
[12:43:29] Epoch 17/100 | Train: 0.035902 (MSE=0.002882 BCE=0.6604) | Val: 0.042554 (MSE=0.009185 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042269 (ep 11)
[12:43:33] Epoch 18/100 | Train: 0.035881 (MSE=0.002874 BCE=0.6601) | Val: 0.042612 (MSE=0.009247 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042269 (ep 11)
[12:43:36] Epoch 19/100 | Train: 0.035883 (MSE=0.002875 BCE=0.6602) | Val: 0.042526 (MSE=0.009155 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042269 (ep 11)
[12:43:38] Epoch 20/100 | Train: 0.035876 (MSE=0.002869 BCE=0.6601) | Val: 0.042694 (MSE=0.009317 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042269 (ep 11)
[12:43:41] Epoch 21/100 | Train: 0.035872 (MSE=0.002867 BCE=0.6601) | Val: 0.042754 (MSE=0.009359 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042269 (ep 11)
[12:43:41] Early stopping at epoch 21 (no improvement for 10 epochs)
[12:43:42] Factor 10 done — best val loss: 0.042269 at epoch 11
[12:43:42] 
Best factor: 9 (val loss 0.042255)
[12:43:42] Training done. Best factor=9, val_loss=0.042255
[12:47:32] Building validation dataset...
[12:47:32] Building features: 0% (1/175846)
[12:47:33] Building features: 5% (8793/175846)
[12:47:33] Building features: 10% (17585/175846)
[12:47:34] Building features: 15% (26377/175846)
[12:47:34] Building features: 20% (35169/175846)
[12:47:35] Building features: 25% (43961/175846)
[12:47:35] Building features: 30% (52753/175846)
[12:47:36] Building features: 35% (61545/175846)
[12:47:37] Building features: 40% (70337/175846)
[12:47:37] Building features: 45% (79129/175846)
[12:47:38] Building features: 50% (87921/175846)
[12:47:38] Building features: 55% (96713/175846)
[12:47:39] Building features: 60% (105505/175846)
[12:47:40] Building features: 65% (114297/175846)
[12:47:40] Building features: 70% (123089/175846)
[12:47:41] Building features: 75% (131881/175846)
[12:47:41] Building features: 80% (140673/175846)
[12:47:42] Building features: 85% (149465/175846)
[12:47:43] Building features: 90% (158257/175846)
[12:47:43] Building features: 95% (167049/175846)
[12:47:44] Building features: 100% (175841/175846)
[12:47:44] Computing Hurst exponent...
[12:47:49] Computing market regimes (GMM)...
[12:47:57] Running backtest...
[12:47:58] Backtest complete: 8939 trades (7921L/1018S), WR=47.9%, PF=0.92
[13:01:52] Training started.
[13:01:52] 
============================================================
[13:01:52] STF Factor 5 of [5..10]
[13:01:52] ============================================================
[13:01:52] Building features: 0% (1/175846)
[13:01:52] Building features: 5% (8793/175846)
[13:01:53] Building features: 10% (17585/175846)
[13:01:53] Building features: 15% (26377/175846)
[13:01:54] Building features: 20% (35169/175846)
[13:01:54] Building features: 25% (43961/175846)
[13:01:55] Building features: 30% (52753/175846)
[13:01:55] Building features: 35% (61545/175846)
[13:01:56] Building features: 40% (70337/175846)
[13:01:56] Building features: 45% (79129/175846)
[13:01:57] Building features: 50% (87921/175846)
[13:01:58] Building features: 55% (96713/175846)
[13:01:58] Building features: 60% (105505/175846)
[13:01:59] Building features: 65% (114297/175846)
[13:02:00] Building features: 70% (123089/175846)
[13:02:00] Building features: 75% (131881/175846)
[13:02:01] Building features: 80% (140673/175846)
[13:02:02] Building features: 85% (149465/175846)
[13:02:02] Building features: 90% (158257/175846)
[13:02:03] Building features: 95% (167049/175846)
[13:02:03] Building features: 100% (175841/175846)
[13:02:03] Computing Hurst exponent...
[13:02:09] Computing market regimes (GMM)...
[13:02:16] Factor 5: 175704 samples, 92 features
[13:02:18] Batch stats — Input:  mean=0.0523 std=0.2637 min=-3.5521 max=7.5420
[13:02:18] Batch stats — Target: mean=-0.0021 std=0.0669 min=-0.4720 max=0.3706
[13:02:18] Batch stats — Cls:    pos_long=109/256 pos_short=91/256
[13:02:18] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:02:23] Epoch 1/100 | Train: 0.037138 (MSE=0.003951 BCE=0.6637) | Val: 0.044506 (MSE=0.011166 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044506 (ep 1)
[13:02:26] Epoch 2/100 | Train: 0.036188 (MSE=0.003111 BCE=0.6615) | Val: 0.042928 (MSE=0.009600 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042928 (ep 2)
[13:02:29] Epoch 3/100 | Train: 0.036121 (MSE=0.003049 BCE=0.6614) | Val: 0.042518 (MSE=0.009181 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042518 (ep 3)
[13:02:31] Epoch 4/100 | Train: 0.036079 (MSE=0.003016 BCE=0.6613) | Val: 0.042422 (MSE=0.009098 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042422 (ep 4)
[13:02:34] Epoch 5/100 | Train: 0.036046 (MSE=0.002989 BCE=0.6611) | Val: 0.042314 (MSE=0.008989 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042314 (ep 5)
[13:02:37] Epoch 6/100 | Train: 0.036020 (MSE=0.002970 BCE=0.6610) | Val: 0.042283 (MSE=0.008951 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042283 (ep 6)
[13:02:40] Epoch 7/100 | Train: 0.036002 (MSE=0.002956 BCE=0.6609) | Val: 0.042250 (MSE=0.008929 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042250 (ep 7)
[13:02:43] Epoch 8/100 | Train: 0.035987 (MSE=0.002941 BCE=0.6609) | Val: 0.042172 (MSE=0.008843 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:02:46] Epoch 9/100 | Train: 0.035965 (MSE=0.002929 BCE=0.6607) | Val: 0.042226 (MSE=0.008885 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:02:49] Epoch 10/100 | Train: 0.035952 (MSE=0.002919 BCE=0.6607) | Val: 0.042260 (MSE=0.008933 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:02:52] Epoch 11/100 | Train: 0.035946 (MSE=0.002913 BCE=0.6607) | Val: 0.042256 (MSE=0.008901 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:02:55] Epoch 12/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6606) | Val: 0.042265 (MSE=0.008912 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:02:58] Epoch 13/100 | Train: 0.035921 (MSE=0.002899 BCE=0.6605) | Val: 0.042396 (MSE=0.009051 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042172 (ep 8)
[13:03:01] Epoch 14/100 | Train: 0.035912 (MSE=0.002891 BCE=0.6604) | Val: 0.042346 (MSE=0.009002 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042172 (ep 8)
[13:03:04] Epoch 15/100 | Train: 0.035898 (MSE=0.002881 BCE=0.6603) | Val: 0.042358 (MSE=0.009014 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042172 (ep 8)
[13:03:07] Epoch 16/100 | Train: 0.035896 (MSE=0.002878 BCE=0.6603) | Val: 0.042547 (MSE=0.009192 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042172 (ep 8)
[13:03:10] Epoch 17/100 | Train: 0.035884 (MSE=0.002873 BCE=0.6602) | Val: 0.042612 (MSE=0.009258 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042172 (ep 8)
[13:03:13] Epoch 18/100 | Train: 0.035881 (MSE=0.002871 BCE=0.6602) | Val: 0.042505 (MSE=0.009163 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042172 (ep 8)
[13:03:13] Early stopping at epoch 18 (no improvement for 10 epochs)
[13:03:14] Factor 5 done — best val loss: 0.042172 at epoch 8
[13:03:14] 
============================================================
[13:03:14] STF Factor 6 of [5..10]
[13:03:14] ============================================================
[13:03:14] Building features: 0% (1/175846)
[13:03:15] Building features: 5% (8793/175846)
[13:03:15] Building features: 10% (17585/175846)
[13:03:16] Building features: 15% (26377/175846)
[13:03:16] Building features: 20% (35169/175846)
[13:03:17] Building features: 25% (43961/175846)
[13:03:18] Building features: 30% (52753/175846)
[13:03:18] Building features: 35% (61545/175846)
[13:03:19] Building features: 40% (70337/175846)
[13:03:19] Building features: 45% (79129/175846)
[13:03:20] Building features: 50% (87921/175846)
[13:03:20] Building features: 55% (96713/175846)
[13:03:21] Building features: 60% (105505/175846)
[13:03:22] Building features: 65% (114297/175846)
[13:03:22] Building features: 70% (123089/175846)
[13:03:23] Building features: 75% (131881/175846)
[13:03:23] Building features: 80% (140673/175846)
[13:03:24] Building features: 85% (149465/175846)
[13:03:24] Building features: 90% (158257/175846)
[13:03:25] Building features: 95% (167049/175846)
[13:03:26] Building features: 100% (175841/175846)
[13:03:26] Computing Hurst exponent...
[13:03:31] Computing market regimes (GMM)...
[13:03:39] Factor 6: 175704 samples, 92 features
[13:03:41] Batch stats — Input:  mean=0.0532 std=0.2685 min=-5.1296 max=13.1528
[13:03:41] Batch stats — Target: mean=0.0008 std=0.0673 min=-0.4720 max=0.2968
[13:03:41] Batch stats — Cls:    pos_long=96/256 pos_short=89/256
[13:03:41] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:03:45] Epoch 1/100 | Train: 0.037097 (MSE=0.003906 BCE=0.6638) | Val: 0.044358 (MSE=0.010995 BCE=0.6673) | LR: 1.00e-04 | Best: 0.044358 (ep 1)
[13:03:47] Epoch 2/100 | Train: 0.036208 (MSE=0.003127 BCE=0.6616) | Val: 0.042968 (MSE=0.009617 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042968 (ep 2)
[13:03:49] Epoch 3/100 | Train: 0.036137 (MSE=0.003067 BCE=0.6614) | Val: 0.042562 (MSE=0.009201 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042562 (ep 3)
[13:03:52] Epoch 4/100 | Train: 0.036092 (MSE=0.003030 BCE=0.6612) | Val: 0.042476 (MSE=0.009131 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042476 (ep 4)
[13:03:54] Epoch 5/100 | Train: 0.036053 (MSE=0.002998 BCE=0.6611) | Val: 0.042340 (MSE=0.009004 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042340 (ep 5)
[13:03:56] Epoch 6/100 | Train: 0.036026 (MSE=0.002977 BCE=0.6610) | Val: 0.042266 (MSE=0.008928 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042266 (ep 6)
[13:03:59] Epoch 7/100 | Train: 0.036005 (MSE=0.002962 BCE=0.6609) | Val: 0.042249 (MSE=0.008910 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042249 (ep 7)
[13:04:01] Epoch 8/100 | Train: 0.035989 (MSE=0.002947 BCE=0.6608) | Val: 0.042243 (MSE=0.008894 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:04] Epoch 9/100 | Train: 0.035974 (MSE=0.002937 BCE=0.6607) | Val: 0.042256 (MSE=0.008906 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:06] Epoch 10/100 | Train: 0.035968 (MSE=0.002929 BCE=0.6608) | Val: 0.042342 (MSE=0.009003 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:09] Epoch 11/100 | Train: 0.035953 (MSE=0.002919 BCE=0.6607) | Val: 0.042312 (MSE=0.008947 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:12] Epoch 12/100 | Train: 0.035946 (MSE=0.002914 BCE=0.6607) | Val: 0.042335 (MSE=0.008979 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:15] Epoch 13/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6605) | Val: 0.042450 (MSE=0.009092 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042243 (ep 8)
[13:04:18] Epoch 14/100 | Train: 0.035927 (MSE=0.002902 BCE=0.6605) | Val: 0.042522 (MSE=0.009167 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042243 (ep 8)
[13:04:22] Epoch 15/100 | Train: 0.035912 (MSE=0.002892 BCE=0.6604) | Val: 0.042489 (MSE=0.009139 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042243 (ep 8)
[13:04:25] Epoch 16/100 | Train: 0.035902 (MSE=0.002888 BCE=0.6603) | Val: 0.042471 (MSE=0.009100 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042243 (ep 8)
[13:04:28] Epoch 17/100 | Train: 0.035897 (MSE=0.002885 BCE=0.6602) | Val: 0.042499 (MSE=0.009137 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042243 (ep 8)
[13:04:31] Epoch 18/100 | Train: 0.035893 (MSE=0.002881 BCE=0.6602) | Val: 0.042585 (MSE=0.009225 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042243 (ep 8)
[13:04:31] Early stopping at epoch 18 (no improvement for 10 epochs)
[13:04:31] Factor 6 done — best val loss: 0.042243 at epoch 8
[13:04:31] 
============================================================
[13:04:31] STF Factor 7 of [5..10]
[13:04:31] ============================================================
[13:04:32] Building features: 0% (1/175846)
[13:04:32] Building features: 5% (8793/175846)
[13:04:33] Building features: 10% (17585/175846)
[13:04:33] Building features: 15% (26377/175846)
[13:04:34] Building features: 20% (35169/175846)
[13:04:35] Building features: 25% (43961/175846)
[13:04:35] Building features: 30% (52753/175846)
[13:04:36] Building features: 35% (61545/175846)
[13:04:36] Building features: 40% (70337/175846)
[13:04:37] Building features: 45% (79129/175846)
[13:04:38] Building features: 50% (87921/175846)
[13:04:38] Building features: 55% (96713/175846)
[13:04:39] Building features: 60% (105505/175846)
[13:04:39] Building features: 65% (114297/175846)
[13:04:40] Building features: 70% (123089/175846)
[13:04:40] Building features: 75% (131881/175846)
[13:04:41] Building features: 80% (140673/175846)
[13:04:42] Building features: 85% (149465/175846)
[13:04:42] Building features: 90% (158257/175846)
[13:04:43] Building features: 95% (167049/175846)
[13:04:43] Building features: 100% (175841/175846)
[13:04:43] Computing Hurst exponent...
[13:04:49] Computing market regimes (GMM)...
[13:04:57] Factor 7: 175704 samples, 92 features
[13:04:59] Batch stats — Input:  mean=0.0535 std=0.2658 min=-5.5995 max=12.2195
[13:04:59] Batch stats — Target: mean=0.0027 std=0.0629 min=-0.4720 max=0.3371
[13:04:59] Batch stats — Cls:    pos_long=106/256 pos_short=93/256
[13:04:59] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:05:04] Epoch 1/100 | Train: 0.037005 (MSE=0.003801 BCE=0.6641) | Val: 0.044095 (MSE=0.010738 BCE=0.6672) | LR: 1.00e-04 | Best: 0.044095 (ep 1)
[13:05:07] Epoch 2/100 | Train: 0.036201 (MSE=0.003122 BCE=0.6616) | Val: 0.042945 (MSE=0.009581 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042945 (ep 2)
[13:05:10] Epoch 3/100 | Train: 0.036130 (MSE=0.003066 BCE=0.6613) | Val: 0.042748 (MSE=0.009399 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042748 (ep 3)
[13:05:13] Epoch 4/100 | Train: 0.036098 (MSE=0.003033 BCE=0.6613) | Val: 0.042512 (MSE=0.009175 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042512 (ep 4)
[13:05:16] Epoch 5/100 | Train: 0.036057 (MSE=0.003004 BCE=0.6611) | Val: 0.042500 (MSE=0.009153 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042500 (ep 5)
[13:05:19] Epoch 6/100 | Train: 0.036030 (MSE=0.002980 BCE=0.6610) | Val: 0.042381 (MSE=0.009045 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042381 (ep 6)
[13:05:22] Epoch 7/100 | Train: 0.036009 (MSE=0.002961 BCE=0.6610) | Val: 0.042289 (MSE=0.008957 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:26] Epoch 8/100 | Train: 0.035995 (MSE=0.002949 BCE=0.6609) | Val: 0.042323 (MSE=0.008984 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:29] Epoch 9/100 | Train: 0.035978 (MSE=0.002938 BCE=0.6608) | Val: 0.042370 (MSE=0.009025 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:32] Epoch 10/100 | Train: 0.035963 (MSE=0.002926 BCE=0.6607) | Val: 0.042306 (MSE=0.008948 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:35] Epoch 11/100 | Train: 0.035953 (MSE=0.002919 BCE=0.6607) | Val: 0.042397 (MSE=0.009041 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:38] Epoch 12/100 | Train: 0.035942 (MSE=0.002910 BCE=0.6606) | Val: 0.042353 (MSE=0.009000 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042289 (ep 7)
[13:05:40] Epoch 13/100 | Train: 0.035927 (MSE=0.002902 BCE=0.6605) | Val: 0.042381 (MSE=0.009035 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042289 (ep 7)
[13:05:43] Epoch 14/100 | Train: 0.035914 (MSE=0.002894 BCE=0.6604) | Val: 0.042371 (MSE=0.009013 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042289 (ep 7)
[13:05:45] Epoch 15/100 | Train: 0.035910 (MSE=0.002889 BCE=0.6604) | Val: 0.042390 (MSE=0.009040 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042289 (ep 7)
[13:05:48] Epoch 16/100 | Train: 0.035904 (MSE=0.002886 BCE=0.6604) | Val: 0.042435 (MSE=0.009070 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042289 (ep 7)
[13:05:50] Epoch 17/100 | Train: 0.035899 (MSE=0.002884 BCE=0.6603) | Val: 0.042489 (MSE=0.009124 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042289 (ep 7)
[13:05:50] Early stopping at epoch 17 (no improvement for 10 epochs)
[13:05:51] Factor 7 done — best val loss: 0.042289 at epoch 7
[13:05:51] 
============================================================
[13:05:51] STF Factor 8 of [5..10]
[13:05:51] ============================================================
[13:05:51] Building features: 0% (1/175846)
[13:05:52] Building features: 5% (8793/175846)
[13:05:52] Building features: 10% (17585/175846)
[13:05:53] Building features: 15% (26377/175846)
[13:05:53] Building features: 20% (35169/175846)
[13:05:54] Building features: 25% (43961/175846)
[13:05:54] Building features: 30% (52753/175846)
[13:05:55] Building features: 35% (61545/175846)
[13:05:55] Building features: 40% (70337/175846)
[13:05:56] Building features: 45% (79129/175846)
[13:05:56] Building features: 50% (87921/175846)
[13:05:57] Building features: 55% (96713/175846)
[13:05:57] Building features: 60% (105505/175846)
[13:05:58] Building features: 65% (114297/175846)
[13:05:58] Building features: 70% (123089/175846)
[13:05:59] Building features: 75% (131881/175846)
[13:05:59] Building features: 80% (140673/175846)
[13:06:00] Building features: 85% (149465/175846)
[13:06:00] Building features: 90% (158257/175846)
[13:06:01] Building features: 95% (167049/175846)
[13:06:01] Building features: 100% (175841/175846)
[13:06:01] Computing Hurst exponent...
[13:06:06] Computing market regimes (GMM)...
[13:06:13] Factor 8: 175704 samples, 92 features
[13:06:14] Batch stats — Input:  mean=0.0540 std=0.2613 min=-3.3776 max=7.5420
[13:06:14] Batch stats — Target: mean=0.0015 std=0.0592 min=-0.3838 max=0.4134
[13:06:14] Batch stats — Cls:    pos_long=103/256 pos_short=92/256
[13:06:14] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:06:19] Epoch 1/100 | Train: 0.037285 (MSE=0.004054 BCE=0.6646) | Val: 0.044760 (MSE=0.011418 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044760 (ep 1)
[13:06:21] Epoch 2/100 | Train: 0.036215 (MSE=0.003133 BCE=0.6616) | Val: 0.043319 (MSE=0.009991 BCE=0.6666) | LR: 1.00e-04 | Best: 0.043319 (ep 2)
[13:06:23] Epoch 3/100 | Train: 0.036135 (MSE=0.003065 BCE=0.6614) | Val: 0.042621 (MSE=0.009293 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042621 (ep 3)
[13:06:26] Epoch 4/100 | Train: 0.036101 (MSE=0.003029 BCE=0.6614) | Val: 0.042532 (MSE=0.009191 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042532 (ep 4)
[13:06:28] Epoch 5/100 | Train: 0.036061 (MSE=0.003002 BCE=0.6612) | Val: 0.042496 (MSE=0.009160 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042496 (ep 5)
[13:06:31] Epoch 6/100 | Train: 0.036033 (MSE=0.002982 BCE=0.6610) | Val: 0.042464 (MSE=0.009097 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042464 (ep 6)
[13:06:33] Epoch 7/100 | Train: 0.036015 (MSE=0.002964 BCE=0.6610) | Val: 0.042434 (MSE=0.009073 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042434 (ep 7)
[13:06:36] Epoch 8/100 | Train: 0.036001 (MSE=0.002955 BCE=0.6609) | Val: 0.042353 (MSE=0.009004 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042353 (ep 8)
[13:06:38] Epoch 9/100 | Train: 0.035986 (MSE=0.002944 BCE=0.6608) | Val: 0.042349 (MSE=0.008989 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042349 (ep 9)
[13:06:41] Epoch 10/100 | Train: 0.035978 (MSE=0.002938 BCE=0.6608) | Val: 0.042582 (MSE=0.009188 BCE=0.6679) | LR: 1.00e-04 | Best: 0.042349 (ep 9)
[13:06:43] Epoch 11/100 | Train: 0.035965 (MSE=0.002927 BCE=0.6607) | Val: 0.042551 (MSE=0.009200 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042349 (ep 9)
[13:06:45] Epoch 12/100 | Train: 0.035958 (MSE=0.002921 BCE=0.6607) | Val: 0.042419 (MSE=0.009073 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042349 (ep 9)
[13:06:48] Epoch 13/100 | Train: 0.035945 (MSE=0.002912 BCE=0.6607) | Val: 0.042514 (MSE=0.009157 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042349 (ep 9)
[13:06:50] Epoch 14/100 | Train: 0.035931 (MSE=0.002905 BCE=0.6605) | Val: 0.042666 (MSE=0.009318 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:06:53] Epoch 15/100 | Train: 0.035916 (MSE=0.002896 BCE=0.6604) | Val: 0.042658 (MSE=0.009302 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:06:56] Epoch 16/100 | Train: 0.035912 (MSE=0.002894 BCE=0.6604) | Val: 0.042699 (MSE=0.009339 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:06:59] Epoch 17/100 | Train: 0.035911 (MSE=0.002891 BCE=0.6604) | Val: 0.042629 (MSE=0.009269 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:07:01] Epoch 18/100 | Train: 0.035906 (MSE=0.002888 BCE=0.6604) | Val: 0.042697 (MSE=0.009340 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:07:04] Epoch 19/100 | Train: 0.035896 (MSE=0.002882 BCE=0.6603) | Val: 0.042813 (MSE=0.009454 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042349 (ep 9)
[13:07:04] Early stopping at epoch 19 (no improvement for 10 epochs)
[13:07:05] Factor 8 done — best val loss: 0.042349 at epoch 9
[13:07:05] 
============================================================
[13:07:05] STF Factor 9 of [5..10]
[13:07:05] ============================================================
[13:07:05] Building features: 0% (1/175846)
[13:07:06] Building features: 5% (8793/175846)
[13:07:07] Building features: 10% (17585/175846)
[13:07:07] Building features: 15% (26377/175846)
[13:07:08] Building features: 20% (35169/175846)
[13:07:08] Building features: 25% (43961/175846)
[13:07:09] Building features: 30% (52753/175846)
[13:07:10] Building features: 35% (61545/175846)
[13:07:10] Building features: 40% (70337/175846)
[13:07:11] Building features: 45% (79129/175846)
[13:07:11] Building features: 50% (87921/175846)
[13:07:12] Building features: 55% (96713/175846)
[13:07:13] Building features: 60% (105505/175846)
[13:07:13] Building features: 65% (114297/175846)
[13:07:14] Building features: 70% (123089/175846)
[13:07:14] Building features: 75% (131881/175846)
[13:07:15] Building features: 80% (140673/175846)
[13:07:16] Building features: 85% (149465/175846)
[13:07:16] Building features: 90% (158257/175846)
[13:07:17] Building features: 95% (167049/175846)
[13:07:17] Building features: 100% (175841/175846)
[13:07:18] Computing Hurst exponent...
[13:07:23] Computing market regimes (GMM)...
[13:07:31] Factor 9: 175704 samples, 92 features
[13:07:33] Batch stats — Input:  mean=0.0548 std=0.2656 min=-4.0208 max=10.0390
[13:07:33] Batch stats — Target: mean=0.0019 std=0.0674 min=-0.4720 max=0.3898
[13:07:33] Batch stats — Cls:    pos_long=109/256 pos_short=82/256
[13:07:33] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:07:37] Epoch 1/100 | Train: 0.036849 (MSE=0.003620 BCE=0.6646) | Val: 0.043792 (MSE=0.010415 BCE=0.6675) | LR: 1.00e-04 | Best: 0.043792 (ep 1)
[13:07:40] Epoch 2/100 | Train: 0.036191 (MSE=0.003100 BCE=0.6618) | Val: 0.042742 (MSE=0.009386 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042742 (ep 2)
[13:07:42] Epoch 3/100 | Train: 0.036117 (MSE=0.003049 BCE=0.6614) | Val: 0.042634 (MSE=0.009276 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042634 (ep 3)
[13:07:45] Epoch 4/100 | Train: 0.036071 (MSE=0.003012 BCE=0.6612) | Val: 0.042556 (MSE=0.009213 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042556 (ep 4)
[13:07:47] Epoch 5/100 | Train: 0.036038 (MSE=0.002987 BCE=0.6610) | Val: 0.042527 (MSE=0.009181 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042527 (ep 5)
[13:07:50] Epoch 6/100 | Train: 0.036022 (MSE=0.002969 BCE=0.6611) | Val: 0.042530 (MSE=0.009176 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042527 (ep 5)
[13:07:52] Epoch 7/100 | Train: 0.036000 (MSE=0.002952 BCE=0.6610) | Val: 0.042513 (MSE=0.009184 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042513 (ep 7)
[13:07:55] Epoch 8/100 | Train: 0.035983 (MSE=0.002941 BCE=0.6608) | Val: 0.042489 (MSE=0.009144 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:07:57] Epoch 9/100 | Train: 0.035971 (MSE=0.002928 BCE=0.6609) | Val: 0.042542 (MSE=0.009191 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:08:00] Epoch 10/100 | Train: 0.035957 (MSE=0.002920 BCE=0.6607) | Val: 0.042815 (MSE=0.009448 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:08:03] Epoch 11/100 | Train: 0.035948 (MSE=0.002911 BCE=0.6607) | Val: 0.042666 (MSE=0.009320 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:08:06] Epoch 12/100 | Train: 0.035940 (MSE=0.002908 BCE=0.6606) | Val: 0.042614 (MSE=0.009264 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:08:09] Epoch 13/100 | Train: 0.035924 (MSE=0.002898 BCE=0.6605) | Val: 0.042875 (MSE=0.009492 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042489 (ep 8)
[13:08:11] Epoch 14/100 | Train: 0.035917 (MSE=0.002893 BCE=0.6605) | Val: 0.043186 (MSE=0.009825 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042489 (ep 8)
[13:08:14] Epoch 15/100 | Train: 0.035897 (MSE=0.002882 BCE=0.6603) | Val: 0.043052 (MSE=0.009694 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042489 (ep 8)
[13:08:18] Epoch 16/100 | Train: 0.035894 (MSE=0.002879 BCE=0.6603) | Val: 0.043144 (MSE=0.009777 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042489 (ep 8)
[13:08:21] Epoch 17/100 | Train: 0.035886 (MSE=0.002874 BCE=0.6602) | Val: 0.043121 (MSE=0.009763 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042489 (ep 8)
[13:08:23] Epoch 18/100 | Train: 0.035885 (MSE=0.002873 BCE=0.6602) | Val: 0.043243 (MSE=0.009871 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042489 (ep 8)
[13:08:23] Early stopping at epoch 18 (no improvement for 10 epochs)
[13:08:24] Factor 9 done — best val loss: 0.042489 at epoch 8
[13:08:24] 
============================================================
[13:08:24] STF Factor 10 of [5..10]
[13:08:24] ============================================================
[13:08:24] Building features: 0% (1/175846)
[13:08:25] Building features: 5% (8793/175846)
[13:08:26] Building features: 10% (17585/175846)
[13:08:26] Building features: 15% (26377/175846)
[13:08:27] Building features: 20% (35169/175846)
[13:08:27] Building features: 25% (43961/175846)
[13:08:28] Building features: 30% (52753/175846)
[13:08:29] Building features: 35% (61545/175846)
[13:08:29] Building features: 40% (70337/175846)
[13:08:30] Building features: 45% (79129/175846)
[13:08:30] Building features: 50% (87921/175846)
[13:08:31] Building features: 55% (96713/175846)
[13:08:32] Building features: 60% (105505/175846)
[13:08:32] Building features: 65% (114297/175846)
[13:08:33] Building features: 70% (123089/175846)
[13:08:33] Building features: 75% (131881/175846)
[13:08:34] Building features: 80% (140673/175846)
[13:08:35] Building features: 85% (149465/175846)
[13:08:35] Building features: 90% (158257/175846)
[13:08:36] Building features: 95% (167049/175846)
[13:08:37] Building features: 100% (175841/175846)
[13:08:37] Computing Hurst exponent...
[13:08:43] Computing market regimes (GMM)...
[13:08:51] Factor 10: 175704 samples, 92 features
[13:08:53] Batch stats — Input:  mean=0.0534 std=0.2681 min=-4.1594 max=9.1841
[13:08:53] Batch stats — Target: mean=0.0019 std=0.0666 min=-0.4720 max=0.4134
[13:08:53] Batch stats — Cls:    pos_long=113/256 pos_short=84/256
[13:08:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:08:58] Epoch 1/100 | Train: 0.037126 (MSE=0.003935 BCE=0.6638) | Val: 0.044228 (MSE=0.010868 BCE=0.6672) | LR: 1.00e-04 | Best: 0.044228 (ep 1)
[13:09:01] Epoch 2/100 | Train: 0.036201 (MSE=0.003123 BCE=0.6616) | Val: 0.042990 (MSE=0.009643 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042990 (ep 2)
[13:09:04] Epoch 3/100 | Train: 0.036123 (MSE=0.003060 BCE=0.6613) | Val: 0.042609 (MSE=0.009269 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042609 (ep 3)
[13:09:07] Epoch 4/100 | Train: 0.036085 (MSE=0.003025 BCE=0.6612) | Val: 0.042503 (MSE=0.009169 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042503 (ep 4)
[13:09:10] Epoch 5/100 | Train: 0.036055 (MSE=0.002998 BCE=0.6611) | Val: 0.042380 (MSE=0.009036 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042380 (ep 5)
[13:09:13] Epoch 6/100 | Train: 0.036023 (MSE=0.002978 BCE=0.6609) | Val: 0.042351 (MSE=0.009017 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042351 (ep 6)
[13:09:16] Epoch 7/100 | Train: 0.036005 (MSE=0.002961 BCE=0.6609) | Val: 0.042277 (MSE=0.008952 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042277 (ep 7)
[13:09:19] Epoch 8/100 | Train: 0.035990 (MSE=0.002948 BCE=0.6609) | Val: 0.042279 (MSE=0.008952 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042277 (ep 7)
[13:09:21] Epoch 9/100 | Train: 0.035979 (MSE=0.002939 BCE=0.6608) | Val: 0.042230 (MSE=0.008897 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:23] Epoch 10/100 | Train: 0.035959 (MSE=0.002926 BCE=0.6607) | Val: 0.042240 (MSE=0.008900 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:26] Epoch 11/100 | Train: 0.035950 (MSE=0.002919 BCE=0.6606) | Val: 0.042245 (MSE=0.008907 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:28] Epoch 12/100 | Train: 0.035935 (MSE=0.002909 BCE=0.6605) | Val: 0.042268 (MSE=0.008927 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:31] Epoch 13/100 | Train: 0.035930 (MSE=0.002905 BCE=0.6605) | Val: 0.042304 (MSE=0.008943 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:33] Epoch 14/100 | Train: 0.035923 (MSE=0.002898 BCE=0.6605) | Val: 0.042257 (MSE=0.008912 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042230 (ep 9)
[13:09:35] Epoch 15/100 | Train: 0.035911 (MSE=0.002891 BCE=0.6604) | Val: 0.042508 (MSE=0.009141 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042230 (ep 9)
[13:09:38] Epoch 16/100 | Train: 0.035895 (MSE=0.002883 BCE=0.6602) | Val: 0.042383 (MSE=0.008999 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042230 (ep 9)
[13:09:40] Epoch 17/100 | Train: 0.035897 (MSE=0.002880 BCE=0.6604) | Val: 0.042412 (MSE=0.009034 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042230 (ep 9)
[13:09:43] Epoch 18/100 | Train: 0.035893 (MSE=0.002879 BCE=0.6603) | Val: 0.042457 (MSE=0.009070 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042230 (ep 9)
[13:09:45] Epoch 19/100 | Train: 0.035885 (MSE=0.002877 BCE=0.6602) | Val: 0.042482 (MSE=0.009098 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042230 (ep 9)
[13:09:45] Early stopping at epoch 19 (no improvement for 10 epochs)
[13:09:46] Factor 10 done — best val loss: 0.042230 at epoch 9
[13:09:46] 
Best factor: 5 (val loss 0.042172)
[13:09:46] Training done. Best factor=5, val_loss=0.042172
[13:10:21] Building validation dataset...
[13:10:21] Building features: 0% (1/175846)
[13:10:22] Building features: 5% (8793/175846)
[13:10:22] Building features: 10% (17585/175846)
[13:10:23] Building features: 15% (26377/175846)
[13:10:23] Building features: 20% (35169/175846)
[13:10:24] Building features: 25% (43961/175846)
[13:10:24] Building features: 30% (52753/175846)
[13:10:25] Building features: 35% (61545/175846)
[13:10:26] Building features: 40% (70337/175846)
[13:10:26] Building features: 45% (79129/175846)
[13:10:27] Building features: 50% (87921/175846)
[13:10:27] Building features: 55% (96713/175846)
[13:10:28] Building features: 60% (105505/175846)
[13:10:29] Building features: 65% (114297/175846)
[13:10:29] Building features: 70% (123089/175846)
[13:10:30] Building features: 75% (131881/175846)
[13:10:30] Building features: 80% (140673/175846)
[13:10:31] Building features: 85% (149465/175846)
[13:10:32] Building features: 90% (158257/175846)
[13:10:32] Building features: 95% (167049/175846)
[13:10:33] Building features: 100% (175841/175846)
[13:10:33] Computing Hurst exponent...
[13:10:39] Computing market regimes (GMM)...
[13:10:46] Running backtest...
[13:10:47] Backtest complete: 10622 trades (7164L/3458S), WR=48.3%, PF=0.96
[13:15:32] Training started.
[13:15:32] 
============================================================
[13:15:32] STF Factor 4 of [4..5]
[13:15:32] ============================================================
[13:15:32] Building features: 0% (1/175846)
[13:15:32] Building features: 5% (8793/175846)
[13:15:33] Building features: 10% (17585/175846)
[13:15:33] Building features: 15% (26377/175846)
[13:15:34] Building features: 20% (35169/175846)
[13:15:34] Building features: 25% (43961/175846)
[13:15:35] Building features: 30% (52753/175846)
[13:15:35] Building features: 35% (61545/175846)
[13:15:36] Building features: 40% (70337/175846)
[13:15:37] Building features: 45% (79129/175846)
[13:15:37] Building features: 50% (87921/175846)
[13:15:38] Building features: 55% (96713/175846)
[13:15:38] Building features: 60% (105505/175846)
[13:15:39] Building features: 65% (114297/175846)
[13:15:39] Building features: 70% (123089/175846)
[13:15:40] Building features: 75% (131881/175846)
[13:15:41] Building features: 80% (140673/175846)
[13:15:41] Building features: 85% (149465/175846)
[13:15:42] Building features: 90% (158257/175846)
[13:15:42] Building features: 95% (167049/175846)
[13:15:43] Building features: 100% (175841/175846)
[13:15:43] Computing Hurst exponent...
[13:15:49] Computing market regimes (GMM)...
[13:15:56] Factor 4: 175704 samples, 92 features
[13:15:58] Batch stats — Input:  mean=0.0556 std=0.2637 min=-3.5041 max=7.2633
[13:15:58] Batch stats — Target: mean=-0.0006 std=0.0674 min=-0.4720 max=0.4086
[13:15:58] Batch stats — Cls:    pos_long=96/256 pos_short=81/256
[13:15:58] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:16:03] Epoch 1/100 | Train: 0.036433 (MSE=0.003224 BCE=0.6642) | Val: 0.043234 (MSE=0.009861 BCE=0.6675) | LR: 1.00e-04 | Best: 0.043234 (ep 1)
[13:16:05] Epoch 2/100 | Train: 0.036105 (MSE=0.003032 BCE=0.6615) | Val: 0.042450 (MSE=0.009114 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042450 (ep 2)
[13:16:08] Epoch 3/100 | Train: 0.036041 (MSE=0.002981 BCE=0.6612) | Val: 0.042357 (MSE=0.009036 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042357 (ep 3)
[13:16:10] Epoch 4/100 | Train: 0.036003 (MSE=0.002953 BCE=0.6610) | Val: 0.042254 (MSE=0.008927 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042254 (ep 4)
[13:16:12] Epoch 5/100 | Train: 0.035983 (MSE=0.002936 BCE=0.6609) | Val: 0.042158 (MSE=0.008829 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:15] Epoch 6/100 | Train: 0.035965 (MSE=0.002921 BCE=0.6609) | Val: 0.042178 (MSE=0.008832 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:17] Epoch 7/100 | Train: 0.035955 (MSE=0.002912 BCE=0.6609) | Val: 0.042180 (MSE=0.008839 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:20] Epoch 8/100 | Train: 0.035943 (MSE=0.002904 BCE=0.6608) | Val: 0.042205 (MSE=0.008863 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:22] Epoch 9/100 | Train: 0.035928 (MSE=0.002893 BCE=0.6607) | Val: 0.042201 (MSE=0.008853 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:24] Epoch 10/100 | Train: 0.035921 (MSE=0.002889 BCE=0.6607) | Val: 0.042169 (MSE=0.008829 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042158 (ep 5)
[13:16:27] Epoch 11/100 | Train: 0.035916 (MSE=0.002884 BCE=0.6606) | Val: 0.042133 (MSE=0.008801 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:29] Epoch 12/100 | Train: 0.035910 (MSE=0.002878 BCE=0.6606) | Val: 0.042334 (MSE=0.008997 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:32] Epoch 13/100 | Train: 0.035901 (MSE=0.002872 BCE=0.6606) | Val: 0.042213 (MSE=0.008885 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:34] Epoch 14/100 | Train: 0.035893 (MSE=0.002867 BCE=0.6605) | Val: 0.042207 (MSE=0.008869 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:36] Epoch 15/100 | Train: 0.035884 (MSE=0.002862 BCE=0.6604) | Val: 0.042281 (MSE=0.008948 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:39] Epoch 16/100 | Train: 0.035873 (MSE=0.002855 BCE=0.6604) | Val: 0.042253 (MSE=0.008926 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042133 (ep 11)
[13:16:41] Epoch 17/100 | Train: 0.035872 (MSE=0.002853 BCE=0.6604) | Val: 0.042280 (MSE=0.008941 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042133 (ep 11)
[13:16:44] Epoch 18/100 | Train: 0.035855 (MSE=0.002841 BCE=0.6603) | Val: 0.042365 (MSE=0.009010 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042133 (ep 11)
[13:16:46] Epoch 19/100 | Train: 0.035849 (MSE=0.002836 BCE=0.6603) | Val: 0.042507 (MSE=0.009165 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042133 (ep 11)
[13:16:48] Epoch 20/100 | Train: 0.035839 (MSE=0.002834 BCE=0.6601) | Val: 0.042506 (MSE=0.009171 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042133 (ep 11)
[13:16:51] Epoch 21/100 | Train: 0.035835 (MSE=0.002830 BCE=0.6601) | Val: 0.042526 (MSE=0.009186 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042133 (ep 11)
[13:16:51] Early stopping at epoch 21 (no improvement for 10 epochs)
[13:16:52] Factor 4 done — best val loss: 0.042133 at epoch 11
[13:16:52] 
============================================================
[13:16:52] STF Factor 5 of [4..5]
[13:16:52] ============================================================
[13:16:52] Building features: 0% (1/175846)
[13:16:53] Building features: 5% (8793/175846)
[13:16:53] Building features: 10% (17585/175846)
[13:16:54] Building features: 15% (26377/175846)
[13:16:55] Building features: 20% (35169/175846)
[13:16:55] Building features: 25% (43961/175846)
[13:16:56] Building features: 30% (52753/175846)
[13:16:56] Building features: 35% (61545/175846)
[13:16:57] Building features: 40% (70337/175846)
[13:16:57] Building features: 45% (79129/175846)
[13:16:58] Building features: 50% (87921/175846)
[13:16:59] Building features: 55% (96713/175846)
[13:16:59] Building features: 60% (105505/175846)
[13:17:00] Building features: 65% (114297/175846)
[13:17:00] Building features: 70% (123089/175846)
[13:17:01] Building features: 75% (131881/175846)
[13:17:02] Building features: 80% (140673/175846)
[13:17:02] Building features: 85% (149465/175846)
[13:17:03] Building features: 90% (158257/175846)
[13:17:04] Building features: 95% (167049/175846)
[13:17:04] Building features: 100% (175841/175846)
[13:17:04] Computing Hurst exponent...
[13:17:10] Computing market regimes (GMM)...
[13:17:18] Factor 5: 175704 samples, 92 features
[13:17:20] Batch stats — Input:  mean=0.0563 std=0.2620 min=-4.0295 max=7.8878
[13:17:20] Batch stats — Target: mean=0.0022 std=0.0675 min=-0.4720 max=0.4134
[13:17:20] Batch stats — Cls:    pos_long=113/256 pos_short=80/256
[13:17:20] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:17:25] Epoch 1/100 | Train: 0.036456 (MSE=0.003219 BCE=0.6647) | Val: 0.043494 (MSE=0.010127 BCE=0.6673) | LR: 1.00e-04 | Best: 0.043494 (ep 1)
[13:17:28] Epoch 2/100 | Train: 0.036109 (MSE=0.003033 BCE=0.6615) | Val: 0.042556 (MSE=0.009217 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042556 (ep 2)
[13:17:31] Epoch 3/100 | Train: 0.036041 (MSE=0.002983 BCE=0.6612) | Val: 0.042386 (MSE=0.009057 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042386 (ep 3)
[13:17:34] Epoch 4/100 | Train: 0.036005 (MSE=0.002957 BCE=0.6610) | Val: 0.042287 (MSE=0.008963 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042287 (ep 4)
[13:17:37] Epoch 5/100 | Train: 0.035988 (MSE=0.002940 BCE=0.6610) | Val: 0.042152 (MSE=0.008835 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:41] Epoch 6/100 | Train: 0.035972 (MSE=0.002926 BCE=0.6609) | Val: 0.042210 (MSE=0.008875 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:44] Epoch 7/100 | Train: 0.035956 (MSE=0.002913 BCE=0.6609) | Val: 0.042165 (MSE=0.008831 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:46] Epoch 8/100 | Train: 0.035945 (MSE=0.002905 BCE=0.6608) | Val: 0.042160 (MSE=0.008819 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:49] Epoch 9/100 | Train: 0.035934 (MSE=0.002898 BCE=0.6607) | Val: 0.042175 (MSE=0.008861 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:52] Epoch 10/100 | Train: 0.035927 (MSE=0.002893 BCE=0.6607) | Val: 0.042164 (MSE=0.008837 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042152 (ep 5)
[13:17:55] Epoch 11/100 | Train: 0.035915 (MSE=0.002885 BCE=0.6606) | Val: 0.042261 (MSE=0.008934 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042152 (ep 5)
[13:17:59] Epoch 12/100 | Train: 0.035900 (MSE=0.002872 BCE=0.6606) | Val: 0.042147 (MSE=0.008823 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:02] Epoch 13/100 | Train: 0.035900 (MSE=0.002869 BCE=0.6606) | Val: 0.042201 (MSE=0.008879 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:05] Epoch 14/100 | Train: 0.035894 (MSE=0.002866 BCE=0.6606) | Val: 0.042292 (MSE=0.008977 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:08] Epoch 15/100 | Train: 0.035889 (MSE=0.002866 BCE=0.6605) | Val: 0.042163 (MSE=0.008843 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:11] Epoch 16/100 | Train: 0.035883 (MSE=0.002860 BCE=0.6605) | Val: 0.042286 (MSE=0.008970 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:14] Epoch 17/100 | Train: 0.035881 (MSE=0.002858 BCE=0.6604) | Val: 0.042240 (MSE=0.008925 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042147 (ep 12)
[13:18:17] Epoch 18/100 | Train: 0.035870 (MSE=0.002853 BCE=0.6603) | Val: 0.042226 (MSE=0.008908 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 12)
[13:18:20] Epoch 19/100 | Train: 0.035867 (MSE=0.002850 BCE=0.6603) | Val: 0.042253 (MSE=0.008935 BCE=0.6663) | LR: 2.50e-05 | Best: 0.042147 (ep 12)
[13:18:23] Epoch 20/100 | Train: 0.035864 (MSE=0.002848 BCE=0.6603) | Val: 0.042214 (MSE=0.008894 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 12)
[13:18:26] Epoch 21/100 | Train: 0.035859 (MSE=0.002846 BCE=0.6603) | Val: 0.042309 (MSE=0.008987 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 12)
[13:18:29] Epoch 22/100 | Train: 0.035860 (MSE=0.002845 BCE=0.6603) | Val: 0.042269 (MSE=0.008945 BCE=0.6665) | LR: 2.50e-05 | Best: 0.042147 (ep 12)
[13:18:29] Early stopping at epoch 22 (no improvement for 10 epochs)
[13:18:30] Factor 5 done — best val loss: 0.042147 at epoch 12
[13:18:30] 
Best factor: 4 (val loss 0.042133)
[13:18:30] Training done. Best factor=4, val_loss=0.042133
[13:18:42] Building validation dataset...
[13:18:42] Building features: 0% (1/175846)
[13:18:43] Building features: 5% (8793/175846)
[13:18:43] Building features: 10% (17585/175846)
[13:18:44] Building features: 15% (26377/175846)
[13:18:44] Building features: 20% (35169/175846)
[13:18:45] Building features: 25% (43961/175846)
[13:18:45] Building features: 30% (52753/175846)
[13:18:45] Building features: 35% (61545/175846)
[13:18:46] Building features: 40% (70337/175846)
[13:18:46] Building features: 45% (79129/175846)
[13:18:47] Building features: 50% (87921/175846)
[13:18:47] Building features: 55% (96713/175846)
[13:18:48] Building features: 60% (105505/175846)
[13:18:49] Building features: 65% (114297/175846)
[13:18:49] Building features: 70% (123089/175846)
[13:18:50] Building features: 75% (131881/175846)
[13:18:51] Building features: 80% (140673/175846)
[13:18:51] Building features: 85% (149465/175846)
[13:18:52] Building features: 90% (158257/175846)
[13:18:52] Building features: 95% (167049/175846)
[13:18:53] Building features: 100% (175841/175846)
[13:18:53] Computing Hurst exponent...
[13:18:59] Computing market regimes (GMM)...
[13:19:07] Running backtest...
[13:19:07] Backtest complete: 8294 trades (2190L/6104S), WR=50.2%, PF=0.98
[13:27:34] NTCP initialized.
[13:27:46] Loaded 175846 M5 bars.
[13:28:14] Training started.
[13:28:14] 
============================================================
[13:28:14] STF Factor 5 of [5..20]
[13:28:14] ============================================================
[13:28:14] Building features: 0% (1/175846)
[13:28:15] Building features: 5% (8793/175846)
[13:28:15] Building features: 10% (17585/175846)
[13:28:16] Building features: 15% (26377/175846)
[13:28:16] Building features: 20% (35169/175846)
[13:28:17] Building features: 25% (43961/175846)
[13:28:17] Building features: 30% (52753/175846)
[13:28:18] Building features: 35% (61545/175846)
[13:28:18] Building features: 40% (70337/175846)
[13:28:18] Building features: 45% (79129/175846)
[13:28:19] Building features: 50% (87921/175846)
[13:28:19] Building features: 55% (96713/175846)
[13:28:20] Building features: 60% (105505/175846)
[13:28:20] Building features: 65% (114297/175846)
[13:28:21] Building features: 70% (123089/175846)
[13:28:22] Building features: 75% (131881/175846)
[13:28:22] Building features: 80% (140673/175846)
[13:28:23] Building features: 85% (149465/175846)
[13:28:23] Building features: 90% (158257/175846)
[13:28:24] Building features: 95% (167049/175846)
[13:28:25] Building features: 100% (175841/175846)
[13:28:25] Computing Hurst exponent...
[13:28:30] Computing market regimes (GMM)...
[13:28:40] Factor 5: 175724 samples, 92 features
[13:28:42] Batch stats — Input:  mean=0.0534 std=0.2629 min=-4.1002 max=7.3847
[13:28:42] Batch stats — Target: mean=-0.0020 std=0.0659 min=-0.4720 max=0.2638
[13:28:42] Batch stats — Cls:    pos_long=98/256 pos_short=94/256
[13:28:42] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:28:48] Epoch 1/100 | Train: 0.036990 (MSE=0.003794 BCE=0.6639) | Val: 0.044186 (MSE=0.010794 BCE=0.6678) | LR: 1.00e-04 | Best: 0.044186 (ep 1)
[13:28:51] Epoch 2/100 | Train: 0.036188 (MSE=0.003105 BCE=0.6617) | Val: 0.042957 (MSE=0.009568 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042957 (ep 2)
[13:28:53] Epoch 3/100 | Train: 0.036115 (MSE=0.003050 BCE=0.6613) | Val: 0.042703 (MSE=0.009318 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042703 (ep 3)
[13:28:56] Epoch 4/100 | Train: 0.036070 (MSE=0.003013 BCE=0.6611) | Val: 0.042416 (MSE=0.009074 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042416 (ep 4)
[13:28:58] Epoch 5/100 | Train: 0.036041 (MSE=0.002985 BCE=0.6611) | Val: 0.042367 (MSE=0.009026 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042367 (ep 5)
[13:29:01] Epoch 6/100 | Train: 0.036013 (MSE=0.002965 BCE=0.6610) | Val: 0.042345 (MSE=0.009017 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042345 (ep 6)
[13:29:03] Epoch 7/100 | Train: 0.035997 (MSE=0.002953 BCE=0.6609) | Val: 0.042256 (MSE=0.008922 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:05] Epoch 8/100 | Train: 0.035985 (MSE=0.002941 BCE=0.6609) | Val: 0.042275 (MSE=0.008935 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:08] Epoch 9/100 | Train: 0.035975 (MSE=0.002934 BCE=0.6608) | Val: 0.042322 (MSE=0.008997 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:10] Epoch 10/100 | Train: 0.035966 (MSE=0.002928 BCE=0.6608) | Val: 0.042324 (MSE=0.008989 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:12] Epoch 11/100 | Train: 0.035953 (MSE=0.002921 BCE=0.6606) | Val: 0.042337 (MSE=0.008983 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:15] Epoch 12/100 | Train: 0.035944 (MSE=0.002916 BCE=0.6606) | Val: 0.042316 (MSE=0.008984 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042256 (ep 7)
[13:29:17] Epoch 13/100 | Train: 0.035932 (MSE=0.002910 BCE=0.6604) | Val: 0.042325 (MSE=0.008977 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042256 (ep 7)
[13:29:20] Epoch 14/100 | Train: 0.035920 (MSE=0.002898 BCE=0.6604) | Val: 0.042378 (MSE=0.009030 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042256 (ep 7)
[13:29:22] Epoch 15/100 | Train: 0.035911 (MSE=0.002895 BCE=0.6603) | Val: 0.042478 (MSE=0.009125 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042256 (ep 7)
[13:29:25] Epoch 16/100 | Train: 0.035910 (MSE=0.002893 BCE=0.6604) | Val: 0.042478 (MSE=0.009137 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042256 (ep 7)
[13:29:28] Epoch 17/100 | Train: 0.035901 (MSE=0.002891 BCE=0.6602) | Val: 0.042516 (MSE=0.009171 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042256 (ep 7)
[13:29:28] Early stopping at epoch 17 (no improvement for 10 epochs)
[13:29:29] Factor 5 done — best val loss: 0.042256 at epoch 7
[13:29:29] 
============================================================
[13:29:29] STF Factor 6 of [5..20]
[13:29:29] ============================================================
[13:29:29] Building features: 0% (1/175846)
[13:29:29] Building features: 5% (8793/175846)
[13:29:30] Building features: 10% (17585/175846)
[13:29:31] Building features: 15% (26377/175846)
[13:29:31] Building features: 20% (35169/175846)
[13:29:32] Building features: 25% (43961/175846)
[13:29:32] Building features: 30% (52753/175846)
[13:29:33] Building features: 35% (61545/175846)
[13:29:34] Building features: 40% (70337/175846)
[13:29:34] Building features: 45% (79129/175846)
[13:29:35] Building features: 50% (87921/175846)
[13:29:35] Building features: 55% (96713/175846)
[13:29:36] Building features: 60% (105505/175846)
[13:29:36] Building features: 65% (114297/175846)
[13:29:37] Building features: 70% (123089/175846)
[13:29:38] Building features: 75% (131881/175846)
[13:29:38] Building features: 80% (140673/175846)
[13:29:39] Building features: 85% (149465/175846)
[13:29:39] Building features: 90% (158257/175846)
[13:29:40] Building features: 95% (167049/175846)
[13:29:40] Building features: 100% (175841/175846)
[13:29:40] Computing Hurst exponent...
[13:29:46] Computing market regimes (GMM)...
[13:29:53] Factor 6: 175724 samples, 92 features
[13:29:55] Batch stats — Input:  mean=0.0540 std=0.2660 min=-5.4250 max=9.9344
[13:29:55] Batch stats — Target: mean=-0.0007 std=0.0621 min=-0.4720 max=0.4134
[13:29:55] Batch stats — Cls:    pos_long=103/256 pos_short=87/256
[13:29:55] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:30:00] Epoch 1/100 | Train: 0.037079 (MSE=0.003857 BCE=0.6644) | Val: 0.044609 (MSE=0.011254 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044609 (ep 1)
[13:30:03] Epoch 2/100 | Train: 0.036194 (MSE=0.003113 BCE=0.6616) | Val: 0.043173 (MSE=0.009834 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043173 (ep 2)
[13:30:06] Epoch 3/100 | Train: 0.036125 (MSE=0.003057 BCE=0.6614) | Val: 0.042826 (MSE=0.009466 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042826 (ep 3)
[13:30:08] Epoch 4/100 | Train: 0.036085 (MSE=0.003027 BCE=0.6612) | Val: 0.042665 (MSE=0.009305 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042665 (ep 4)
[13:30:11] Epoch 5/100 | Train: 0.036053 (MSE=0.002999 BCE=0.6611) | Val: 0.042539 (MSE=0.009186 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042539 (ep 5)
[13:30:14] Epoch 6/100 | Train: 0.036031 (MSE=0.002981 BCE=0.6610) | Val: 0.042498 (MSE=0.009165 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042498 (ep 6)
[13:30:17] Epoch 7/100 | Train: 0.036004 (MSE=0.002962 BCE=0.6608) | Val: 0.042412 (MSE=0.009067 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042412 (ep 7)
[13:30:20] Epoch 8/100 | Train: 0.035991 (MSE=0.002945 BCE=0.6609) | Val: 0.042430 (MSE=0.009087 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042412 (ep 7)
[13:30:23] Epoch 9/100 | Train: 0.035972 (MSE=0.002937 BCE=0.6607) | Val: 0.042397 (MSE=0.009038 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042397 (ep 9)
[13:30:26] Epoch 10/100 | Train: 0.035958 (MSE=0.002924 BCE=0.6607) | Val: 0.042380 (MSE=0.009029 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042380 (ep 10)
[13:30:29] Epoch 11/100 | Train: 0.035951 (MSE=0.002917 BCE=0.6607) | Val: 0.042371 (MSE=0.009024 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:32] Epoch 12/100 | Train: 0.035936 (MSE=0.002907 BCE=0.6606) | Val: 0.042500 (MSE=0.009139 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:34] Epoch 13/100 | Train: 0.035926 (MSE=0.002903 BCE=0.6605) | Val: 0.042621 (MSE=0.009269 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:37] Epoch 14/100 | Train: 0.035914 (MSE=0.002894 BCE=0.6604) | Val: 0.042677 (MSE=0.009322 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:40] Epoch 15/100 | Train: 0.035910 (MSE=0.002889 BCE=0.6604) | Val: 0.042639 (MSE=0.009280 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:43] Epoch 16/100 | Train: 0.035907 (MSE=0.002884 BCE=0.6605) | Val: 0.042726 (MSE=0.009372 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042371 (ep 11)
[13:30:46] Epoch 17/100 | Train: 0.035900 (MSE=0.002882 BCE=0.6603) | Val: 0.042819 (MSE=0.009444 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042371 (ep 11)
[13:30:49] Epoch 18/100 | Train: 0.035877 (MSE=0.002869 BCE=0.6602) | Val: 0.042924 (MSE=0.009570 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042371 (ep 11)
[13:30:51] Epoch 19/100 | Train: 0.035877 (MSE=0.002868 BCE=0.6602) | Val: 0.042971 (MSE=0.009612 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042371 (ep 11)
[13:30:54] Epoch 20/100 | Train: 0.035867 (MSE=0.002864 BCE=0.6601) | Val: 0.042942 (MSE=0.009568 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042371 (ep 11)
[13:30:57] Epoch 21/100 | Train: 0.035867 (MSE=0.002860 BCE=0.6601) | Val: 0.043140 (MSE=0.009769 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042371 (ep 11)
[13:30:57] Early stopping at epoch 21 (no improvement for 10 epochs)
[13:30:58] Factor 6 done — best val loss: 0.042371 at epoch 11
[13:30:58] 
============================================================
[13:30:58] STF Factor 7 of [5..20]
[13:30:58] ============================================================
[13:30:58] Building features: 0% (1/175846)
[13:30:59] Building features: 5% (8793/175846)
[13:30:59] Building features: 10% (17585/175846)
[13:31:00] Building features: 15% (26377/175846)
[13:31:00] Building features: 20% (35169/175846)
[13:31:01] Building features: 25% (43961/175846)
[13:31:02] Building features: 30% (52753/175846)
[13:31:02] Building features: 35% (61545/175846)
[13:31:03] Building features: 40% (70337/175846)
[13:31:03] Building features: 45% (79129/175846)
[13:31:04] Building features: 50% (87921/175846)
[13:31:04] Building features: 55% (96713/175846)
[13:31:05] Building features: 60% (105505/175846)
[13:31:06] Building features: 65% (114297/175846)
[13:31:06] Building features: 70% (123089/175846)
[13:31:07] Building features: 75% (131881/175846)
[13:31:07] Building features: 80% (140673/175846)
[13:31:08] Building features: 85% (149465/175846)
[13:31:08] Building features: 90% (158257/175846)
[13:31:09] Building features: 95% (167049/175846)
[13:31:09] Building features: 100% (175841/175846)
[13:31:09] Computing Hurst exponent...
[13:31:15] Computing market regimes (GMM)...
[13:31:22] Factor 7: 175724 samples, 92 features
[13:31:24] Batch stats — Input:  mean=0.0535 std=0.2660 min=-5.4479 max=15.9549
[13:31:24] Batch stats — Target: mean=-0.0003 std=0.0668 min=-0.4720 max=0.4134
[13:31:24] Batch stats — Cls:    pos_long=99/256 pos_short=96/256
[13:31:24] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:31:28] Epoch 1/100 | Train: 0.036980 (MSE=0.003742 BCE=0.6648) | Val: 0.043682 (MSE=0.010325 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043682 (ep 1)
[13:31:30] Epoch 2/100 | Train: 0.036185 (MSE=0.003111 BCE=0.6615) | Val: 0.042745 (MSE=0.009418 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042745 (ep 2)
[13:31:32] Epoch 3/100 | Train: 0.036111 (MSE=0.003049 BCE=0.6612) | Val: 0.042543 (MSE=0.009210 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042543 (ep 3)
[13:31:35] Epoch 4/100 | Train: 0.036071 (MSE=0.003014 BCE=0.6611) | Val: 0.042465 (MSE=0.009116 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042465 (ep 4)
[13:31:37] Epoch 5/100 | Train: 0.036034 (MSE=0.002986 BCE=0.6610) | Val: 0.042374 (MSE=0.009023 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042374 (ep 5)
[13:31:39] Epoch 6/100 | Train: 0.036011 (MSE=0.002967 BCE=0.6609) | Val: 0.042341 (MSE=0.008995 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:42] Epoch 7/100 | Train: 0.035998 (MSE=0.002955 BCE=0.6609) | Val: 0.042471 (MSE=0.009117 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:44] Epoch 8/100 | Train: 0.035980 (MSE=0.002941 BCE=0.6608) | Val: 0.042395 (MSE=0.009029 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:47] Epoch 9/100 | Train: 0.035967 (MSE=0.002933 BCE=0.6607) | Val: 0.042384 (MSE=0.009032 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:49] Epoch 10/100 | Train: 0.035954 (MSE=0.002923 BCE=0.6606) | Val: 0.042366 (MSE=0.009003 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:51] Epoch 11/100 | Train: 0.035952 (MSE=0.002918 BCE=0.6607) | Val: 0.042521 (MSE=0.009095 BCE=0.6685) | LR: 1.00e-04 | Best: 0.042341 (ep 6)
[13:31:54] Epoch 12/100 | Train: 0.035938 (MSE=0.002911 BCE=0.6605) | Val: 0.042659 (MSE=0.009279 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042341 (ep 6)
[13:31:56] Epoch 13/100 | Train: 0.035923 (MSE=0.002902 BCE=0.6604) | Val: 0.042580 (MSE=0.009211 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042341 (ep 6)
[13:31:58] Epoch 14/100 | Train: 0.035909 (MSE=0.002895 BCE=0.6603) | Val: 0.042591 (MSE=0.009223 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042341 (ep 6)
[13:32:01] Epoch 15/100 | Train: 0.035903 (MSE=0.002890 BCE=0.6602) | Val: 0.042734 (MSE=0.009365 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042341 (ep 6)
[13:32:03] Epoch 16/100 | Train: 0.035906 (MSE=0.002889 BCE=0.6603) | Val: 0.042658 (MSE=0.009288 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042341 (ep 6)
[13:32:03] Early stopping at epoch 16 (no improvement for 10 epochs)
[13:32:04] Factor 7 done — best val loss: 0.042341 at epoch 6
[13:32:04] 
============================================================
[13:32:04] STF Factor 8 of [5..20]
[13:32:04] ============================================================
[13:32:04] Building features: 0% (1/175846)
[13:32:05] Building features: 5% (8793/175846)
[13:32:05] Building features: 10% (17585/175846)
[13:32:06] Building features: 15% (26377/175846)
[13:32:06] Building features: 20% (35169/175846)
[13:32:07] Building features: 25% (43961/175846)
[13:32:07] Building features: 30% (52753/175846)
[13:32:08] Building features: 35% (61545/175846)
[13:32:08] Building features: 40% (70337/175846)
[13:32:09] Building features: 45% (79129/175846)
[13:32:09] Building features: 50% (87921/175846)
[13:32:09] Building features: 55% (96713/175846)
[13:32:10] Building features: 60% (105505/175846)
[13:32:10] Building features: 65% (114297/175846)
[13:32:11] Building features: 70% (123089/175846)
[13:32:11] Building features: 75% (131881/175846)
[13:32:12] Building features: 80% (140673/175846)
[13:32:12] Building features: 85% (149465/175846)
[13:32:13] Building features: 90% (158257/175846)
[13:32:13] Building features: 95% (167049/175846)
[13:32:14] Building features: 100% (175841/175846)
[13:32:14] Computing Hurst exponent...
[13:32:19] Computing market regimes (GMM)...
[13:32:26] Factor 8: 175724 samples, 92 features
[13:32:27] Batch stats — Input:  mean=0.0524 std=0.2689 min=-4.7237 max=9.5638
[13:32:27] Batch stats — Target: mean=-0.0005 std=0.0687 min=-0.4720 max=0.4134
[13:32:27] Batch stats — Cls:    pos_long=104/256 pos_short=103/256
[13:32:27] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:32:31] Epoch 1/100 | Train: 0.036941 (MSE=0.003750 BCE=0.6638) | Val: 0.043760 (MSE=0.010392 BCE=0.6674) | LR: 1.00e-04 | Best: 0.043760 (ep 1)
[13:32:34] Epoch 2/100 | Train: 0.036188 (MSE=0.003108 BCE=0.6616) | Val: 0.042661 (MSE=0.009323 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042661 (ep 2)
[13:32:36] Epoch 3/100 | Train: 0.036125 (MSE=0.003052 BCE=0.6615) | Val: 0.042470 (MSE=0.009126 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042470 (ep 3)
[13:32:38] Epoch 4/100 | Train: 0.036077 (MSE=0.003020 BCE=0.6611) | Val: 0.042435 (MSE=0.009105 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042435 (ep 4)
[13:32:41] Epoch 5/100 | Train: 0.036049 (MSE=0.002992 BCE=0.6611) | Val: 0.042442 (MSE=0.009111 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042435 (ep 4)
[13:32:43] Epoch 6/100 | Train: 0.036025 (MSE=0.002971 BCE=0.6611) | Val: 0.042350 (MSE=0.009020 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:32:46] Epoch 7/100 | Train: 0.036002 (MSE=0.002959 BCE=0.6609) | Val: 0.042416 (MSE=0.009058 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:32:49] Epoch 8/100 | Train: 0.035986 (MSE=0.002945 BCE=0.6608) | Val: 0.042402 (MSE=0.009061 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:32:51] Epoch 9/100 | Train: 0.035974 (MSE=0.002936 BCE=0.6608) | Val: 0.042432 (MSE=0.009106 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:32:54] Epoch 10/100 | Train: 0.035966 (MSE=0.002929 BCE=0.6607) | Val: 0.042497 (MSE=0.009150 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:32:57] Epoch 11/100 | Train: 0.035953 (MSE=0.002920 BCE=0.6607) | Val: 0.042567 (MSE=0.009226 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042350 (ep 6)
[13:33:00] Epoch 12/100 | Train: 0.035940 (MSE=0.002913 BCE=0.6605) | Val: 0.042679 (MSE=0.009323 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042350 (ep 6)
[13:33:02] Epoch 13/100 | Train: 0.035926 (MSE=0.002903 BCE=0.6605) | Val: 0.042698 (MSE=0.009357 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042350 (ep 6)
[13:33:05] Epoch 14/100 | Train: 0.035919 (MSE=0.002898 BCE=0.6604) | Val: 0.042767 (MSE=0.009414 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042350 (ep 6)
[13:33:08] Epoch 15/100 | Train: 0.035912 (MSE=0.002896 BCE=0.6603) | Val: 0.042702 (MSE=0.009364 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042350 (ep 6)
[13:33:10] Epoch 16/100 | Train: 0.035907 (MSE=0.002893 BCE=0.6603) | Val: 0.042799 (MSE=0.009455 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042350 (ep 6)
[13:33:10] Early stopping at epoch 16 (no improvement for 10 epochs)
[13:33:11] Factor 8 done — best val loss: 0.042350 at epoch 6
[13:33:11] 
============================================================
[13:33:11] STF Factor 9 of [5..20]
[13:33:11] ============================================================
[13:33:12] Building features: 0% (1/175846)
[13:33:12] Building features: 5% (8793/175846)
[13:33:13] Building features: 10% (17585/175846)
[13:33:13] Building features: 15% (26377/175846)
[13:33:14] Building features: 20% (35169/175846)
[13:33:14] Building features: 25% (43961/175846)
[13:33:15] Building features: 30% (52753/175846)
[13:33:15] Building features: 35% (61545/175846)
[13:33:16] Building features: 40% (70337/175846)
[13:33:17] Building features: 45% (79129/175846)
[13:33:17] Building features: 50% (87921/175846)
[13:33:18] Building features: 55% (96713/175846)
[13:33:18] Building features: 60% (105505/175846)
[13:33:19] Building features: 65% (114297/175846)
[13:33:19] Building features: 70% (123089/175846)
[13:33:20] Building features: 75% (131881/175846)
[13:33:20] Building features: 80% (140673/175846)
[13:33:21] Building features: 85% (149465/175846)
[13:33:21] Building features: 90% (158257/175846)
[13:33:22] Building features: 95% (167049/175846)
[13:33:23] Building features: 100% (175841/175846)
[13:33:23] Computing Hurst exponent...
[13:33:28] Computing market regimes (GMM)...
[13:33:35] Factor 9: 175724 samples, 92 features
[13:33:37] Batch stats — Input:  mean=0.0518 std=0.2660 min=-6.3104 max=8.8804
[13:33:37] Batch stats — Target: mean=-0.0007 std=0.0687 min=-0.4720 max=0.4134
[13:33:37] Batch stats — Cls:    pos_long=108/256 pos_short=90/256
[13:33:37] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:33:42] Epoch 1/100 | Train: 0.037233 (MSE=0.003969 BCE=0.6653) | Val: 0.044627 (MSE=0.011272 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044627 (ep 1)
[13:33:44] Epoch 2/100 | Train: 0.036217 (MSE=0.003131 BCE=0.6617) | Val: 0.043241 (MSE=0.009861 BCE=0.6676) | LR: 1.00e-04 | Best: 0.043241 (ep 2)
[13:33:47] Epoch 3/100 | Train: 0.036146 (MSE=0.003071 BCE=0.6615) | Val: 0.042815 (MSE=0.009470 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042815 (ep 3)
[13:33:50] Epoch 4/100 | Train: 0.036099 (MSE=0.003036 BCE=0.6612) | Val: 0.042594 (MSE=0.009238 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042594 (ep 4)
[13:33:53] Epoch 5/100 | Train: 0.036065 (MSE=0.003008 BCE=0.6611) | Val: 0.042495 (MSE=0.009147 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042495 (ep 5)
[13:33:55] Epoch 6/100 | Train: 0.036037 (MSE=0.002984 BCE=0.6611) | Val: 0.042365 (MSE=0.009027 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042365 (ep 6)
[13:33:58] Epoch 7/100 | Train: 0.036009 (MSE=0.002966 BCE=0.6609) | Val: 0.042401 (MSE=0.009043 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042365 (ep 6)
[13:34:01] Epoch 8/100 | Train: 0.036001 (MSE=0.002953 BCE=0.6610) | Val: 0.042308 (MSE=0.008944 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042308 (ep 8)
[13:34:03] Epoch 9/100 | Train: 0.035983 (MSE=0.002943 BCE=0.6608) | Val: 0.042361 (MSE=0.009015 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042308 (ep 8)
[13:34:06] Epoch 10/100 | Train: 0.035971 (MSE=0.002931 BCE=0.6608) | Val: 0.042314 (MSE=0.008949 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042308 (ep 8)
[13:34:09] Epoch 11/100 | Train: 0.035954 (MSE=0.002921 BCE=0.6606) | Val: 0.042358 (MSE=0.008954 BCE=0.6681) | LR: 1.00e-04 | Best: 0.042308 (ep 8)
[13:34:12] Epoch 12/100 | Train: 0.035949 (MSE=0.002916 BCE=0.6607) | Val: 0.042300 (MSE=0.008954 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:14] Epoch 13/100 | Train: 0.035937 (MSE=0.002909 BCE=0.6606) | Val: 0.042313 (MSE=0.008942 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:17] Epoch 14/100 | Train: 0.035924 (MSE=0.002902 BCE=0.6604) | Val: 0.042446 (MSE=0.009081 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:20] Epoch 15/100 | Train: 0.035917 (MSE=0.002895 BCE=0.6604) | Val: 0.042456 (MSE=0.009087 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:22] Epoch 16/100 | Train: 0.035912 (MSE=0.002892 BCE=0.6604) | Val: 0.042449 (MSE=0.009080 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:25] Epoch 17/100 | Train: 0.035902 (MSE=0.002885 BCE=0.6603) | Val: 0.042410 (MSE=0.009033 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042300 (ep 12)
[13:34:28] Epoch 18/100 | Train: 0.035895 (MSE=0.002884 BCE=0.6602) | Val: 0.042426 (MSE=0.009072 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042300 (ep 12)
[13:34:31] Epoch 19/100 | Train: 0.035879 (MSE=0.002870 BCE=0.6602) | Val: 0.042496 (MSE=0.009129 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042300 (ep 12)
[13:34:33] Epoch 20/100 | Train: 0.035876 (MSE=0.002868 BCE=0.6602) | Val: 0.042490 (MSE=0.009135 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042300 (ep 12)
[13:34:36] Epoch 21/100 | Train: 0.035868 (MSE=0.002865 BCE=0.6601) | Val: 0.042550 (MSE=0.009176 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042300 (ep 12)
[13:34:39] Epoch 22/100 | Train: 0.035871 (MSE=0.002865 BCE=0.6601) | Val: 0.042511 (MSE=0.009146 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042300 (ep 12)
[13:34:39] Early stopping at epoch 22 (no improvement for 10 epochs)
[13:34:40] Factor 9 done — best val loss: 0.042300 at epoch 12
[13:34:40] 
============================================================
[13:34:40] STF Factor 10 of [5..20]
[13:34:40] ============================================================
[13:34:40] Building features: 0% (1/175846)
[13:34:40] Building features: 5% (8793/175846)
[13:34:41] Building features: 10% (17585/175846)
[13:34:41] Building features: 15% (26377/175846)
[13:34:42] Building features: 20% (35169/175846)
[13:34:43] Building features: 25% (43961/175846)
[13:34:43] Building features: 30% (52753/175846)
[13:34:44] Building features: 35% (61545/175846)
[13:34:44] Building features: 40% (70337/175846)
[13:34:45] Building features: 45% (79129/175846)
[13:34:45] Building features: 50% (87921/175846)
[13:34:46] Building features: 55% (96713/175846)
[13:34:46] Building features: 60% (105505/175846)
[13:34:47] Building features: 65% (114297/175846)
[13:34:48] Building features: 70% (123089/175846)
[13:34:48] Building features: 75% (131881/175846)
[13:34:49] Building features: 80% (140673/175846)
[13:34:49] Building features: 85% (149465/175846)
[13:34:50] Building features: 90% (158257/175846)
[13:34:50] Building features: 95% (167049/175846)
[13:34:51] Building features: 100% (175841/175846)
[13:34:51] Computing Hurst exponent...
[13:34:56] Computing market regimes (GMM)...
[13:35:03] Factor 10: 175724 samples, 92 features
[13:35:05] Batch stats — Input:  mean=0.0536 std=0.2649 min=-3.1297 max=6.0636
[13:35:05] Batch stats — Target: mean=0.0003 std=0.0568 min=-0.3254 max=0.3338
[13:35:05] Batch stats — Cls:    pos_long=95/256 pos_short=87/256
[13:35:05] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:35:10] Epoch 1/100 | Train: 0.036901 (MSE=0.003735 BCE=0.6633) | Val: 0.044130 (MSE=0.010783 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044130 (ep 1)
[13:35:13] Epoch 2/100 | Train: 0.036180 (MSE=0.003101 BCE=0.6616) | Val: 0.042912 (MSE=0.009578 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042912 (ep 2)
[13:35:15] Epoch 3/100 | Train: 0.036115 (MSE=0.003050 BCE=0.6613) | Val: 0.042653 (MSE=0.009329 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042653 (ep 3)
[13:35:18] Epoch 4/100 | Train: 0.036077 (MSE=0.003018 BCE=0.6612) | Val: 0.042621 (MSE=0.009294 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042621 (ep 4)
[13:35:21] Epoch 5/100 | Train: 0.036041 (MSE=0.002991 BCE=0.6610) | Val: 0.042439 (MSE=0.009111 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042439 (ep 5)
[13:35:24] Epoch 6/100 | Train: 0.036020 (MSE=0.002971 BCE=0.6610) | Val: 0.042331 (MSE=0.009006 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042331 (ep 6)
[13:35:26] Epoch 7/100 | Train: 0.035999 (MSE=0.002955 BCE=0.6609) | Val: 0.042388 (MSE=0.009049 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042331 (ep 6)
[13:35:29] Epoch 8/100 | Train: 0.035982 (MSE=0.002943 BCE=0.6608) | Val: 0.042324 (MSE=0.008991 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042324 (ep 8)
[13:35:32] Epoch 9/100 | Train: 0.035974 (MSE=0.002935 BCE=0.6608) | Val: 0.042278 (MSE=0.008943 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:34] Epoch 10/100 | Train: 0.035959 (MSE=0.002924 BCE=0.6607) | Val: 0.042285 (MSE=0.008949 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:37] Epoch 11/100 | Train: 0.035950 (MSE=0.002917 BCE=0.6607) | Val: 0.042287 (MSE=0.008956 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:40] Epoch 12/100 | Train: 0.035943 (MSE=0.002908 BCE=0.6607) | Val: 0.042367 (MSE=0.009030 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:42] Epoch 13/100 | Train: 0.035939 (MSE=0.002906 BCE=0.6607) | Val: 0.042685 (MSE=0.009321 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:45] Epoch 14/100 | Train: 0.035917 (MSE=0.002899 BCE=0.6604) | Val: 0.042768 (MSE=0.009380 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042278 (ep 9)
[13:35:48] Epoch 15/100 | Train: 0.035918 (MSE=0.002892 BCE=0.6605) | Val: 0.043230 (MSE=0.009854 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042278 (ep 9)
[13:35:51] Epoch 16/100 | Train: 0.035897 (MSE=0.002882 BCE=0.6603) | Val: 0.042965 (MSE=0.009595 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042278 (ep 9)
[13:35:53] Epoch 17/100 | Train: 0.035893 (MSE=0.002880 BCE=0.6602) | Val: 0.042967 (MSE=0.009612 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042278 (ep 9)
[13:35:56] Epoch 18/100 | Train: 0.035884 (MSE=0.002875 BCE=0.6602) | Val: 0.043004 (MSE=0.009641 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042278 (ep 9)
[13:35:59] Epoch 19/100 | Train: 0.035883 (MSE=0.002874 BCE=0.6602) | Val: 0.043019 (MSE=0.009664 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042278 (ep 9)
[13:35:59] Early stopping at epoch 19 (no improvement for 10 epochs)
[13:36:00] Factor 10 done — best val loss: 0.042278 at epoch 9
[13:36:00] 
============================================================
[13:36:00] STF Factor 11 of [5..20]
[13:36:00] ============================================================
[13:36:00] Building features: 0% (1/175846)
[13:36:00] Building features: 5% (8793/175846)
[13:36:01] Building features: 10% (17585/175846)
[13:36:01] Building features: 15% (26377/175846)
[13:36:02] Building features: 20% (35169/175846)
[13:36:03] Building features: 25% (43961/175846)
[13:36:03] Building features: 30% (52753/175846)
[13:36:04] Building features: 35% (61545/175846)
[13:36:04] Building features: 40% (70337/175846)
[13:36:05] Building features: 45% (79129/175846)
[13:36:05] Building features: 50% (87921/175846)
[13:36:06] Building features: 55% (96713/175846)
[13:36:06] Building features: 60% (105505/175846)
[13:36:07] Building features: 65% (114297/175846)
[13:36:07] Building features: 70% (123089/175846)
[13:36:08] Building features: 75% (131881/175846)
[13:36:08] Building features: 80% (140673/175846)
[13:36:09] Building features: 85% (149465/175846)
[13:36:09] Building features: 90% (158257/175846)
[13:36:10] Building features: 95% (167049/175846)
[13:36:11] Building features: 100% (175841/175846)
[13:36:11] Computing Hurst exponent...
[13:36:16] Computing market regimes (GMM)...
[13:36:23] Factor 11: 175724 samples, 92 features
[13:36:25] Batch stats — Input:  mean=0.0539 std=0.2733 min=-5.3639 max=9.5561
[13:36:25] Batch stats — Target: mean=-0.0042 std=0.0694 min=-0.4720 max=0.4134
[13:36:25] Batch stats — Cls:    pos_long=109/256 pos_short=98/256
[13:36:25] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:36:30] Epoch 1/100 | Train: 0.036968 (MSE=0.003771 BCE=0.6639) | Val: 0.044380 (MSE=0.011033 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044380 (ep 1)
[13:36:32] Epoch 2/100 | Train: 0.036194 (MSE=0.003105 BCE=0.6618) | Val: 0.043018 (MSE=0.009655 BCE=0.6673) | LR: 1.00e-04 | Best: 0.043018 (ep 2)
[13:36:35] Epoch 3/100 | Train: 0.036125 (MSE=0.003053 BCE=0.6614) | Val: 0.042740 (MSE=0.009411 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042740 (ep 3)
[13:36:38] Epoch 4/100 | Train: 0.036086 (MSE=0.003021 BCE=0.6613) | Val: 0.042546 (MSE=0.009214 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042546 (ep 4)
[13:36:41] Epoch 5/100 | Train: 0.036042 (MSE=0.002992 BCE=0.6610) | Val: 0.042430 (MSE=0.009099 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042430 (ep 5)
[13:36:43] Epoch 6/100 | Train: 0.036025 (MSE=0.002970 BCE=0.6611) | Val: 0.042375 (MSE=0.009034 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042375 (ep 6)
[13:36:46] Epoch 7/100 | Train: 0.036002 (MSE=0.002956 BCE=0.6609) | Val: 0.042412 (MSE=0.009076 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042375 (ep 6)
[13:36:49] Epoch 8/100 | Train: 0.035985 (MSE=0.002943 BCE=0.6608) | Val: 0.042313 (MSE=0.008976 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042313 (ep 8)
[13:36:51] Epoch 9/100 | Train: 0.035973 (MSE=0.002931 BCE=0.6608) | Val: 0.042312 (MSE=0.008963 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042312 (ep 9)
[13:36:54] Epoch 10/100 | Train: 0.035959 (MSE=0.002921 BCE=0.6608) | Val: 0.042308 (MSE=0.008972 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042308 (ep 10)
[13:36:57] Epoch 11/100 | Train: 0.035948 (MSE=0.002917 BCE=0.6606) | Val: 0.042284 (MSE=0.008935 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:00] Epoch 12/100 | Train: 0.035943 (MSE=0.002909 BCE=0.6607) | Val: 0.042401 (MSE=0.009038 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:02] Epoch 13/100 | Train: 0.035932 (MSE=0.002904 BCE=0.6606) | Val: 0.042361 (MSE=0.009019 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:05] Epoch 14/100 | Train: 0.035915 (MSE=0.002897 BCE=0.6604) | Val: 0.042383 (MSE=0.009036 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:08] Epoch 15/100 | Train: 0.035907 (MSE=0.002888 BCE=0.6604) | Val: 0.042418 (MSE=0.009072 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:11] Epoch 16/100 | Train: 0.035910 (MSE=0.002890 BCE=0.6604) | Val: 0.042573 (MSE=0.009218 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[13:37:14] Epoch 17/100 | Train: 0.035896 (MSE=0.002883 BCE=0.6603) | Val: 0.042585 (MSE=0.009223 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[13:37:17] Epoch 18/100 | Train: 0.035883 (MSE=0.002874 BCE=0.6602) | Val: 0.042610 (MSE=0.009254 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[13:37:19] Epoch 19/100 | Train: 0.035875 (MSE=0.002870 BCE=0.6601) | Val: 0.042661 (MSE=0.009300 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[13:37:22] Epoch 20/100 | Train: 0.035870 (MSE=0.002868 BCE=0.6600) | Val: 0.042628 (MSE=0.009256 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[13:37:25] Epoch 21/100 | Train: 0.035867 (MSE=0.002865 BCE=0.6600) | Val: 0.042686 (MSE=0.009327 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[13:37:25] Early stopping at epoch 21 (no improvement for 10 epochs)
[13:37:26] Factor 11 done — best val loss: 0.042284 at epoch 11
[13:37:26] 
============================================================
[13:37:26] STF Factor 12 of [5..20]
[13:37:26] ============================================================
[13:37:26] Building features: 0% (1/175846)
[13:37:27] Building features: 5% (8793/175846)
[13:37:27] Building features: 10% (17585/175846)
[13:37:28] Building features: 15% (26377/175846)
[13:37:28] Building features: 20% (35169/175846)
[13:37:29] Building features: 25% (43961/175846)
[13:37:29] Building features: 30% (52753/175846)
[13:37:30] Building features: 35% (61545/175846)
[13:37:30] Building features: 40% (70337/175846)
[13:37:31] Building features: 45% (79129/175846)
[13:37:31] Building features: 50% (87921/175846)
[13:37:32] Building features: 55% (96713/175846)
[13:37:33] Building features: 60% (105505/175846)
[13:37:33] Building features: 65% (114297/175846)
[13:37:34] Building features: 70% (123089/175846)
[13:37:34] Building features: 75% (131881/175846)
[13:37:35] Building features: 80% (140673/175846)
[13:37:35] Building features: 85% (149465/175846)
[13:37:36] Building features: 90% (158257/175846)
[13:37:36] Building features: 95% (167049/175846)
[13:37:37] Building features: 100% (175841/175846)
[13:37:37] Computing Hurst exponent...
[13:37:42] Computing market regimes (GMM)...
[13:37:50] Factor 12: 175724 samples, 92 features
[13:37:55] Batch stats — Input:  mean=0.0523 std=0.2714 min=-4.4368 max=12.2195
[13:37:55] Batch stats — Target: mean=0.0011 std=0.0606 min=-0.3722 max=0.3888
[13:37:55] Batch stats — Cls:    pos_long=114/256 pos_short=88/256
[13:37:55] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:37:59] Epoch 1/100 | Train: 0.037011 (MSE=0.003804 BCE=0.6641) | Val: 0.044153 (MSE=0.010807 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044153 (ep 1)
[13:38:02] Epoch 2/100 | Train: 0.036177 (MSE=0.003097 BCE=0.6616) | Val: 0.042984 (MSE=0.009655 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042984 (ep 2)
[13:38:05] Epoch 3/100 | Train: 0.036111 (MSE=0.003044 BCE=0.6614) | Val: 0.042609 (MSE=0.009256 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042609 (ep 3)
[13:38:07] Epoch 4/100 | Train: 0.036075 (MSE=0.003016 BCE=0.6612) | Val: 0.042537 (MSE=0.009220 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042537 (ep 4)
[13:38:10] Epoch 5/100 | Train: 0.036045 (MSE=0.002991 BCE=0.6611) | Val: 0.042459 (MSE=0.009138 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042459 (ep 5)
[13:38:13] Epoch 6/100 | Train: 0.036020 (MSE=0.002970 BCE=0.6610) | Val: 0.042315 (MSE=0.008975 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:16] Epoch 7/100 | Train: 0.036001 (MSE=0.002954 BCE=0.6609) | Val: 0.042329 (MSE=0.008999 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:18] Epoch 8/100 | Train: 0.035981 (MSE=0.002943 BCE=0.6608) | Val: 0.042340 (MSE=0.009001 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:21] Epoch 9/100 | Train: 0.035971 (MSE=0.002935 BCE=0.6607) | Val: 0.042373 (MSE=0.009018 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:24] Epoch 10/100 | Train: 0.035960 (MSE=0.002925 BCE=0.6607) | Val: 0.042360 (MSE=0.009019 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:27] Epoch 11/100 | Train: 0.035948 (MSE=0.002917 BCE=0.6606) | Val: 0.042426 (MSE=0.009089 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042315 (ep 6)
[13:38:29] Epoch 12/100 | Train: 0.035937 (MSE=0.002911 BCE=0.6605) | Val: 0.042480 (MSE=0.009146 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042315 (ep 6)
[13:38:32] Epoch 13/100 | Train: 0.035922 (MSE=0.002901 BCE=0.6604) | Val: 0.042508 (MSE=0.009166 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042315 (ep 6)
[13:38:35] Epoch 14/100 | Train: 0.035917 (MSE=0.002900 BCE=0.6603) | Val: 0.042568 (MSE=0.009220 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042315 (ep 6)
[13:38:37] Epoch 15/100 | Train: 0.035912 (MSE=0.002893 BCE=0.6604) | Val: 0.042603 (MSE=0.009252 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042315 (ep 6)
[13:38:40] Epoch 16/100 | Train: 0.035907 (MSE=0.002891 BCE=0.6603) | Val: 0.042682 (MSE=0.009330 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042315 (ep 6)
[13:38:40] Early stopping at epoch 16 (no improvement for 10 epochs)
[13:38:41] Factor 12 done — best val loss: 0.042315 at epoch 6
[13:38:41] 
============================================================
[13:38:41] STF Factor 13 of [5..20]
[13:38:41] ============================================================
[13:38:41] Building features: 0% (1/175846)
[13:38:42] Building features: 5% (8793/175846)
[13:38:42] Building features: 10% (17585/175846)
[13:38:43] Building features: 15% (26377/175846)
[13:38:43] Building features: 20% (35169/175846)
[13:38:44] Building features: 25% (43961/175846)
[13:38:44] Building features: 30% (52753/175846)
[13:38:45] Building features: 35% (61545/175846)
[13:38:46] Building features: 40% (70337/175846)
[13:38:46] Building features: 45% (79129/175846)
[13:38:47] Building features: 50% (87921/175846)
[13:38:47] Building features: 55% (96713/175846)
[13:38:48] Building features: 60% (105505/175846)
[13:38:48] Building features: 65% (114297/175846)
[13:38:49] Building features: 70% (123089/175846)
[13:38:49] Building features: 75% (131881/175846)
[13:38:50] Building features: 80% (140673/175846)
[13:38:50] Building features: 85% (149465/175846)
[13:38:51] Building features: 90% (158257/175846)
[13:38:51] Building features: 95% (167049/175846)
[13:38:52] Building features: 100% (175841/175846)
[13:38:52] Computing Hurst exponent...
[13:38:57] Computing market regimes (GMM)...
[13:39:05] Factor 13: 175724 samples, 92 features
[13:39:07] Batch stats — Input:  mean=0.0521 std=0.2676 min=-4.5782 max=6.1413
[13:39:07] Batch stats — Target: mean=0.0024 std=0.0695 min=-0.4720 max=0.3922
[13:39:07] Batch stats — Cls:    pos_long=108/256 pos_short=78/256
[13:39:07] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:39:11] Epoch 1/100 | Train: 0.037177 (MSE=0.003947 BCE=0.6646) | Val: 0.044144 (MSE=0.010791 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044144 (ep 1)
[13:39:14] Epoch 2/100 | Train: 0.036210 (MSE=0.003121 BCE=0.6618) | Val: 0.042973 (MSE=0.009627 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042973 (ep 2)
[13:39:17] Epoch 3/100 | Train: 0.036127 (MSE=0.003059 BCE=0.6614) | Val: 0.042611 (MSE=0.009283 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042611 (ep 3)
[13:39:20] Epoch 4/100 | Train: 0.036091 (MSE=0.003024 BCE=0.6613) | Val: 0.042556 (MSE=0.009218 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042556 (ep 4)
[13:39:22] Epoch 5/100 | Train: 0.036061 (MSE=0.002999 BCE=0.6612) | Val: 0.042481 (MSE=0.009135 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042481 (ep 5)
[13:39:25] Epoch 6/100 | Train: 0.036033 (MSE=0.002981 BCE=0.6611) | Val: 0.042445 (MSE=0.009110 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042445 (ep 6)
[13:39:28] Epoch 7/100 | Train: 0.036014 (MSE=0.002965 BCE=0.6610) | Val: 0.042409 (MSE=0.009054 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042409 (ep 7)
[13:39:31] Epoch 8/100 | Train: 0.035995 (MSE=0.002951 BCE=0.6609) | Val: 0.042358 (MSE=0.009024 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042358 (ep 8)
[13:39:34] Epoch 9/100 | Train: 0.035983 (MSE=0.002941 BCE=0.6608) | Val: 0.042397 (MSE=0.009051 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042358 (ep 8)
[13:39:37] Epoch 10/100 | Train: 0.035966 (MSE=0.002930 BCE=0.6607) | Val: 0.042335 (MSE=0.008975 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042335 (ep 10)
[13:39:39] Epoch 11/100 | Train: 0.035956 (MSE=0.002925 BCE=0.6606) | Val: 0.042356 (MSE=0.009003 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042335 (ep 10)
[13:39:42] Epoch 12/100 | Train: 0.035947 (MSE=0.002916 BCE=0.6606) | Val: 0.042289 (MSE=0.008931 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:45] Epoch 13/100 | Train: 0.035935 (MSE=0.002907 BCE=0.6606) | Val: 0.042360 (MSE=0.009007 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:48] Epoch 14/100 | Train: 0.035925 (MSE=0.002904 BCE=0.6604) | Val: 0.042358 (MSE=0.008998 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:50] Epoch 15/100 | Train: 0.035917 (MSE=0.002896 BCE=0.6604) | Val: 0.042406 (MSE=0.009056 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:53] Epoch 16/100 | Train: 0.035908 (MSE=0.002890 BCE=0.6604) | Val: 0.042431 (MSE=0.009066 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:56] Epoch 17/100 | Train: 0.035902 (MSE=0.002889 BCE=0.6603) | Val: 0.042522 (MSE=0.009187 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042289 (ep 12)
[13:39:58] Epoch 18/100 | Train: 0.035889 (MSE=0.002878 BCE=0.6602) | Val: 0.042570 (MSE=0.009202 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042289 (ep 12)
[13:40:01] Epoch 19/100 | Train: 0.035871 (MSE=0.002870 BCE=0.6600) | Val: 0.042616 (MSE=0.009240 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042289 (ep 12)
[13:40:04] Epoch 20/100 | Train: 0.035871 (MSE=0.002869 BCE=0.6600) | Val: 0.042680 (MSE=0.009302 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042289 (ep 12)
[13:40:07] Epoch 21/100 | Train: 0.035866 (MSE=0.002868 BCE=0.6600) | Val: 0.042683 (MSE=0.009301 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042289 (ep 12)
[13:40:09] Epoch 22/100 | Train: 0.035867 (MSE=0.002867 BCE=0.6600) | Val: 0.042541 (MSE=0.009170 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042289 (ep 12)
[13:40:09] Early stopping at epoch 22 (no improvement for 10 epochs)
[13:40:10] Factor 13 done — best val loss: 0.042289 at epoch 12
[13:40:10] 
============================================================
[13:40:10] STF Factor 14 of [5..20]
[13:40:10] ============================================================
[13:40:11] Building features: 0% (1/175846)
[13:40:11] Building features: 5% (8793/175846)
[13:40:12] Building features: 10% (17585/175846)
[13:40:12] Building features: 15% (26377/175846)
[13:40:13] Building features: 20% (35169/175846)
[13:40:13] Building features: 25% (43961/175846)
[13:40:14] Building features: 30% (52753/175846)
[13:40:14] Building features: 35% (61545/175846)
[13:40:15] Building features: 40% (70337/175846)
[13:40:15] Building features: 45% (79129/175846)
[13:40:16] Building features: 50% (87921/175846)
[13:40:16] Building features: 55% (96713/175846)
[13:40:17] Building features: 60% (105505/175846)
[13:40:17] Building features: 65% (114297/175846)
[13:40:18] Building features: 70% (123089/175846)
[13:40:19] Building features: 75% (131881/175846)
[13:40:19] Building features: 80% (140673/175846)
[13:40:20] Building features: 85% (149465/175846)
[13:40:20] Building features: 90% (158257/175846)
[13:40:21] Building features: 95% (167049/175846)
[13:40:21] Building features: 100% (175841/175846)
[13:40:21] Computing Hurst exponent...
[13:40:26] Computing market regimes (GMM)...
[13:40:34] Factor 14: 175724 samples, 92 features
[13:40:36] Batch stats — Input:  mean=0.0526 std=0.2669 min=-5.4479 max=5.6124
[13:40:36] Batch stats — Target: mean=-0.0013 std=0.0655 min=-0.4720 max=0.4134
[13:40:36] Batch stats — Cls:    pos_long=95/256 pos_short=96/256
[13:40:36] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:40:40] Epoch 1/100 | Train: 0.036909 (MSE=0.003761 BCE=0.6630) | Val: 0.043337 (MSE=0.009976 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043337 (ep 1)
[13:40:43] Epoch 2/100 | Train: 0.036161 (MSE=0.003086 BCE=0.6615) | Val: 0.042659 (MSE=0.009290 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042659 (ep 2)
[13:40:46] Epoch 3/100 | Train: 0.036107 (MSE=0.003042 BCE=0.6613) | Val: 0.042518 (MSE=0.009166 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042518 (ep 3)
[13:40:48] Epoch 4/100 | Train: 0.036066 (MSE=0.003012 BCE=0.6611) | Val: 0.042515 (MSE=0.009164 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042515 (ep 4)
[13:40:51] Epoch 5/100 | Train: 0.036041 (MSE=0.002989 BCE=0.6610) | Val: 0.042495 (MSE=0.009147 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042495 (ep 5)
[13:40:54] Epoch 6/100 | Train: 0.036016 (MSE=0.002970 BCE=0.6609) | Val: 0.042466 (MSE=0.009119 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042466 (ep 6)
[13:40:57] Epoch 7/100 | Train: 0.035998 (MSE=0.002955 BCE=0.6609) | Val: 0.042371 (MSE=0.009035 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042371 (ep 7)
[13:40:59] Epoch 8/100 | Train: 0.035979 (MSE=0.002942 BCE=0.6607) | Val: 0.042402 (MSE=0.009039 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042371 (ep 7)
[13:41:02] Epoch 9/100 | Train: 0.035966 (MSE=0.002931 BCE=0.6607) | Val: 0.042377 (MSE=0.009011 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042371 (ep 7)
[13:41:05] Epoch 10/100 | Train: 0.035957 (MSE=0.002921 BCE=0.6607) | Val: 0.042344 (MSE=0.008976 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042344 (ep 10)
[13:41:08] Epoch 11/100 | Train: 0.035944 (MSE=0.002914 BCE=0.6606) | Val: 0.042456 (MSE=0.009114 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042344 (ep 10)
[13:41:10] Epoch 12/100 | Train: 0.035931 (MSE=0.002905 BCE=0.6605) | Val: 0.042280 (MSE=0.008936 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:13] Epoch 13/100 | Train: 0.035923 (MSE=0.002899 BCE=0.6605) | Val: 0.042306 (MSE=0.008956 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:16] Epoch 14/100 | Train: 0.035912 (MSE=0.002891 BCE=0.6604) | Val: 0.042296 (MSE=0.008957 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:19] Epoch 15/100 | Train: 0.035907 (MSE=0.002887 BCE=0.6604) | Val: 0.042417 (MSE=0.009066 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:21] Epoch 16/100 | Train: 0.035899 (MSE=0.002882 BCE=0.6603) | Val: 0.042310 (MSE=0.008952 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:24] Epoch 17/100 | Train: 0.035891 (MSE=0.002878 BCE=0.6603) | Val: 0.042486 (MSE=0.009136 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042280 (ep 12)
[13:41:27] Epoch 18/100 | Train: 0.035884 (MSE=0.002870 BCE=0.6603) | Val: 0.042424 (MSE=0.009070 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042280 (ep 12)
[13:41:30] Epoch 19/100 | Train: 0.035864 (MSE=0.002865 BCE=0.6600) | Val: 0.042627 (MSE=0.009272 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042280 (ep 12)
[13:41:32] Epoch 20/100 | Train: 0.035862 (MSE=0.002860 BCE=0.6600) | Val: 0.042517 (MSE=0.009157 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042280 (ep 12)
[13:41:35] Epoch 21/100 | Train: 0.035854 (MSE=0.002855 BCE=0.6600) | Val: 0.042613 (MSE=0.009240 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042280 (ep 12)
[13:41:38] Epoch 22/100 | Train: 0.035850 (MSE=0.002851 BCE=0.6600) | Val: 0.042582 (MSE=0.009219 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042280 (ep 12)
[13:41:38] Early stopping at epoch 22 (no improvement for 10 epochs)
[13:41:39] Factor 14 done — best val loss: 0.042280 at epoch 12
[13:41:39] 
============================================================
[13:41:39] STF Factor 15 of [5..20]
[13:41:39] ============================================================
[13:41:39] Building features: 0% (1/175846)
[13:41:39] Building features: 5% (8793/175846)
[13:41:40] Building features: 10% (17585/175846)
[13:41:41] Building features: 15% (26377/175846)
[13:41:41] Building features: 20% (35169/175846)
[13:41:42] Building features: 25% (43961/175846)
[13:41:42] Building features: 30% (52753/175846)
[13:41:43] Building features: 35% (61545/175846)
[13:41:43] Building features: 40% (70337/175846)
[13:41:44] Building features: 45% (79129/175846)
[13:41:44] Building features: 50% (87921/175846)
[13:41:45] Building features: 55% (96713/175846)
[13:41:45] Building features: 60% (105505/175846)
[13:41:46] Building features: 65% (114297/175846)
[13:41:47] Building features: 70% (123089/175846)
[13:41:47] Building features: 75% (131881/175846)
[13:41:48] Building features: 80% (140673/175846)
[13:41:48] Building features: 85% (149465/175846)
[13:41:49] Building features: 90% (158257/175846)
[13:41:49] Building features: 95% (167049/175846)
[13:41:50] Building features: 100% (175841/175846)
[13:41:50] Computing Hurst exponent...
[13:41:55] Computing market regimes (GMM)...
[13:42:02] Factor 15: 175724 samples, 92 features
[13:42:04] Batch stats — Input:  mean=0.0515 std=0.2703 min=-4.8553 max=7.1652
[13:42:04] Batch stats — Target: mean=-0.0023 std=0.0685 min=-0.4720 max=0.3229
[13:42:04] Batch stats — Cls:    pos_long=105/256 pos_short=92/256
[13:42:04] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:42:09] Epoch 1/100 | Train: 0.037113 (MSE=0.003865 BCE=0.6650) | Val: 0.044198 (MSE=0.010845 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044198 (ep 1)
[13:42:11] Epoch 2/100 | Train: 0.036192 (MSE=0.003109 BCE=0.6617) | Val: 0.043137 (MSE=0.009797 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043137 (ep 2)
[13:42:14] Epoch 3/100 | Train: 0.036134 (MSE=0.003065 BCE=0.6614) | Val: 0.042792 (MSE=0.009412 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042792 (ep 3)
[13:42:17] Epoch 4/100 | Train: 0.036104 (MSE=0.003034 BCE=0.6614) | Val: 0.042602 (MSE=0.009260 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042602 (ep 4)
[13:42:20] Epoch 5/100 | Train: 0.036062 (MSE=0.003002 BCE=0.6612) | Val: 0.042496 (MSE=0.009168 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042496 (ep 5)
[13:42:23] Epoch 6/100 | Train: 0.036033 (MSE=0.002979 BCE=0.6611) | Val: 0.042445 (MSE=0.009072 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042445 (ep 6)
[13:42:26] Epoch 7/100 | Train: 0.036008 (MSE=0.002963 BCE=0.6609) | Val: 0.042441 (MSE=0.009097 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042441 (ep 7)
[13:42:29] Epoch 8/100 | Train: 0.035990 (MSE=0.002948 BCE=0.6608) | Val: 0.042387 (MSE=0.009026 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[13:42:32] Epoch 9/100 | Train: 0.035974 (MSE=0.002937 BCE=0.6607) | Val: 0.042387 (MSE=0.009044 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[13:42:34] Epoch 10/100 | Train: 0.035963 (MSE=0.002930 BCE=0.6607) | Val: 0.042466 (MSE=0.009090 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[13:42:37] Epoch 11/100 | Train: 0.035950 (MSE=0.002919 BCE=0.6606) | Val: 0.042488 (MSE=0.009135 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[13:42:40] Epoch 12/100 | Train: 0.035940 (MSE=0.002913 BCE=0.6605) | Val: 0.042452 (MSE=0.009061 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[13:42:43] Epoch 13/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6605) | Val: 0.042385 (MSE=0.009029 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042385 (ep 13)
[13:42:45] Epoch 14/100 | Train: 0.035919 (MSE=0.002901 BCE=0.6604) | Val: 0.042500 (MSE=0.009154 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:42:48] Epoch 15/100 | Train: 0.035899 (MSE=0.002890 BCE=0.6602) | Val: 0.042765 (MSE=0.009394 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:42:51] Epoch 16/100 | Train: 0.035899 (MSE=0.002886 BCE=0.6603) | Val: 0.042530 (MSE=0.009171 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:42:54] Epoch 17/100 | Train: 0.035897 (MSE=0.002884 BCE=0.6603) | Val: 0.042749 (MSE=0.009385 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:42:57] Epoch 18/100 | Train: 0.035890 (MSE=0.002882 BCE=0.6602) | Val: 0.043161 (MSE=0.009783 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:43:00] Epoch 19/100 | Train: 0.035880 (MSE=0.002878 BCE=0.6600) | Val: 0.043009 (MSE=0.009628 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042385 (ep 13)
[13:43:03] Epoch 20/100 | Train: 0.035884 (MSE=0.002879 BCE=0.6601) | Val: 0.042994 (MSE=0.009614 BCE=0.6676) | LR: 2.50e-05 | Best: 0.042385 (ep 13)
[13:43:06] Epoch 21/100 | Train: 0.035873 (MSE=0.002871 BCE=0.6600) | Val: 0.042991 (MSE=0.009603 BCE=0.6678) | LR: 2.50e-05 | Best: 0.042385 (ep 13)
[13:43:08] Epoch 22/100 | Train: 0.035863 (MSE=0.002868 BCE=0.6599) | Val: 0.043146 (MSE=0.009749 BCE=0.6679) | LR: 2.50e-05 | Best: 0.042385 (ep 13)
[13:43:11] Epoch 23/100 | Train: 0.035865 (MSE=0.002867 BCE=0.6600) | Val: 0.043200 (MSE=0.009802 BCE=0.6680) | LR: 2.50e-05 | Best: 0.042385 (ep 13)
[13:43:11] Early stopping at epoch 23 (no improvement for 10 epochs)
[13:43:12] Factor 15 done — best val loss: 0.042385 at epoch 13
[13:43:12] 
============================================================
[13:43:12] STF Factor 16 of [5..20]
[13:43:12] ============================================================
[13:43:12] Building features: 0% (1/175846)
[13:43:13] Building features: 5% (8793/175846)
[13:43:13] Building features: 10% (17585/175846)
[13:43:14] Building features: 15% (26377/175846)
[13:43:14] Building features: 20% (35169/175846)
[13:43:15] Building features: 25% (43961/175846)
[13:43:16] Building features: 30% (52753/175846)
[13:43:16] Building features: 35% (61545/175846)
[13:43:17] Building features: 40% (70337/175846)
[13:43:17] Building features: 45% (79129/175846)
[13:43:18] Building features: 50% (87921/175846)
[13:43:19] Building features: 55% (96713/175846)
[13:43:19] Building features: 60% (105505/175846)
[13:43:20] Building features: 65% (114297/175846)
[13:43:21] Building features: 70% (123089/175846)
[13:43:21] Building features: 75% (131881/175846)
[13:43:22] Building features: 80% (140673/175846)
[13:43:22] Building features: 85% (149465/175846)
[13:43:23] Building features: 90% (158257/175846)
[13:43:24] Building features: 95% (167049/175846)
[13:43:24] Building features: 100% (175841/175846)
[13:43:24] Computing Hurst exponent...
[13:43:30] Computing market regimes (GMM)...
[13:43:38] Factor 16: 175724 samples, 92 features
[13:43:39] Batch stats — Input:  mean=0.0524 std=0.2755 min=-3.5943 max=10.0390
[13:43:39] Batch stats — Target: mean=0.0018 std=0.0717 min=-0.4720 max=0.4134
[13:43:39] Batch stats — Cls:    pos_long=100/256 pos_short=93/256
[13:43:39] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:43:44] Epoch 1/100 | Train: 0.037060 (MSE=0.003860 BCE=0.6640) | Val: 0.044120 (MSE=0.010771 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044120 (ep 1)
[13:43:47] Epoch 2/100 | Train: 0.036196 (MSE=0.003104 BCE=0.6618) | Val: 0.042925 (MSE=0.009575 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042925 (ep 2)
[13:43:50] Epoch 3/100 | Train: 0.036117 (MSE=0.003050 BCE=0.6613) | Val: 0.042619 (MSE=0.009275 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042619 (ep 3)
[13:43:52] Epoch 4/100 | Train: 0.036083 (MSE=0.003021 BCE=0.6612) | Val: 0.042569 (MSE=0.009229 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042569 (ep 4)
[13:43:55] Epoch 5/100 | Train: 0.036052 (MSE=0.002996 BCE=0.6611) | Val: 0.042477 (MSE=0.009135 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042477 (ep 5)
[13:43:58] Epoch 6/100 | Train: 0.036020 (MSE=0.002973 BCE=0.6609) | Val: 0.042485 (MSE=0.009126 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042477 (ep 5)
[13:44:01] Epoch 7/100 | Train: 0.036001 (MSE=0.002960 BCE=0.6608) | Val: 0.042433 (MSE=0.009078 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042433 (ep 7)
[13:44:03] Epoch 8/100 | Train: 0.035986 (MSE=0.002946 BCE=0.6608) | Val: 0.042346 (MSE=0.008997 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042346 (ep 8)
[13:44:06] Epoch 9/100 | Train: 0.035966 (MSE=0.002935 BCE=0.6606) | Val: 0.042395 (MSE=0.009025 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042346 (ep 8)
[13:44:09] Epoch 10/100 | Train: 0.035957 (MSE=0.002925 BCE=0.6606) | Val: 0.042364 (MSE=0.008997 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042346 (ep 8)
[13:44:12] Epoch 11/100 | Train: 0.035948 (MSE=0.002919 BCE=0.6606) | Val: 0.042314 (MSE=0.008976 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:15] Epoch 12/100 | Train: 0.035927 (MSE=0.002910 BCE=0.6603) | Val: 0.042424 (MSE=0.009066 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:18] Epoch 13/100 | Train: 0.035924 (MSE=0.002905 BCE=0.6604) | Val: 0.042415 (MSE=0.009067 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:20] Epoch 14/100 | Train: 0.035914 (MSE=0.002898 BCE=0.6603) | Val: 0.042440 (MSE=0.009082 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:23] Epoch 15/100 | Train: 0.035908 (MSE=0.002893 BCE=0.6603) | Val: 0.042532 (MSE=0.009149 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:26] Epoch 16/100 | Train: 0.035898 (MSE=0.002889 BCE=0.6602) | Val: 0.042620 (MSE=0.009223 BCE=0.6679) | LR: 1.00e-04 | Best: 0.042314 (ep 11)
[13:44:29] Epoch 17/100 | Train: 0.035887 (MSE=0.002883 BCE=0.6601) | Val: 0.042659 (MSE=0.009261 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042314 (ep 11)
[13:44:32] Epoch 18/100 | Train: 0.035874 (MSE=0.002873 BCE=0.6600) | Val: 0.042622 (MSE=0.009239 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042314 (ep 11)
[13:44:35] Epoch 19/100 | Train: 0.035866 (MSE=0.002872 BCE=0.6599) | Val: 0.042681 (MSE=0.009275 BCE=0.6681) | LR: 5.00e-05 | Best: 0.042314 (ep 11)
[13:44:38] Epoch 20/100 | Train: 0.035856 (MSE=0.002867 BCE=0.6598) | Val: 0.042660 (MSE=0.009263 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042314 (ep 11)
[13:44:41] Epoch 21/100 | Train: 0.035849 (MSE=0.002865 BCE=0.6597) | Val: 0.042765 (MSE=0.009349 BCE=0.6683) | LR: 5.00e-05 | Best: 0.042314 (ep 11)
[13:44:41] Early stopping at epoch 21 (no improvement for 10 epochs)
[13:44:42] Factor 16 done — best val loss: 0.042314 at epoch 11
[13:44:42] 
============================================================
[13:44:42] STF Factor 17 of [5..20]
[13:44:42] ============================================================
[13:44:42] Building features: 0% (1/175846)
[13:44:42] Building features: 5% (8793/175846)
[13:44:43] Building features: 10% (17585/175846)
[13:44:44] Building features: 15% (26377/175846)
[13:44:44] Building features: 20% (35169/175846)
[13:44:45] Building features: 25% (43961/175846)
[13:44:45] Building features: 30% (52753/175846)
[13:44:46] Building features: 35% (61545/175846)
[13:44:47] Building features: 40% (70337/175846)
[13:44:47] Building features: 45% (79129/175846)
[13:44:48] Building features: 50% (87921/175846)
[13:44:48] Building features: 55% (96713/175846)
[13:44:49] Building features: 60% (105505/175846)
[13:44:50] Building features: 65% (114297/175846)
[13:44:50] Building features: 70% (123089/175846)
[13:44:51] Building features: 75% (131881/175846)
[13:44:51] Building features: 80% (140673/175846)
[13:44:52] Building features: 85% (149465/175846)
[13:44:53] Building features: 90% (158257/175846)
[13:44:53] Building features: 95% (167049/175846)
[13:44:54] Building features: 100% (175841/175846)
[13:44:54] Computing Hurst exponent...
[13:44:59] Computing market regimes (GMM)...
[13:45:07] Factor 17: 175724 samples, 92 features
[13:45:09] Batch stats — Input:  mean=0.0512 std=0.2751 min=-5.4479 max=12.6954
[13:45:09] Batch stats — Target: mean=0.0067 std=0.0601 min=-0.3271 max=0.3978
[13:45:09] Batch stats — Cls:    pos_long=100/256 pos_short=84/256
[13:45:09] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:45:14] Epoch 1/100 | Train: 0.036988 (MSE=0.003803 BCE=0.6637) | Val: 0.044254 (MSE=0.010903 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044254 (ep 1)
[13:45:17] Epoch 2/100 | Train: 0.036198 (MSE=0.003110 BCE=0.6617) | Val: 0.042988 (MSE=0.009625 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042988 (ep 2)
[13:45:20] Epoch 3/100 | Train: 0.036125 (MSE=0.003056 BCE=0.6614) | Val: 0.042660 (MSE=0.009305 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042660 (ep 3)
[13:45:23] Epoch 4/100 | Train: 0.036079 (MSE=0.003019 BCE=0.6612) | Val: 0.042602 (MSE=0.009253 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042602 (ep 4)
[13:45:25] Epoch 5/100 | Train: 0.036040 (MSE=0.002992 BCE=0.6610) | Val: 0.042466 (MSE=0.009131 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042466 (ep 5)
[13:45:28] Epoch 6/100 | Train: 0.036024 (MSE=0.002976 BCE=0.6609) | Val: 0.042449 (MSE=0.009124 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:31] Epoch 7/100 | Train: 0.036007 (MSE=0.002960 BCE=0.6609) | Val: 0.042554 (MSE=0.009219 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:34] Epoch 8/100 | Train: 0.035989 (MSE=0.002948 BCE=0.6608) | Val: 0.042518 (MSE=0.009191 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:37] Epoch 9/100 | Train: 0.035971 (MSE=0.002936 BCE=0.6607) | Val: 0.042531 (MSE=0.009192 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:40] Epoch 10/100 | Train: 0.035960 (MSE=0.002926 BCE=0.6607) | Val: 0.042489 (MSE=0.009149 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:42] Epoch 11/100 | Train: 0.035945 (MSE=0.002915 BCE=0.6606) | Val: 0.042531 (MSE=0.009195 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042449 (ep 6)
[13:45:45] Epoch 12/100 | Train: 0.035939 (MSE=0.002909 BCE=0.6606) | Val: 0.042571 (MSE=0.009232 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042449 (ep 6)
[13:45:47] Epoch 13/100 | Train: 0.035917 (MSE=0.002898 BCE=0.6604) | Val: 0.042735 (MSE=0.009386 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042449 (ep 6)
[13:45:50] Epoch 14/100 | Train: 0.035914 (MSE=0.002896 BCE=0.6604) | Val: 0.042658 (MSE=0.009305 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042449 (ep 6)
[13:45:52] Epoch 15/100 | Train: 0.035905 (MSE=0.002891 BCE=0.6603) | Val: 0.042663 (MSE=0.009308 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042449 (ep 6)
[13:45:55] Epoch 16/100 | Train: 0.035902 (MSE=0.002888 BCE=0.6603) | Val: 0.042782 (MSE=0.009412 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042449 (ep 6)
[13:45:55] Early stopping at epoch 16 (no improvement for 10 epochs)
[13:45:56] Factor 17 done — best val loss: 0.042449 at epoch 6
[13:45:56] 
============================================================
[13:45:56] STF Factor 18 of [5..20]
[13:45:56] ============================================================
[13:45:56] Building features: 0% (1/175846)
[13:45:56] Building features: 5% (8793/175846)
[13:45:57] Building features: 10% (17585/175846)
[13:45:58] Building features: 15% (26377/175846)
[13:45:58] Building features: 20% (35169/175846)
[13:45:59] Building features: 25% (43961/175846)
[13:45:59] Building features: 30% (52753/175846)
[13:46:00] Building features: 35% (61545/175846)
[13:46:01] Building features: 40% (70337/175846)
[13:46:01] Building features: 45% (79129/175846)
[13:46:02] Building features: 50% (87921/175846)
[13:46:02] Building features: 55% (96713/175846)
[13:46:03] Building features: 60% (105505/175846)
[13:46:04] Building features: 65% (114297/175846)
[13:46:04] Building features: 70% (123089/175846)
[13:46:05] Building features: 75% (131881/175846)
[13:46:05] Building features: 80% (140673/175846)
[13:46:06] Building features: 85% (149465/175846)
[13:46:07] Building features: 90% (158257/175846)
[13:46:07] Building features: 95% (167049/175846)
[13:46:08] Building features: 100% (175841/175846)
[13:46:08] Computing Hurst exponent...
[13:46:13] Computing market regimes (GMM)...
[13:46:21] Factor 18: 175724 samples, 92 features
[13:46:23] Batch stats — Input:  mean=0.0529 std=0.2683 min=-3.4715 max=9.4431
[13:46:23] Batch stats — Target: mean=-0.0026 std=0.0703 min=-0.4720 max=0.4134
[13:46:23] Batch stats — Cls:    pos_long=100/256 pos_short=93/256
[13:46:23] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:46:28] Epoch 1/100 | Train: 0.037243 (MSE=0.004026 BCE=0.6643) | Val: 0.044130 (MSE=0.010774 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044130 (ep 1)
[13:46:31] Epoch 2/100 | Train: 0.036205 (MSE=0.003115 BCE=0.6618) | Val: 0.043009 (MSE=0.009653 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043009 (ep 2)
[13:46:33] Epoch 3/100 | Train: 0.036136 (MSE=0.003064 BCE=0.6614) | Val: 0.042651 (MSE=0.009306 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042651 (ep 3)
[13:46:35] Epoch 4/100 | Train: 0.036096 (MSE=0.003033 BCE=0.6613) | Val: 0.042599 (MSE=0.009250 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042599 (ep 4)
[13:46:38] Epoch 5/100 | Train: 0.036064 (MSE=0.003006 BCE=0.6612) | Val: 0.042472 (MSE=0.009136 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042472 (ep 5)
[13:46:40] Epoch 6/100 | Train: 0.036038 (MSE=0.002985 BCE=0.6611) | Val: 0.042420 (MSE=0.009095 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:43] Epoch 7/100 | Train: 0.036011 (MSE=0.002968 BCE=0.6609) | Val: 0.042456 (MSE=0.009115 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:46] Epoch 8/100 | Train: 0.036000 (MSE=0.002954 BCE=0.6609) | Val: 0.042490 (MSE=0.009158 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:48] Epoch 9/100 | Train: 0.035987 (MSE=0.002944 BCE=0.6609) | Val: 0.042487 (MSE=0.009144 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:51] Epoch 10/100 | Train: 0.035968 (MSE=0.002932 BCE=0.6607) | Val: 0.042771 (MSE=0.009438 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:54] Epoch 11/100 | Train: 0.035952 (MSE=0.002924 BCE=0.6606) | Val: 0.042762 (MSE=0.009403 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042420 (ep 6)
[13:46:57] Epoch 12/100 | Train: 0.035939 (MSE=0.002915 BCE=0.6605) | Val: 0.043027 (MSE=0.009678 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042420 (ep 6)
[13:46:59] Epoch 13/100 | Train: 0.035924 (MSE=0.002904 BCE=0.6604) | Val: 0.042952 (MSE=0.009612 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042420 (ep 6)
[13:47:02] Epoch 14/100 | Train: 0.035914 (MSE=0.002899 BCE=0.6603) | Val: 0.043345 (MSE=0.009999 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042420 (ep 6)
[13:47:05] Epoch 15/100 | Train: 0.035907 (MSE=0.002895 BCE=0.6602) | Val: 0.043247 (MSE=0.009903 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042420 (ep 6)
[13:47:08] Epoch 16/100 | Train: 0.035901 (MSE=0.002893 BCE=0.6602) | Val: 0.043418 (MSE=0.010063 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042420 (ep 6)
[13:47:08] Early stopping at epoch 16 (no improvement for 10 epochs)
[13:47:09] Factor 18 done — best val loss: 0.042420 at epoch 6
[13:47:09] 
============================================================
[13:47:09] STF Factor 19 of [5..20]
[13:47:09] ============================================================
[13:47:09] Building features: 0% (1/175846)
[13:47:10] Building features: 5% (8793/175846)
[13:47:10] Building features: 10% (17585/175846)
[13:47:11] Building features: 15% (26377/175846)
[13:47:11] Building features: 20% (35169/175846)
[13:47:12] Building features: 25% (43961/175846)
[13:47:12] Building features: 30% (52753/175846)
[13:47:13] Building features: 35% (61545/175846)
[13:47:13] Building features: 40% (70337/175846)
[13:47:14] Building features: 45% (79129/175846)
[13:47:14] Building features: 50% (87921/175846)
[13:47:15] Building features: 55% (96713/175846)
[13:47:16] Building features: 60% (105505/175846)
[13:47:16] Building features: 65% (114297/175846)
[13:47:17] Building features: 70% (123089/175846)
[13:47:17] Building features: 75% (131881/175846)
[13:47:18] Building features: 80% (140673/175846)
[13:47:18] Building features: 85% (149465/175846)
[13:47:19] Building features: 90% (158257/175846)
[13:47:19] Building features: 95% (167049/175846)
[13:47:20] Building features: 100% (175841/175846)
[13:47:20] Computing Hurst exponent...
[13:47:25] Computing market regimes (GMM)...
[13:47:33] Factor 19: 175724 samples, 92 features
[13:47:35] Batch stats — Input:  mean=0.0505 std=0.2682 min=-2.9965 max=7.6980
[13:47:35] Batch stats — Target: mean=0.0016 std=0.0631 min=-0.3099 max=0.3819
[13:47:35] Batch stats — Cls:    pos_long=99/256 pos_short=88/256
[13:47:35] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:47:40] Epoch 1/100 | Train: 0.037280 (MSE=0.004059 BCE=0.6644) | Val: 0.043847 (MSE=0.010482 BCE=0.6673) | LR: 1.00e-04 | Best: 0.043847 (ep 1)
[13:47:43] Epoch 2/100 | Train: 0.036210 (MSE=0.003115 BCE=0.6619) | Val: 0.042876 (MSE=0.009537 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042876 (ep 2)
[13:47:46] Epoch 3/100 | Train: 0.036135 (MSE=0.003058 BCE=0.6615) | Val: 0.042609 (MSE=0.009271 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042609 (ep 3)
[13:47:49] Epoch 4/100 | Train: 0.036088 (MSE=0.003029 BCE=0.6612) | Val: 0.042544 (MSE=0.009203 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042544 (ep 4)
[13:47:52] Epoch 5/100 | Train: 0.036064 (MSE=0.003004 BCE=0.6612) | Val: 0.042445 (MSE=0.009115 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042445 (ep 5)
[13:47:54] Epoch 6/100 | Train: 0.036027 (MSE=0.002980 BCE=0.6609) | Val: 0.042395 (MSE=0.009083 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042395 (ep 6)
[13:47:57] Epoch 7/100 | Train: 0.036019 (MSE=0.002966 BCE=0.6611) | Val: 0.042347 (MSE=0.009036 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042347 (ep 7)
[13:48:00] Epoch 8/100 | Train: 0.035996 (MSE=0.002955 BCE=0.6608) | Val: 0.042353 (MSE=0.009035 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042347 (ep 7)
[13:48:03] Epoch 9/100 | Train: 0.035984 (MSE=0.002943 BCE=0.6608) | Val: 0.042293 (MSE=0.008966 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042293 (ep 9)
[13:48:06] Epoch 10/100 | Train: 0.035973 (MSE=0.002935 BCE=0.6608) | Val: 0.042235 (MSE=0.008910 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:09] Epoch 11/100 | Train: 0.035959 (MSE=0.002925 BCE=0.6607) | Val: 0.042280 (MSE=0.008951 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:12] Epoch 12/100 | Train: 0.035950 (MSE=0.002917 BCE=0.6606) | Val: 0.042288 (MSE=0.008957 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:15] Epoch 13/100 | Train: 0.035941 (MSE=0.002910 BCE=0.6606) | Val: 0.042330 (MSE=0.009013 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:17] Epoch 14/100 | Train: 0.035929 (MSE=0.002908 BCE=0.6604) | Val: 0.042390 (MSE=0.009068 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:20] Epoch 15/100 | Train: 0.035921 (MSE=0.002900 BCE=0.6604) | Val: 0.042428 (MSE=0.009095 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042235 (ep 10)
[13:48:23] Epoch 16/100 | Train: 0.035920 (MSE=0.002897 BCE=0.6605) | Val: 0.042459 (MSE=0.009131 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042235 (ep 10)
[13:48:26] Epoch 17/100 | Train: 0.035898 (MSE=0.002888 BCE=0.6602) | Val: 0.042552 (MSE=0.009228 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042235 (ep 10)
[13:48:29] Epoch 18/100 | Train: 0.035890 (MSE=0.002884 BCE=0.6601) | Val: 0.042495 (MSE=0.009165 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042235 (ep 10)
[13:48:31] Epoch 19/100 | Train: 0.035892 (MSE=0.002884 BCE=0.6602) | Val: 0.042497 (MSE=0.009165 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042235 (ep 10)
[13:48:34] Epoch 20/100 | Train: 0.035883 (MSE=0.002878 BCE=0.6601) | Val: 0.042636 (MSE=0.009298 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042235 (ep 10)
[13:48:34] Early stopping at epoch 20 (no improvement for 10 epochs)
[13:48:35] Factor 19 done — best val loss: 0.042235 at epoch 10
[13:48:35] 
============================================================
[13:48:35] STF Factor 20 of [5..20]
[13:48:35] ============================================================
[13:48:35] Building features: 0% (1/175846)
[13:48:36] Building features: 5% (8793/175846)
[13:48:36] Building features: 10% (17585/175846)
[13:48:37] Building features: 15% (26377/175846)
[13:48:38] Building features: 20% (35169/175846)
[13:48:38] Building features: 25% (43961/175846)
[13:48:39] Building features: 30% (52753/175846)
[13:48:39] Building features: 35% (61545/175846)
[13:48:40] Building features: 40% (70337/175846)
[13:48:40] Building features: 45% (79129/175846)
[13:48:41] Building features: 50% (87921/175846)
[13:48:42] Building features: 55% (96713/175846)
[13:48:42] Building features: 60% (105505/175846)
[13:48:43] Building features: 65% (114297/175846)
[13:48:43] Building features: 70% (123089/175846)
[13:48:44] Building features: 75% (131881/175846)
[13:48:44] Building features: 80% (140673/175846)
[13:48:45] Building features: 85% (149465/175846)
[13:48:46] Building features: 90% (158257/175846)
[13:48:46] Building features: 95% (167049/175846)
[13:48:47] Building features: 100% (175841/175846)
[13:48:47] Computing Hurst exponent...
[13:48:52] Computing market regimes (GMM)...
[13:49:00] Factor 20: 175724 samples, 92 features
[13:49:02] Batch stats — Input:  mean=0.0520 std=0.2841 min=-5.3639 max=60.4783
[13:49:02] Batch stats — Target: mean=-0.0063 std=0.0641 min=-0.4720 max=0.2875
[13:49:02] Batch stats — Cls:    pos_long=90/256 pos_short=105/256
[13:49:02] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:49:07] Epoch 1/100 | Train: 0.037189 (MSE=0.003978 BCE=0.6642) | Val: 0.043645 (MSE=0.010290 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043645 (ep 1)
[13:49:10] Epoch 2/100 | Train: 0.036197 (MSE=0.003111 BCE=0.6617) | Val: 0.042797 (MSE=0.009428 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042797 (ep 2)
[13:49:12] Epoch 3/100 | Train: 0.036123 (MSE=0.003054 BCE=0.6614) | Val: 0.042750 (MSE=0.009392 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042750 (ep 3)
[13:49:15] Epoch 4/100 | Train: 0.036080 (MSE=0.003021 BCE=0.6612) | Val: 0.042639 (MSE=0.009285 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042639 (ep 4)
[13:49:18] Epoch 5/100 | Train: 0.036048 (MSE=0.002992 BCE=0.6611) | Val: 0.042742 (MSE=0.009395 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042639 (ep 4)
[13:49:21] Epoch 6/100 | Train: 0.036023 (MSE=0.002976 BCE=0.6609) | Val: 0.042508 (MSE=0.009140 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042508 (ep 6)
[13:49:23] Epoch 7/100 | Train: 0.036009 (MSE=0.002962 BCE=0.6609) | Val: 0.042550 (MSE=0.009202 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042508 (ep 6)
[13:49:26] Epoch 8/100 | Train: 0.035984 (MSE=0.002947 BCE=0.6607) | Val: 0.042481 (MSE=0.009116 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:29] Epoch 9/100 | Train: 0.035974 (MSE=0.002936 BCE=0.6607) | Val: 0.042504 (MSE=0.009139 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:31] Epoch 10/100 | Train: 0.035963 (MSE=0.002930 BCE=0.6607) | Val: 0.042524 (MSE=0.009145 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:34] Epoch 11/100 | Train: 0.035947 (MSE=0.002920 BCE=0.6605) | Val: 0.042538 (MSE=0.009132 BCE=0.6681) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:37] Epoch 12/100 | Train: 0.035943 (MSE=0.002915 BCE=0.6606) | Val: 0.042661 (MSE=0.009272 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:40] Epoch 13/100 | Train: 0.035926 (MSE=0.002905 BCE=0.6604) | Val: 0.042645 (MSE=0.009273 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042481 (ep 8)
[13:49:42] Epoch 14/100 | Train: 0.035920 (MSE=0.002898 BCE=0.6604) | Val: 0.042768 (MSE=0.009366 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042481 (ep 8)
[13:49:45] Epoch 15/100 | Train: 0.035904 (MSE=0.002890 BCE=0.6603) | Val: 0.042818 (MSE=0.009404 BCE=0.6683) | LR: 5.00e-05 | Best: 0.042481 (ep 8)
[13:49:48] Epoch 16/100 | Train: 0.035889 (MSE=0.002882 BCE=0.6601) | Val: 0.042883 (MSE=0.009481 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042481 (ep 8)
[13:49:51] Epoch 17/100 | Train: 0.035892 (MSE=0.002883 BCE=0.6602) | Val: 0.042844 (MSE=0.009440 BCE=0.6681) | LR: 5.00e-05 | Best: 0.042481 (ep 8)
[13:49:53] Epoch 18/100 | Train: 0.035886 (MSE=0.002878 BCE=0.6601) | Val: 0.042827 (MSE=0.009418 BCE=0.6682) | LR: 5.00e-05 | Best: 0.042481 (ep 8)
[13:49:53] Early stopping at epoch 18 (no improvement for 10 epochs)
[13:49:54] Factor 20 done — best val loss: 0.042481 at epoch 8
[13:49:54] 
Best factor: 19 (val loss 0.042235)
[13:49:54] Training done. Best factor=19, val_loss=0.042235
[13:52:15] Building validation dataset...
[13:52:15] Building features: 0% (1/175846)
[13:52:16] Building features: 5% (8793/175846)
[13:52:16] Building features: 10% (17585/175846)
[13:52:17] Building features: 15% (26377/175846)
[13:52:17] Building features: 20% (35169/175846)
[13:52:18] Building features: 25% (43961/175846)
[13:52:18] Building features: 30% (52753/175846)
[13:52:19] Building features: 35% (61545/175846)
[13:52:19] Building features: 40% (70337/175846)
[13:52:20] Building features: 45% (79129/175846)
[13:52:20] Building features: 50% (87921/175846)
[13:52:21] Building features: 55% (96713/175846)
[13:52:21] Building features: 60% (105505/175846)
[13:52:22] Building features: 65% (114297/175846)
[13:52:23] Building features: 70% (123089/175846)
[13:52:23] Building features: 75% (131881/175846)
[13:52:24] Building features: 80% (140673/175846)
[13:52:25] Building features: 85% (149465/175846)
[13:52:25] Building features: 90% (158257/175846)
[13:52:26] Building features: 95% (167049/175846)
[13:52:26] Building features: 100% (175841/175846)
[13:52:26] Computing Hurst exponent...
[13:52:31] Computing market regimes (GMM)...
[13:52:38] Running backtest...
[13:52:38] Backtest complete: 8668 trades (7165L/1503S), WR=49.1%, PF=0.95
[13:53:44] Training started.
[13:53:44] 
============================================================
[13:53:44] STF Factor 5 of [5..6]
[13:53:44] ============================================================
[13:53:44] Building features: 0% (1/175846)
[13:53:44] Building features: 5% (8793/175846)
[13:53:45] Building features: 10% (17585/175846)
[13:53:45] Building features: 15% (26377/175846)
[13:53:46] Building features: 20% (35169/175846)
[13:53:46] Building features: 25% (43961/175846)
[13:53:47] Building features: 30% (52753/175846)
[13:53:47] Building features: 35% (61545/175846)
[13:53:48] Building features: 40% (70337/175846)
[13:53:48] Building features: 45% (79129/175846)
[13:53:49] Building features: 50% (87921/175846)
[13:53:50] Building features: 55% (96713/175846)
[13:53:50] Building features: 60% (105505/175846)
[13:53:51] Building features: 65% (114297/175846)
[13:53:51] Building features: 70% (123089/175846)
[13:53:52] Building features: 75% (131881/175846)
[13:53:52] Building features: 80% (140673/175846)
[13:53:53] Building features: 85% (149465/175846)
[13:53:54] Building features: 90% (158257/175846)
[13:53:54] Building features: 95% (167049/175846)
[13:53:55] Building features: 100% (175841/175846)
[13:53:55] Computing Hurst exponent...
[13:54:01] Computing market regimes (GMM)...
[13:54:09] Factor 5: 175694 samples, 92 features
[13:54:11] Batch stats — Input:  mean=0.0538 std=0.2642 min=-5.3639 max=11.1198
[13:54:11] Batch stats — Target: mean=-0.0017 std=0.0565 min=-0.3249 max=0.2935
[13:54:11] Batch stats — Cls:    pos_long=105/256 pos_short=85/256
[13:54:11] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:54:16] Epoch 1/100 | Train: 0.037032 (MSE=0.003810 BCE=0.6644) | Val: 0.044458 (MSE=0.011102 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044458 (ep 1)
[13:54:19] Epoch 2/100 | Train: 0.036198 (MSE=0.003116 BCE=0.6616) | Val: 0.043226 (MSE=0.009870 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043226 (ep 2)
[13:54:22] Epoch 3/100 | Train: 0.036134 (MSE=0.003066 BCE=0.6614) | Val: 0.042690 (MSE=0.009324 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042690 (ep 3)
[13:54:25] Epoch 4/100 | Train: 0.036086 (MSE=0.003026 BCE=0.6612) | Val: 0.042428 (MSE=0.009073 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042428 (ep 4)
[13:54:28] Epoch 5/100 | Train: 0.036051 (MSE=0.002997 BCE=0.6611) | Val: 0.042335 (MSE=0.008978 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042335 (ep 5)
[13:54:31] Epoch 6/100 | Train: 0.036022 (MSE=0.002975 BCE=0.6609) | Val: 0.042381 (MSE=0.009019 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042335 (ep 5)
[13:54:35] Epoch 7/100 | Train: 0.036001 (MSE=0.002956 BCE=0.6609) | Val: 0.042261 (MSE=0.008904 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:38] Epoch 8/100 | Train: 0.035986 (MSE=0.002948 BCE=0.6608) | Val: 0.042353 (MSE=0.008995 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:41] Epoch 9/100 | Train: 0.035970 (MSE=0.002935 BCE=0.6607) | Val: 0.042312 (MSE=0.008968 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:44] Epoch 10/100 | Train: 0.035957 (MSE=0.002929 BCE=0.6606) | Val: 0.042371 (MSE=0.009012 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:47] Epoch 11/100 | Train: 0.035953 (MSE=0.002920 BCE=0.6607) | Val: 0.042411 (MSE=0.009070 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:50] Epoch 12/100 | Train: 0.035939 (MSE=0.002911 BCE=0.6605) | Val: 0.042498 (MSE=0.009155 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042261 (ep 7)
[13:54:53] Epoch 13/100 | Train: 0.035933 (MSE=0.002908 BCE=0.6605) | Val: 0.042419 (MSE=0.009057 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042261 (ep 7)
[13:54:56] Epoch 14/100 | Train: 0.035916 (MSE=0.002897 BCE=0.6604) | Val: 0.042460 (MSE=0.009115 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042261 (ep 7)
[13:55:00] Epoch 15/100 | Train: 0.035910 (MSE=0.002895 BCE=0.6603) | Val: 0.042496 (MSE=0.009152 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042261 (ep 7)
[13:55:03] Epoch 16/100 | Train: 0.035907 (MSE=0.002890 BCE=0.6603) | Val: 0.042540 (MSE=0.009196 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042261 (ep 7)
[13:55:06] Epoch 17/100 | Train: 0.035895 (MSE=0.002885 BCE=0.6602) | Val: 0.042557 (MSE=0.009198 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042261 (ep 7)
[13:55:06] Early stopping at epoch 17 (no improvement for 10 epochs)
[13:55:07] Factor 5 done — best val loss: 0.042261 at epoch 7
[13:55:07] 
============================================================
[13:55:07] STF Factor 6 of [5..6]
[13:55:07] ============================================================
[13:55:07] Building features: 0% (1/175846)
[13:55:08] Building features: 5% (8793/175846)
[13:55:08] Building features: 10% (17585/175846)
[13:55:09] Building features: 15% (26377/175846)
[13:55:09] Building features: 20% (35169/175846)
[13:55:10] Building features: 25% (43961/175846)
[13:55:10] Building features: 30% (52753/175846)
[13:55:11] Building features: 35% (61545/175846)
[13:55:12] Building features: 40% (70337/175846)
[13:55:12] Building features: 45% (79129/175846)
[13:55:13] Building features: 50% (87921/175846)
[13:55:13] Building features: 55% (96713/175846)
[13:55:14] Building features: 60% (105505/175846)
[13:55:15] Building features: 65% (114297/175846)
[13:55:15] Building features: 70% (123089/175846)
[13:55:16] Building features: 75% (131881/175846)
[13:55:16] Building features: 80% (140673/175846)
[13:55:17] Building features: 85% (149465/175846)
[13:55:17] Building features: 90% (158257/175846)
[13:55:18] Building features: 95% (167049/175846)
[13:55:18] Building features: 100% (175841/175846)
[13:55:18] Computing Hurst exponent...
[13:55:24] Computing market regimes (GMM)...
[13:55:32] Factor 6: 175694 samples, 92 features
[13:55:34] Batch stats — Input:  mean=0.0537 std=0.2656 min=-4.8553 max=7.5420
[13:55:34] Batch stats — Target: mean=-0.0014 std=0.0713 min=-0.4720 max=0.4134
[13:55:34] Batch stats — Cls:    pos_long=90/256 pos_short=106/256
[13:55:34] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[13:55:39] Epoch 1/100 | Train: 0.036977 (MSE=0.003789 BCE=0.6638) | Val: 0.044189 (MSE=0.010836 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044189 (ep 1)
[13:55:42] Epoch 2/100 | Train: 0.036184 (MSE=0.003105 BCE=0.6616) | Val: 0.042898 (MSE=0.009550 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042898 (ep 2)
[13:55:45] Epoch 3/100 | Train: 0.036125 (MSE=0.003054 BCE=0.6614) | Val: 0.042623 (MSE=0.009278 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042623 (ep 3)
[13:55:48] Epoch 4/100 | Train: 0.036083 (MSE=0.003020 BCE=0.6613) | Val: 0.042585 (MSE=0.009259 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042585 (ep 4)
[13:55:51] Epoch 5/100 | Train: 0.036045 (MSE=0.002995 BCE=0.6610) | Val: 0.042603 (MSE=0.009274 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042585 (ep 4)
[13:55:54] Epoch 6/100 | Train: 0.036026 (MSE=0.002976 BCE=0.6610) | Val: 0.042489 (MSE=0.009148 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042489 (ep 6)
[13:55:57] Epoch 7/100 | Train: 0.036006 (MSE=0.002962 BCE=0.6609) | Val: 0.042534 (MSE=0.009208 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042489 (ep 6)
[13:56:00] Epoch 8/100 | Train: 0.035992 (MSE=0.002950 BCE=0.6608) | Val: 0.042388 (MSE=0.009061 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042388 (ep 8)
[13:56:03] Epoch 9/100 | Train: 0.035979 (MSE=0.002940 BCE=0.6608) | Val: 0.042459 (MSE=0.009106 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042388 (ep 8)
[13:56:06] Epoch 10/100 | Train: 0.035968 (MSE=0.002930 BCE=0.6607) | Val: 0.042347 (MSE=0.009004 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:08] Epoch 11/100 | Train: 0.035952 (MSE=0.002919 BCE=0.6607) | Val: 0.042505 (MSE=0.009163 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:11] Epoch 12/100 | Train: 0.035939 (MSE=0.002912 BCE=0.6605) | Val: 0.042494 (MSE=0.009140 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:13] Epoch 13/100 | Train: 0.035934 (MSE=0.002906 BCE=0.6606) | Val: 0.042617 (MSE=0.009274 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:16] Epoch 14/100 | Train: 0.035922 (MSE=0.002898 BCE=0.6605) | Val: 0.042869 (MSE=0.009481 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:19] Epoch 15/100 | Train: 0.035911 (MSE=0.002893 BCE=0.6604) | Val: 0.043004 (MSE=0.009620 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[13:56:22] Epoch 16/100 | Train: 0.035906 (MSE=0.002886 BCE=0.6604) | Val: 0.042794 (MSE=0.009440 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042347 (ep 10)
[13:56:25] Epoch 17/100 | Train: 0.035885 (MSE=0.002877 BCE=0.6602) | Val: 0.042729 (MSE=0.009370 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042347 (ep 10)
[13:56:28] Epoch 18/100 | Train: 0.035884 (MSE=0.002873 BCE=0.6602) | Val: 0.042858 (MSE=0.009500 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042347 (ep 10)
[13:56:31] Epoch 19/100 | Train: 0.035878 (MSE=0.002872 BCE=0.6601) | Val: 0.042924 (MSE=0.009538 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042347 (ep 10)
[13:56:34] Epoch 20/100 | Train: 0.035872 (MSE=0.002870 BCE=0.6600) | Val: 0.042910 (MSE=0.009544 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042347 (ep 10)
[13:56:34] Early stopping at epoch 20 (no improvement for 10 epochs)
[13:56:35] Factor 6 done — best val loss: 0.042347 at epoch 10
[13:56:35] 
Best factor: 5 (val loss 0.042261)
[13:56:35] Training done. Best factor=5, val_loss=0.042261
[14:01:16] Building validation dataset...
[14:01:16] Building features: 0% (1/175846)
[14:01:17] Building features: 5% (8793/175846)
[14:01:17] Building features: 10% (17585/175846)
[14:01:18] Building features: 15% (26377/175846)
[14:01:18] Building features: 20% (35169/175846)
[14:01:19] Building features: 25% (43961/175846)
[14:01:19] Building features: 30% (52753/175846)
[14:01:19] Building features: 35% (61545/175846)
[14:01:20] Building features: 40% (70337/175846)
[14:01:20] Building features: 45% (79129/175846)
[14:01:21] Building features: 50% (87921/175846)
[14:01:22] Building features: 55% (96713/175846)
[14:01:22] Building features: 60% (105505/175846)
[14:01:23] Building features: 65% (114297/175846)
[14:01:23] Building features: 70% (123089/175846)
[14:01:24] Building features: 75% (131881/175846)
[14:01:25] Building features: 80% (140673/175846)
[14:01:25] Building features: 85% (149465/175846)
[14:01:26] Building features: 90% (158257/175846)
[14:01:26] Building features: 95% (167049/175846)
[14:01:27] Building features: 100% (175841/175846)
[14:01:27] Computing Hurst exponent...
[14:01:33] Computing market regimes (GMM)...
[14:01:41] Running backtest...
[14:01:41] Backtest complete: 4838 trades (2425L/2413S), WR=49.0%, PF=0.95
[14:03:57] Training started.
[14:03:57] 
============================================================
[14:03:57] STF Factor 14 of [14..20]
[14:03:57] ============================================================
[14:03:58] Building features: 0% (1/175846)
[14:03:58] Building features: 5% (8793/175846)
[14:03:59] Building features: 10% (17585/175846)
[14:03:59] Building features: 15% (26377/175846)
[14:04:00] Building features: 20% (35169/175846)
[14:04:00] Building features: 25% (43961/175846)
[14:04:01] Building features: 30% (52753/175846)
[14:04:02] Building features: 35% (61545/175846)
[14:04:02] Building features: 40% (70337/175846)
[14:04:03] Building features: 45% (79129/175846)
[14:04:03] Building features: 50% (87921/175846)
[14:04:04] Building features: 55% (96713/175846)
[14:04:05] Building features: 60% (105505/175846)
[14:04:05] Building features: 65% (114297/175846)
[14:04:06] Building features: 70% (123089/175846)
[14:04:07] Building features: 75% (131881/175846)
[14:04:07] Building features: 80% (140673/175846)
[14:04:08] Building features: 85% (149465/175846)
[14:04:08] Building features: 90% (158257/175846)
[14:04:09] Building features: 95% (167049/175846)
[14:04:10] Building features: 100% (175841/175846)
[14:04:10] Computing Hurst exponent...
[14:04:16] Computing market regimes (GMM)...
[14:04:23] Factor 14: 175694 samples, 92 features
[14:04:25] Batch stats — Input:  mean=0.0510 std=0.2717 min=-4.1168 max=9.5561
[14:04:25] Batch stats — Target: mean=-0.0038 std=0.0665 min=-0.4720 max=0.4134
[14:04:25] Batch stats — Cls:    pos_long=86/256 pos_short=105/256
[14:04:25] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:04:31] Epoch 1/100 | Train: 0.037419 (MSE=0.004149 BCE=0.6654) | Val: 0.045147 (MSE=0.011783 BCE=0.6673) | LR: 1.00e-04 | Best: 0.045147 (ep 1)
[14:04:34] Epoch 2/100 | Train: 0.036213 (MSE=0.003127 BCE=0.6617) | Val: 0.043503 (MSE=0.010148 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043503 (ep 2)
[14:04:37] Epoch 3/100 | Train: 0.036136 (MSE=0.003062 BCE=0.6615) | Val: 0.042656 (MSE=0.009312 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042656 (ep 3)
[14:04:40] Epoch 4/100 | Train: 0.036097 (MSE=0.003028 BCE=0.6614) | Val: 0.042502 (MSE=0.009169 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042502 (ep 4)
[14:04:43] Epoch 5/100 | Train: 0.036061 (MSE=0.003001 BCE=0.6612) | Val: 0.042458 (MSE=0.009123 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042458 (ep 5)
[14:04:46] Epoch 6/100 | Train: 0.036028 (MSE=0.002974 BCE=0.6611) | Val: 0.042446 (MSE=0.009108 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042446 (ep 6)
[14:04:49] Epoch 7/100 | Train: 0.036005 (MSE=0.002954 BCE=0.6610) | Val: 0.042370 (MSE=0.009039 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042370 (ep 7)
[14:04:52] Epoch 8/100 | Train: 0.035987 (MSE=0.002944 BCE=0.6609) | Val: 0.042329 (MSE=0.008965 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042329 (ep 8)
[14:04:55] Epoch 9/100 | Train: 0.035976 (MSE=0.002934 BCE=0.6609) | Val: 0.042273 (MSE=0.008943 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:04:59] Epoch 10/100 | Train: 0.035958 (MSE=0.002924 BCE=0.6607) | Val: 0.042389 (MSE=0.009061 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:05:02] Epoch 11/100 | Train: 0.035950 (MSE=0.002916 BCE=0.6607) | Val: 0.042336 (MSE=0.008989 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:05:05] Epoch 12/100 | Train: 0.035936 (MSE=0.002908 BCE=0.6606) | Val: 0.042370 (MSE=0.009030 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:05:08] Epoch 13/100 | Train: 0.035929 (MSE=0.002902 BCE=0.6606) | Val: 0.042423 (MSE=0.009083 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:05:11] Epoch 14/100 | Train: 0.035924 (MSE=0.002898 BCE=0.6605) | Val: 0.042491 (MSE=0.009155 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042273 (ep 9)
[14:05:14] Epoch 15/100 | Train: 0.035914 (MSE=0.002892 BCE=0.6604) | Val: 0.042513 (MSE=0.009181 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042273 (ep 9)
[14:05:17] Epoch 16/100 | Train: 0.035897 (MSE=0.002883 BCE=0.6603) | Val: 0.042582 (MSE=0.009245 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042273 (ep 9)
[14:05:20] Epoch 17/100 | Train: 0.035891 (MSE=0.002880 BCE=0.6602) | Val: 0.042539 (MSE=0.009204 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042273 (ep 9)
[14:05:23] Epoch 18/100 | Train: 0.035890 (MSE=0.002875 BCE=0.6603) | Val: 0.042691 (MSE=0.009350 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042273 (ep 9)
[14:05:26] Epoch 19/100 | Train: 0.035886 (MSE=0.002875 BCE=0.6602) | Val: 0.042619 (MSE=0.009274 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042273 (ep 9)
[14:05:26] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:05:27] Factor 14 done — best val loss: 0.042273 at epoch 9
[14:05:27] 
============================================================
[14:05:27] STF Factor 15 of [14..20]
[14:05:27] ============================================================
[14:05:27] Building features: 0% (1/175846)
[14:05:28] Building features: 5% (8793/175846)
[14:05:28] Building features: 10% (17585/175846)
[14:05:29] Building features: 15% (26377/175846)
[14:05:29] Building features: 20% (35169/175846)
[14:05:30] Building features: 25% (43961/175846)
[14:05:30] Building features: 30% (52753/175846)
[14:05:31] Building features: 35% (61545/175846)
[14:05:32] Building features: 40% (70337/175846)
[14:05:32] Building features: 45% (79129/175846)
[14:05:33] Building features: 50% (87921/175846)
[14:05:33] Building features: 55% (96713/175846)
[14:05:34] Building features: 60% (105505/175846)
[14:05:35] Building features: 65% (114297/175846)
[14:05:35] Building features: 70% (123089/175846)
[14:05:36] Building features: 75% (131881/175846)
[14:05:37] Building features: 80% (140673/175846)
[14:05:37] Building features: 85% (149465/175846)
[14:05:38] Building features: 90% (158257/175846)
[14:05:38] Building features: 95% (167049/175846)
[14:05:39] Building features: 100% (175841/175846)
[14:05:39] Computing Hurst exponent...
[14:05:45] Computing market regimes (GMM)...
[14:05:52] Factor 15: 175694 samples, 92 features
[14:05:54] Batch stats — Input:  mean=0.0538 std=0.2711 min=-3.4695 max=7.9394
[14:05:54] Batch stats — Target: mean=0.0041 std=0.0629 min=-0.4720 max=0.3850
[14:05:54] Batch stats — Cls:    pos_long=121/256 pos_short=85/256
[14:05:54] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:05:59] Epoch 1/100 | Train: 0.037077 (MSE=0.003878 BCE=0.6640) | Val: 0.044824 (MSE=0.011468 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044824 (ep 1)
[14:06:02] Epoch 2/100 | Train: 0.036205 (MSE=0.003125 BCE=0.6616) | Val: 0.043365 (MSE=0.010012 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043365 (ep 2)
[14:06:06] Epoch 3/100 | Train: 0.036134 (MSE=0.003070 BCE=0.6613) | Val: 0.042683 (MSE=0.009343 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042683 (ep 3)
[14:06:09] Epoch 4/100 | Train: 0.036096 (MSE=0.003035 BCE=0.6612) | Val: 0.042571 (MSE=0.009236 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042571 (ep 4)
[14:06:12] Epoch 5/100 | Train: 0.036063 (MSE=0.003008 BCE=0.6611) | Val: 0.042486 (MSE=0.009147 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042486 (ep 5)
[14:06:15] Epoch 6/100 | Train: 0.036040 (MSE=0.002985 BCE=0.6611) | Val: 0.042461 (MSE=0.009122 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042461 (ep 6)
[14:06:18] Epoch 7/100 | Train: 0.036014 (MSE=0.002966 BCE=0.6609) | Val: 0.042441 (MSE=0.009074 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042441 (ep 7)
[14:06:21] Epoch 8/100 | Train: 0.035993 (MSE=0.002954 BCE=0.6608) | Val: 0.042416 (MSE=0.009050 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042416 (ep 8)
[14:06:24] Epoch 9/100 | Train: 0.035979 (MSE=0.002940 BCE=0.6608) | Val: 0.042335 (MSE=0.008987 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:27] Epoch 10/100 | Train: 0.035964 (MSE=0.002932 BCE=0.6607) | Val: 0.042406 (MSE=0.009049 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:29] Epoch 11/100 | Train: 0.035956 (MSE=0.002922 BCE=0.6607) | Val: 0.042351 (MSE=0.009011 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:32] Epoch 12/100 | Train: 0.035940 (MSE=0.002913 BCE=0.6606) | Val: 0.042422 (MSE=0.009070 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:35] Epoch 13/100 | Train: 0.035934 (MSE=0.002908 BCE=0.6605) | Val: 0.042452 (MSE=0.009104 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:38] Epoch 14/100 | Train: 0.035922 (MSE=0.002900 BCE=0.6604) | Val: 0.042547 (MSE=0.009194 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042335 (ep 9)
[14:06:41] Epoch 15/100 | Train: 0.035917 (MSE=0.002896 BCE=0.6604) | Val: 0.042659 (MSE=0.009291 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042335 (ep 9)
[14:06:45] Epoch 16/100 | Train: 0.035893 (MSE=0.002885 BCE=0.6602) | Val: 0.042576 (MSE=0.009218 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042335 (ep 9)
[14:06:48] Epoch 17/100 | Train: 0.035895 (MSE=0.002883 BCE=0.6602) | Val: 0.042704 (MSE=0.009342 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042335 (ep 9)
[14:06:51] Epoch 18/100 | Train: 0.035883 (MSE=0.002878 BCE=0.6601) | Val: 0.042829 (MSE=0.009458 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042335 (ep 9)
[14:06:54] Epoch 19/100 | Train: 0.035873 (MSE=0.002874 BCE=0.6600) | Val: 0.042754 (MSE=0.009389 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042335 (ep 9)
[14:06:54] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:06:55] Factor 15 done — best val loss: 0.042335 at epoch 9
[14:06:55] 
============================================================
[14:06:55] STF Factor 16 of [14..20]
[14:06:55] ============================================================
[14:06:55] Building features: 0% (1/175846)
[14:06:56] Building features: 5% (8793/175846)
[14:06:56] Building features: 10% (17585/175846)
[14:06:57] Building features: 15% (26377/175846)
[14:06:57] Building features: 20% (35169/175846)
[14:06:58] Building features: 25% (43961/175846)
[14:06:59] Building features: 30% (52753/175846)
[14:06:59] Building features: 35% (61545/175846)
[14:07:00] Building features: 40% (70337/175846)
[14:07:00] Building features: 45% (79129/175846)
[14:07:01] Building features: 50% (87921/175846)
[14:07:01] Building features: 55% (96713/175846)
[14:07:02] Building features: 60% (105505/175846)
[14:07:02] Building features: 65% (114297/175846)
[14:07:03] Building features: 70% (123089/175846)
[14:07:04] Building features: 75% (131881/175846)
[14:07:04] Building features: 80% (140673/175846)
[14:07:05] Building features: 85% (149465/175846)
[14:07:05] Building features: 90% (158257/175846)
[14:07:06] Building features: 95% (167049/175846)
[14:07:06] Building features: 100% (175841/175846)
[14:07:06] Computing Hurst exponent...
[14:07:12] Computing market regimes (GMM)...
[14:07:20] Factor 16: 175694 samples, 92 features
[14:07:22] Batch stats — Input:  mean=0.0518 std=0.2716 min=-4.1783 max=10.0671
[14:07:22] Batch stats — Target: mean=0.0018 std=0.0691 min=-0.4221 max=0.4134
[14:07:22] Batch stats — Cls:    pos_long=104/256 pos_short=92/256
[14:07:22] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:07:27] Epoch 1/100 | Train: 0.037341 (MSE=0.004142 BCE=0.6640) | Val: 0.045167 (MSE=0.011822 BCE=0.6669) | LR: 1.00e-04 | Best: 0.045167 (ep 1)
[14:07:30] Epoch 2/100 | Train: 0.036210 (MSE=0.003128 BCE=0.6616) | Val: 0.043568 (MSE=0.010194 BCE=0.6675) | LR: 1.00e-04 | Best: 0.043568 (ep 2)
[14:07:33] Epoch 3/100 | Train: 0.036135 (MSE=0.003062 BCE=0.6615) | Val: 0.042749 (MSE=0.009408 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042749 (ep 3)
[14:07:36] Epoch 4/100 | Train: 0.036095 (MSE=0.003028 BCE=0.6613) | Val: 0.042536 (MSE=0.009171 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042536 (ep 4)
[14:07:39] Epoch 5/100 | Train: 0.036054 (MSE=0.003002 BCE=0.6610) | Val: 0.042469 (MSE=0.009147 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042469 (ep 5)
[14:07:42] Epoch 6/100 | Train: 0.036027 (MSE=0.002982 BCE=0.6609) | Val: 0.042380 (MSE=0.009032 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042380 (ep 6)
[14:07:45] Epoch 7/100 | Train: 0.036016 (MSE=0.002971 BCE=0.6609) | Val: 0.042396 (MSE=0.009033 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042380 (ep 6)
[14:07:48] Epoch 8/100 | Train: 0.035993 (MSE=0.002956 BCE=0.6607) | Val: 0.042322 (MSE=0.008955 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042322 (ep 8)
[14:07:51] Epoch 9/100 | Train: 0.035978 (MSE=0.002943 BCE=0.6607) | Val: 0.042359 (MSE=0.008975 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042322 (ep 8)
[14:07:54] Epoch 10/100 | Train: 0.035965 (MSE=0.002934 BCE=0.6606) | Val: 0.042320 (MSE=0.008942 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042320 (ep 10)
[14:07:57] Epoch 11/100 | Train: 0.035951 (MSE=0.002925 BCE=0.6605) | Val: 0.042394 (MSE=0.009004 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042320 (ep 10)
[14:08:00] Epoch 12/100 | Train: 0.035948 (MSE=0.002919 BCE=0.6606) | Val: 0.042355 (MSE=0.008969 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042320 (ep 10)
[14:08:03] Epoch 13/100 | Train: 0.035934 (MSE=0.002910 BCE=0.6605) | Val: 0.042310 (MSE=0.008934 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:07] Epoch 14/100 | Train: 0.035927 (MSE=0.002904 BCE=0.6604) | Val: 0.042379 (MSE=0.009011 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:10] Epoch 15/100 | Train: 0.035916 (MSE=0.002901 BCE=0.6603) | Val: 0.042390 (MSE=0.009008 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:13] Epoch 16/100 | Train: 0.035908 (MSE=0.002894 BCE=0.6603) | Val: 0.042384 (MSE=0.009008 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:16] Epoch 17/100 | Train: 0.035898 (MSE=0.002888 BCE=0.6602) | Val: 0.042415 (MSE=0.009040 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:19] Epoch 18/100 | Train: 0.035887 (MSE=0.002886 BCE=0.6600) | Val: 0.042472 (MSE=0.009098 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042310 (ep 13)
[14:08:22] Epoch 19/100 | Train: 0.035880 (MSE=0.002881 BCE=0.6600) | Val: 0.042576 (MSE=0.009221 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042310 (ep 13)
[14:08:25] Epoch 20/100 | Train: 0.035866 (MSE=0.002874 BCE=0.6598) | Val: 0.042568 (MSE=0.009170 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042310 (ep 13)
[14:08:28] Epoch 21/100 | Train: 0.035853 (MSE=0.002867 BCE=0.6597) | Val: 0.042518 (MSE=0.009150 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042310 (ep 13)
[14:08:31] Epoch 22/100 | Train: 0.035855 (MSE=0.002867 BCE=0.6597) | Val: 0.042463 (MSE=0.009107 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042310 (ep 13)
[14:08:34] Epoch 23/100 | Train: 0.035854 (MSE=0.002864 BCE=0.6598) | Val: 0.042515 (MSE=0.009120 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042310 (ep 13)
[14:08:34] Early stopping at epoch 23 (no improvement for 10 epochs)
[14:08:35] Factor 16 done — best val loss: 0.042310 at epoch 13
[14:08:35] 
============================================================
[14:08:35] STF Factor 17 of [14..20]
[14:08:35] ============================================================
[14:08:35] Building features: 0% (1/175846)
[14:08:36] Building features: 5% (8793/175846)
[14:08:36] Building features: 10% (17585/175846)
[14:08:37] Building features: 15% (26377/175846)
[14:08:38] Building features: 20% (35169/175846)
[14:08:38] Building features: 25% (43961/175846)
[14:08:39] Building features: 30% (52753/175846)
[14:08:39] Building features: 35% (61545/175846)
[14:08:40] Building features: 40% (70337/175846)
[14:08:40] Building features: 45% (79129/175846)
[14:08:41] Building features: 50% (87921/175846)
[14:08:41] Building features: 55% (96713/175846)
[14:08:42] Building features: 60% (105505/175846)
[14:08:42] Building features: 65% (114297/175846)
[14:08:43] Building features: 70% (123089/175846)
[14:08:43] Building features: 75% (131881/175846)
[14:08:44] Building features: 80% (140673/175846)
[14:08:44] Building features: 85% (149465/175846)
[14:08:45] Building features: 90% (158257/175846)
[14:08:45] Building features: 95% (167049/175846)
[14:08:46] Building features: 100% (175841/175846)
[14:08:46] Computing Hurst exponent...
[14:08:52] Computing market regimes (GMM)...
[14:08:59] Factor 17: 175694 samples, 92 features
[14:09:01] Batch stats — Input:  mean=0.0527 std=0.2761 min=-4.7575 max=15.9549
[14:09:01] Batch stats — Target: mean=0.0026 std=0.0636 min=-0.4685 max=0.4134
[14:09:01] Batch stats — Cls:    pos_long=100/256 pos_short=86/256
[14:09:01] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:09:06] Epoch 1/100 | Train: 0.037174 (MSE=0.004011 BCE=0.6633) | Val: 0.044206 (MSE=0.010858 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044206 (ep 1)
[14:09:09] Epoch 2/100 | Train: 0.036202 (MSE=0.003118 BCE=0.6617) | Val: 0.042879 (MSE=0.009501 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042879 (ep 2)
[14:09:12] Epoch 3/100 | Train: 0.036120 (MSE=0.003057 BCE=0.6613) | Val: 0.042564 (MSE=0.009210 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042564 (ep 3)
[14:09:15] Epoch 4/100 | Train: 0.036086 (MSE=0.003023 BCE=0.6613) | Val: 0.042484 (MSE=0.009134 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042484 (ep 4)
[14:09:18] Epoch 5/100 | Train: 0.036048 (MSE=0.002995 BCE=0.6611) | Val: 0.042486 (MSE=0.009145 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042484 (ep 4)
[14:09:21] Epoch 6/100 | Train: 0.036018 (MSE=0.002974 BCE=0.6609) | Val: 0.042406 (MSE=0.009044 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042406 (ep 6)
[14:09:24] Epoch 7/100 | Train: 0.036007 (MSE=0.002960 BCE=0.6609) | Val: 0.042336 (MSE=0.008995 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042336 (ep 7)
[14:09:27] Epoch 8/100 | Train: 0.035986 (MSE=0.002946 BCE=0.6608) | Val: 0.042372 (MSE=0.009004 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042336 (ep 7)
[14:09:30] Epoch 9/100 | Train: 0.035967 (MSE=0.002935 BCE=0.6606) | Val: 0.042291 (MSE=0.008939 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:33] Epoch 10/100 | Train: 0.035958 (MSE=0.002925 BCE=0.6607) | Val: 0.042392 (MSE=0.009021 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:36] Epoch 11/100 | Train: 0.035944 (MSE=0.002916 BCE=0.6605) | Val: 0.042525 (MSE=0.009130 BCE=0.6679) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:39] Epoch 12/100 | Train: 0.035927 (MSE=0.002905 BCE=0.6604) | Val: 0.042439 (MSE=0.009069 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:42] Epoch 13/100 | Train: 0.035923 (MSE=0.002899 BCE=0.6605) | Val: 0.042550 (MSE=0.009173 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:45] Epoch 14/100 | Train: 0.035914 (MSE=0.002891 BCE=0.6604) | Val: 0.042637 (MSE=0.009231 BCE=0.6681) | LR: 1.00e-04 | Best: 0.042291 (ep 9)
[14:09:49] Epoch 15/100 | Train: 0.035904 (MSE=0.002887 BCE=0.6603) | Val: 0.043002 (MSE=0.009609 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042291 (ep 9)
[14:09:52] Epoch 16/100 | Train: 0.035881 (MSE=0.002874 BCE=0.6602) | Val: 0.042598 (MSE=0.009213 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042291 (ep 9)
[14:09:54] Epoch 17/100 | Train: 0.035877 (MSE=0.002874 BCE=0.6601) | Val: 0.042547 (MSE=0.009170 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042291 (ep 9)
[14:09:57] Epoch 18/100 | Train: 0.035870 (MSE=0.002869 BCE=0.6600) | Val: 0.042618 (MSE=0.009241 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042291 (ep 9)
[14:10:00] Epoch 19/100 | Train: 0.035869 (MSE=0.002867 BCE=0.6601) | Val: 0.042566 (MSE=0.009180 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042291 (ep 9)
[14:10:00] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:10:01] Factor 17 done — best val loss: 0.042291 at epoch 9
[14:10:01] 
============================================================
[14:10:01] STF Factor 18 of [14..20]
[14:10:01] ============================================================
[14:10:02] Building features: 0% (1/175846)
[14:10:02] Building features: 5% (8793/175846)
[14:10:03] Building features: 10% (17585/175846)
[14:10:03] Building features: 15% (26377/175846)
[14:10:04] Building features: 20% (35169/175846)
[14:10:04] Building features: 25% (43961/175846)
[14:10:05] Building features: 30% (52753/175846)
[14:10:05] Building features: 35% (61545/175846)
[14:10:06] Building features: 40% (70337/175846)
[14:10:07] Building features: 45% (79129/175846)
[14:10:07] Building features: 50% (87921/175846)
[14:10:08] Building features: 55% (96713/175846)
[14:10:08] Building features: 60% (105505/175846)
[14:10:09] Building features: 65% (114297/175846)
[14:10:09] Building features: 70% (123089/175846)
[14:10:10] Building features: 75% (131881/175846)
[14:10:11] Building features: 80% (140673/175846)
[14:10:11] Building features: 85% (149465/175846)
[14:10:12] Building features: 90% (158257/175846)
[14:10:12] Building features: 95% (167049/175846)
[14:10:13] Building features: 100% (175841/175846)
[14:10:13] Computing Hurst exponent...
[14:10:18] Computing market regimes (GMM)...
[14:10:26] Factor 18: 175694 samples, 92 features
[14:10:28] Batch stats — Input:  mean=0.0525 std=0.2689 min=-5.5995 max=6.8647
[14:10:28] Batch stats — Target: mean=0.0039 std=0.0624 min=-0.3713 max=0.3653
[14:10:28] Batch stats — Cls:    pos_long=112/256 pos_short=90/256
[14:10:28] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:10:33] Epoch 1/100 | Train: 0.037123 (MSE=0.003886 BCE=0.6647) | Val: 0.044037 (MSE=0.010671 BCE=0.6673) | LR: 1.00e-04 | Best: 0.044037 (ep 1)
[14:10:36] Epoch 2/100 | Train: 0.036182 (MSE=0.003104 BCE=0.6616) | Val: 0.042999 (MSE=0.009639 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042999 (ep 2)
[14:10:39] Epoch 3/100 | Train: 0.036124 (MSE=0.003055 BCE=0.6614) | Val: 0.042717 (MSE=0.009377 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042717 (ep 3)
[14:10:42] Epoch 4/100 | Train: 0.036083 (MSE=0.003025 BCE=0.6611) | Val: 0.042561 (MSE=0.009220 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042561 (ep 4)
[14:10:45] Epoch 5/100 | Train: 0.036053 (MSE=0.003001 BCE=0.6610) | Val: 0.042552 (MSE=0.009216 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042552 (ep 5)
[14:10:48] Epoch 6/100 | Train: 0.036024 (MSE=0.002977 BCE=0.6609) | Val: 0.042553 (MSE=0.009211 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042552 (ep 5)
[14:10:51] Epoch 7/100 | Train: 0.036002 (MSE=0.002958 BCE=0.6609) | Val: 0.042486 (MSE=0.009142 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042486 (ep 7)
[14:10:54] Epoch 8/100 | Train: 0.035989 (MSE=0.002946 BCE=0.6609) | Val: 0.042399 (MSE=0.009042 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042399 (ep 8)
[14:10:57] Epoch 9/100 | Train: 0.035975 (MSE=0.002937 BCE=0.6608) | Val: 0.042424 (MSE=0.009068 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042399 (ep 8)
[14:11:00] Epoch 10/100 | Train: 0.035960 (MSE=0.002928 BCE=0.6606) | Val: 0.042413 (MSE=0.009061 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042399 (ep 8)
[14:11:03] Epoch 11/100 | Train: 0.035954 (MSE=0.002920 BCE=0.6607) | Val: 0.042340 (MSE=0.008990 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042340 (ep 11)
[14:11:06] Epoch 12/100 | Train: 0.035941 (MSE=0.002911 BCE=0.6606) | Val: 0.042316 (MSE=0.008951 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:09] Epoch 13/100 | Train: 0.035930 (MSE=0.002904 BCE=0.6605) | Val: 0.042328 (MSE=0.008977 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:12] Epoch 14/100 | Train: 0.035915 (MSE=0.002896 BCE=0.6604) | Val: 0.042590 (MSE=0.009222 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:15] Epoch 15/100 | Train: 0.035914 (MSE=0.002891 BCE=0.6605) | Val: 0.042524 (MSE=0.009156 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:18] Epoch 16/100 | Train: 0.035900 (MSE=0.002886 BCE=0.6603) | Val: 0.042756 (MSE=0.009385 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:21] Epoch 17/100 | Train: 0.035898 (MSE=0.002884 BCE=0.6603) | Val: 0.042823 (MSE=0.009469 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042316 (ep 12)
[14:11:24] Epoch 18/100 | Train: 0.035892 (MSE=0.002877 BCE=0.6603) | Val: 0.042752 (MSE=0.009382 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042316 (ep 12)
[14:11:27] Epoch 19/100 | Train: 0.035869 (MSE=0.002867 BCE=0.6600) | Val: 0.042759 (MSE=0.009389 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042316 (ep 12)
[14:11:30] Epoch 20/100 | Train: 0.035860 (MSE=0.002864 BCE=0.6599) | Val: 0.042996 (MSE=0.009620 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042316 (ep 12)
[14:11:33] Epoch 21/100 | Train: 0.035855 (MSE=0.002858 BCE=0.6599) | Val: 0.042811 (MSE=0.009428 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042316 (ep 12)
[14:11:36] Epoch 22/100 | Train: 0.035851 (MSE=0.002857 BCE=0.6599) | Val: 0.042918 (MSE=0.009544 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042316 (ep 12)
[14:11:36] Early stopping at epoch 22 (no improvement for 10 epochs)
[14:11:37] Factor 18 done — best val loss: 0.042316 at epoch 12
[14:11:37] 
============================================================
[14:11:37] STF Factor 19 of [14..20]
[14:11:37] ============================================================
[14:11:37] Building features: 0% (1/175846)
[14:11:38] Building features: 5% (8793/175846)
[14:11:38] Building features: 10% (17585/175846)
[14:11:39] Building features: 15% (26377/175846)
[14:11:39] Building features: 20% (35169/175846)
[14:11:40] Building features: 25% (43961/175846)
[14:11:41] Building features: 30% (52753/175846)
[14:11:41] Building features: 35% (61545/175846)
[14:11:42] Building features: 40% (70337/175846)
[14:11:42] Building features: 45% (79129/175846)
[14:11:43] Building features: 50% (87921/175846)
[14:11:43] Building features: 55% (96713/175846)
[14:11:44] Building features: 60% (105505/175846)
[14:11:44] Building features: 65% (114297/175846)
[14:11:45] Building features: 70% (123089/175846)
[14:11:46] Building features: 75% (131881/175846)
[14:11:46] Building features: 80% (140673/175846)
[14:11:47] Building features: 85% (149465/175846)
[14:11:47] Building features: 90% (158257/175846)
[14:11:48] Building features: 95% (167049/175846)
[14:11:48] Building features: 100% (175841/175846)
[14:11:48] Computing Hurst exponent...
[14:11:54] Computing market regimes (GMM)...
[14:12:01] Factor 19: 175694 samples, 92 features
[14:12:03] Batch stats — Input:  mean=0.0512 std=0.2728 min=-6.3561 max=15.9549
[14:12:03] Batch stats — Target: mean=-0.0021 std=0.0680 min=-0.4720 max=0.3705
[14:12:03] Batch stats — Cls:    pos_long=102/256 pos_short=86/256
[14:12:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:12:08] Epoch 1/100 | Train: 0.037229 (MSE=0.003976 BCE=0.6651) | Val: 0.044216 (MSE=0.010859 BCE=0.6672) | LR: 1.00e-04 | Best: 0.044216 (ep 1)
[14:12:11] Epoch 2/100 | Train: 0.036190 (MSE=0.003104 BCE=0.6617) | Val: 0.043002 (MSE=0.009661 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043002 (ep 2)
[14:12:14] Epoch 3/100 | Train: 0.036122 (MSE=0.003050 BCE=0.6614) | Val: 0.042592 (MSE=0.009254 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042592 (ep 3)
[14:12:17] Epoch 4/100 | Train: 0.036090 (MSE=0.003024 BCE=0.6613) | Val: 0.042529 (MSE=0.009190 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042529 (ep 4)
[14:12:21] Epoch 5/100 | Train: 0.036062 (MSE=0.002999 BCE=0.6613) | Val: 0.042481 (MSE=0.009124 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042481 (ep 5)
[14:12:24] Epoch 6/100 | Train: 0.036033 (MSE=0.002977 BCE=0.6611) | Val: 0.042469 (MSE=0.009130 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042469 (ep 6)
[14:12:27] Epoch 7/100 | Train: 0.036017 (MSE=0.002966 BCE=0.6610) | Val: 0.042453 (MSE=0.009108 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042453 (ep 7)
[14:12:30] Epoch 8/100 | Train: 0.036001 (MSE=0.002951 BCE=0.6610) | Val: 0.042342 (MSE=0.009000 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042342 (ep 8)
[14:12:33] Epoch 9/100 | Train: 0.035982 (MSE=0.002937 BCE=0.6609) | Val: 0.042320 (MSE=0.008969 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042320 (ep 9)
[14:12:35] Epoch 10/100 | Train: 0.035969 (MSE=0.002927 BCE=0.6608) | Val: 0.042290 (MSE=0.008911 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:38] Epoch 11/100 | Train: 0.035959 (MSE=0.002918 BCE=0.6608) | Val: 0.042410 (MSE=0.009048 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:42] Epoch 12/100 | Train: 0.035943 (MSE=0.002910 BCE=0.6607) | Val: 0.042307 (MSE=0.008942 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:45] Epoch 13/100 | Train: 0.035934 (MSE=0.002905 BCE=0.6606) | Val: 0.042340 (MSE=0.008963 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:48] Epoch 14/100 | Train: 0.035920 (MSE=0.002897 BCE=0.6605) | Val: 0.042302 (MSE=0.008926 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:51] Epoch 15/100 | Train: 0.035912 (MSE=0.002892 BCE=0.6604) | Val: 0.042528 (MSE=0.009161 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042290 (ep 10)
[14:12:54] Epoch 16/100 | Train: 0.035900 (MSE=0.002887 BCE=0.6603) | Val: 0.042726 (MSE=0.009353 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042290 (ep 10)
[14:12:57] Epoch 17/100 | Train: 0.035885 (MSE=0.002876 BCE=0.6602) | Val: 0.042552 (MSE=0.009169 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042290 (ep 10)
[14:13:00] Epoch 18/100 | Train: 0.035877 (MSE=0.002870 BCE=0.6601) | Val: 0.042741 (MSE=0.009356 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042290 (ep 10)
[14:13:03] Epoch 19/100 | Train: 0.035872 (MSE=0.002869 BCE=0.6601) | Val: 0.042782 (MSE=0.009398 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042290 (ep 10)
[14:13:06] Epoch 20/100 | Train: 0.035868 (MSE=0.002866 BCE=0.6600) | Val: 0.042739 (MSE=0.009354 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042290 (ep 10)
[14:13:06] Early stopping at epoch 20 (no improvement for 10 epochs)
[14:13:07] Factor 19 done — best val loss: 0.042290 at epoch 10
[14:13:07] 
============================================================
[14:13:07] STF Factor 20 of [14..20]
[14:13:07] ============================================================
[14:13:07] Building features: 0% (1/175846)
[14:13:08] Building features: 5% (8793/175846)
[14:13:08] Building features: 10% (17585/175846)
[14:13:09] Building features: 15% (26377/175846)
[14:13:09] Building features: 20% (35169/175846)
[14:13:10] Building features: 25% (43961/175846)
[14:13:10] Building features: 30% (52753/175846)
[14:13:11] Building features: 35% (61545/175846)
[14:13:11] Building features: 40% (70337/175846)
[14:13:12] Building features: 45% (79129/175846)
[14:13:13] Building features: 50% (87921/175846)
[14:13:13] Building features: 55% (96713/175846)
[14:13:14] Building features: 60% (105505/175846)
[14:13:14] Building features: 65% (114297/175846)
[14:13:15] Building features: 70% (123089/175846)
[14:13:15] Building features: 75% (131881/175846)
[14:13:16] Building features: 80% (140673/175846)
[14:13:16] Building features: 85% (149465/175846)
[14:13:17] Building features: 90% (158257/175846)
[14:13:18] Building features: 95% (167049/175846)
[14:13:18] Building features: 100% (175841/175846)
[14:13:18] Computing Hurst exponent...
[14:13:24] Computing market regimes (GMM)...
[14:13:31] Factor 20: 175694 samples, 92 features
[14:13:33] Batch stats — Input:  mean=0.0498 std=0.2777 min=-5.4479 max=60.4783
[14:13:33] Batch stats — Target: mean=-0.0020 std=0.0712 min=-0.4720 max=0.4134
[14:13:33] Batch stats — Cls:    pos_long=103/256 pos_short=101/256
[14:13:33] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:13:38] Epoch 1/100 | Train: 0.037249 (MSE=0.003977 BCE=0.6655) | Val: 0.044495 (MSE=0.011142 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044495 (ep 1)
[14:13:41] Epoch 2/100 | Train: 0.036212 (MSE=0.003124 BCE=0.6618) | Val: 0.043079 (MSE=0.009725 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043079 (ep 2)
[14:13:44] Epoch 3/100 | Train: 0.036140 (MSE=0.003070 BCE=0.6614) | Val: 0.042642 (MSE=0.009317 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042642 (ep 3)
[14:13:47] Epoch 4/100 | Train: 0.036103 (MSE=0.003037 BCE=0.6613) | Val: 0.042621 (MSE=0.009255 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042621 (ep 4)
[14:13:50] Epoch 5/100 | Train: 0.036074 (MSE=0.003011 BCE=0.6613) | Val: 0.042476 (MSE=0.009140 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042476 (ep 5)
[14:13:53] Epoch 6/100 | Train: 0.036036 (MSE=0.002987 BCE=0.6610) | Val: 0.042466 (MSE=0.009130 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042466 (ep 6)
[14:13:56] Epoch 7/100 | Train: 0.036019 (MSE=0.002972 BCE=0.6609) | Val: 0.042455 (MSE=0.009078 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042455 (ep 7)
[14:13:59] Epoch 8/100 | Train: 0.035996 (MSE=0.002954 BCE=0.6608) | Val: 0.042433 (MSE=0.009055 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042433 (ep 8)
[14:14:02] Epoch 9/100 | Train: 0.035980 (MSE=0.002943 BCE=0.6607) | Val: 0.042418 (MSE=0.009054 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:06] Epoch 10/100 | Train: 0.035967 (MSE=0.002932 BCE=0.6607) | Val: 0.042479 (MSE=0.009129 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:09] Epoch 11/100 | Train: 0.035957 (MSE=0.002925 BCE=0.6606) | Val: 0.042513 (MSE=0.009140 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:12] Epoch 12/100 | Train: 0.035941 (MSE=0.002915 BCE=0.6605) | Val: 0.042503 (MSE=0.009133 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:15] Epoch 13/100 | Train: 0.035937 (MSE=0.002910 BCE=0.6605) | Val: 0.042551 (MSE=0.009159 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:18] Epoch 14/100 | Train: 0.035927 (MSE=0.002904 BCE=0.6604) | Val: 0.042424 (MSE=0.009046 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042418 (ep 9)
[14:14:20] Epoch 15/100 | Train: 0.035912 (MSE=0.002896 BCE=0.6603) | Val: 0.042516 (MSE=0.009146 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042418 (ep 9)
[14:14:24] Epoch 16/100 | Train: 0.035889 (MSE=0.002885 BCE=0.6601) | Val: 0.042544 (MSE=0.009157 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042418 (ep 9)
[14:14:27] Epoch 17/100 | Train: 0.035891 (MSE=0.002883 BCE=0.6602) | Val: 0.042556 (MSE=0.009166 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042418 (ep 9)
[14:14:30] Epoch 18/100 | Train: 0.035886 (MSE=0.002882 BCE=0.6601) | Val: 0.042573 (MSE=0.009184 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042418 (ep 9)
[14:14:33] Epoch 19/100 | Train: 0.035880 (MSE=0.002877 BCE=0.6601) | Val: 0.042631 (MSE=0.009232 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042418 (ep 9)
[14:14:33] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:14:34] Factor 20 done — best val loss: 0.042418 at epoch 9
[14:14:34] 
Best factor: 14 (val loss 0.042273)
[14:14:34] Training done. Best factor=14, val_loss=0.042273
[14:19:13] Building validation dataset...
[14:19:13] Building features: 0% (1/175846)
[14:19:14] Building features: 5% (8793/175846)
[14:19:14] Building features: 10% (17585/175846)
[14:19:15] Building features: 15% (26377/175846)
[14:19:16] Building features: 20% (35169/175846)
[14:19:16] Building features: 25% (43961/175846)
[14:19:17] Building features: 30% (52753/175846)
[14:19:17] Building features: 35% (61545/175846)
[14:19:18] Building features: 40% (70337/175846)
[14:19:18] Building features: 45% (79129/175846)
[14:19:19] Building features: 50% (87921/175846)
[14:19:19] Building features: 55% (96713/175846)
[14:19:20] Building features: 60% (105505/175846)
[14:19:21] Building features: 65% (114297/175846)
[14:19:21] Building features: 70% (123089/175846)
[14:19:22] Building features: 75% (131881/175846)
[14:19:22] Building features: 80% (140673/175846)
[14:19:23] Building features: 85% (149465/175846)
[14:19:23] Building features: 90% (158257/175846)
[14:19:24] Building features: 95% (167049/175846)
[14:19:24] Building features: 100% (175841/175846)
[14:19:24] Computing Hurst exponent...
[14:19:30] Computing market regimes (GMM)...
[14:19:37] Running backtest...
[14:19:38] Backtest complete: 16031 trades (15310L/721S), WR=48.4%, PF=0.94
[14:36:10] Training started.
[14:36:10] 
============================================================
[14:36:10] STF Factor 14 of [14..20]
[14:36:10] ============================================================
[14:36:10] Building features: 0% (1/175846)
[14:36:11] Building features: 5% (8793/175846)
[14:36:11] Building features: 10% (17585/175846)
[14:36:12] Building features: 15% (26377/175846)
[14:36:13] Building features: 20% (35169/175846)
[14:36:13] Building features: 25% (43961/175846)
[14:36:14] Building features: 30% (52753/175846)
[14:36:14] Building features: 35% (61545/175846)
[14:36:15] Building features: 40% (70337/175846)
[14:36:16] Building features: 45% (79129/175846)
[14:36:16] Building features: 50% (87921/175846)
[14:36:17] Building features: 55% (96713/175846)
[14:36:17] Building features: 60% (105505/175846)
[14:36:18] Building features: 65% (114297/175846)
[14:36:19] Building features: 70% (123089/175846)
[14:36:19] Building features: 75% (131881/175846)
[14:36:20] Building features: 80% (140673/175846)
[14:36:20] Building features: 85% (149465/175846)
[14:36:21] Building features: 90% (158257/175846)
[14:36:21] Building features: 95% (167049/175846)
[14:36:22] Building features: 100% (175841/175846)
[14:36:22] Computing Hurst exponent...
[14:36:28] Computing market regimes (GMM)...
[14:36:36] Factor 14: 175694 samples, 92 features
[14:36:38] Batch stats — Input:  mean=0.0517 std=0.2750 min=-4.8553 max=10.0671
[14:36:38] Batch stats — Target: mean=-0.0008 std=0.0748 min=-0.4720 max=0.4134
[14:36:38] Batch stats — Cls:    pos_long=106/256 pos_short=93/256
[14:36:38] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:36:43] Epoch 1/100 | Train: 0.036429 (MSE=0.003201 BCE=0.6646) | Val: 0.043335 (MSE=0.009951 BCE=0.6677) | LR: 1.00e-04 | Best: 0.043335 (ep 1)
[14:36:46] Epoch 2/100 | Train: 0.036098 (MSE=0.003022 BCE=0.6615) | Val: 0.042567 (MSE=0.009236 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042567 (ep 2)
[14:36:49] Epoch 3/100 | Train: 0.036033 (MSE=0.002976 BCE=0.6611) | Val: 0.042611 (MSE=0.009278 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042567 (ep 2)
[14:36:52] Epoch 4/100 | Train: 0.036006 (MSE=0.002952 BCE=0.6611) | Val: 0.042568 (MSE=0.009242 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042567 (ep 2)
[14:36:55] Epoch 5/100 | Train: 0.035974 (MSE=0.002931 BCE=0.6608) | Val: 0.042444 (MSE=0.009128 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042444 (ep 5)
[14:36:58] Epoch 6/100 | Train: 0.035958 (MSE=0.002922 BCE=0.6607) | Val: 0.042294 (MSE=0.008962 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042294 (ep 6)
[14:37:02] Epoch 7/100 | Train: 0.035946 (MSE=0.002909 BCE=0.6607) | Val: 0.042307 (MSE=0.008978 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042294 (ep 6)
[14:37:05] Epoch 8/100 | Train: 0.035935 (MSE=0.002900 BCE=0.6607) | Val: 0.042252 (MSE=0.008938 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042252 (ep 8)
[14:37:08] Epoch 9/100 | Train: 0.035928 (MSE=0.002894 BCE=0.6607) | Val: 0.042279 (MSE=0.008934 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042252 (ep 8)
[14:37:11] Epoch 10/100 | Train: 0.035921 (MSE=0.002887 BCE=0.6607) | Val: 0.042248 (MSE=0.008933 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042248 (ep 10)
[14:37:14] Epoch 11/100 | Train: 0.035909 (MSE=0.002881 BCE=0.6606) | Val: 0.042244 (MSE=0.008921 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[14:37:17] Epoch 12/100 | Train: 0.035904 (MSE=0.002876 BCE=0.6606) | Val: 0.042213 (MSE=0.008891 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:20] Epoch 13/100 | Train: 0.035896 (MSE=0.002870 BCE=0.6605) | Val: 0.042266 (MSE=0.008928 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:23] Epoch 14/100 | Train: 0.035893 (MSE=0.002869 BCE=0.6605) | Val: 0.042270 (MSE=0.008942 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:27] Epoch 15/100 | Train: 0.035881 (MSE=0.002861 BCE=0.6604) | Val: 0.042363 (MSE=0.009026 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:30] Epoch 16/100 | Train: 0.035872 (MSE=0.002858 BCE=0.6603) | Val: 0.042592 (MSE=0.009236 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:33] Epoch 17/100 | Train: 0.035867 (MSE=0.002851 BCE=0.6603) | Val: 0.042463 (MSE=0.009118 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042213 (ep 12)
[14:37:36] Epoch 18/100 | Train: 0.035859 (MSE=0.002849 BCE=0.6602) | Val: 0.042533 (MSE=0.009172 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042213 (ep 12)
[14:37:39] Epoch 19/100 | Train: 0.035842 (MSE=0.002837 BCE=0.6601) | Val: 0.042638 (MSE=0.009279 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042213 (ep 12)
[14:37:43] Epoch 20/100 | Train: 0.035840 (MSE=0.002835 BCE=0.6601) | Val: 0.042679 (MSE=0.009317 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042213 (ep 12)
[14:37:46] Epoch 21/100 | Train: 0.035831 (MSE=0.002833 BCE=0.6600) | Val: 0.042737 (MSE=0.009356 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042213 (ep 12)
[14:37:49] Epoch 22/100 | Train: 0.035829 (MSE=0.002829 BCE=0.6600) | Val: 0.042811 (MSE=0.009437 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042213 (ep 12)
[14:37:49] Early stopping at epoch 22 (no improvement for 10 epochs)
[14:37:49] Factor 14 done — best val loss: 0.042213 at epoch 12
[14:37:49] 
============================================================
[14:37:49] STF Factor 15 of [14..20]
[14:37:49] ============================================================
[14:37:50] Building features: 0% (1/175846)
[14:37:50] Building features: 5% (8793/175846)
[14:37:51] Building features: 10% (17585/175846)
[14:37:51] Building features: 15% (26377/175846)
[14:37:52] Building features: 20% (35169/175846)
[14:37:53] Building features: 25% (43961/175846)
[14:37:53] Building features: 30% (52753/175846)
[14:37:54] Building features: 35% (61545/175846)
[14:37:54] Building features: 40% (70337/175846)
[14:37:55] Building features: 45% (79129/175846)
[14:37:55] Building features: 50% (87921/175846)
[14:37:56] Building features: 55% (96713/175846)
[14:37:57] Building features: 60% (105505/175846)
[14:37:57] Building features: 65% (114297/175846)
[14:37:58] Building features: 70% (123089/175846)
[14:37:58] Building features: 75% (131881/175846)
[14:37:59] Building features: 80% (140673/175846)
[14:38:00] Building features: 85% (149465/175846)
[14:38:00] Building features: 90% (158257/175846)
[14:38:01] Building features: 95% (167049/175846)
[14:38:01] Building features: 100% (175841/175846)
[14:38:01] Computing Hurst exponent...
[14:38:07] Computing market regimes (GMM)...
[14:38:15] Factor 15: 175694 samples, 92 features
[14:38:17] Batch stats — Input:  mean=0.0525 std=0.2704 min=-4.7237 max=15.9549
[14:38:17] Batch stats — Target: mean=-0.0012 std=0.0709 min=-0.4720 max=0.4134
[14:38:17] Batch stats — Cls:    pos_long=92/256 pos_short=79/256
[14:38:17] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:38:22] Epoch 1/100 | Train: 0.036476 (MSE=0.003238 BCE=0.6648) | Val: 0.043784 (MSE=0.010414 BCE=0.6674) | LR: 1.00e-04 | Best: 0.043784 (ep 1)
[14:38:25] Epoch 2/100 | Train: 0.036104 (MSE=0.003030 BCE=0.6615) | Val: 0.042524 (MSE=0.009182 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042524 (ep 2)
[14:38:28] Epoch 3/100 | Train: 0.036034 (MSE=0.002976 BCE=0.6612) | Val: 0.042581 (MSE=0.009254 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042524 (ep 2)
[14:38:31] Epoch 4/100 | Train: 0.036003 (MSE=0.002948 BCE=0.6611) | Val: 0.042530 (MSE=0.009197 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042524 (ep 2)
[14:38:34] Epoch 5/100 | Train: 0.035979 (MSE=0.002931 BCE=0.6609) | Val: 0.042485 (MSE=0.009146 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042485 (ep 5)
[14:38:37] Epoch 6/100 | Train: 0.035959 (MSE=0.002917 BCE=0.6608) | Val: 0.042370 (MSE=0.009047 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042370 (ep 6)
[14:38:41] Epoch 7/100 | Train: 0.035949 (MSE=0.002908 BCE=0.6608) | Val: 0.042514 (MSE=0.009146 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042370 (ep 6)
[14:38:44] Epoch 8/100 | Train: 0.035938 (MSE=0.002901 BCE=0.6607) | Val: 0.042295 (MSE=0.008959 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042295 (ep 8)
[14:38:47] Epoch 9/100 | Train: 0.035927 (MSE=0.002894 BCE=0.6607) | Val: 0.042222 (MSE=0.008887 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:38:50] Epoch 10/100 | Train: 0.035920 (MSE=0.002887 BCE=0.6607) | Val: 0.042246 (MSE=0.008915 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:38:53] Epoch 11/100 | Train: 0.035909 (MSE=0.002881 BCE=0.6606) | Val: 0.042269 (MSE=0.008948 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:38:56] Epoch 12/100 | Train: 0.035902 (MSE=0.002875 BCE=0.6605) | Val: 0.042282 (MSE=0.008943 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:38:59] Epoch 13/100 | Train: 0.035893 (MSE=0.002871 BCE=0.6604) | Val: 0.042305 (MSE=0.008970 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:39:02] Epoch 14/100 | Train: 0.035892 (MSE=0.002864 BCE=0.6605) | Val: 0.042225 (MSE=0.008902 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042222 (ep 9)
[14:39:05] Epoch 15/100 | Train: 0.035887 (MSE=0.002864 BCE=0.6605) | Val: 0.042241 (MSE=0.008913 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042222 (ep 9)
[14:39:09] Epoch 16/100 | Train: 0.035864 (MSE=0.002848 BCE=0.6603) | Val: 0.042305 (MSE=0.008974 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042222 (ep 9)
[14:39:12] Epoch 17/100 | Train: 0.035860 (MSE=0.002847 BCE=0.6603) | Val: 0.042317 (MSE=0.008979 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042222 (ep 9)
[14:39:15] Epoch 18/100 | Train: 0.035854 (MSE=0.002844 BCE=0.6602) | Val: 0.042371 (MSE=0.009040 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042222 (ep 9)
[14:39:18] Epoch 19/100 | Train: 0.035854 (MSE=0.002842 BCE=0.6602) | Val: 0.042272 (MSE=0.008937 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042222 (ep 9)
[14:39:18] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:39:19] Factor 15 done — best val loss: 0.042222 at epoch 9
[14:39:19] 
============================================================
[14:39:19] STF Factor 16 of [14..20]
[14:39:19] ============================================================
[14:39:19] Building features: 0% (1/175846)
[14:39:20] Building features: 5% (8793/175846)
[14:39:20] Building features: 10% (17585/175846)
[14:39:21] Building features: 15% (26377/175846)
[14:39:22] Building features: 20% (35169/175846)
[14:39:22] Building features: 25% (43961/175846)
[14:39:23] Building features: 30% (52753/175846)
[14:39:23] Building features: 35% (61545/175846)
[14:39:24] Building features: 40% (70337/175846)
[14:39:25] Building features: 45% (79129/175846)
[14:39:25] Building features: 50% (87921/175846)
[14:39:26] Building features: 55% (96713/175846)
[14:39:26] Building features: 60% (105505/175846)
[14:39:27] Building features: 65% (114297/175846)
[14:39:28] Building features: 70% (123089/175846)
[14:39:28] Building features: 75% (131881/175846)
[14:39:29] Building features: 80% (140673/175846)
[14:39:29] Building features: 85% (149465/175846)
[14:39:30] Building features: 90% (158257/175846)
[14:39:31] Building features: 95% (167049/175846)
[14:39:31] Building features: 100% (175841/175846)
[14:39:31] Computing Hurst exponent...
[14:39:37] Computing market regimes (GMM)...
[14:39:45] Factor 16: 175694 samples, 92 features
[14:39:46] Batch stats — Input:  mean=0.0530 std=0.2686 min=-4.2128 max=12.6954
[14:39:46] Batch stats — Target: mean=-0.0024 std=0.0701 min=-0.4720 max=0.4134
[14:39:46] Batch stats — Cls:    pos_long=98/256 pos_short=92/256
[14:39:46] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:39:52] Epoch 1/100 | Train: 0.036417 (MSE=0.003202 BCE=0.6643) | Val: 0.043426 (MSE=0.010047 BCE=0.6676) | LR: 1.00e-04 | Best: 0.043426 (ep 1)
[14:39:55] Epoch 2/100 | Train: 0.036095 (MSE=0.003019 BCE=0.6615) | Val: 0.042634 (MSE=0.009285 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042634 (ep 2)
[14:39:58] Epoch 3/100 | Train: 0.036031 (MSE=0.002976 BCE=0.6611) | Val: 0.042590 (MSE=0.009264 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042590 (ep 3)
[14:40:01] Epoch 4/100 | Train: 0.035998 (MSE=0.002947 BCE=0.6610) | Val: 0.042568 (MSE=0.009240 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042568 (ep 4)
[14:40:04] Epoch 5/100 | Train: 0.035976 (MSE=0.002931 BCE=0.6609) | Val: 0.042411 (MSE=0.009091 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042411 (ep 5)
[14:40:07] Epoch 6/100 | Train: 0.035963 (MSE=0.002918 BCE=0.6609) | Val: 0.042367 (MSE=0.009044 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042367 (ep 6)
[14:40:10] Epoch 7/100 | Train: 0.035947 (MSE=0.002908 BCE=0.6608) | Val: 0.042315 (MSE=0.009000 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042315 (ep 7)
[14:40:13] Epoch 8/100 | Train: 0.035935 (MSE=0.002899 BCE=0.6607) | Val: 0.042303 (MSE=0.008980 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042303 (ep 8)
[14:40:16] Epoch 9/100 | Train: 0.035924 (MSE=0.002892 BCE=0.6606) | Val: 0.042263 (MSE=0.008941 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:19] Epoch 10/100 | Train: 0.035915 (MSE=0.002885 BCE=0.6606) | Val: 0.042303 (MSE=0.008978 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:23] Epoch 11/100 | Train: 0.035908 (MSE=0.002879 BCE=0.6606) | Val: 0.042349 (MSE=0.009008 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:26] Epoch 12/100 | Train: 0.035897 (MSE=0.002875 BCE=0.6604) | Val: 0.042362 (MSE=0.009022 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:29] Epoch 13/100 | Train: 0.035890 (MSE=0.002870 BCE=0.6604) | Val: 0.042401 (MSE=0.009058 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:32] Epoch 14/100 | Train: 0.035882 (MSE=0.002864 BCE=0.6604) | Val: 0.042450 (MSE=0.009092 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042263 (ep 9)
[14:40:35] Epoch 15/100 | Train: 0.035877 (MSE=0.002860 BCE=0.6603) | Val: 0.042365 (MSE=0.009010 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042263 (ep 9)
[14:40:38] Epoch 16/100 | Train: 0.035860 (MSE=0.002851 BCE=0.6602) | Val: 0.042408 (MSE=0.009035 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042263 (ep 9)
[14:40:41] Epoch 17/100 | Train: 0.035848 (MSE=0.002846 BCE=0.6600) | Val: 0.042444 (MSE=0.009061 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042263 (ep 9)
[14:40:44] Epoch 18/100 | Train: 0.035846 (MSE=0.002844 BCE=0.6600) | Val: 0.042518 (MSE=0.009145 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042263 (ep 9)
[14:40:47] Epoch 19/100 | Train: 0.035845 (MSE=0.002842 BCE=0.6601) | Val: 0.042511 (MSE=0.009116 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042263 (ep 9)
[14:40:47] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:40:48] Factor 16 done — best val loss: 0.042263 at epoch 9
[14:40:48] 
============================================================
[14:40:48] STF Factor 17 of [14..20]
[14:40:48] ============================================================
[14:40:48] Building features: 0% (1/175846)
[14:40:49] Building features: 5% (8793/175846)
[14:40:49] Building features: 10% (17585/175846)
[14:40:50] Building features: 15% (26377/175846)
[14:40:51] Building features: 20% (35169/175846)
[14:40:51] Building features: 25% (43961/175846)
[14:40:52] Building features: 30% (52753/175846)
[14:40:52] Building features: 35% (61545/175846)
[14:40:53] Building features: 40% (70337/175846)
[14:40:54] Building features: 45% (79129/175846)
[14:40:54] Building features: 50% (87921/175846)
[14:40:55] Building features: 55% (96713/175846)
[14:40:55] Building features: 60% (105505/175846)
[14:40:56] Building features: 65% (114297/175846)
[14:40:57] Building features: 70% (123089/175846)
[14:40:57] Building features: 75% (131881/175846)
[14:40:58] Building features: 80% (140673/175846)
[14:40:58] Building features: 85% (149465/175846)
[14:40:59] Building features: 90% (158257/175846)
[14:40:59] Building features: 95% (167049/175846)
[14:41:00] Building features: 100% (175841/175846)
[14:41:00] Computing Hurst exponent...
[14:41:06] Computing market regimes (GMM)...
[14:41:14] Factor 17: 175694 samples, 92 features
[14:41:16] Batch stats — Input:  mean=0.0526 std=0.2736 min=-4.2087 max=12.6954
[14:41:16] Batch stats — Target: mean=-0.0018 std=0.0613 min=-0.4720 max=0.3203
[14:41:16] Batch stats — Cls:    pos_long=104/256 pos_short=89/256
[14:41:16] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:41:21] Epoch 1/100 | Train: 0.036432 (MSE=0.003217 BCE=0.6643) | Val: 0.043294 (MSE=0.009935 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043294 (ep 1)
[14:41:24] Epoch 2/100 | Train: 0.036091 (MSE=0.003018 BCE=0.6615) | Val: 0.042541 (MSE=0.009184 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042541 (ep 2)
[14:41:27] Epoch 3/100 | Train: 0.036033 (MSE=0.002972 BCE=0.6612) | Val: 0.042566 (MSE=0.009230 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042541 (ep 2)
[14:41:30] Epoch 4/100 | Train: 0.035996 (MSE=0.002944 BCE=0.6610) | Val: 0.042565 (MSE=0.009216 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042541 (ep 2)
[14:41:33] Epoch 5/100 | Train: 0.035978 (MSE=0.002927 BCE=0.6610) | Val: 0.042405 (MSE=0.009072 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042405 (ep 5)
[14:41:36] Epoch 6/100 | Train: 0.035955 (MSE=0.002915 BCE=0.6608) | Val: 0.042258 (MSE=0.008930 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042258 (ep 6)
[14:41:39] Epoch 7/100 | Train: 0.035951 (MSE=0.002908 BCE=0.6609) | Val: 0.042266 (MSE=0.008915 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042258 (ep 6)
[14:41:42] Epoch 8/100 | Train: 0.035939 (MSE=0.002899 BCE=0.6608) | Val: 0.042238 (MSE=0.008894 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042238 (ep 8)
[14:41:45] Epoch 9/100 | Train: 0.035930 (MSE=0.002893 BCE=0.6607) | Val: 0.042156 (MSE=0.008825 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:41:48] Epoch 10/100 | Train: 0.035919 (MSE=0.002885 BCE=0.6607) | Val: 0.042176 (MSE=0.008841 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:41:51] Epoch 11/100 | Train: 0.035910 (MSE=0.002883 BCE=0.6605) | Val: 0.042159 (MSE=0.008828 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:41:54] Epoch 12/100 | Train: 0.035903 (MSE=0.002876 BCE=0.6605) | Val: 0.042182 (MSE=0.008850 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:41:57] Epoch 13/100 | Train: 0.035900 (MSE=0.002871 BCE=0.6606) | Val: 0.042194 (MSE=0.008854 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:42:00] Epoch 14/100 | Train: 0.035887 (MSE=0.002864 BCE=0.6605) | Val: 0.042268 (MSE=0.008926 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042156 (ep 9)
[14:42:03] Epoch 15/100 | Train: 0.035881 (MSE=0.002861 BCE=0.6604) | Val: 0.042205 (MSE=0.008880 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042156 (ep 9)
[14:42:07] Epoch 16/100 | Train: 0.035864 (MSE=0.002851 BCE=0.6603) | Val: 0.042299 (MSE=0.008969 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042156 (ep 9)
[14:42:10] Epoch 17/100 | Train: 0.035859 (MSE=0.002847 BCE=0.6602) | Val: 0.042256 (MSE=0.008924 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042156 (ep 9)
[14:42:13] Epoch 18/100 | Train: 0.035859 (MSE=0.002846 BCE=0.6603) | Val: 0.042298 (MSE=0.008960 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042156 (ep 9)
[14:42:16] Epoch 19/100 | Train: 0.035856 (MSE=0.002844 BCE=0.6602) | Val: 0.042308 (MSE=0.008971 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042156 (ep 9)
[14:42:16] Early stopping at epoch 19 (no improvement for 10 epochs)
[14:42:17] Factor 17 done — best val loss: 0.042156 at epoch 9
[14:42:17] 
============================================================
[14:42:17] STF Factor 18 of [14..20]
[14:42:17] ============================================================
[14:42:17] Building features: 0% (1/175846)
[14:42:17] Building features: 5% (8793/175846)
[14:42:18] Building features: 10% (17585/175846)
[14:42:19] Building features: 15% (26377/175846)
[14:42:19] Building features: 20% (35169/175846)
[14:42:20] Building features: 25% (43961/175846)
[14:42:20] Building features: 30% (52753/175846)
[14:42:21] Building features: 35% (61545/175846)
[14:42:22] Building features: 40% (70337/175846)
[14:42:22] Building features: 45% (79129/175846)
[14:42:23] Building features: 50% (87921/175846)
[14:42:23] Building features: 55% (96713/175846)
[14:42:24] Building features: 60% (105505/175846)
[14:42:25] Building features: 65% (114297/175846)
[14:42:25] Building features: 70% (123089/175846)
[14:42:26] Building features: 75% (131881/175846)
[14:42:26] Building features: 80% (140673/175846)
[14:42:27] Building features: 85% (149465/175846)
[14:42:27] Building features: 90% (158257/175846)
[14:42:28] Building features: 95% (167049/175846)
[14:42:29] Building features: 100% (175841/175846)
[14:42:29] Computing Hurst exponent...
[14:42:34] Computing market regimes (GMM)...
[14:42:42] Factor 18: 175694 samples, 92 features
[14:42:44] Batch stats — Input:  mean=0.0510 std=0.2671 min=-4.8553 max=6.4480
[14:42:44] Batch stats — Target: mean=-0.0007 std=0.0679 min=-0.4720 max=0.4134
[14:42:44] Batch stats — Cls:    pos_long=105/256 pos_short=88/256
[14:42:44] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:42:50] Epoch 1/100 | Train: 0.036503 (MSE=0.003249 BCE=0.6651) | Val: 0.043748 (MSE=0.010376 BCE=0.6674) | LR: 1.00e-04 | Best: 0.043748 (ep 1)
[14:42:53] Epoch 2/100 | Train: 0.036103 (MSE=0.003031 BCE=0.6614) | Val: 0.042555 (MSE=0.009211 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042555 (ep 2)
[14:42:56] Epoch 3/100 | Train: 0.036043 (MSE=0.002980 BCE=0.6613) | Val: 0.042561 (MSE=0.009225 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042555 (ep 2)
[14:42:59] Epoch 4/100 | Train: 0.036004 (MSE=0.002951 BCE=0.6611) | Val: 0.042512 (MSE=0.009173 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042512 (ep 4)
[14:43:02] Epoch 5/100 | Train: 0.035978 (MSE=0.002927 BCE=0.6610) | Val: 0.042377 (MSE=0.009011 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042377 (ep 5)
[14:43:05] Epoch 6/100 | Train: 0.035966 (MSE=0.002918 BCE=0.6610) | Val: 0.042362 (MSE=0.009012 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042362 (ep 6)
[14:43:08] Epoch 7/100 | Train: 0.035949 (MSE=0.002907 BCE=0.6608) | Val: 0.042335 (MSE=0.008982 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042335 (ep 7)
[14:43:11] Epoch 8/100 | Train: 0.035937 (MSE=0.002900 BCE=0.6607) | Val: 0.042327 (MSE=0.008986 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:14] Epoch 9/100 | Train: 0.035931 (MSE=0.002893 BCE=0.6608) | Val: 0.042411 (MSE=0.009069 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:17] Epoch 10/100 | Train: 0.035918 (MSE=0.002886 BCE=0.6606) | Val: 0.042391 (MSE=0.009039 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:21] Epoch 11/100 | Train: 0.035908 (MSE=0.002879 BCE=0.6606) | Val: 0.042366 (MSE=0.009006 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:24] Epoch 12/100 | Train: 0.035907 (MSE=0.002873 BCE=0.6607) | Val: 0.042524 (MSE=0.009162 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:27] Epoch 13/100 | Train: 0.035892 (MSE=0.002868 BCE=0.6605) | Val: 0.042638 (MSE=0.009254 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042327 (ep 8)
[14:43:30] Epoch 14/100 | Train: 0.035889 (MSE=0.002864 BCE=0.6605) | Val: 0.042619 (MSE=0.009268 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042327 (ep 8)
[14:43:33] Epoch 15/100 | Train: 0.035871 (MSE=0.002852 BCE=0.6604) | Val: 0.042570 (MSE=0.009221 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042327 (ep 8)
[14:43:36] Epoch 16/100 | Train: 0.035864 (MSE=0.002849 BCE=0.6603) | Val: 0.042590 (MSE=0.009233 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042327 (ep 8)
[14:43:39] Epoch 17/100 | Train: 0.035856 (MSE=0.002846 BCE=0.6602) | Val: 0.042586 (MSE=0.009229 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042327 (ep 8)
[14:43:42] Epoch 18/100 | Train: 0.035863 (MSE=0.002846 BCE=0.6603) | Val: 0.042737 (MSE=0.009375 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042327 (ep 8)
[14:43:42] Early stopping at epoch 18 (no improvement for 10 epochs)
[14:43:43] Factor 18 done — best val loss: 0.042327 at epoch 8
[14:43:43] 
============================================================
[14:43:43] STF Factor 19 of [14..20]
[14:43:43] ============================================================
[14:43:43] Building features: 0% (1/175846)
[14:43:44] Building features: 5% (8793/175846)
[14:43:44] Building features: 10% (17585/175846)
[14:43:45] Building features: 15% (26377/175846)
[14:43:45] Building features: 20% (35169/175846)
[14:43:46] Building features: 25% (43961/175846)
[14:43:47] Building features: 30% (52753/175846)
[14:43:47] Building features: 35% (61545/175846)
[14:43:48] Building features: 40% (70337/175846)
[14:43:48] Building features: 45% (79129/175846)
[14:43:49] Building features: 50% (87921/175846)
[14:43:50] Building features: 55% (96713/175846)
[14:43:50] Building features: 60% (105505/175846)
[14:43:51] Building features: 65% (114297/175846)
[14:43:51] Building features: 70% (123089/175846)
[14:43:52] Building features: 75% (131881/175846)
[14:43:52] Building features: 80% (140673/175846)
[14:43:53] Building features: 85% (149465/175846)
[14:43:54] Building features: 90% (158257/175846)
[14:43:54] Building features: 95% (167049/175846)
[14:43:55] Building features: 100% (175841/175846)
[14:43:55] Computing Hurst exponent...
[14:44:01] Computing market regimes (GMM)...
[14:44:08] Factor 19: 175694 samples, 92 features
[14:44:10] Batch stats — Input:  mean=0.0531 std=0.2691 min=-4.3019 max=7.5420
[14:44:10] Batch stats — Target: mean=0.0057 std=0.0617 min=-0.3349 max=0.4134
[14:44:10] Batch stats — Cls:    pos_long=108/256 pos_short=77/256
[14:44:10] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:44:15] Epoch 1/100 | Train: 0.036420 (MSE=0.003213 BCE=0.6641) | Val: 0.043366 (MSE=0.009971 BCE=0.6679) | LR: 1.00e-04 | Best: 0.043366 (ep 1)
[14:44:18] Epoch 2/100 | Train: 0.036101 (MSE=0.003026 BCE=0.6615) | Val: 0.042585 (MSE=0.009247 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042585 (ep 2)
[14:44:22] Epoch 3/100 | Train: 0.036037 (MSE=0.002977 BCE=0.6612) | Val: 0.042748 (MSE=0.009425 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042585 (ep 2)
[14:44:25] Epoch 4/100 | Train: 0.035999 (MSE=0.002947 BCE=0.6610) | Val: 0.042616 (MSE=0.009290 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042585 (ep 2)
[14:44:28] Epoch 5/100 | Train: 0.035974 (MSE=0.002929 BCE=0.6609) | Val: 0.042400 (MSE=0.009059 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042400 (ep 5)
[14:44:31] Epoch 6/100 | Train: 0.035954 (MSE=0.002914 BCE=0.6608) | Val: 0.042334 (MSE=0.008998 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042334 (ep 6)
[14:44:34] Epoch 7/100 | Train: 0.035944 (MSE=0.002904 BCE=0.6608) | Val: 0.042195 (MSE=0.008876 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042195 (ep 7)
[14:44:37] Epoch 8/100 | Train: 0.035936 (MSE=0.002896 BCE=0.6608) | Val: 0.042198 (MSE=0.008865 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042195 (ep 7)
[14:44:40] Epoch 9/100 | Train: 0.035921 (MSE=0.002889 BCE=0.6607) | Val: 0.042164 (MSE=0.008835 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042164 (ep 9)
[14:44:43] Epoch 10/100 | Train: 0.035916 (MSE=0.002886 BCE=0.6606) | Val: 0.042122 (MSE=0.008810 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:44:46] Epoch 11/100 | Train: 0.035903 (MSE=0.002875 BCE=0.6606) | Val: 0.042158 (MSE=0.008835 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:44:49] Epoch 12/100 | Train: 0.035897 (MSE=0.002873 BCE=0.6605) | Val: 0.042176 (MSE=0.008825 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:44:52] Epoch 13/100 | Train: 0.035891 (MSE=0.002867 BCE=0.6605) | Val: 0.042165 (MSE=0.008822 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:44:55] Epoch 14/100 | Train: 0.035884 (MSE=0.002861 BCE=0.6605) | Val: 0.042144 (MSE=0.008814 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:44:58] Epoch 15/100 | Train: 0.035878 (MSE=0.002858 BCE=0.6604) | Val: 0.042284 (MSE=0.008947 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042122 (ep 10)
[14:45:02] Epoch 16/100 | Train: 0.035867 (MSE=0.002852 BCE=0.6603) | Val: 0.042203 (MSE=0.008860 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042122 (ep 10)
[14:45:05] Epoch 17/100 | Train: 0.035848 (MSE=0.002841 BCE=0.6601) | Val: 0.042259 (MSE=0.008919 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042122 (ep 10)
[14:45:08] Epoch 18/100 | Train: 0.035848 (MSE=0.002836 BCE=0.6602) | Val: 0.042248 (MSE=0.008906 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042122 (ep 10)
[14:45:11] Epoch 19/100 | Train: 0.035842 (MSE=0.002834 BCE=0.6602) | Val: 0.042285 (MSE=0.008941 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042122 (ep 10)
[14:45:14] Epoch 20/100 | Train: 0.035838 (MSE=0.002834 BCE=0.6601) | Val: 0.042337 (MSE=0.008986 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042122 (ep 10)
[14:45:14] Early stopping at epoch 20 (no improvement for 10 epochs)
[14:45:15] Factor 19 done — best val loss: 0.042122 at epoch 10
[14:45:15] 
============================================================
[14:45:15] STF Factor 20 of [14..20]
[14:45:15] ============================================================
[14:45:15] Building features: 0% (1/175846)
[14:45:15] Building features: 5% (8793/175846)
[14:45:16] Building features: 10% (17585/175846)
[14:45:17] Building features: 15% (26377/175846)
[14:45:17] Building features: 20% (35169/175846)
[14:45:18] Building features: 25% (43961/175846)
[14:45:19] Building features: 30% (52753/175846)
[14:45:19] Building features: 35% (61545/175846)
[14:45:20] Building features: 40% (70337/175846)
[14:45:20] Building features: 45% (79129/175846)
[14:45:21] Building features: 50% (87921/175846)
[14:45:22] Building features: 55% (96713/175846)
[14:45:22] Building features: 60% (105505/175846)
[14:45:23] Building features: 65% (114297/175846)
[14:45:23] Building features: 70% (123089/175846)
[14:45:24] Building features: 75% (131881/175846)
[14:45:25] Building features: 80% (140673/175846)
[14:45:25] Building features: 85% (149465/175846)
[14:45:26] Building features: 90% (158257/175846)
[14:45:26] Building features: 95% (167049/175846)
[14:45:27] Building features: 100% (175841/175846)
[14:45:27] Computing Hurst exponent...
[14:45:32] Computing market regimes (GMM)...
[14:45:40] Factor 20: 175694 samples, 92 features
[14:45:42] Batch stats — Input:  mean=0.0530 std=0.2705 min=-4.2773 max=10.2202
[14:45:42] Batch stats — Target: mean=-0.0001 std=0.0686 min=-0.4720 max=0.3779
[14:45:42] Batch stats — Cls:    pos_long=97/256 pos_short=94/256
[14:45:42] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[14:45:47] Epoch 1/100 | Train: 0.036463 (MSE=0.003257 BCE=0.6641) | Val: 0.043640 (MSE=0.010255 BCE=0.6677) | LR: 1.00e-04 | Best: 0.043640 (ep 1)
[14:45:51] Epoch 2/100 | Train: 0.036111 (MSE=0.003036 BCE=0.6615) | Val: 0.042585 (MSE=0.009227 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042585 (ep 2)
[14:45:54] Epoch 3/100 | Train: 0.036034 (MSE=0.002977 BCE=0.6611) | Val: 0.042662 (MSE=0.009334 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042585 (ep 2)
[14:45:57] Epoch 4/100 | Train: 0.035999 (MSE=0.002951 BCE=0.6610) | Val: 0.042526 (MSE=0.009205 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042526 (ep 4)
[14:46:00] Epoch 5/100 | Train: 0.035978 (MSE=0.002931 BCE=0.6609) | Val: 0.042405 (MSE=0.009077 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042405 (ep 5)
[14:46:03] Epoch 6/100 | Train: 0.035963 (MSE=0.002918 BCE=0.6609) | Val: 0.042563 (MSE=0.009208 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042405 (ep 5)
[14:46:06] Epoch 7/100 | Train: 0.035953 (MSE=0.002910 BCE=0.6609) | Val: 0.042380 (MSE=0.009042 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042380 (ep 7)
[14:46:09] Epoch 8/100 | Train: 0.035939 (MSE=0.002902 BCE=0.6608) | Val: 0.042361 (MSE=0.009031 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042361 (ep 8)
[14:46:12] Epoch 9/100 | Train: 0.035928 (MSE=0.002894 BCE=0.6607) | Val: 0.042356 (MSE=0.009004 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042356 (ep 9)
[14:46:15] Epoch 10/100 | Train: 0.035918 (MSE=0.002885 BCE=0.6607) | Val: 0.042366 (MSE=0.009024 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042356 (ep 9)
[14:46:18] Epoch 11/100 | Train: 0.035913 (MSE=0.002881 BCE=0.6606) | Val: 0.042276 (MSE=0.008927 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:21] Epoch 12/100 | Train: 0.035899 (MSE=0.002871 BCE=0.6606) | Val: 0.042380 (MSE=0.009026 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:24] Epoch 13/100 | Train: 0.035893 (MSE=0.002866 BCE=0.6605) | Val: 0.042387 (MSE=0.009032 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:27] Epoch 14/100 | Train: 0.035888 (MSE=0.002863 BCE=0.6605) | Val: 0.042537 (MSE=0.009162 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:31] Epoch 15/100 | Train: 0.035879 (MSE=0.002859 BCE=0.6604) | Val: 0.042415 (MSE=0.009059 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:34] Epoch 16/100 | Train: 0.035872 (MSE=0.002853 BCE=0.6604) | Val: 0.042559 (MSE=0.009177 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042276 (ep 11)
[14:46:37] Epoch 17/100 | Train: 0.035863 (MSE=0.002847 BCE=0.6603) | Val: 0.042832 (MSE=0.009433 BCE=0.6680) | LR: 5.00e-05 | Best: 0.042276 (ep 11)
[14:46:40] Epoch 18/100 | Train: 0.035848 (MSE=0.002837 BCE=0.6602) | Val: 0.042826 (MSE=0.009431 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042276 (ep 11)
[14:46:43] Epoch 19/100 | Train: 0.035842 (MSE=0.002834 BCE=0.6602) | Val: 0.042745 (MSE=0.009351 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042276 (ep 11)
[14:46:46] Epoch 20/100 | Train: 0.035841 (MSE=0.002830 BCE=0.6602) | Val: 0.042879 (MSE=0.009485 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042276 (ep 11)
[14:46:49] Epoch 21/100 | Train: 0.035833 (MSE=0.002827 BCE=0.6601) | Val: 0.042894 (MSE=0.009502 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042276 (ep 11)
[14:46:49] Early stopping at epoch 21 (no improvement for 10 epochs)
[14:46:50] Factor 20 done — best val loss: 0.042276 at epoch 11
[14:46:50] 
Best factor: 19 (val loss 0.042122)
[14:46:50] Training done. Best factor=19, val_loss=0.042122
[15:34:54] Building validation dataset...
[15:34:54] Building features: 0% (1/175846)
[15:34:55] Building features: 5% (8793/175846)
[15:34:55] Building features: 10% (17585/175846)
[15:34:56] Building features: 15% (26377/175846)
[15:34:56] Building features: 20% (35169/175846)
[15:34:57] Building features: 25% (43961/175846)
[15:34:57] Building features: 30% (52753/175846)
[15:34:58] Building features: 35% (61545/175846)
[15:34:58] Building features: 40% (70337/175846)
[15:34:59] Building features: 45% (79129/175846)
[15:34:59] Building features: 50% (87921/175846)
[15:35:00] Building features: 55% (96713/175846)
[15:35:00] Building features: 60% (105505/175846)
[15:35:01] Building features: 65% (114297/175846)
[15:35:01] Building features: 70% (123089/175846)
[15:35:02] Building features: 75% (131881/175846)
[15:35:02] Building features: 80% (140673/175846)
[15:35:03] Building features: 85% (149465/175846)
[15:35:03] Building features: 90% (158257/175846)
[15:35:04] Building features: 95% (167049/175846)
[15:35:04] Building features: 100% (175841/175846)
[15:35:04] Computing Hurst exponent...
[15:35:09] Computing market regimes (GMM)...
[15:35:16] Running backtest...
[15:35:16] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[15:35:26] Building validation dataset...
[15:35:26] Building features: 0% (1/175846)
[15:35:26] Building features: 5% (8793/175846)
[15:35:27] Building features: 10% (17585/175846)
[15:35:27] Building features: 15% (26377/175846)
[15:35:28] Building features: 20% (35169/175846)
[15:35:28] Building features: 25% (43961/175846)
[15:35:29] Building features: 30% (52753/175846)
[15:35:29] Building features: 35% (61545/175846)
[15:35:30] Building features: 40% (70337/175846)
[15:35:30] Building features: 45% (79129/175846)
[15:35:31] Building features: 50% (87921/175846)
[15:35:31] Building features: 55% (96713/175846)
[15:35:32] Building features: 60% (105505/175846)
[15:35:32] Building features: 65% (114297/175846)
[15:35:33] Building features: 70% (123089/175846)
[15:35:33] Building features: 75% (131881/175846)
[15:35:34] Building features: 80% (140673/175846)
[15:35:34] Building features: 85% (149465/175846)
[15:35:35] Building features: 90% (158257/175846)
[15:35:35] Building features: 95% (167049/175846)
[15:35:36] Building features: 100% (175841/175846)
[15:35:36] Computing Hurst exponent...
[15:35:41] Computing market regimes (GMM)...
[15:35:47] Running backtest...
[15:35:48] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[15:57:27] Training started.
[15:57:27] 
============================================================
[15:57:27] STF Factor 2 of [2..5]
[15:57:27] ============================================================
[15:57:27] Building features: 0% (1/175846)
[15:57:28] Building features: 5% (8793/175846)
[15:57:28] Building features: 10% (17585/175846)
[15:57:29] Building features: 15% (26377/175846)
[15:57:29] Building features: 20% (35169/175846)
[15:57:30] Building features: 25% (43961/175846)
[15:57:30] Building features: 30% (52753/175846)
[15:57:31] Building features: 35% (61545/175846)
[15:57:31] Building features: 40% (70337/175846)
[15:57:32] Building features: 45% (79129/175846)
[15:57:32] Building features: 50% (87921/175846)
[15:57:33] Building features: 55% (96713/175846)
[15:57:34] Building features: 60% (105505/175846)
[15:57:34] Building features: 65% (114297/175846)
[15:57:35] Building features: 70% (123089/175846)
[15:57:35] Building features: 75% (131881/175846)
[15:57:36] Building features: 80% (140673/175846)
[15:57:36] Building features: 85% (149465/175846)
[15:57:37] Building features: 90% (158257/175846)
[15:57:37] Building features: 95% (167049/175846)
[15:57:38] Building features: 100% (175841/175846)
[15:57:38] Computing Hurst exponent...
[15:57:43] Computing market regimes (GMM)...
[15:57:51] Factor 2: 175694 samples, 92 features
[15:57:53] Batch stats — Input:  mean=0.0571 std=0.2575 min=-4.8553 max=7.9394
[15:57:53] Batch stats — Target: mean=0.0021 std=0.0589 min=-0.3885 max=0.3793
[15:57:53] Batch stats — Cls:    pos_long=105/256 pos_short=82/256
[15:57:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[15:57:58] Epoch 1/100 | Train: 0.036459 (MSE=0.003214 BCE=0.6649) | Val: 0.043788 (MSE=0.010415 BCE=0.6675) | LR: 1.00e-04 | Best: 0.043788 (ep 1)
[15:58:01] Epoch 2/100 | Train: 0.036097 (MSE=0.003025 BCE=0.6614) | Val: 0.042469 (MSE=0.009110 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042469 (ep 2)
[15:58:04] Epoch 3/100 | Train: 0.036026 (MSE=0.002967 BCE=0.6612) | Val: 0.042320 (MSE=0.008988 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042320 (ep 3)
[15:58:07] Epoch 4/100 | Train: 0.035993 (MSE=0.002941 BCE=0.6610) | Val: 0.042264 (MSE=0.008935 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042264 (ep 4)
[15:58:10] Epoch 5/100 | Train: 0.035973 (MSE=0.002924 BCE=0.6610) | Val: 0.042155 (MSE=0.008821 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042155 (ep 5)
[15:58:13] Epoch 6/100 | Train: 0.035962 (MSE=0.002915 BCE=0.6610) | Val: 0.042142 (MSE=0.008819 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042142 (ep 6)
[15:58:16] Epoch 7/100 | Train: 0.035948 (MSE=0.002910 BCE=0.6608) | Val: 0.042092 (MSE=0.008765 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:19] Epoch 8/100 | Train: 0.035941 (MSE=0.002898 BCE=0.6609) | Val: 0.042128 (MSE=0.008806 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:23] Epoch 9/100 | Train: 0.035930 (MSE=0.002891 BCE=0.6608) | Val: 0.042238 (MSE=0.008917 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:26] Epoch 10/100 | Train: 0.035923 (MSE=0.002888 BCE=0.6607) | Val: 0.042205 (MSE=0.008870 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:29] Epoch 11/100 | Train: 0.035915 (MSE=0.002882 BCE=0.6607) | Val: 0.042260 (MSE=0.008915 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:32] Epoch 12/100 | Train: 0.035905 (MSE=0.002876 BCE=0.6606) | Val: 0.042234 (MSE=0.008901 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042092 (ep 7)
[15:58:35] Epoch 13/100 | Train: 0.035898 (MSE=0.002870 BCE=0.6606) | Val: 0.042323 (MSE=0.008995 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042092 (ep 7)
[15:58:39] Epoch 14/100 | Train: 0.035881 (MSE=0.002861 BCE=0.6604) | Val: 0.042265 (MSE=0.008935 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042092 (ep 7)
[15:58:42] Epoch 15/100 | Train: 0.035881 (MSE=0.002858 BCE=0.6605) | Val: 0.042350 (MSE=0.009010 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042092 (ep 7)
[15:58:45] Epoch 16/100 | Train: 0.035869 (MSE=0.002854 BCE=0.6603) | Val: 0.042384 (MSE=0.009056 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042092 (ep 7)
[15:58:48] Epoch 17/100 | Train: 0.035866 (MSE=0.002849 BCE=0.6603) | Val: 0.042506 (MSE=0.009177 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042092 (ep 7)
[15:58:48] Early stopping at epoch 17 (no improvement for 10 epochs)
[15:58:49] Factor 2 done — best val loss: 0.042092 at epoch 7
[15:58:49] 
============================================================
[15:58:49] STF Factor 3 of [2..5]
[15:58:49] ============================================================
[15:58:49] Building features: 0% (1/175846)
[15:58:50] Building features: 5% (8793/175846)
[15:58:50] Building features: 10% (17585/175846)
[15:58:51] Building features: 15% (26377/175846)
[15:58:51] Building features: 20% (35169/175846)
[15:58:52] Building features: 25% (43961/175846)
[15:58:52] Building features: 30% (52753/175846)
[15:58:53] Building features: 35% (61545/175846)
[15:58:53] Building features: 40% (70337/175846)
[15:58:54] Building features: 45% (79129/175846)
[15:58:54] Building features: 50% (87921/175846)
[15:58:55] Building features: 55% (96713/175846)
[15:58:56] Building features: 60% (105505/175846)
[15:58:56] Building features: 65% (114297/175846)
[15:58:57] Building features: 70% (123089/175846)
[15:58:57] Building features: 75% (131881/175846)
[15:58:58] Building features: 80% (140673/175846)
[15:58:58] Building features: 85% (149465/175846)
[15:58:59] Building features: 90% (158257/175846)
[15:58:59] Building features: 95% (167049/175846)
[15:59:00] Building features: 100% (175841/175846)
[15:59:00] Computing Hurst exponent...
[15:59:05] Computing market regimes (GMM)...
[15:59:13] Factor 3: 175694 samples, 92 features
[15:59:15] Batch stats — Input:  mean=0.0544 std=0.2616 min=-3.5888 max=9.5561
[15:59:15] Batch stats — Target: mean=0.0013 std=0.0636 min=-0.4720 max=0.4134
[15:59:15] Batch stats — Cls:    pos_long=107/256 pos_short=86/256
[15:59:15] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[15:59:20] Epoch 1/100 | Train: 0.036475 (MSE=0.003252 BCE=0.6645) | Val: 0.043901 (MSE=0.010537 BCE=0.6673) | LR: 1.00e-04 | Best: 0.043901 (ep 1)
[15:59:23] Epoch 2/100 | Train: 0.036103 (MSE=0.003036 BCE=0.6613) | Val: 0.042501 (MSE=0.009162 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042501 (ep 2)
[15:59:26] Epoch 3/100 | Train: 0.036041 (MSE=0.002984 BCE=0.6611) | Val: 0.042477 (MSE=0.009150 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042477 (ep 3)
[15:59:29] Epoch 4/100 | Train: 0.036004 (MSE=0.002957 BCE=0.6609) | Val: 0.042328 (MSE=0.009001 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042328 (ep 4)
[15:59:32] Epoch 5/100 | Train: 0.035985 (MSE=0.002940 BCE=0.6609) | Val: 0.042168 (MSE=0.008845 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:35] Epoch 6/100 | Train: 0.035970 (MSE=0.002927 BCE=0.6609) | Val: 0.042239 (MSE=0.008910 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:38] Epoch 7/100 | Train: 0.035951 (MSE=0.002916 BCE=0.6607) | Val: 0.042188 (MSE=0.008856 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:41] Epoch 8/100 | Train: 0.035941 (MSE=0.002906 BCE=0.6607) | Val: 0.042180 (MSE=0.008844 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:44] Epoch 9/100 | Train: 0.035933 (MSE=0.002898 BCE=0.6607) | Val: 0.042168 (MSE=0.008843 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:47] Epoch 10/100 | Train: 0.035920 (MSE=0.002891 BCE=0.6606) | Val: 0.042333 (MSE=0.009003 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042168 (ep 5)
[15:59:50] Epoch 11/100 | Train: 0.035911 (MSE=0.002883 BCE=0.6605) | Val: 0.042177 (MSE=0.008852 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042168 (ep 5)
[15:59:53] Epoch 12/100 | Train: 0.035896 (MSE=0.002873 BCE=0.6605) | Val: 0.042210 (MSE=0.008890 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042168 (ep 5)
[15:59:56] Epoch 13/100 | Train: 0.035892 (MSE=0.002870 BCE=0.6604) | Val: 0.042147 (MSE=0.008825 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[15:59:59] Epoch 14/100 | Train: 0.035890 (MSE=0.002868 BCE=0.6604) | Val: 0.042165 (MSE=0.008837 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[16:00:02] Epoch 15/100 | Train: 0.035884 (MSE=0.002863 BCE=0.6604) | Val: 0.042174 (MSE=0.008854 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[16:00:04] Epoch 16/100 | Train: 0.035883 (MSE=0.002864 BCE=0.6604) | Val: 0.042221 (MSE=0.008900 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[16:00:07] Epoch 17/100 | Train: 0.035875 (MSE=0.002856 BCE=0.6604) | Val: 0.042265 (MSE=0.008937 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[16:00:09] Epoch 18/100 | Train: 0.035875 (MSE=0.002854 BCE=0.6604) | Val: 0.042240 (MSE=0.008922 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042147 (ep 13)
[16:00:12] Epoch 19/100 | Train: 0.035866 (MSE=0.002853 BCE=0.6603) | Val: 0.042307 (MSE=0.008985 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 13)
[16:00:15] Epoch 20/100 | Train: 0.035857 (MSE=0.002845 BCE=0.6602) | Val: 0.042290 (MSE=0.008968 BCE=0.6665) | LR: 2.50e-05 | Best: 0.042147 (ep 13)
[16:00:18] Epoch 21/100 | Train: 0.035855 (MSE=0.002845 BCE=0.6602) | Val: 0.042270 (MSE=0.008949 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 13)
[16:00:21] Epoch 22/100 | Train: 0.035852 (MSE=0.002843 BCE=0.6602) | Val: 0.042317 (MSE=0.008996 BCE=0.6664) | LR: 2.50e-05 | Best: 0.042147 (ep 13)
[16:00:24] Epoch 23/100 | Train: 0.035854 (MSE=0.002844 BCE=0.6602) | Val: 0.042287 (MSE=0.008962 BCE=0.6665) | LR: 2.50e-05 | Best: 0.042147 (ep 13)
[16:00:24] Early stopping at epoch 23 (no improvement for 10 epochs)
[16:00:25] Factor 3 done — best val loss: 0.042147 at epoch 13
[16:00:25] 
============================================================
[16:00:25] STF Factor 4 of [2..5]
[16:00:25] ============================================================
[16:00:25] Building features: 0% (1/175846)
[16:00:26] Building features: 5% (8793/175846)
[16:00:26] Building features: 10% (17585/175846)
[16:00:27] Building features: 15% (26377/175846)
[16:00:27] Building features: 20% (35169/175846)
[16:00:28] Building features: 25% (43961/175846)
[16:00:28] Building features: 30% (52753/175846)
[16:00:29] Building features: 35% (61545/175846)
[16:00:30] Building features: 40% (70337/175846)
[16:00:30] Building features: 45% (79129/175846)
[16:00:31] Building features: 50% (87921/175846)
[16:00:31] Building features: 55% (96713/175846)
[16:00:32] Building features: 60% (105505/175846)
[16:00:32] Building features: 65% (114297/175846)
[16:00:33] Building features: 70% (123089/175846)
[16:00:33] Building features: 75% (131881/175846)
[16:00:34] Building features: 80% (140673/175846)
[16:00:34] Building features: 85% (149465/175846)
[16:00:35] Building features: 90% (158257/175846)
[16:00:35] Building features: 95% (167049/175846)
[16:00:36] Building features: 100% (175841/175846)
[16:00:36] Computing Hurst exponent...
[16:00:41] Computing market regimes (GMM)...
[16:00:49] Factor 4: 175694 samples, 92 features
[16:00:51] Batch stats — Input:  mean=0.0550 std=0.2619 min=-4.8659 max=9.5561
[16:00:51] Batch stats — Target: mean=-0.0020 std=0.0651 min=-0.4720 max=0.3722
[16:00:51] Batch stats — Cls:    pos_long=101/256 pos_short=87/256
[16:00:51] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:00:56] Epoch 1/100 | Train: 0.036464 (MSE=0.003231 BCE=0.6646) | Val: 0.043483 (MSE=0.010134 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043483 (ep 1)
[16:00:59] Epoch 2/100 | Train: 0.036104 (MSE=0.003037 BCE=0.6613) | Val: 0.042512 (MSE=0.009177 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042512 (ep 2)
[16:01:02] Epoch 3/100 | Train: 0.036044 (MSE=0.002988 BCE=0.6611) | Val: 0.042394 (MSE=0.009057 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042394 (ep 3)
[16:01:05] Epoch 4/100 | Train: 0.036008 (MSE=0.002960 BCE=0.6610) | Val: 0.042304 (MSE=0.008973 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042304 (ep 4)
[16:01:08] Epoch 5/100 | Train: 0.035995 (MSE=0.002944 BCE=0.6610) | Val: 0.042279 (MSE=0.008943 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042279 (ep 5)
[16:01:11] Epoch 6/100 | Train: 0.035968 (MSE=0.002928 BCE=0.6608) | Val: 0.042235 (MSE=0.008893 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042235 (ep 6)
[16:01:14] Epoch 7/100 | Train: 0.035957 (MSE=0.002914 BCE=0.6609) | Val: 0.042180 (MSE=0.008841 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:17] Epoch 8/100 | Train: 0.035941 (MSE=0.002904 BCE=0.6607) | Val: 0.042197 (MSE=0.008854 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:20] Epoch 9/100 | Train: 0.035930 (MSE=0.002897 BCE=0.6607) | Val: 0.042204 (MSE=0.008863 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:23] Epoch 10/100 | Train: 0.035920 (MSE=0.002889 BCE=0.6606) | Val: 0.042208 (MSE=0.008876 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:26] Epoch 11/100 | Train: 0.035912 (MSE=0.002881 BCE=0.6606) | Val: 0.042241 (MSE=0.008895 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:29] Epoch 12/100 | Train: 0.035905 (MSE=0.002875 BCE=0.6606) | Val: 0.042204 (MSE=0.008864 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042180 (ep 7)
[16:01:32] Epoch 13/100 | Train: 0.035896 (MSE=0.002869 BCE=0.6605) | Val: 0.042197 (MSE=0.008869 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042180 (ep 7)
[16:01:35] Epoch 14/100 | Train: 0.035878 (MSE=0.002857 BCE=0.6604) | Val: 0.042236 (MSE=0.008900 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042180 (ep 7)
[16:01:38] Epoch 15/100 | Train: 0.035872 (MSE=0.002854 BCE=0.6604) | Val: 0.042311 (MSE=0.008966 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042180 (ep 7)
[16:01:41] Epoch 16/100 | Train: 0.035873 (MSE=0.002854 BCE=0.6604) | Val: 0.042286 (MSE=0.008942 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042180 (ep 7)
[16:01:44] Epoch 17/100 | Train: 0.035861 (MSE=0.002849 BCE=0.6602) | Val: 0.042297 (MSE=0.008968 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042180 (ep 7)
[16:01:44] Early stopping at epoch 17 (no improvement for 10 epochs)
[16:01:45] Factor 4 done — best val loss: 0.042180 at epoch 7
[16:01:45] 
============================================================
[16:01:45] STF Factor 5 of [2..5]
[16:01:45] ============================================================
[16:01:45] Building features: 0% (1/175846)
[16:01:46] Building features: 5% (8793/175846)
[16:01:46] Building features: 10% (17585/175846)
[16:01:47] Building features: 15% (26377/175846)
[16:01:47] Building features: 20% (35169/175846)
[16:01:48] Building features: 25% (43961/175846)
[16:01:48] Building features: 30% (52753/175846)
[16:01:49] Building features: 35% (61545/175846)
[16:01:49] Building features: 40% (70337/175846)
[16:01:50] Building features: 45% (79129/175846)
[16:01:50] Building features: 50% (87921/175846)
[16:01:51] Building features: 55% (96713/175846)
[16:01:51] Building features: 60% (105505/175846)
[16:01:52] Building features: 65% (114297/175846)
[16:01:52] Building features: 70% (123089/175846)
[16:01:53] Building features: 75% (131881/175846)
[16:01:54] Building features: 80% (140673/175846)
[16:01:54] Building features: 85% (149465/175846)
[16:01:55] Building features: 90% (158257/175846)
[16:01:55] Building features: 95% (167049/175846)
[16:01:56] Building features: 100% (175841/175846)
[16:01:56] Computing Hurst exponent...
[16:02:01] Computing market regimes (GMM)...
[16:02:08] Factor 5: 175694 samples, 92 features
[16:02:10] Batch stats — Input:  mean=0.0533 std=0.2674 min=-5.8362 max=9.1841
[16:02:10] Batch stats — Target: mean=-0.0010 std=0.0699 min=-0.4720 max=0.4134
[16:02:10] Batch stats — Cls:    pos_long=96/256 pos_short=93/256
[16:02:10] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:02:15] Epoch 1/100 | Train: 0.036441 (MSE=0.003240 BCE=0.6640) | Val: 0.043881 (MSE=0.010499 BCE=0.6676) | LR: 1.00e-04 | Best: 0.043881 (ep 1)
[16:02:18] Epoch 2/100 | Train: 0.036102 (MSE=0.003038 BCE=0.6613) | Val: 0.042504 (MSE=0.009139 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042504 (ep 2)
[16:02:21] Epoch 3/100 | Train: 0.036036 (MSE=0.002982 BCE=0.6611) | Val: 0.042382 (MSE=0.009046 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042382 (ep 3)
[16:02:24] Epoch 4/100 | Train: 0.036007 (MSE=0.002956 BCE=0.6610) | Val: 0.042250 (MSE=0.008933 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042250 (ep 4)
[16:02:27] Epoch 5/100 | Train: 0.035981 (MSE=0.002938 BCE=0.6609) | Val: 0.042232 (MSE=0.008911 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042232 (ep 5)
[16:02:30] Epoch 6/100 | Train: 0.035964 (MSE=0.002922 BCE=0.6608) | Val: 0.042167 (MSE=0.008838 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042167 (ep 6)
[16:02:34] Epoch 7/100 | Train: 0.035951 (MSE=0.002912 BCE=0.6608) | Val: 0.042140 (MSE=0.008814 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042140 (ep 7)
[16:02:37] Epoch 8/100 | Train: 0.035938 (MSE=0.002901 BCE=0.6607) | Val: 0.042135 (MSE=0.008808 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042135 (ep 8)
[16:02:40] Epoch 9/100 | Train: 0.035929 (MSE=0.002894 BCE=0.6607) | Val: 0.042091 (MSE=0.008772 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042091 (ep 9)
[16:02:43] Epoch 10/100 | Train: 0.035919 (MSE=0.002887 BCE=0.6606) | Val: 0.042139 (MSE=0.008819 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042091 (ep 9)
[16:02:46] Epoch 11/100 | Train: 0.035908 (MSE=0.002880 BCE=0.6605) | Val: 0.042089 (MSE=0.008754 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042089 (ep 11)
[16:02:49] Epoch 12/100 | Train: 0.035899 (MSE=0.002871 BCE=0.6606) | Val: 0.042246 (MSE=0.008918 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042089 (ep 11)
[16:02:52] Epoch 13/100 | Train: 0.035889 (MSE=0.002866 BCE=0.6605) | Val: 0.042276 (MSE=0.008953 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042089 (ep 11)
[16:02:55] Epoch 14/100 | Train: 0.035887 (MSE=0.002863 BCE=0.6605) | Val: 0.042146 (MSE=0.008799 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042089 (ep 11)
[16:02:58] Epoch 15/100 | Train: 0.035877 (MSE=0.002856 BCE=0.6604) | Val: 0.042243 (MSE=0.008918 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:01] Epoch 16/100 | Train: 0.035863 (MSE=0.002846 BCE=0.6603) | Val: 0.042197 (MSE=0.008860 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:04] Epoch 17/100 | Train: 0.035856 (MSE=0.002840 BCE=0.6603) | Val: 0.042224 (MSE=0.008893 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:07] Epoch 18/100 | Train: 0.035854 (MSE=0.002841 BCE=0.6603) | Val: 0.042248 (MSE=0.008910 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:10] Epoch 19/100 | Train: 0.035846 (MSE=0.002837 BCE=0.6602) | Val: 0.042293 (MSE=0.008931 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:13] Epoch 20/100 | Train: 0.035844 (MSE=0.002834 BCE=0.6602) | Val: 0.042323 (MSE=0.008982 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042089 (ep 11)
[16:03:16] Epoch 21/100 | Train: 0.035834 (MSE=0.002833 BCE=0.6600) | Val: 0.042324 (MSE=0.008992 BCE=0.6666) | LR: 2.50e-05 | Best: 0.042089 (ep 11)
[16:03:16] Early stopping at epoch 21 (no improvement for 10 epochs)
[16:03:17] Factor 5 done — best val loss: 0.042089 at epoch 11
[16:03:17] 
Best factor: 5 (val loss 0.042089)
[16:03:17] Training done. Best factor=5, val_loss=0.042089
[16:35:09] NTCP initialized.
[16:35:45] Set CSV path first.
[16:35:59] Loaded 175846 M5 bars.
[16:36:11] Training started.
[16:36:11] 
============================================================
[16:36:11] STF Factor 6 of [6..24]
[16:36:11] ============================================================
[16:36:11] Building features: 0% (1/175846)
[16:36:11] Building features: 5% (8793/175846)
[16:36:12] Building features: 10% (17585/175846)
[16:36:12] Building features: 15% (26377/175846)
[16:36:13] Building features: 20% (35169/175846)
[16:36:13] Building features: 25% (43961/175846)
[16:36:14] Building features: 30% (52753/175846)
[16:36:14] Building features: 35% (61545/175846)
[16:36:15] Building features: 40% (70337/175846)
[16:36:15] Building features: 45% (79129/175846)
[16:36:16] Building features: 50% (87921/175846)
[16:36:17] Building features: 55% (96713/175846)
[16:36:17] Building features: 60% (105505/175846)
[16:36:18] Building features: 65% (114297/175846)
[16:36:18] Building features: 70% (123089/175846)
[16:36:19] Building features: 75% (131881/175846)
[16:36:19] Building features: 80% (140673/175846)
[16:36:20] Building features: 85% (149465/175846)
[16:36:20] Building features: 90% (158257/175846)
[16:36:21] Building features: 95% (167049/175846)
[16:36:21] Building features: 100% (175841/175846)
[16:36:21] Computing Hurst exponent...
[16:36:27] Computing market regimes (GMM)...
[16:36:41] Factor 6: 175724 samples, 92 features
[16:36:43] Batch stats — Input:  mean=0.0534 std=0.2705 min=-5.4479 max=27.8570
[16:36:43] Batch stats — Target: mean=-0.0010 std=0.0718 min=-0.4720 max=0.4134
[16:36:43] Batch stats — Cls:    pos_long=108/256 pos_short=90/256
[16:36:43] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:36:49] Epoch 1/100 | Train: 0.037021 (MSE=0.003855 BCE=0.6633) | Val: 0.044236 (MSE=0.010864 BCE=0.6674) | LR: 1.00e-04 | Best: 0.044236 (ep 1)
[16:36:51] Epoch 2/100 | Train: 0.036181 (MSE=0.003107 BCE=0.6615) | Val: 0.043019 (MSE=0.009666 BCE=0.6671) | LR: 1.00e-04 | Best: 0.043019 (ep 2)
[16:36:54] Epoch 3/100 | Train: 0.036119 (MSE=0.003053 BCE=0.6613) | Val: 0.042593 (MSE=0.009251 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042593 (ep 3)
[16:36:57] Epoch 4/100 | Train: 0.036083 (MSE=0.003020 BCE=0.6613) | Val: 0.042476 (MSE=0.009140 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042476 (ep 4)
[16:37:00] Epoch 5/100 | Train: 0.036055 (MSE=0.002997 BCE=0.6611) | Val: 0.042408 (MSE=0.009088 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042408 (ep 5)
[16:37:03] Epoch 6/100 | Train: 0.036025 (MSE=0.002974 BCE=0.6610) | Val: 0.042439 (MSE=0.009119 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042408 (ep 5)
[16:37:05] Epoch 7/100 | Train: 0.036003 (MSE=0.002961 BCE=0.6608) | Val: 0.042387 (MSE=0.009061 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042387 (ep 7)
[16:37:08] Epoch 8/100 | Train: 0.035988 (MSE=0.002944 BCE=0.6609) | Val: 0.042357 (MSE=0.009006 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042357 (ep 8)
[16:37:11] Epoch 9/100 | Train: 0.035972 (MSE=0.002934 BCE=0.6608) | Val: 0.042283 (MSE=0.008945 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:13] Epoch 10/100 | Train: 0.035966 (MSE=0.002929 BCE=0.6607) | Val: 0.042337 (MSE=0.009021 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:16] Epoch 11/100 | Train: 0.035949 (MSE=0.002919 BCE=0.6606) | Val: 0.042378 (MSE=0.009053 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:19] Epoch 12/100 | Train: 0.035943 (MSE=0.002913 BCE=0.6606) | Val: 0.042295 (MSE=0.008974 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:22] Epoch 13/100 | Train: 0.035939 (MSE=0.002908 BCE=0.6606) | Val: 0.042448 (MSE=0.009091 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:25] Epoch 14/100 | Train: 0.035921 (MSE=0.002899 BCE=0.6604) | Val: 0.042410 (MSE=0.009067 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[16:37:28] Epoch 15/100 | Train: 0.035919 (MSE=0.002897 BCE=0.6604) | Val: 0.042387 (MSE=0.009046 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[16:37:31] Epoch 16/100 | Train: 0.035901 (MSE=0.002888 BCE=0.6603) | Val: 0.042472 (MSE=0.009130 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[16:37:34] Epoch 17/100 | Train: 0.035888 (MSE=0.002881 BCE=0.6601) | Val: 0.042503 (MSE=0.009146 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[16:37:36] Epoch 18/100 | Train: 0.035888 (MSE=0.002879 BCE=0.6602) | Val: 0.042615 (MSE=0.009266 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[16:37:39] Epoch 19/100 | Train: 0.035885 (MSE=0.002876 BCE=0.6602) | Val: 0.042520 (MSE=0.009173 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[16:37:39] Early stopping at epoch 19 (no improvement for 10 epochs)
[16:37:40] Factor 6 done — best val loss: 0.042283 at epoch 9
[16:37:40] 
============================================================
[16:37:40] STF Factor 7 of [6..24]
[16:37:40] ============================================================
[16:37:40] Building features: 0% (1/175846)
[16:37:41] Building features: 5% (8793/175846)
[16:37:41] Building features: 10% (17585/175846)
[16:37:42] Building features: 15% (26377/175846)
[16:37:42] Building features: 20% (35169/175846)
[16:37:43] Building features: 25% (43961/175846)
[16:37:44] Building features: 30% (52753/175846)
[16:37:44] Building features: 35% (61545/175846)
[16:37:45] Building features: 40% (70337/175846)
[16:37:45] Building features: 45% (79129/175846)
[16:37:46] Building features: 50% (87921/175846)
[16:37:47] Building features: 55% (96713/175846)
[16:37:47] Building features: 60% (105505/175846)
[16:37:48] Building features: 65% (114297/175846)
[16:37:48] Building features: 70% (123089/175846)
[16:37:49] Building features: 75% (131881/175846)
[16:37:49] Building features: 80% (140673/175846)
[16:37:50] Building features: 85% (149465/175846)
[16:37:51] Building features: 90% (158257/175846)
[16:37:51] Building features: 95% (167049/175846)
[16:37:52] Building features: 100% (175841/175846)
[16:37:52] Computing Hurst exponent...
[16:37:57] Computing market regimes (GMM)...
[16:38:05] Factor 7: 175724 samples, 92 features
[16:38:07] Batch stats — Input:  mean=0.0525 std=0.2869 min=-6.3561 max=60.4783
[16:38:07] Batch stats — Target: mean=0.0013 std=0.0628 min=-0.4720 max=0.4134
[16:38:07] Batch stats — Cls:    pos_long=101/256 pos_short=93/256
[16:38:07] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:38:11] Epoch 1/100 | Train: 0.037040 (MSE=0.003801 BCE=0.6648) | Val: 0.043534 (MSE=0.010184 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043534 (ep 1)
[16:38:14] Epoch 2/100 | Train: 0.036179 (MSE=0.003101 BCE=0.6616) | Val: 0.042677 (MSE=0.009329 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042677 (ep 2)
[16:38:17] Epoch 3/100 | Train: 0.036113 (MSE=0.003046 BCE=0.6613) | Val: 0.042534 (MSE=0.009192 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042534 (ep 3)
[16:38:20] Epoch 4/100 | Train: 0.036084 (MSE=0.003016 BCE=0.6614) | Val: 0.042452 (MSE=0.009116 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042452 (ep 4)
[16:38:22] Epoch 5/100 | Train: 0.036042 (MSE=0.002985 BCE=0.6611) | Val: 0.042398 (MSE=0.009050 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042398 (ep 5)
[16:38:25] Epoch 6/100 | Train: 0.036013 (MSE=0.002965 BCE=0.6609) | Val: 0.042318 (MSE=0.008971 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042318 (ep 6)
[16:38:28] Epoch 7/100 | Train: 0.035997 (MSE=0.002952 BCE=0.6609) | Val: 0.042337 (MSE=0.008981 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042318 (ep 6)
[16:38:31] Epoch 8/100 | Train: 0.035978 (MSE=0.002939 BCE=0.6608) | Val: 0.042370 (MSE=0.009003 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042318 (ep 6)
[16:38:33] Epoch 9/100 | Train: 0.035970 (MSE=0.002930 BCE=0.6608) | Val: 0.042356 (MSE=0.008996 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042318 (ep 6)
[16:38:36] Epoch 10/100 | Train: 0.035955 (MSE=0.002918 BCE=0.6607) | Val: 0.042250 (MSE=0.008899 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:39] Epoch 11/100 | Train: 0.035941 (MSE=0.002911 BCE=0.6606) | Val: 0.042313 (MSE=0.008954 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:42] Epoch 12/100 | Train: 0.035939 (MSE=0.002906 BCE=0.6606) | Val: 0.042393 (MSE=0.009033 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:44] Epoch 13/100 | Train: 0.035925 (MSE=0.002900 BCE=0.6605) | Val: 0.042401 (MSE=0.009034 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:47] Epoch 14/100 | Train: 0.035924 (MSE=0.002894 BCE=0.6606) | Val: 0.042347 (MSE=0.008994 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:50] Epoch 15/100 | Train: 0.035909 (MSE=0.002888 BCE=0.6604) | Val: 0.042525 (MSE=0.009141 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042250 (ep 10)
[16:38:53] Epoch 16/100 | Train: 0.035906 (MSE=0.002884 BCE=0.6604) | Val: 0.042470 (MSE=0.009100 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042250 (ep 10)
[16:38:55] Epoch 17/100 | Train: 0.035888 (MSE=0.002873 BCE=0.6603) | Val: 0.042560 (MSE=0.009196 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042250 (ep 10)
[16:38:58] Epoch 18/100 | Train: 0.035879 (MSE=0.002871 BCE=0.6602) | Val: 0.042495 (MSE=0.009113 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042250 (ep 10)
[16:39:01] Epoch 19/100 | Train: 0.035878 (MSE=0.002869 BCE=0.6602) | Val: 0.042654 (MSE=0.009274 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042250 (ep 10)
[16:39:04] Epoch 20/100 | Train: 0.035876 (MSE=0.002866 BCE=0.6602) | Val: 0.042730 (MSE=0.009359 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042250 (ep 10)
[16:39:04] Early stopping at epoch 20 (no improvement for 10 epochs)
[16:39:05] Factor 7 done — best val loss: 0.042250 at epoch 10
[16:39:05] 
============================================================
[16:39:05] STF Factor 8 of [6..24]
[16:39:05] ============================================================
[16:39:05] Building features: 0% (1/175846)
[16:39:06] Building features: 5% (8793/175846)
[16:39:06] Building features: 10% (17585/175846)
[16:39:07] Building features: 15% (26377/175846)
[16:39:07] Building features: 20% (35169/175846)
[16:39:08] Building features: 25% (43961/175846)
[16:39:08] Building features: 30% (52753/175846)
[16:39:09] Building features: 35% (61545/175846)
[16:39:09] Building features: 40% (70337/175846)
[16:39:10] Building features: 45% (79129/175846)
[16:39:11] Building features: 50% (87921/175846)
[16:39:11] Building features: 55% (96713/175846)
[16:39:12] Building features: 60% (105505/175846)
[16:39:12] Building features: 65% (114297/175846)
[16:39:13] Building features: 70% (123089/175846)
[16:39:13] Building features: 75% (131881/175846)
[16:39:14] Building features: 80% (140673/175846)
[16:39:14] Building features: 85% (149465/175846)
[16:39:15] Building features: 90% (158257/175846)
[16:39:16] Building features: 95% (167049/175846)
[16:39:16] Building features: 100% (175841/175846)
[16:39:16] Computing Hurst exponent...
[16:39:21] Computing market regimes (GMM)...
[16:39:29] Factor 8: 175724 samples, 92 features
[16:39:31] Batch stats — Input:  mean=0.0527 std=0.2698 min=-4.4937 max=10.0671
[16:39:31] Batch stats — Target: mean=-0.0008 std=0.0654 min=-0.4428 max=0.4134
[16:39:31] Batch stats — Cls:    pos_long=84/256 pos_short=107/256
[16:39:31] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:39:36] Epoch 1/100 | Train: 0.037170 (MSE=0.003973 BCE=0.6639) | Val: 0.044619 (MSE=0.011250 BCE=0.6674) | LR: 1.00e-04 | Best: 0.044619 (ep 1)
[16:39:38] Epoch 2/100 | Train: 0.036204 (MSE=0.003117 BCE=0.6617) | Val: 0.043251 (MSE=0.009915 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043251 (ep 2)
[16:39:41] Epoch 3/100 | Train: 0.036130 (MSE=0.003061 BCE=0.6614) | Val: 0.042750 (MSE=0.009425 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042750 (ep 3)
[16:39:44] Epoch 4/100 | Train: 0.036092 (MSE=0.003032 BCE=0.6612) | Val: 0.042671 (MSE=0.009334 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042671 (ep 4)
[16:39:47] Epoch 5/100 | Train: 0.036061 (MSE=0.003004 BCE=0.6611) | Val: 0.042575 (MSE=0.009235 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042575 (ep 5)
[16:39:49] Epoch 6/100 | Train: 0.036031 (MSE=0.002982 BCE=0.6610) | Val: 0.042467 (MSE=0.009115 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042467 (ep 6)
[16:39:52] Epoch 7/100 | Train: 0.036015 (MSE=0.002968 BCE=0.6609) | Val: 0.042357 (MSE=0.009022 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042357 (ep 7)
[16:39:55] Epoch 8/100 | Train: 0.036002 (MSE=0.002957 BCE=0.6609) | Val: 0.042477 (MSE=0.009129 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042357 (ep 7)
[16:39:58] Epoch 9/100 | Train: 0.035986 (MSE=0.002947 BCE=0.6608) | Val: 0.042325 (MSE=0.008980 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042325 (ep 9)
[16:40:00] Epoch 10/100 | Train: 0.035970 (MSE=0.002935 BCE=0.6607) | Val: 0.042344 (MSE=0.008996 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042325 (ep 9)
[16:40:03] Epoch 11/100 | Train: 0.035961 (MSE=0.002925 BCE=0.6607) | Val: 0.042359 (MSE=0.009012 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042325 (ep 9)
[16:40:06] Epoch 12/100 | Train: 0.035948 (MSE=0.002918 BCE=0.6606) | Val: 0.042491 (MSE=0.009108 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042325 (ep 9)
[16:40:09] Epoch 13/100 | Train: 0.035937 (MSE=0.002910 BCE=0.6605) | Val: 0.042322 (MSE=0.008962 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042322 (ep 13)
[16:40:12] Epoch 14/100 | Train: 0.035934 (MSE=0.002906 BCE=0.6605) | Val: 0.042411 (MSE=0.009029 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042322 (ep 13)
[16:40:15] Epoch 15/100 | Train: 0.035917 (MSE=0.002896 BCE=0.6604) | Val: 0.042468 (MSE=0.009087 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:17] Epoch 16/100 | Train: 0.035900 (MSE=0.002887 BCE=0.6603) | Val: 0.042576 (MSE=0.009205 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:20] Epoch 17/100 | Train: 0.035890 (MSE=0.002885 BCE=0.6601) | Val: 0.042626 (MSE=0.009250 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:23] Epoch 18/100 | Train: 0.035893 (MSE=0.002881 BCE=0.6602) | Val: 0.042646 (MSE=0.009275 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:26] Epoch 19/100 | Train: 0.035890 (MSE=0.002881 BCE=0.6602) | Val: 0.042758 (MSE=0.009374 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:29] Epoch 20/100 | Train: 0.035880 (MSE=0.002875 BCE=0.6601) | Val: 0.042859 (MSE=0.009464 BCE=0.6679) | LR: 5.00e-05 | Best: 0.042322 (ep 13)
[16:40:31] Epoch 21/100 | Train: 0.035883 (MSE=0.002875 BCE=0.6602) | Val: 0.042690 (MSE=0.009302 BCE=0.6678) | LR: 2.50e-05 | Best: 0.042322 (ep 13)
[16:40:34] Epoch 22/100 | Train: 0.035865 (MSE=0.002867 BCE=0.6600) | Val: 0.042710 (MSE=0.009321 BCE=0.6678) | LR: 2.50e-05 | Best: 0.042322 (ep 13)
[16:40:37] Epoch 23/100 | Train: 0.035863 (MSE=0.002868 BCE=0.6599) | Val: 0.042837 (MSE=0.009443 BCE=0.6679) | LR: 2.50e-05 | Best: 0.042322 (ep 13)
[16:40:37] Early stopping at epoch 23 (no improvement for 10 epochs)
[16:40:38] Factor 8 done — best val loss: 0.042322 at epoch 13
[16:40:38] 
============================================================
[16:40:38] STF Factor 9 of [6..24]
[16:40:38] ============================================================
[16:40:38] Building features: 0% (1/175846)
[16:40:39] Building features: 5% (8793/175846)
[16:40:39] Building features: 10% (17585/175846)
[16:40:40] Building features: 15% (26377/175846)
[16:40:40] Building features: 20% (35169/175846)
[16:40:41] Building features: 25% (43961/175846)
[16:40:41] Building features: 30% (52753/175846)
[16:40:42] Building features: 35% (61545/175846)
[16:40:42] Building features: 40% (70337/175846)
[16:40:43] Building features: 45% (79129/175846)
[16:40:43] Building features: 50% (87921/175846)
[16:40:44] Building features: 55% (96713/175846)
[16:40:44] Building features: 60% (105505/175846)
[16:40:45] Building features: 65% (114297/175846)
[16:40:45] Building features: 70% (123089/175846)
[16:40:46] Building features: 75% (131881/175846)
[16:40:46] Building features: 80% (140673/175846)
[16:40:47] Building features: 85% (149465/175846)
[16:40:48] Building features: 90% (158257/175846)
[16:40:48] Building features: 95% (167049/175846)
[16:40:49] Building features: 100% (175841/175846)
[16:40:49] Computing Hurst exponent...
[16:40:54] Computing market regimes (GMM)...
[16:41:01] Factor 9: 175724 samples, 92 features
[16:41:03] Batch stats — Input:  mean=0.0519 std=0.2655 min=-5.2872 max=4.5497
[16:41:03] Batch stats — Target: mean=0.0048 std=0.0614 min=-0.2789 max=0.4134
[16:41:03] Batch stats — Cls:    pos_long=112/256 pos_short=77/256
[16:41:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:41:08] Epoch 1/100 | Train: 0.037403 (MSE=0.004156 BCE=0.6649) | Val: 0.043930 (MSE=0.010585 BCE=0.6669) | LR: 1.00e-04 | Best: 0.043930 (ep 1)
[16:41:11] Epoch 2/100 | Train: 0.036217 (MSE=0.003131 BCE=0.6617) | Val: 0.042920 (MSE=0.009559 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042920 (ep 2)
[16:41:14] Epoch 3/100 | Train: 0.036149 (MSE=0.003073 BCE=0.6615) | Val: 0.042615 (MSE=0.009297 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042615 (ep 3)
[16:41:16] Epoch 4/100 | Train: 0.036099 (MSE=0.003041 BCE=0.6612) | Val: 0.042552 (MSE=0.009227 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042552 (ep 4)
[16:41:19] Epoch 5/100 | Train: 0.036065 (MSE=0.003010 BCE=0.6611) | Val: 0.042567 (MSE=0.009188 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042552 (ep 4)
[16:41:22] Epoch 6/100 | Train: 0.036038 (MSE=0.002985 BCE=0.6611) | Val: 0.042387 (MSE=0.009048 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042387 (ep 6)
[16:41:25] Epoch 7/100 | Train: 0.036014 (MSE=0.002964 BCE=0.6610) | Val: 0.042365 (MSE=0.009037 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042365 (ep 7)
[16:41:27] Epoch 8/100 | Train: 0.035999 (MSE=0.002952 BCE=0.6609) | Val: 0.042388 (MSE=0.009055 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042365 (ep 7)
[16:41:30] Epoch 9/100 | Train: 0.035979 (MSE=0.002941 BCE=0.6608) | Val: 0.042362 (MSE=0.008997 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042362 (ep 9)
[16:41:32] Epoch 10/100 | Train: 0.035971 (MSE=0.002933 BCE=0.6608) | Val: 0.042347 (MSE=0.008989 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042347 (ep 10)
[16:41:34] Epoch 11/100 | Train: 0.035962 (MSE=0.002926 BCE=0.6607) | Val: 0.042312 (MSE=0.008927 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042312 (ep 11)
[16:41:37] Epoch 12/100 | Train: 0.035957 (MSE=0.002920 BCE=0.6607) | Val: 0.042219 (MSE=0.008874 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:39] Epoch 13/100 | Train: 0.035939 (MSE=0.002912 BCE=0.6605) | Val: 0.042253 (MSE=0.008903 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:42] Epoch 14/100 | Train: 0.035937 (MSE=0.002907 BCE=0.6606) | Val: 0.042259 (MSE=0.008908 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:44] Epoch 15/100 | Train: 0.035925 (MSE=0.002903 BCE=0.6604) | Val: 0.042342 (MSE=0.008989 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:47] Epoch 16/100 | Train: 0.035918 (MSE=0.002897 BCE=0.6604) | Val: 0.042392 (MSE=0.009033 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:50] Epoch 17/100 | Train: 0.035907 (MSE=0.002891 BCE=0.6603) | Val: 0.042431 (MSE=0.009066 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042219 (ep 12)
[16:41:53] Epoch 18/100 | Train: 0.035911 (MSE=0.002889 BCE=0.6604) | Val: 0.042359 (MSE=0.009013 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042219 (ep 12)
[16:41:55] Epoch 19/100 | Train: 0.035886 (MSE=0.002881 BCE=0.6601) | Val: 0.042583 (MSE=0.009229 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042219 (ep 12)
[16:41:58] Epoch 20/100 | Train: 0.035886 (MSE=0.002876 BCE=0.6602) | Val: 0.042562 (MSE=0.009211 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042219 (ep 12)
[16:42:01] Epoch 21/100 | Train: 0.035878 (MSE=0.002875 BCE=0.6601) | Val: 0.042526 (MSE=0.009158 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042219 (ep 12)
[16:42:04] Epoch 22/100 | Train: 0.035879 (MSE=0.002874 BCE=0.6601) | Val: 0.042595 (MSE=0.009223 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042219 (ep 12)
[16:42:04] Early stopping at epoch 22 (no improvement for 10 epochs)
[16:42:05] Factor 9 done — best val loss: 0.042219 at epoch 12
[16:42:05] 
============================================================
[16:42:05] STF Factor 10 of [6..24]
[16:42:05] ============================================================
[16:42:05] Building features: 0% (1/175846)
[16:42:05] Building features: 5% (8793/175846)
[16:42:06] Building features: 10% (17585/175846)
[16:42:06] Building features: 15% (26377/175846)
[16:42:07] Building features: 20% (35169/175846)
[16:42:07] Building features: 25% (43961/175846)
[16:42:08] Building features: 30% (52753/175846)
[16:42:09] Building features: 35% (61545/175846)
[16:42:09] Building features: 40% (70337/175846)
[16:42:10] Building features: 45% (79129/175846)
[16:42:10] Building features: 50% (87921/175846)
[16:42:11] Building features: 55% (96713/175846)
[16:42:11] Building features: 60% (105505/175846)
[16:42:12] Building features: 65% (114297/175846)
[16:42:12] Building features: 70% (123089/175846)
[16:42:13] Building features: 75% (131881/175846)
[16:42:13] Building features: 80% (140673/175846)
[16:42:14] Building features: 85% (149465/175846)
[16:42:15] Building features: 90% (158257/175846)
[16:42:15] Building features: 95% (167049/175846)
[16:42:16] Building features: 100% (175841/175846)
[16:42:16] Computing Hurst exponent...
[16:42:21] Computing market regimes (GMM)...
[16:42:29] Factor 10: 175724 samples, 92 features
[16:42:30] Batch stats — Input:  mean=0.0534 std=0.2664 min=-3.4787 max=13.1528
[16:42:30] Batch stats — Target: mean=-0.0016 std=0.0672 min=-0.4720 max=0.4134
[16:42:30] Batch stats — Cls:    pos_long=103/256 pos_short=104/256
[16:42:30] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:42:35] Epoch 1/100 | Train: 0.037080 (MSE=0.003886 BCE=0.6639) | Val: 0.044509 (MSE=0.011148 BCE=0.6672) | LR: 1.00e-04 | Best: 0.044509 (ep 1)
[16:42:38] Epoch 2/100 | Train: 0.036186 (MSE=0.003105 BCE=0.6616) | Val: 0.043141 (MSE=0.009764 BCE=0.6675) | LR: 1.00e-04 | Best: 0.043141 (ep 2)
[16:42:41] Epoch 3/100 | Train: 0.036110 (MSE=0.003046 BCE=0.6613) | Val: 0.042627 (MSE=0.009279 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042627 (ep 3)
[16:42:43] Epoch 4/100 | Train: 0.036062 (MSE=0.003007 BCE=0.6611) | Val: 0.042490 (MSE=0.009155 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042490 (ep 4)
[16:42:46] Epoch 5/100 | Train: 0.036033 (MSE=0.002980 BCE=0.6611) | Val: 0.042366 (MSE=0.009036 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042366 (ep 5)
[16:42:49] Epoch 6/100 | Train: 0.036012 (MSE=0.002961 BCE=0.6610) | Val: 0.042320 (MSE=0.008998 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042320 (ep 6)
[16:42:52] Epoch 7/100 | Train: 0.035993 (MSE=0.002947 BCE=0.6609) | Val: 0.042271 (MSE=0.008939 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042271 (ep 7)
[16:42:54] Epoch 8/100 | Train: 0.035975 (MSE=0.002937 BCE=0.6608) | Val: 0.042209 (MSE=0.008885 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042209 (ep 8)
[16:42:57] Epoch 9/100 | Train: 0.035960 (MSE=0.002926 BCE=0.6607) | Val: 0.042189 (MSE=0.008850 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042189 (ep 9)
[16:43:00] Epoch 10/100 | Train: 0.035951 (MSE=0.002920 BCE=0.6606) | Val: 0.042208 (MSE=0.008877 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042189 (ep 9)
[16:43:03] Epoch 11/100 | Train: 0.035946 (MSE=0.002912 BCE=0.6607) | Val: 0.042183 (MSE=0.008845 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042183 (ep 11)
[16:43:06] Epoch 12/100 | Train: 0.035934 (MSE=0.002905 BCE=0.6606) | Val: 0.042237 (MSE=0.008890 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042183 (ep 11)
[16:43:08] Epoch 13/100 | Train: 0.035928 (MSE=0.002901 BCE=0.6605) | Val: 0.042194 (MSE=0.008854 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042183 (ep 11)
[16:43:11] Epoch 14/100 | Train: 0.035916 (MSE=0.002896 BCE=0.6604) | Val: 0.042224 (MSE=0.008881 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042183 (ep 11)
[16:43:14] Epoch 15/100 | Train: 0.035909 (MSE=0.002889 BCE=0.6604) | Val: 0.042181 (MSE=0.008838 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042181 (ep 15)
[16:43:16] Epoch 16/100 | Train: 0.035905 (MSE=0.002886 BCE=0.6604) | Val: 0.042244 (MSE=0.008879 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042181 (ep 15)
[16:43:18] Epoch 17/100 | Train: 0.035899 (MSE=0.002884 BCE=0.6603) | Val: 0.042233 (MSE=0.008866 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:21] Epoch 18/100 | Train: 0.035883 (MSE=0.002876 BCE=0.6601) | Val: 0.042245 (MSE=0.008892 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:23] Epoch 19/100 | Train: 0.035877 (MSE=0.002872 BCE=0.6601) | Val: 0.042233 (MSE=0.008869 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:25] Epoch 20/100 | Train: 0.035869 (MSE=0.002870 BCE=0.6600) | Val: 0.042307 (MSE=0.008944 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:28] Epoch 21/100 | Train: 0.035868 (MSE=0.002868 BCE=0.6600) | Val: 0.042347 (MSE=0.008969 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:30] Epoch 22/100 | Train: 0.035864 (MSE=0.002865 BCE=0.6600) | Val: 0.042381 (MSE=0.008997 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042181 (ep 15)
[16:43:32] Epoch 23/100 | Train: 0.035862 (MSE=0.002863 BCE=0.6600) | Val: 0.042442 (MSE=0.009029 BCE=0.6682) | LR: 2.50e-05 | Best: 0.042181 (ep 15)
[16:43:35] Epoch 24/100 | Train: 0.035853 (MSE=0.002860 BCE=0.6599) | Val: 0.042451 (MSE=0.009037 BCE=0.6683) | LR: 2.50e-05 | Best: 0.042181 (ep 15)
[16:43:37] Epoch 25/100 | Train: 0.035846 (MSE=0.002856 BCE=0.6598) | Val: 0.042463 (MSE=0.009063 BCE=0.6680) | LR: 2.50e-05 | Best: 0.042181 (ep 15)
[16:43:37] Early stopping at epoch 25 (no improvement for 10 epochs)
[16:43:38] Factor 10 done — best val loss: 0.042181 at epoch 15
[16:43:38] 
============================================================
[16:43:38] STF Factor 11 of [6..24]
[16:43:38] ============================================================
[16:43:38] Building features: 0% (1/175846)
[16:43:38] Building features: 5% (8793/175846)
[16:43:39] Building features: 10% (17585/175846)
[16:43:39] Building features: 15% (26377/175846)
[16:43:40] Building features: 20% (35169/175846)
[16:43:40] Building features: 25% (43961/175846)
[16:43:41] Building features: 30% (52753/175846)
[16:43:41] Building features: 35% (61545/175846)
[16:43:42] Building features: 40% (70337/175846)
[16:43:42] Building features: 45% (79129/175846)
[16:43:43] Building features: 50% (87921/175846)
[16:43:43] Building features: 55% (96713/175846)
[16:43:44] Building features: 60% (105505/175846)
[16:43:44] Building features: 65% (114297/175846)
[16:43:45] Building features: 70% (123089/175846)
[16:43:45] Building features: 75% (131881/175846)
[16:43:46] Building features: 80% (140673/175846)
[16:43:46] Building features: 85% (149465/175846)
[16:43:47] Building features: 90% (158257/175846)
[16:43:47] Building features: 95% (167049/175846)
[16:43:48] Building features: 100% (175841/175846)
[16:43:48] Computing Hurst exponent...
[16:43:53] Computing market regimes (GMM)...
[16:44:01] Factor 11: 175724 samples, 92 features
[16:44:03] Batch stats — Input:  mean=0.0523 std=0.2669 min=-5.2129 max=5.1746
[16:44:03] Batch stats — Target: mean=0.0007 std=0.0589 min=-0.3304 max=0.3701
[16:44:03] Batch stats — Cls:    pos_long=111/256 pos_short=96/256
[16:44:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:44:07] Epoch 1/100 | Train: 0.036980 (MSE=0.003782 BCE=0.6640) | Val: 0.043941 (MSE=0.010595 BCE=0.6669) | LR: 1.00e-04 | Best: 0.043941 (ep 1)
[16:44:10] Epoch 2/100 | Train: 0.036183 (MSE=0.003103 BCE=0.6616) | Val: 0.042943 (MSE=0.009601 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042943 (ep 2)
[16:44:13] Epoch 3/100 | Train: 0.036118 (MSE=0.003047 BCE=0.6614) | Val: 0.042651 (MSE=0.009326 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042651 (ep 3)
[16:44:16] Epoch 4/100 | Train: 0.036081 (MSE=0.003018 BCE=0.6612) | Val: 0.042712 (MSE=0.009385 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042651 (ep 3)
[16:44:18] Epoch 5/100 | Train: 0.036046 (MSE=0.002992 BCE=0.6611) | Val: 0.042489 (MSE=0.009156 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042489 (ep 5)
[16:44:21] Epoch 6/100 | Train: 0.036023 (MSE=0.002975 BCE=0.6610) | Val: 0.042485 (MSE=0.009140 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042485 (ep 6)
[16:44:24] Epoch 7/100 | Train: 0.036006 (MSE=0.002961 BCE=0.6609) | Val: 0.042417 (MSE=0.009092 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042417 (ep 7)
[16:44:27] Epoch 8/100 | Train: 0.035989 (MSE=0.002950 BCE=0.6608) | Val: 0.042387 (MSE=0.009070 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[16:44:30] Epoch 9/100 | Train: 0.035980 (MSE=0.002940 BCE=0.6608) | Val: 0.042428 (MSE=0.009096 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042387 (ep 8)
[16:44:33] Epoch 10/100 | Train: 0.035962 (MSE=0.002930 BCE=0.6607) | Val: 0.042354 (MSE=0.009028 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:35] Epoch 11/100 | Train: 0.035948 (MSE=0.002922 BCE=0.6605) | Val: 0.042493 (MSE=0.009146 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:38] Epoch 12/100 | Train: 0.035945 (MSE=0.002915 BCE=0.6606) | Val: 0.042437 (MSE=0.009100 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:41] Epoch 13/100 | Train: 0.035934 (MSE=0.002907 BCE=0.6605) | Val: 0.042532 (MSE=0.009200 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:43] Epoch 14/100 | Train: 0.035922 (MSE=0.002901 BCE=0.6604) | Val: 0.042644 (MSE=0.009300 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:46] Epoch 15/100 | Train: 0.035913 (MSE=0.002895 BCE=0.6604) | Val: 0.042555 (MSE=0.009215 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042354 (ep 10)
[16:44:48] Epoch 16/100 | Train: 0.035905 (MSE=0.002891 BCE=0.6603) | Val: 0.042692 (MSE=0.009341 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042354 (ep 10)
[16:44:50] Epoch 17/100 | Train: 0.035883 (MSE=0.002882 BCE=0.6600) | Val: 0.042831 (MSE=0.009467 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042354 (ep 10)
[16:44:53] Epoch 18/100 | Train: 0.035886 (MSE=0.002879 BCE=0.6601) | Val: 0.042727 (MSE=0.009369 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042354 (ep 10)
[16:44:55] Epoch 19/100 | Train: 0.035874 (MSE=0.002874 BCE=0.6600) | Val: 0.042897 (MSE=0.009528 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042354 (ep 10)
[16:44:57] Epoch 20/100 | Train: 0.035868 (MSE=0.002871 BCE=0.6599) | Val: 0.042991 (MSE=0.009619 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042354 (ep 10)
[16:44:57] Early stopping at epoch 20 (no improvement for 10 epochs)
[16:44:58] Factor 11 done — best val loss: 0.042354 at epoch 10
[16:44:58] 
============================================================
[16:44:58] STF Factor 12 of [6..24]
[16:44:58] ============================================================
[16:44:58] Building features: 0% (1/175846)
[16:44:59] Building features: 5% (8793/175846)
[16:44:59] Building features: 10% (17585/175846)
[16:45:00] Building features: 15% (26377/175846)
[16:45:00] Building features: 20% (35169/175846)
[16:45:01] Building features: 25% (43961/175846)
[16:45:01] Building features: 30% (52753/175846)
[16:45:02] Building features: 35% (61545/175846)
[16:45:02] Building features: 40% (70337/175846)
[16:45:03] Building features: 45% (79129/175846)
[16:45:03] Building features: 50% (87921/175846)
[16:45:04] Building features: 55% (96713/175846)
[16:45:04] Building features: 60% (105505/175846)
[16:45:05] Building features: 65% (114297/175846)
[16:45:05] Building features: 70% (123089/175846)
[16:45:06] Building features: 75% (131881/175846)
[16:45:06] Building features: 80% (140673/175846)
[16:45:07] Building features: 85% (149465/175846)
[16:45:07] Building features: 90% (158257/175846)
[16:45:08] Building features: 95% (167049/175846)
[16:45:08] Building features: 100% (175841/175846)
[16:45:08] Computing Hurst exponent...
[16:45:14] Computing market regimes (GMM)...
[16:45:21] Factor 12: 175724 samples, 92 features
[16:45:23] Batch stats — Input:  mean=0.0522 std=0.2709 min=-3.9536 max=13.1528
[16:45:23] Batch stats — Target: mean=-0.0039 std=0.0701 min=-0.4720 max=0.4134
[16:45:23] Batch stats — Cls:    pos_long=92/256 pos_short=93/256
[16:45:23] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:45:28] Epoch 1/100 | Train: 0.036931 (MSE=0.003697 BCE=0.6647) | Val: 0.043595 (MSE=0.010226 BCE=0.6674) | LR: 1.00e-04 | Best: 0.043595 (ep 1)
[16:45:30] Epoch 2/100 | Train: 0.036180 (MSE=0.003101 BCE=0.6616) | Val: 0.042754 (MSE=0.009406 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042754 (ep 2)
[16:45:33] Epoch 3/100 | Train: 0.036117 (MSE=0.003050 BCE=0.6613) | Val: 0.042519 (MSE=0.009183 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042519 (ep 3)
[16:45:36] Epoch 4/100 | Train: 0.036077 (MSE=0.003016 BCE=0.6612) | Val: 0.042482 (MSE=0.009146 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042482 (ep 4)
[16:45:39] Epoch 5/100 | Train: 0.036045 (MSE=0.002986 BCE=0.6612) | Val: 0.042437 (MSE=0.009117 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042437 (ep 5)
[16:45:41] Epoch 6/100 | Train: 0.036015 (MSE=0.002966 BCE=0.6610) | Val: 0.042373 (MSE=0.009026 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042373 (ep 6)
[16:45:44] Epoch 7/100 | Train: 0.035995 (MSE=0.002948 BCE=0.6609) | Val: 0.042286 (MSE=0.008937 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042286 (ep 7)
[16:45:47] Epoch 8/100 | Train: 0.035981 (MSE=0.002938 BCE=0.6609) | Val: 0.042274 (MSE=0.008938 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042274 (ep 8)
[16:45:49] Epoch 9/100 | Train: 0.035970 (MSE=0.002930 BCE=0.6608) | Val: 0.042254 (MSE=0.008909 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042254 (ep 9)
[16:45:52] Epoch 10/100 | Train: 0.035958 (MSE=0.002918 BCE=0.6608) | Val: 0.042281 (MSE=0.008955 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042254 (ep 9)
[16:45:55] Epoch 11/100 | Train: 0.035945 (MSE=0.002914 BCE=0.6606) | Val: 0.042276 (MSE=0.008939 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042254 (ep 9)
[16:45:58] Epoch 12/100 | Train: 0.035935 (MSE=0.002908 BCE=0.6605) | Val: 0.042223 (MSE=0.008899 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042223 (ep 12)
[16:46:01] Epoch 13/100 | Train: 0.035924 (MSE=0.002899 BCE=0.6605) | Val: 0.042197 (MSE=0.008863 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:03] Epoch 14/100 | Train: 0.035909 (MSE=0.002892 BCE=0.6603) | Val: 0.042253 (MSE=0.008909 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:06] Epoch 15/100 | Train: 0.035909 (MSE=0.002889 BCE=0.6604) | Val: 0.042303 (MSE=0.008956 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:09] Epoch 16/100 | Train: 0.035901 (MSE=0.002884 BCE=0.6603) | Val: 0.042245 (MSE=0.008910 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:12] Epoch 17/100 | Train: 0.035893 (MSE=0.002879 BCE=0.6603) | Val: 0.042308 (MSE=0.008957 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:15] Epoch 18/100 | Train: 0.035887 (MSE=0.002873 BCE=0.6603) | Val: 0.042287 (MSE=0.008949 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042197 (ep 13)
[16:46:18] Epoch 19/100 | Train: 0.035882 (MSE=0.002870 BCE=0.6602) | Val: 0.042454 (MSE=0.009093 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042197 (ep 13)
[16:46:21] Epoch 20/100 | Train: 0.035862 (MSE=0.002863 BCE=0.6600) | Val: 0.042412 (MSE=0.009069 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042197 (ep 13)
[16:46:23] Epoch 21/100 | Train: 0.035859 (MSE=0.002859 BCE=0.6600) | Val: 0.042450 (MSE=0.009106 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042197 (ep 13)
[16:46:26] Epoch 22/100 | Train: 0.035855 (MSE=0.002857 BCE=0.6599) | Val: 0.042378 (MSE=0.009036 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042197 (ep 13)
[16:46:29] Epoch 23/100 | Train: 0.035849 (MSE=0.002853 BCE=0.6599) | Val: 0.042388 (MSE=0.009039 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042197 (ep 13)
[16:46:29] Early stopping at epoch 23 (no improvement for 10 epochs)
[16:46:30] Factor 12 done — best val loss: 0.042197 at epoch 13
[16:46:30] 
============================================================
[16:46:30] STF Factor 13 of [6..24]
[16:46:30] ============================================================
[16:46:30] Building features: 0% (1/175846)
[16:46:31] Building features: 5% (8793/175846)
[16:46:31] Building features: 10% (17585/175846)
[16:46:32] Building features: 15% (26377/175846)
[16:46:32] Building features: 20% (35169/175846)
[16:46:33] Building features: 25% (43961/175846)
[16:46:33] Building features: 30% (52753/175846)
[16:46:34] Building features: 35% (61545/175846)
[16:46:35] Building features: 40% (70337/175846)
[16:46:35] Building features: 45% (79129/175846)
[16:46:36] Building features: 50% (87921/175846)
[16:46:36] Building features: 55% (96713/175846)
[16:46:37] Building features: 60% (105505/175846)
[16:46:38] Building features: 65% (114297/175846)
[16:46:38] Building features: 70% (123089/175846)
[16:46:39] Building features: 75% (131881/175846)
[16:46:39] Building features: 80% (140673/175846)
[16:46:40] Building features: 85% (149465/175846)
[16:46:41] Building features: 90% (158257/175846)
[16:46:41] Building features: 95% (167049/175846)
[16:46:42] Building features: 100% (175841/175846)
[16:46:42] Computing Hurst exponent...
[16:46:47] Computing market regimes (GMM)...
[16:46:55] Factor 13: 175724 samples, 92 features
[16:46:57] Batch stats — Input:  mean=0.0512 std=0.2692 min=-3.6375 max=7.1652
[16:46:57] Batch stats — Target: mean=0.0021 std=0.0678 min=-0.4449 max=0.4134
[16:46:57] Batch stats — Cls:    pos_long=93/256 pos_short=96/256
[16:46:57] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:47:02] Epoch 1/100 | Train: 0.036895 (MSE=0.003696 BCE=0.6640) | Val: 0.044304 (MSE=0.010952 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044304 (ep 1)
[16:47:04] Epoch 2/100 | Train: 0.036181 (MSE=0.003097 BCE=0.6617) | Val: 0.042933 (MSE=0.009580 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042933 (ep 2)
[16:47:07] Epoch 3/100 | Train: 0.036116 (MSE=0.003048 BCE=0.6614) | Val: 0.042660 (MSE=0.009325 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042660 (ep 3)
[16:47:10] Epoch 4/100 | Train: 0.036075 (MSE=0.003013 BCE=0.6612) | Val: 0.042527 (MSE=0.009179 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042527 (ep 4)
[16:47:13] Epoch 5/100 | Train: 0.036045 (MSE=0.002988 BCE=0.6612) | Val: 0.042480 (MSE=0.009147 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042480 (ep 5)
[16:47:15] Epoch 6/100 | Train: 0.036018 (MSE=0.002970 BCE=0.6609) | Val: 0.042497 (MSE=0.009167 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042480 (ep 5)
[16:47:18] Epoch 7/100 | Train: 0.036000 (MSE=0.002954 BCE=0.6609) | Val: 0.042360 (MSE=0.009028 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042360 (ep 7)
[16:47:21] Epoch 8/100 | Train: 0.035978 (MSE=0.002941 BCE=0.6607) | Val: 0.042422 (MSE=0.009090 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042360 (ep 7)
[16:47:24] Epoch 9/100 | Train: 0.035971 (MSE=0.002932 BCE=0.6608) | Val: 0.042394 (MSE=0.009046 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042360 (ep 7)
[16:47:27] Epoch 10/100 | Train: 0.035966 (MSE=0.002924 BCE=0.6608) | Val: 0.042236 (MSE=0.008897 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042236 (ep 10)
[16:47:30] Epoch 11/100 | Train: 0.035948 (MSE=0.002916 BCE=0.6607) | Val: 0.042294 (MSE=0.008931 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042236 (ep 10)
[16:47:32] Epoch 12/100 | Train: 0.035937 (MSE=0.002911 BCE=0.6605) | Val: 0.042293 (MSE=0.008955 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042236 (ep 10)
[16:47:35] Epoch 13/100 | Train: 0.035931 (MSE=0.002902 BCE=0.6606) | Val: 0.042230 (MSE=0.008882 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:37] Epoch 14/100 | Train: 0.035922 (MSE=0.002896 BCE=0.6605) | Val: 0.042266 (MSE=0.008914 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:39] Epoch 15/100 | Train: 0.035915 (MSE=0.002892 BCE=0.6605) | Val: 0.042293 (MSE=0.008943 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:41] Epoch 16/100 | Train: 0.035906 (MSE=0.002885 BCE=0.6604) | Val: 0.042392 (MSE=0.009035 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:44] Epoch 17/100 | Train: 0.035899 (MSE=0.002880 BCE=0.6604) | Val: 0.042273 (MSE=0.008917 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:46] Epoch 18/100 | Train: 0.035885 (MSE=0.002876 BCE=0.6602) | Val: 0.042388 (MSE=0.009033 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[16:47:48] Epoch 19/100 | Train: 0.035877 (MSE=0.002872 BCE=0.6601) | Val: 0.042377 (MSE=0.008993 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[16:47:51] Epoch 20/100 | Train: 0.035873 (MSE=0.002866 BCE=0.6601) | Val: 0.042372 (MSE=0.009008 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[16:47:53] Epoch 21/100 | Train: 0.035858 (MSE=0.002860 BCE=0.6600) | Val: 0.042410 (MSE=0.009053 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[16:47:55] Epoch 22/100 | Train: 0.035860 (MSE=0.002857 BCE=0.6601) | Val: 0.042425 (MSE=0.009062 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[16:47:58] Epoch 23/100 | Train: 0.035850 (MSE=0.002852 BCE=0.6599) | Val: 0.042422 (MSE=0.009051 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[16:47:58] Early stopping at epoch 23 (no improvement for 10 epochs)
[16:47:59] Factor 13 done — best val loss: 0.042230 at epoch 13
[16:47:59] 
============================================================
[16:47:59] STF Factor 14 of [6..24]
[16:47:59] ============================================================
[16:47:59] Building features: 0% (1/175846)
[16:48:00] Building features: 5% (8793/175846)
[16:48:00] Building features: 10% (17585/175846)
[16:48:01] Building features: 15% (26377/175846)
[16:48:01] Building features: 20% (35169/175846)
[16:48:02] Building features: 25% (43961/175846)
[16:48:02] Building features: 30% (52753/175846)
[16:48:03] Building features: 35% (61545/175846)
[16:48:03] Building features: 40% (70337/175846)
[16:48:04] Building features: 45% (79129/175846)
[16:48:04] Building features: 50% (87921/175846)
[16:48:05] Building features: 55% (96713/175846)
[16:48:05] Building features: 60% (105505/175846)
[16:48:06] Building features: 65% (114297/175846)
[16:48:06] Building features: 70% (123089/175846)
[16:48:07] Building features: 75% (131881/175846)
[16:48:07] Building features: 80% (140673/175846)
[16:48:08] Building features: 85% (149465/175846)
[16:48:08] Building features: 90% (158257/175846)
[16:48:09] Building features: 95% (167049/175846)
[16:48:09] Building features: 100% (175841/175846)
[16:48:09] Computing Hurst exponent...
[16:48:14] Computing market regimes (GMM)...
[16:48:21] Factor 14: 175724 samples, 92 features
[16:48:23] Batch stats — Input:  mean=0.0510 std=0.2735 min=-4.9047 max=7.0855
[16:48:23] Batch stats — Target: mean=-0.0010 std=0.0771 min=-0.4595 max=0.4134
[16:48:23] Batch stats — Cls:    pos_long=100/256 pos_short=103/256
[16:48:23] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:48:26] Epoch 1/100 | Train: 0.036902 (MSE=0.003734 BCE=0.6634) | Val: 0.044275 (MSE=0.010932 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044275 (ep 1)
[16:48:29] Epoch 2/100 | Train: 0.036186 (MSE=0.003104 BCE=0.6616) | Val: 0.042910 (MSE=0.009573 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042910 (ep 2)
[16:48:31] Epoch 3/100 | Train: 0.036121 (MSE=0.003055 BCE=0.6613) | Val: 0.042698 (MSE=0.009350 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042698 (ep 3)
[16:48:33] Epoch 4/100 | Train: 0.036078 (MSE=0.003022 BCE=0.6611) | Val: 0.042652 (MSE=0.009318 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042652 (ep 4)
[16:48:36] Epoch 5/100 | Train: 0.036049 (MSE=0.002994 BCE=0.6611) | Val: 0.042512 (MSE=0.009152 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042512 (ep 5)
[16:48:38] Epoch 6/100 | Train: 0.036024 (MSE=0.002977 BCE=0.6609) | Val: 0.042399 (MSE=0.009059 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042399 (ep 6)
[16:48:41] Epoch 7/100 | Train: 0.036007 (MSE=0.002962 BCE=0.6609) | Val: 0.042416 (MSE=0.009076 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042399 (ep 6)
[16:48:43] Epoch 8/100 | Train: 0.035984 (MSE=0.002945 BCE=0.6608) | Val: 0.042450 (MSE=0.009111 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042399 (ep 6)
[16:48:46] Epoch 9/100 | Train: 0.035967 (MSE=0.002933 BCE=0.6607) | Val: 0.042412 (MSE=0.009068 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042399 (ep 6)
[16:48:49] Epoch 10/100 | Train: 0.035959 (MSE=0.002926 BCE=0.6607) | Val: 0.042374 (MSE=0.009011 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:48:52] Epoch 11/100 | Train: 0.035952 (MSE=0.002919 BCE=0.6607) | Val: 0.042378 (MSE=0.009022 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:48:55] Epoch 12/100 | Train: 0.035936 (MSE=0.002907 BCE=0.6606) | Val: 0.042401 (MSE=0.009023 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:48:57] Epoch 13/100 | Train: 0.035932 (MSE=0.002905 BCE=0.6605) | Val: 0.042433 (MSE=0.009082 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:49:00] Epoch 14/100 | Train: 0.035919 (MSE=0.002898 BCE=0.6604) | Val: 0.042403 (MSE=0.009054 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:49:03] Epoch 15/100 | Train: 0.035914 (MSE=0.002894 BCE=0.6604) | Val: 0.042418 (MSE=0.009061 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042374 (ep 10)
[16:49:06] Epoch 16/100 | Train: 0.035902 (MSE=0.002887 BCE=0.6603) | Val: 0.042517 (MSE=0.009135 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042374 (ep 10)
[16:49:08] Epoch 17/100 | Train: 0.035887 (MSE=0.002876 BCE=0.6602) | Val: 0.042705 (MSE=0.009338 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042374 (ep 10)
[16:49:11] Epoch 18/100 | Train: 0.035881 (MSE=0.002874 BCE=0.6601) | Val: 0.042623 (MSE=0.009266 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042374 (ep 10)
[16:49:14] Epoch 19/100 | Train: 0.035875 (MSE=0.002869 BCE=0.6601) | Val: 0.042712 (MSE=0.009349 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042374 (ep 10)
[16:49:17] Epoch 20/100 | Train: 0.035873 (MSE=0.002870 BCE=0.6601) | Val: 0.042874 (MSE=0.009509 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042374 (ep 10)
[16:49:17] Early stopping at epoch 20 (no improvement for 10 epochs)
[16:49:18] Factor 14 done — best val loss: 0.042374 at epoch 10
[16:49:18] 
============================================================
[16:49:18] STF Factor 15 of [6..24]
[16:49:18] ============================================================
[16:49:18] Building features: 0% (1/175846)
[16:49:18] Building features: 5% (8793/175846)
[16:49:19] Building features: 10% (17585/175846)
[16:49:20] Building features: 15% (26377/175846)
[16:49:20] Building features: 20% (35169/175846)
[16:49:21] Building features: 25% (43961/175846)
[16:49:21] Building features: 30% (52753/175846)
[16:49:22] Building features: 35% (61545/175846)
[16:49:22] Building features: 40% (70337/175846)
[16:49:23] Building features: 45% (79129/175846)
[16:49:24] Building features: 50% (87921/175846)
[16:49:24] Building features: 55% (96713/175846)
[16:49:25] Building features: 60% (105505/175846)
[16:49:25] Building features: 65% (114297/175846)
[16:49:26] Building features: 70% (123089/175846)
[16:49:27] Building features: 75% (131881/175846)
[16:49:27] Building features: 80% (140673/175846)
[16:49:28] Building features: 85% (149465/175846)
[16:49:28] Building features: 90% (158257/175846)
[16:49:29] Building features: 95% (167049/175846)
[16:49:29] Building features: 100% (175841/175846)
[16:49:29] Computing Hurst exponent...
[16:49:35] Computing market regimes (GMM)...
[16:49:43] Factor 15: 175724 samples, 92 features
[16:49:44] Batch stats — Input:  mean=0.0513 std=0.2719 min=-4.5653 max=12.6954
[16:49:44] Batch stats — Target: mean=-0.0040 std=0.0748 min=-0.4720 max=0.4134
[16:49:44] Batch stats — Cls:    pos_long=90/256 pos_short=95/256
[16:49:44] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:49:49] Epoch 1/100 | Train: 0.036900 (MSE=0.003735 BCE=0.6633) | Val: 0.044324 (MSE=0.010977 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044324 (ep 1)
[16:49:52] Epoch 2/100 | Train: 0.036176 (MSE=0.003095 BCE=0.6616) | Val: 0.042829 (MSE=0.009497 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042829 (ep 2)
[16:49:55] Epoch 3/100 | Train: 0.036116 (MSE=0.003046 BCE=0.6614) | Val: 0.042568 (MSE=0.009225 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042568 (ep 3)
[16:49:57] Epoch 4/100 | Train: 0.036075 (MSE=0.003013 BCE=0.6613) | Val: 0.042517 (MSE=0.009188 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042517 (ep 4)
[16:50:00] Epoch 5/100 | Train: 0.036035 (MSE=0.002984 BCE=0.6610) | Val: 0.042487 (MSE=0.009159 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042487 (ep 5)
[16:50:03] Epoch 6/100 | Train: 0.036015 (MSE=0.002968 BCE=0.6609) | Val: 0.042421 (MSE=0.009094 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042421 (ep 6)
[16:50:06] Epoch 7/100 | Train: 0.035995 (MSE=0.002954 BCE=0.6608) | Val: 0.042397 (MSE=0.009064 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042397 (ep 7)
[16:50:08] Epoch 8/100 | Train: 0.035979 (MSE=0.002941 BCE=0.6608) | Val: 0.042335 (MSE=0.008980 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042335 (ep 8)
[16:50:11] Epoch 9/100 | Train: 0.035972 (MSE=0.002934 BCE=0.6608) | Val: 0.042302 (MSE=0.008961 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042302 (ep 9)
[16:50:14] Epoch 10/100 | Train: 0.035956 (MSE=0.002921 BCE=0.6607) | Val: 0.042333 (MSE=0.008976 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042302 (ep 9)
[16:50:17] Epoch 11/100 | Train: 0.035946 (MSE=0.002915 BCE=0.6606) | Val: 0.042318 (MSE=0.008982 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042302 (ep 9)
[16:50:20] Epoch 12/100 | Train: 0.035936 (MSE=0.002909 BCE=0.6606) | Val: 0.042299 (MSE=0.008942 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042299 (ep 12)
[16:50:23] Epoch 13/100 | Train: 0.035924 (MSE=0.002902 BCE=0.6604) | Val: 0.042396 (MSE=0.009041 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042299 (ep 12)
[16:50:25] Epoch 14/100 | Train: 0.035915 (MSE=0.002896 BCE=0.6604) | Val: 0.042411 (MSE=0.009046 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042299 (ep 12)
[16:50:28] Epoch 15/100 | Train: 0.035907 (MSE=0.002891 BCE=0.6603) | Val: 0.042497 (MSE=0.009148 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:30] Epoch 16/100 | Train: 0.035894 (MSE=0.002882 BCE=0.6602) | Val: 0.042785 (MSE=0.009423 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:32] Epoch 17/100 | Train: 0.035887 (MSE=0.002880 BCE=0.6602) | Val: 0.042894 (MSE=0.009511 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:35] Epoch 18/100 | Train: 0.035879 (MSE=0.002874 BCE=0.6601) | Val: 0.042823 (MSE=0.009450 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:37] Epoch 19/100 | Train: 0.035878 (MSE=0.002873 BCE=0.6601) | Val: 0.043149 (MSE=0.009775 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:39] Epoch 20/100 | Train: 0.035874 (MSE=0.002872 BCE=0.6600) | Val: 0.043003 (MSE=0.009629 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042299 (ep 12)
[16:50:42] Epoch 21/100 | Train: 0.035871 (MSE=0.002868 BCE=0.6601) | Val: 0.043093 (MSE=0.009719 BCE=0.6675) | LR: 2.50e-05 | Best: 0.042299 (ep 12)
[16:50:44] Epoch 22/100 | Train: 0.035854 (MSE=0.002865 BCE=0.6598) | Val: 0.043293 (MSE=0.009918 BCE=0.6675) | LR: 2.50e-05 | Best: 0.042299 (ep 12)
[16:50:44] Early stopping at epoch 22 (no improvement for 10 epochs)
[16:50:45] Factor 15 done — best val loss: 0.042299 at epoch 12
[16:50:45] 
============================================================
[16:50:45] STF Factor 16 of [6..24]
[16:50:45] ============================================================
[16:50:45] Building features: 0% (1/175846)
[16:50:45] Building features: 5% (8793/175846)
[16:50:46] Building features: 10% (17585/175846)
[16:50:46] Building features: 15% (26377/175846)
[16:50:47] Building features: 20% (35169/175846)
[16:50:47] Building features: 25% (43961/175846)
[16:50:48] Building features: 30% (52753/175846)
[16:50:48] Building features: 35% (61545/175846)
[16:50:49] Building features: 40% (70337/175846)
[16:50:49] Building features: 45% (79129/175846)
[16:50:50] Building features: 50% (87921/175846)
[16:50:50] Building features: 55% (96713/175846)
[16:50:51] Building features: 60% (105505/175846)
[16:50:51] Building features: 65% (114297/175846)
[16:50:52] Building features: 70% (123089/175846)
[16:50:52] Building features: 75% (131881/175846)
[16:50:53] Building features: 80% (140673/175846)
[16:50:53] Building features: 85% (149465/175846)
[16:50:54] Building features: 90% (158257/175846)
[16:50:54] Building features: 95% (167049/175846)
[16:50:55] Building features: 100% (175841/175846)
[16:50:55] Computing Hurst exponent...
[16:51:00] Computing market regimes (GMM)...
[16:51:07] Factor 16: 175724 samples, 92 features
[16:51:09] Batch stats — Input:  mean=0.0520 std=0.2693 min=-4.4488 max=7.0012
[16:51:09] Batch stats — Target: mean=0.0014 std=0.0645 min=-0.4720 max=0.3524
[16:51:09] Batch stats — Cls:    pos_long=107/256 pos_short=92/256
[16:51:09] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:51:14] Epoch 1/100 | Train: 0.037248 (MSE=0.004028 BCE=0.6644) | Val: 0.044703 (MSE=0.011347 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044703 (ep 1)
[16:51:17] Epoch 2/100 | Train: 0.036214 (MSE=0.003126 BCE=0.6618) | Val: 0.043072 (MSE=0.009724 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043072 (ep 2)
[16:51:19] Epoch 3/100 | Train: 0.036131 (MSE=0.003062 BCE=0.6614) | Val: 0.042738 (MSE=0.009409 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042738 (ep 3)
[16:51:22] Epoch 4/100 | Train: 0.036088 (MSE=0.003030 BCE=0.6612) | Val: 0.042590 (MSE=0.009256 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042590 (ep 4)
[16:51:25] Epoch 5/100 | Train: 0.036054 (MSE=0.003001 BCE=0.6611) | Val: 0.042539 (MSE=0.009181 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042539 (ep 5)
[16:51:28] Epoch 6/100 | Train: 0.036031 (MSE=0.002981 BCE=0.6610) | Val: 0.042482 (MSE=0.009146 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042482 (ep 6)
[16:51:30] Epoch 7/100 | Train: 0.036008 (MSE=0.002966 BCE=0.6608) | Val: 0.042363 (MSE=0.009023 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042363 (ep 7)
[16:51:33] Epoch 8/100 | Train: 0.035992 (MSE=0.002950 BCE=0.6608) | Val: 0.042370 (MSE=0.009035 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042363 (ep 7)
[16:51:36] Epoch 9/100 | Train: 0.035975 (MSE=0.002940 BCE=0.6607) | Val: 0.042351 (MSE=0.009013 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:39] Epoch 10/100 | Train: 0.035966 (MSE=0.002932 BCE=0.6607) | Val: 0.042438 (MSE=0.009077 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:41] Epoch 11/100 | Train: 0.035948 (MSE=0.002922 BCE=0.6605) | Val: 0.042449 (MSE=0.009085 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:44] Epoch 12/100 | Train: 0.035943 (MSE=0.002918 BCE=0.6605) | Val: 0.042635 (MSE=0.009255 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:47] Epoch 13/100 | Train: 0.035931 (MSE=0.002912 BCE=0.6604) | Val: 0.042860 (MSE=0.009462 BCE=0.6680) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:50] Epoch 14/100 | Train: 0.035925 (MSE=0.002905 BCE=0.6604) | Val: 0.042822 (MSE=0.009444 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042351 (ep 9)
[16:51:53] Epoch 15/100 | Train: 0.035918 (MSE=0.002900 BCE=0.6603) | Val: 0.042926 (MSE=0.009520 BCE=0.6681) | LR: 5.00e-05 | Best: 0.042351 (ep 9)
[16:51:55] Epoch 16/100 | Train: 0.035899 (MSE=0.002892 BCE=0.6601) | Val: 0.043077 (MSE=0.009689 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042351 (ep 9)
[16:51:58] Epoch 17/100 | Train: 0.035891 (MSE=0.002888 BCE=0.6601) | Val: 0.042976 (MSE=0.009595 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042351 (ep 9)
[16:52:01] Epoch 18/100 | Train: 0.035887 (MSE=0.002884 BCE=0.6601) | Val: 0.043220 (MSE=0.009830 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042351 (ep 9)
[16:52:03] Epoch 19/100 | Train: 0.035884 (MSE=0.002884 BCE=0.6600) | Val: 0.043068 (MSE=0.009662 BCE=0.6681) | LR: 5.00e-05 | Best: 0.042351 (ep 9)
[16:52:03] Early stopping at epoch 19 (no improvement for 10 epochs)
[16:52:04] Factor 16 done — best val loss: 0.042351 at epoch 9
[16:52:04] 
============================================================
[16:52:04] STF Factor 17 of [6..24]
[16:52:04] ============================================================
[16:52:04] Building features: 0% (1/175846)
[16:52:05] Building features: 5% (8793/175846)
[16:52:05] Building features: 10% (17585/175846)
[16:52:06] Building features: 15% (26377/175846)
[16:52:06] Building features: 20% (35169/175846)
[16:52:07] Building features: 25% (43961/175846)
[16:52:07] Building features: 30% (52753/175846)
[16:52:08] Building features: 35% (61545/175846)
[16:52:08] Building features: 40% (70337/175846)
[16:52:09] Building features: 45% (79129/175846)
[16:52:09] Building features: 50% (87921/175846)
[16:52:10] Building features: 55% (96713/175846)
[16:52:10] Building features: 60% (105505/175846)
[16:52:11] Building features: 65% (114297/175846)
[16:52:11] Building features: 70% (123089/175846)
[16:52:12] Building features: 75% (131881/175846)
[16:52:12] Building features: 80% (140673/175846)
[16:52:13] Building features: 85% (149465/175846)
[16:52:13] Building features: 90% (158257/175846)
[16:52:14] Building features: 95% (167049/175846)
[16:52:14] Building features: 100% (175841/175846)
[16:52:14] Computing Hurst exponent...
[16:52:19] Computing market regimes (GMM)...
[16:52:27] Factor 17: 175724 samples, 92 features
[16:52:29] Batch stats — Input:  mean=0.0515 std=0.2699 min=-4.2974 max=6.1942
[16:52:29] Batch stats — Target: mean=0.0000 std=0.0666 min=-0.4720 max=0.3454
[16:52:29] Batch stats — Cls:    pos_long=122/256 pos_short=89/256
[16:52:29] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:52:34] Epoch 1/100 | Train: 0.037236 (MSE=0.003976 BCE=0.6652) | Val: 0.044441 (MSE=0.011090 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044441 (ep 1)
[16:52:36] Epoch 2/100 | Train: 0.036199 (MSE=0.003116 BCE=0.6617) | Val: 0.043147 (MSE=0.009813 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043147 (ep 2)
[16:52:39] Epoch 3/100 | Train: 0.036124 (MSE=0.003057 BCE=0.6613) | Val: 0.042654 (MSE=0.009333 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042654 (ep 3)
[16:52:42] Epoch 4/100 | Train: 0.036084 (MSE=0.003024 BCE=0.6612) | Val: 0.042608 (MSE=0.009289 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042608 (ep 4)
[16:52:45] Epoch 5/100 | Train: 0.036049 (MSE=0.002995 BCE=0.6611) | Val: 0.042571 (MSE=0.009237 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042571 (ep 5)
[16:52:47] Epoch 6/100 | Train: 0.036023 (MSE=0.002974 BCE=0.6610) | Val: 0.042450 (MSE=0.009111 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042450 (ep 6)
[16:52:50] Epoch 7/100 | Train: 0.036006 (MSE=0.002956 BCE=0.6610) | Val: 0.042536 (MSE=0.009194 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042450 (ep 6)
[16:52:52] Epoch 8/100 | Train: 0.035985 (MSE=0.002941 BCE=0.6609) | Val: 0.042423 (MSE=0.009066 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042423 (ep 8)
[16:52:55] Epoch 9/100 | Train: 0.035973 (MSE=0.002930 BCE=0.6609) | Val: 0.042379 (MSE=0.009043 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:52:57] Epoch 10/100 | Train: 0.035959 (MSE=0.002921 BCE=0.6607) | Val: 0.042472 (MSE=0.009131 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:52:59] Epoch 11/100 | Train: 0.035944 (MSE=0.002916 BCE=0.6606) | Val: 0.042658 (MSE=0.009297 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:53:02] Epoch 12/100 | Train: 0.035931 (MSE=0.002905 BCE=0.6605) | Val: 0.042720 (MSE=0.009375 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:53:04] Epoch 13/100 | Train: 0.035927 (MSE=0.002900 BCE=0.6605) | Val: 0.042802 (MSE=0.009446 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:53:06] Epoch 14/100 | Train: 0.035915 (MSE=0.002893 BCE=0.6604) | Val: 0.042945 (MSE=0.009588 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[16:53:09] Epoch 15/100 | Train: 0.035910 (MSE=0.002885 BCE=0.6605) | Val: 0.043110 (MSE=0.009733 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042379 (ep 9)
[16:53:12] Epoch 16/100 | Train: 0.035887 (MSE=0.002875 BCE=0.6602) | Val: 0.043274 (MSE=0.009895 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042379 (ep 9)
[16:53:15] Epoch 17/100 | Train: 0.035883 (MSE=0.002874 BCE=0.6602) | Val: 0.043142 (MSE=0.009775 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042379 (ep 9)
[16:53:17] Epoch 18/100 | Train: 0.035875 (MSE=0.002867 BCE=0.6602) | Val: 0.043485 (MSE=0.010092 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042379 (ep 9)
[16:53:20] Epoch 19/100 | Train: 0.035872 (MSE=0.002864 BCE=0.6602) | Val: 0.043000 (MSE=0.009633 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042379 (ep 9)
[16:53:20] Early stopping at epoch 19 (no improvement for 10 epochs)
[16:53:21] Factor 17 done — best val loss: 0.042379 at epoch 9
[16:53:21] 
============================================================
[16:53:21] STF Factor 18 of [6..24]
[16:53:21] ============================================================
[16:53:21] Building features: 0% (1/175846)
[16:53:22] Building features: 5% (8793/175846)
[16:53:22] Building features: 10% (17585/175846)
[16:53:23] Building features: 15% (26377/175846)
[16:53:23] Building features: 20% (35169/175846)
[16:53:24] Building features: 25% (43961/175846)
[16:53:25] Building features: 30% (52753/175846)
[16:53:25] Building features: 35% (61545/175846)
[16:53:26] Building features: 40% (70337/175846)
[16:53:26] Building features: 45% (79129/175846)
[16:53:27] Building features: 50% (87921/175846)
[16:53:27] Building features: 55% (96713/175846)
[16:53:28] Building features: 60% (105505/175846)
[16:53:28] Building features: 65% (114297/175846)
[16:53:29] Building features: 70% (123089/175846)
[16:53:29] Building features: 75% (131881/175846)
[16:53:30] Building features: 80% (140673/175846)
[16:53:30] Building features: 85% (149465/175846)
[16:53:31] Building features: 90% (158257/175846)
[16:53:31] Building features: 95% (167049/175846)
[16:53:31] Building features: 100% (175841/175846)
[16:53:32] Computing Hurst exponent...
[16:53:36] Computing market regimes (GMM)...
[16:53:43] Factor 18: 175724 samples, 92 features
[16:53:45] Batch stats — Input:  mean=0.0521 std=0.2709 min=-4.4026 max=5.8547
[16:53:45] Batch stats — Target: mean=-0.0019 std=0.0693 min=-0.4720 max=0.4134
[16:53:45] Batch stats — Cls:    pos_long=96/256 pos_short=88/256
[16:53:45] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:53:49] Epoch 1/100 | Train: 0.036995 (MSE=0.003824 BCE=0.6634) | Val: 0.043882 (MSE=0.010531 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043882 (ep 1)
[16:53:52] Epoch 2/100 | Train: 0.036172 (MSE=0.003091 BCE=0.6616) | Val: 0.042835 (MSE=0.009501 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042835 (ep 2)
[16:53:54] Epoch 3/100 | Train: 0.036109 (MSE=0.003046 BCE=0.6613) | Val: 0.042610 (MSE=0.009292 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042610 (ep 3)
[16:53:57] Epoch 4/100 | Train: 0.036073 (MSE=0.003018 BCE=0.6611) | Val: 0.042503 (MSE=0.009181 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042503 (ep 4)
[16:54:00] Epoch 5/100 | Train: 0.036047 (MSE=0.002995 BCE=0.6610) | Val: 0.042469 (MSE=0.009141 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042469 (ep 5)
[16:54:03] Epoch 6/100 | Train: 0.036020 (MSE=0.002972 BCE=0.6610) | Val: 0.042385 (MSE=0.009060 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042385 (ep 6)
[16:54:06] Epoch 7/100 | Train: 0.036001 (MSE=0.002958 BCE=0.6609) | Val: 0.042402 (MSE=0.009062 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042385 (ep 6)
[16:54:09] Epoch 8/100 | Train: 0.035976 (MSE=0.002943 BCE=0.6607) | Val: 0.042323 (MSE=0.008997 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042323 (ep 8)
[16:54:11] Epoch 9/100 | Train: 0.035968 (MSE=0.002932 BCE=0.6607) | Val: 0.042419 (MSE=0.009082 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042323 (ep 8)
[16:54:14] Epoch 10/100 | Train: 0.035956 (MSE=0.002924 BCE=0.6606) | Val: 0.042307 (MSE=0.008983 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:17] Epoch 11/100 | Train: 0.035945 (MSE=0.002916 BCE=0.6606) | Val: 0.042319 (MSE=0.008994 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:19] Epoch 12/100 | Train: 0.035931 (MSE=0.002909 BCE=0.6604) | Val: 0.042488 (MSE=0.009150 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:22] Epoch 13/100 | Train: 0.035927 (MSE=0.002903 BCE=0.6605) | Val: 0.042541 (MSE=0.009208 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:25] Epoch 14/100 | Train: 0.035914 (MSE=0.002897 BCE=0.6603) | Val: 0.042654 (MSE=0.009325 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:28] Epoch 15/100 | Train: 0.035911 (MSE=0.002893 BCE=0.6604) | Val: 0.042480 (MSE=0.009151 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042307 (ep 10)
[16:54:30] Epoch 16/100 | Train: 0.035900 (MSE=0.002887 BCE=0.6603) | Val: 0.042594 (MSE=0.009260 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042307 (ep 10)
[16:54:33] Epoch 17/100 | Train: 0.035885 (MSE=0.002879 BCE=0.6601) | Val: 0.042802 (MSE=0.009447 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042307 (ep 10)
[16:54:35] Epoch 18/100 | Train: 0.035873 (MSE=0.002871 BCE=0.6600) | Val: 0.042824 (MSE=0.009480 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042307 (ep 10)
[16:54:38] Epoch 19/100 | Train: 0.035871 (MSE=0.002873 BCE=0.6600) | Val: 0.042907 (MSE=0.009563 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042307 (ep 10)
[16:54:41] Epoch 20/100 | Train: 0.035867 (MSE=0.002870 BCE=0.6599) | Val: 0.043005 (MSE=0.009665 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042307 (ep 10)
[16:54:41] Early stopping at epoch 20 (no improvement for 10 epochs)
[16:54:42] Factor 18 done — best val loss: 0.042307 at epoch 10
[16:54:42] 
============================================================
[16:54:42] STF Factor 19 of [6..24]
[16:54:42] ============================================================
[16:54:42] Building features: 0% (1/175846)
[16:54:43] Building features: 5% (8793/175846)
[16:54:43] Building features: 10% (17585/175846)
[16:54:44] Building features: 15% (26377/175846)
[16:54:44] Building features: 20% (35169/175846)
[16:54:45] Building features: 25% (43961/175846)
[16:54:45] Building features: 30% (52753/175846)
[16:54:46] Building features: 35% (61545/175846)
[16:54:46] Building features: 40% (70337/175846)
[16:54:47] Building features: 45% (79129/175846)
[16:54:47] Building features: 50% (87921/175846)
[16:54:48] Building features: 55% (96713/175846)
[16:54:49] Building features: 60% (105505/175846)
[16:54:49] Building features: 65% (114297/175846)
[16:54:50] Building features: 70% (123089/175846)
[16:54:50] Building features: 75% (131881/175846)
[16:54:51] Building features: 80% (140673/175846)
[16:54:51] Building features: 85% (149465/175846)
[16:54:52] Building features: 90% (158257/175846)
[16:54:52] Building features: 95% (167049/175846)
[16:54:53] Building features: 100% (175841/175846)
[16:54:53] Computing Hurst exponent...
[16:54:58] Computing market regimes (GMM)...
[16:55:05] Factor 19: 175724 samples, 92 features
[16:55:07] Batch stats — Input:  mean=0.0525 std=0.2732 min=-6.9747 max=15.9549
[16:55:07] Batch stats — Target: mean=-0.0003 std=0.0645 min=-0.4166 max=0.4134
[16:55:07] Batch stats — Cls:    pos_long=102/256 pos_short=99/256
[16:55:07] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:55:12] Epoch 1/100 | Train: 0.036968 (MSE=0.003782 BCE=0.6637) | Val: 0.044379 (MSE=0.011033 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044379 (ep 1)
[16:55:15] Epoch 2/100 | Train: 0.036173 (MSE=0.003098 BCE=0.6615) | Val: 0.042966 (MSE=0.009634 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042966 (ep 2)
[16:55:18] Epoch 3/100 | Train: 0.036114 (MSE=0.003048 BCE=0.6613) | Val: 0.042652 (MSE=0.009331 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042652 (ep 3)
[16:55:20] Epoch 4/100 | Train: 0.036070 (MSE=0.003014 BCE=0.6611) | Val: 0.042535 (MSE=0.009212 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042535 (ep 4)
[16:55:23] Epoch 5/100 | Train: 0.036040 (MSE=0.002990 BCE=0.6610) | Val: 0.042564 (MSE=0.009226 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042535 (ep 4)
[16:55:26] Epoch 6/100 | Train: 0.036014 (MSE=0.002972 BCE=0.6608) | Val: 0.042525 (MSE=0.009190 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042525 (ep 6)
[16:55:29] Epoch 7/100 | Train: 0.035995 (MSE=0.002955 BCE=0.6608) | Val: 0.042498 (MSE=0.009144 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:32] Epoch 8/100 | Train: 0.035978 (MSE=0.002943 BCE=0.6607) | Val: 0.042511 (MSE=0.009121 BCE=0.6678) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:34] Epoch 9/100 | Train: 0.035970 (MSE=0.002934 BCE=0.6607) | Val: 0.042613 (MSE=0.009265 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:37] Epoch 10/100 | Train: 0.035953 (MSE=0.002923 BCE=0.6606) | Val: 0.042554 (MSE=0.009212 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:40] Epoch 11/100 | Train: 0.035945 (MSE=0.002917 BCE=0.6606) | Val: 0.042672 (MSE=0.009311 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:43] Epoch 12/100 | Train: 0.035933 (MSE=0.002908 BCE=0.6605) | Val: 0.042564 (MSE=0.009214 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042498 (ep 7)
[16:55:46] Epoch 13/100 | Train: 0.035923 (MSE=0.002901 BCE=0.6605) | Val: 0.042638 (MSE=0.009282 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042498 (ep 7)
[16:55:49] Epoch 14/100 | Train: 0.035907 (MSE=0.002890 BCE=0.6603) | Val: 0.042753 (MSE=0.009391 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042498 (ep 7)
[16:55:51] Epoch 15/100 | Train: 0.035903 (MSE=0.002886 BCE=0.6603) | Val: 0.042819 (MSE=0.009446 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042498 (ep 7)
[16:55:54] Epoch 16/100 | Train: 0.035899 (MSE=0.002886 BCE=0.6603) | Val: 0.042816 (MSE=0.009456 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042498 (ep 7)
[16:55:57] Epoch 17/100 | Train: 0.035893 (MSE=0.002879 BCE=0.6603) | Val: 0.042918 (MSE=0.009544 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042498 (ep 7)
[16:55:57] Early stopping at epoch 17 (no improvement for 10 epochs)
[16:55:58] Factor 19 done — best val loss: 0.042498 at epoch 7
[16:55:58] 
============================================================
[16:55:58] STF Factor 20 of [6..24]
[16:55:58] ============================================================
[16:55:58] Building features: 0% (1/175846)
[16:55:59] Building features: 5% (8793/175846)
[16:55:59] Building features: 10% (17585/175846)
[16:56:00] Building features: 15% (26377/175846)
[16:56:01] Building features: 20% (35169/175846)
[16:56:01] Building features: 25% (43961/175846)
[16:56:02] Building features: 30% (52753/175846)
[16:56:02] Building features: 35% (61545/175846)
[16:56:03] Building features: 40% (70337/175846)
[16:56:03] Building features: 45% (79129/175846)
[16:56:04] Building features: 50% (87921/175846)
[16:56:04] Building features: 55% (96713/175846)
[16:56:05] Building features: 60% (105505/175846)
[16:56:05] Building features: 65% (114297/175846)
[16:56:06] Building features: 70% (123089/175846)
[16:56:06] Building features: 75% (131881/175846)
[16:56:07] Building features: 80% (140673/175846)
[16:56:08] Building features: 85% (149465/175846)
[16:56:08] Building features: 90% (158257/175846)
[16:56:09] Building features: 95% (167049/175846)
[16:56:09] Building features: 100% (175841/175846)
[16:56:09] Computing Hurst exponent...
[16:56:15] Computing market regimes (GMM)...
[16:56:22] Factor 20: 175724 samples, 92 features
[16:56:24] Batch stats — Input:  mean=0.0534 std=0.2737 min=-3.8493 max=7.2633
[16:56:24] Batch stats — Target: mean=0.0027 std=0.0724 min=-0.4720 max=0.4134
[16:56:24] Batch stats — Cls:    pos_long=102/256 pos_short=88/256
[16:56:24] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:56:29] Epoch 1/100 | Train: 0.037101 (MSE=0.003878 BCE=0.6645) | Val: 0.044698 (MSE=0.011302 BCE=0.6679) | LR: 1.00e-04 | Best: 0.044698 (ep 1)
[16:56:31] Epoch 2/100 | Train: 0.036189 (MSE=0.003105 BCE=0.6617) | Val: 0.043264 (MSE=0.009882 BCE=0.6676) | LR: 1.00e-04 | Best: 0.043264 (ep 2)
[16:56:34] Epoch 3/100 | Train: 0.036127 (MSE=0.003055 BCE=0.6614) | Val: 0.042764 (MSE=0.009408 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042764 (ep 3)
[16:56:37] Epoch 4/100 | Train: 0.036080 (MSE=0.003023 BCE=0.6611) | Val: 0.042574 (MSE=0.009226 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042574 (ep 4)
[16:56:40] Epoch 5/100 | Train: 0.036055 (MSE=0.002997 BCE=0.6612) | Val: 0.042566 (MSE=0.009203 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042566 (ep 5)
[16:56:43] Epoch 6/100 | Train: 0.036029 (MSE=0.002978 BCE=0.6610) | Val: 0.042453 (MSE=0.009087 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042453 (ep 6)
[16:56:46] Epoch 7/100 | Train: 0.036006 (MSE=0.002960 BCE=0.6609) | Val: 0.042366 (MSE=0.009045 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042366 (ep 7)
[16:56:48] Epoch 8/100 | Train: 0.035988 (MSE=0.002949 BCE=0.6608) | Val: 0.042367 (MSE=0.009007 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042366 (ep 7)
[16:56:51] Epoch 9/100 | Train: 0.035978 (MSE=0.002938 BCE=0.6608) | Val: 0.042285 (MSE=0.008958 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042285 (ep 9)
[16:56:54] Epoch 10/100 | Train: 0.035960 (MSE=0.002925 BCE=0.6607) | Val: 0.042304 (MSE=0.008962 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042285 (ep 9)
[16:56:57] Epoch 11/100 | Train: 0.035953 (MSE=0.002919 BCE=0.6607) | Val: 0.042284 (MSE=0.008943 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[16:57:00] Epoch 12/100 | Train: 0.035943 (MSE=0.002914 BCE=0.6606) | Val: 0.042335 (MSE=0.008987 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[16:57:03] Epoch 13/100 | Train: 0.035928 (MSE=0.002904 BCE=0.6605) | Val: 0.042357 (MSE=0.009021 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[16:57:06] Epoch 14/100 | Train: 0.035918 (MSE=0.002897 BCE=0.6604) | Val: 0.042436 (MSE=0.009088 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042284 (ep 11)
[16:57:09] Epoch 15/100 | Train: 0.035912 (MSE=0.002891 BCE=0.6604) | Val: 0.042484 (MSE=0.009130 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:12] Epoch 16/100 | Train: 0.035895 (MSE=0.002883 BCE=0.6602) | Val: 0.042523 (MSE=0.009161 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:14] Epoch 17/100 | Train: 0.035892 (MSE=0.002880 BCE=0.6602) | Val: 0.042578 (MSE=0.009211 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:17] Epoch 18/100 | Train: 0.035881 (MSE=0.002875 BCE=0.6601) | Val: 0.042557 (MSE=0.009206 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:20] Epoch 19/100 | Train: 0.035879 (MSE=0.002873 BCE=0.6601) | Val: 0.042534 (MSE=0.009181 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:23] Epoch 20/100 | Train: 0.035873 (MSE=0.002869 BCE=0.6601) | Val: 0.042610 (MSE=0.009253 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042284 (ep 11)
[16:57:26] Epoch 21/100 | Train: 0.035872 (MSE=0.002868 BCE=0.6601) | Val: 0.042744 (MSE=0.009385 BCE=0.6672) | LR: 2.50e-05 | Best: 0.042284 (ep 11)
[16:57:26] Early stopping at epoch 21 (no improvement for 10 epochs)
[16:57:27] Factor 20 done — best val loss: 0.042284 at epoch 11
[16:57:27] 
============================================================
[16:57:27] STF Factor 21 of [6..24]
[16:57:27] ============================================================
[16:57:27] Building features: 0% (1/175846)
[16:57:28] Building features: 5% (8793/175846)
[16:57:28] Building features: 10% (17585/175846)
[16:57:29] Building features: 15% (26377/175846)
[16:57:29] Building features: 20% (35169/175846)
[16:57:30] Building features: 25% (43961/175846)
[16:57:30] Building features: 30% (52753/175846)
[16:57:31] Building features: 35% (61545/175846)
[16:57:32] Building features: 40% (70337/175846)
[16:57:32] Building features: 45% (79129/175846)
[16:57:33] Building features: 50% (87921/175846)
[16:57:33] Building features: 55% (96713/175846)
[16:57:34] Building features: 60% (105505/175846)
[16:57:34] Building features: 65% (114297/175846)
[16:57:35] Building features: 70% (123089/175846)
[16:57:36] Building features: 75% (131881/175846)
[16:57:36] Building features: 80% (140673/175846)
[16:57:37] Building features: 85% (149465/175846)
[16:57:37] Building features: 90% (158257/175846)
[16:57:38] Building features: 95% (167049/175846)
[16:57:38] Building features: 100% (175841/175846)
[16:57:38] Computing Hurst exponent...
[16:57:44] Computing market regimes (GMM)...
[16:57:51] Factor 21: 175724 samples, 92 features
[16:57:53] Batch stats — Input:  mean=0.0516 std=0.2705 min=-4.2291 max=7.0895
[16:57:53] Batch stats — Target: mean=-0.0035 std=0.0643 min=-0.4720 max=0.4134
[16:57:53] Batch stats — Cls:    pos_long=93/256 pos_short=101/256
[16:57:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:57:58] Epoch 1/100 | Train: 0.037060 (MSE=0.003879 BCE=0.6636) | Val: 0.044340 (MSE=0.010968 BCE=0.6674) | LR: 1.00e-04 | Best: 0.044340 (ep 1)
[16:58:01] Epoch 2/100 | Train: 0.036195 (MSE=0.003113 BCE=0.6617) | Val: 0.043190 (MSE=0.009849 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043190 (ep 2)
[16:58:04] Epoch 3/100 | Train: 0.036127 (MSE=0.003056 BCE=0.6614) | Val: 0.042776 (MSE=0.009424 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042776 (ep 3)
[16:58:07] Epoch 4/100 | Train: 0.036085 (MSE=0.003025 BCE=0.6612) | Val: 0.042618 (MSE=0.009275 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042618 (ep 4)
[16:58:09] Epoch 5/100 | Train: 0.036055 (MSE=0.003000 BCE=0.6611) | Val: 0.042529 (MSE=0.009177 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042529 (ep 5)
[16:58:12] Epoch 6/100 | Train: 0.036027 (MSE=0.002979 BCE=0.6609) | Val: 0.042504 (MSE=0.009162 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042504 (ep 6)
[16:58:15] Epoch 7/100 | Train: 0.036007 (MSE=0.002963 BCE=0.6609) | Val: 0.042510 (MSE=0.009169 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042504 (ep 6)
[16:58:18] Epoch 8/100 | Train: 0.035989 (MSE=0.002948 BCE=0.6608) | Val: 0.042535 (MSE=0.009152 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042504 (ep 6)
[16:58:21] Epoch 9/100 | Train: 0.035974 (MSE=0.002937 BCE=0.6608) | Val: 0.042569 (MSE=0.009225 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042504 (ep 6)
[16:58:24] Epoch 10/100 | Train: 0.035958 (MSE=0.002925 BCE=0.6607) | Val: 0.042493 (MSE=0.009146 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042493 (ep 10)
[16:58:26] Epoch 11/100 | Train: 0.035949 (MSE=0.002918 BCE=0.6606) | Val: 0.042470 (MSE=0.009109 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042470 (ep 11)
[16:58:29] Epoch 12/100 | Train: 0.035927 (MSE=0.002905 BCE=0.6604) | Val: 0.042440 (MSE=0.009061 BCE=0.6676) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:32] Epoch 13/100 | Train: 0.035929 (MSE=0.002901 BCE=0.6605) | Val: 0.042500 (MSE=0.009159 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:35] Epoch 14/100 | Train: 0.035920 (MSE=0.002894 BCE=0.6605) | Val: 0.042629 (MSE=0.009266 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:38] Epoch 15/100 | Train: 0.035907 (MSE=0.002891 BCE=0.6603) | Val: 0.042789 (MSE=0.009434 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:40] Epoch 16/100 | Train: 0.035901 (MSE=0.002883 BCE=0.6604) | Val: 0.042734 (MSE=0.009374 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:43] Epoch 17/100 | Train: 0.035891 (MSE=0.002878 BCE=0.6603) | Val: 0.042913 (MSE=0.009541 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042440 (ep 12)
[16:58:46] Epoch 18/100 | Train: 0.035889 (MSE=0.002876 BCE=0.6603) | Val: 0.042970 (MSE=0.009597 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042440 (ep 12)
[16:58:49] Epoch 19/100 | Train: 0.035858 (MSE=0.002863 BCE=0.6599) | Val: 0.043051 (MSE=0.009685 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042440 (ep 12)
[16:58:51] Epoch 20/100 | Train: 0.035858 (MSE=0.002860 BCE=0.6599) | Val: 0.042913 (MSE=0.009538 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042440 (ep 12)
[16:58:54] Epoch 21/100 | Train: 0.035854 (MSE=0.002860 BCE=0.6599) | Val: 0.043144 (MSE=0.009741 BCE=0.6681) | LR: 5.00e-05 | Best: 0.042440 (ep 12)
[16:58:57] Epoch 22/100 | Train: 0.035849 (MSE=0.002855 BCE=0.6599) | Val: 0.043015 (MSE=0.009652 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042440 (ep 12)
[16:58:57] Early stopping at epoch 22 (no improvement for 10 epochs)
[16:58:58] Factor 21 done — best val loss: 0.042440 at epoch 12
[16:58:58] 
============================================================
[16:58:58] STF Factor 22 of [6..24]
[16:58:58] ============================================================
[16:58:58] Building features: 0% (1/175846)
[16:58:59] Building features: 5% (8793/175846)
[16:58:59] Building features: 10% (17585/175846)
[16:59:00] Building features: 15% (26377/175846)
[16:59:00] Building features: 20% (35169/175846)
[16:59:01] Building features: 25% (43961/175846)
[16:59:01] Building features: 30% (52753/175846)
[16:59:02] Building features: 35% (61545/175846)
[16:59:03] Building features: 40% (70337/175846)
[16:59:03] Building features: 45% (79129/175846)
[16:59:04] Building features: 50% (87921/175846)
[16:59:04] Building features: 55% (96713/175846)
[16:59:05] Building features: 60% (105505/175846)
[16:59:05] Building features: 65% (114297/175846)
[16:59:06] Building features: 70% (123089/175846)
[16:59:06] Building features: 75% (131881/175846)
[16:59:07] Building features: 80% (140673/175846)
[16:59:07] Building features: 85% (149465/175846)
[16:59:08] Building features: 90% (158257/175846)
[16:59:08] Building features: 95% (167049/175846)
[16:59:09] Building features: 100% (175841/175846)
[16:59:09] Computing Hurst exponent...
[16:59:14] Computing market regimes (GMM)...
[16:59:22] Factor 22: 175724 samples, 92 features
[16:59:24] Batch stats — Input:  mean=0.0540 std=0.2752 min=-4.1163 max=13.1528
[16:59:24] Batch stats — Target: mean=-0.0008 std=0.0719 min=-0.4720 max=0.4134
[16:59:24] Batch stats — Cls:    pos_long=107/256 pos_short=89/256
[16:59:24] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[16:59:28] Epoch 1/100 | Train: 0.037174 (MSE=0.003985 BCE=0.6638) | Val: 0.044868 (MSE=0.011526 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044868 (ep 1)
[16:59:31] Epoch 2/100 | Train: 0.036198 (MSE=0.003112 BCE=0.6617) | Val: 0.043589 (MSE=0.010256 BCE=0.6666) | LR: 1.00e-04 | Best: 0.043589 (ep 2)
[16:59:34] Epoch 3/100 | Train: 0.036126 (MSE=0.003057 BCE=0.6614) | Val: 0.042750 (MSE=0.009421 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042750 (ep 3)
[16:59:36] Epoch 4/100 | Train: 0.036087 (MSE=0.003030 BCE=0.6611) | Val: 0.042568 (MSE=0.009240 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042568 (ep 4)
[16:59:39] Epoch 5/100 | Train: 0.036061 (MSE=0.003003 BCE=0.6611) | Val: 0.042586 (MSE=0.009243 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042568 (ep 4)
[16:59:42] Epoch 6/100 | Train: 0.036033 (MSE=0.002980 BCE=0.6611) | Val: 0.042391 (MSE=0.009054 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042391 (ep 6)
[16:59:45] Epoch 7/100 | Train: 0.036006 (MSE=0.002961 BCE=0.6609) | Val: 0.042419 (MSE=0.009086 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042391 (ep 6)
[16:59:48] Epoch 8/100 | Train: 0.035990 (MSE=0.002950 BCE=0.6608) | Val: 0.042341 (MSE=0.009004 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042341 (ep 8)
[16:59:50] Epoch 9/100 | Train: 0.035979 (MSE=0.002939 BCE=0.6608) | Val: 0.042367 (MSE=0.009011 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042341 (ep 8)
[16:59:53] Epoch 10/100 | Train: 0.035963 (MSE=0.002928 BCE=0.6607) | Val: 0.042319 (MSE=0.008976 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042319 (ep 10)
[16:59:56] Epoch 11/100 | Train: 0.035948 (MSE=0.002921 BCE=0.6605) | Val: 0.042289 (MSE=0.008943 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[16:59:59] Epoch 12/100 | Train: 0.035946 (MSE=0.002912 BCE=0.6607) | Val: 0.042297 (MSE=0.008937 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[17:00:02] Epoch 13/100 | Train: 0.035930 (MSE=0.002907 BCE=0.6604) | Val: 0.042499 (MSE=0.009125 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[17:00:05] Epoch 14/100 | Train: 0.035917 (MSE=0.002899 BCE=0.6604) | Val: 0.042442 (MSE=0.009074 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[17:00:08] Epoch 15/100 | Train: 0.035915 (MSE=0.002895 BCE=0.6604) | Val: 0.042538 (MSE=0.009142 BCE=0.6679) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[17:00:10] Epoch 16/100 | Train: 0.035898 (MSE=0.002886 BCE=0.6602) | Val: 0.042514 (MSE=0.009130 BCE=0.6677) | LR: 1.00e-04 | Best: 0.042289 (ep 11)
[17:00:12] Epoch 17/100 | Train: 0.035894 (MSE=0.002882 BCE=0.6603) | Val: 0.042502 (MSE=0.009143 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042289 (ep 11)
[17:00:15] Epoch 18/100 | Train: 0.035878 (MSE=0.002873 BCE=0.6601) | Val: 0.042595 (MSE=0.009229 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042289 (ep 11)
[17:00:17] Epoch 19/100 | Train: 0.035875 (MSE=0.002871 BCE=0.6601) | Val: 0.042636 (MSE=0.009259 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042289 (ep 11)
[17:00:19] Epoch 20/100 | Train: 0.035871 (MSE=0.002868 BCE=0.6601) | Val: 0.042671 (MSE=0.009296 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042289 (ep 11)
[17:00:22] Epoch 21/100 | Train: 0.035858 (MSE=0.002863 BCE=0.6599) | Val: 0.042739 (MSE=0.009352 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042289 (ep 11)
[17:00:22] Early stopping at epoch 21 (no improvement for 10 epochs)
[17:00:23] Factor 22 done — best val loss: 0.042289 at epoch 11
[17:00:23] 
============================================================
[17:00:23] STF Factor 23 of [6..24]
[17:00:23] ============================================================
[17:00:23] Building features: 0% (1/175846)
[17:00:23] Building features: 5% (8793/175846)
[17:00:24] Building features: 10% (17585/175846)
[17:00:24] Building features: 15% (26377/175846)
[17:00:25] Building features: 20% (35169/175846)
[17:00:25] Building features: 25% (43961/175846)
[17:00:26] Building features: 30% (52753/175846)
[17:00:26] Building features: 35% (61545/175846)
[17:00:27] Building features: 40% (70337/175846)
[17:00:27] Building features: 45% (79129/175846)
[17:00:28] Building features: 50% (87921/175846)
[17:00:28] Building features: 55% (96713/175846)
[17:00:29] Building features: 60% (105505/175846)
[17:00:29] Building features: 65% (114297/175846)
[17:00:30] Building features: 70% (123089/175846)
[17:00:30] Building features: 75% (131881/175846)
[17:00:31] Building features: 80% (140673/175846)
[17:00:31] Building features: 85% (149465/175846)
[17:00:32] Building features: 90% (158257/175846)
[17:00:32] Building features: 95% (167049/175846)
[17:00:33] Building features: 100% (175841/175846)
[17:00:33] Computing Hurst exponent...
[17:00:38] Computing market regimes (GMM)...
[17:00:45] Factor 23: 175724 samples, 92 features
[17:00:46] Batch stats — Input:  mean=0.0542 std=0.2725 min=-4.1605 max=9.5561
[17:00:46] Batch stats — Target: mean=0.0023 std=0.0638 min=-0.3664 max=0.4134
[17:00:46] Batch stats — Cls:    pos_long=109/256 pos_short=80/256
[17:00:46] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:00:51] Epoch 1/100 | Train: 0.037084 (MSE=0.003892 BCE=0.6638) | Val: 0.044243 (MSE=0.010889 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044243 (ep 1)
[17:00:54] Epoch 2/100 | Train: 0.036191 (MSE=0.003112 BCE=0.6616) | Val: 0.043065 (MSE=0.009715 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043065 (ep 2)
[17:00:56] Epoch 3/100 | Train: 0.036128 (MSE=0.003058 BCE=0.6614) | Val: 0.042593 (MSE=0.009252 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042593 (ep 3)
[17:00:59] Epoch 4/100 | Train: 0.036087 (MSE=0.003027 BCE=0.6612) | Val: 0.042469 (MSE=0.009150 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042469 (ep 4)
[17:01:02] Epoch 5/100 | Train: 0.036051 (MSE=0.002997 BCE=0.6611) | Val: 0.042413 (MSE=0.009097 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042413 (ep 5)
[17:01:05] Epoch 6/100 | Train: 0.036025 (MSE=0.002978 BCE=0.6609) | Val: 0.042327 (MSE=0.009009 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042327 (ep 6)
[17:01:07] Epoch 7/100 | Train: 0.036000 (MSE=0.002959 BCE=0.6608) | Val: 0.042292 (MSE=0.008981 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042292 (ep 7)
[17:01:09] Epoch 8/100 | Train: 0.035987 (MSE=0.002947 BCE=0.6608) | Val: 0.042365 (MSE=0.009035 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042292 (ep 7)
[17:01:12] Epoch 9/100 | Train: 0.035977 (MSE=0.002938 BCE=0.6608) | Val: 0.042258 (MSE=0.008928 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042258 (ep 9)
[17:01:14] Epoch 10/100 | Train: 0.035957 (MSE=0.002927 BCE=0.6606) | Val: 0.042337 (MSE=0.009004 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042258 (ep 9)
[17:01:17] Epoch 11/100 | Train: 0.035945 (MSE=0.002917 BCE=0.6606) | Val: 0.042238 (MSE=0.008921 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042238 (ep 11)
[17:01:19] Epoch 12/100 | Train: 0.035932 (MSE=0.002909 BCE=0.6605) | Val: 0.042215 (MSE=0.008890 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:21] Epoch 13/100 | Train: 0.035929 (MSE=0.002904 BCE=0.6605) | Val: 0.042308 (MSE=0.008970 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:24] Epoch 14/100 | Train: 0.035921 (MSE=0.002897 BCE=0.6605) | Val: 0.042287 (MSE=0.008958 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:26] Epoch 15/100 | Train: 0.035910 (MSE=0.002892 BCE=0.6604) | Val: 0.042282 (MSE=0.008949 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:29] Epoch 16/100 | Train: 0.035897 (MSE=0.002885 BCE=0.6603) | Val: 0.042392 (MSE=0.009047 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:32] Epoch 17/100 | Train: 0.035892 (MSE=0.002881 BCE=0.6602) | Val: 0.042392 (MSE=0.009051 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042215 (ep 12)
[17:01:34] Epoch 18/100 | Train: 0.035882 (MSE=0.002873 BCE=0.6602) | Val: 0.042377 (MSE=0.009045 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042215 (ep 12)
[17:01:37] Epoch 19/100 | Train: 0.035864 (MSE=0.002864 BCE=0.6600) | Val: 0.042415 (MSE=0.009073 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042215 (ep 12)
[17:01:40] Epoch 20/100 | Train: 0.035866 (MSE=0.002865 BCE=0.6600) | Val: 0.042505 (MSE=0.009156 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042215 (ep 12)
[17:01:43] Epoch 21/100 | Train: 0.035861 (MSE=0.002863 BCE=0.6600) | Val: 0.042489 (MSE=0.009146 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042215 (ep 12)
[17:01:46] Epoch 22/100 | Train: 0.035857 (MSE=0.002860 BCE=0.6600) | Val: 0.042486 (MSE=0.009137 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042215 (ep 12)
[17:01:46] Early stopping at epoch 22 (no improvement for 10 epochs)
[17:01:47] Factor 23 done — best val loss: 0.042215 at epoch 12
[17:01:47] 
============================================================
[17:01:47] STF Factor 24 of [6..24]
[17:01:47] ============================================================
[17:01:47] Building features: 0% (1/175846)
[17:01:47] Building features: 5% (8793/175846)
[17:01:48] Building features: 10% (17585/175846)
[17:01:49] Building features: 15% (26377/175846)
[17:01:49] Building features: 20% (35169/175846)
[17:01:50] Building features: 25% (43961/175846)
[17:01:50] Building features: 30% (52753/175846)
[17:01:51] Building features: 35% (61545/175846)
[17:01:51] Building features: 40% (70337/175846)
[17:01:52] Building features: 45% (79129/175846)
[17:01:52] Building features: 50% (87921/175846)
[17:01:53] Building features: 55% (96713/175846)
[17:01:54] Building features: 60% (105505/175846)
[17:01:54] Building features: 65% (114297/175846)
[17:01:55] Building features: 70% (123089/175846)
[17:01:55] Building features: 75% (131881/175846)
[17:01:56] Building features: 80% (140673/175846)
[17:01:56] Building features: 85% (149465/175846)
[17:01:57] Building features: 90% (158257/175846)
[17:01:57] Building features: 95% (167049/175846)
[17:01:58] Building features: 100% (175841/175846)
[17:01:58] Computing Hurst exponent...
[17:02:03] Computing market regimes (GMM)...
[17:02:10] Factor 24: 175724 samples, 92 features
[17:02:12] Batch stats — Input:  mean=0.0500 std=0.2685 min=-3.8831 max=5.5972
[17:02:12] Batch stats — Target: mean=0.0011 std=0.0600 min=-0.4720 max=0.3273
[17:02:12] Batch stats — Cls:    pos_long=109/256 pos_short=80/256
[17:02:12] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:02:17] Epoch 1/100 | Train: 0.037166 (MSE=0.003920 BCE=0.6649) | Val: 0.044028 (MSE=0.010680 BCE=0.6670) | LR: 1.00e-04 | Best: 0.044028 (ep 1)
[17:02:20] Epoch 2/100 | Train: 0.036179 (MSE=0.003095 BCE=0.6617) | Val: 0.042860 (MSE=0.009523 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042860 (ep 2)
[17:02:22] Epoch 3/100 | Train: 0.036117 (MSE=0.003046 BCE=0.6614) | Val: 0.042585 (MSE=0.009265 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042585 (ep 3)
[17:02:25] Epoch 4/100 | Train: 0.036075 (MSE=0.003017 BCE=0.6611) | Val: 0.042492 (MSE=0.009158 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042492 (ep 4)
[17:02:28] Epoch 5/100 | Train: 0.036052 (MSE=0.002994 BCE=0.6612) | Val: 0.042425 (MSE=0.009102 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042425 (ep 5)
[17:02:31] Epoch 6/100 | Train: 0.036023 (MSE=0.002973 BCE=0.6610) | Val: 0.042400 (MSE=0.009073 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042400 (ep 6)
[17:02:33] Epoch 7/100 | Train: 0.036007 (MSE=0.002962 BCE=0.6609) | Val: 0.042344 (MSE=0.009021 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:36] Epoch 8/100 | Train: 0.035989 (MSE=0.002948 BCE=0.6608) | Val: 0.042414 (MSE=0.009074 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:39] Epoch 9/100 | Train: 0.035975 (MSE=0.002935 BCE=0.6608) | Val: 0.042396 (MSE=0.009065 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:42] Epoch 10/100 | Train: 0.035962 (MSE=0.002928 BCE=0.6607) | Val: 0.042415 (MSE=0.009049 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:44] Epoch 11/100 | Train: 0.035952 (MSE=0.002920 BCE=0.6606) | Val: 0.042511 (MSE=0.009146 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:47] Epoch 12/100 | Train: 0.035944 (MSE=0.002914 BCE=0.6606) | Val: 0.042398 (MSE=0.009045 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042344 (ep 7)
[17:02:50] Epoch 13/100 | Train: 0.035936 (MSE=0.002909 BCE=0.6605) | Val: 0.042408 (MSE=0.009054 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042344 (ep 7)
[17:02:53] Epoch 14/100 | Train: 0.035917 (MSE=0.002897 BCE=0.6604) | Val: 0.042456 (MSE=0.009082 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042344 (ep 7)
[17:02:55] Epoch 15/100 | Train: 0.035909 (MSE=0.002892 BCE=0.6603) | Val: 0.042555 (MSE=0.009166 BCE=0.6678) | LR: 5.00e-05 | Best: 0.042344 (ep 7)
[17:02:58] Epoch 16/100 | Train: 0.035907 (MSE=0.002890 BCE=0.6603) | Val: 0.042532 (MSE=0.009161 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042344 (ep 7)
[17:03:01] Epoch 17/100 | Train: 0.035906 (MSE=0.002887 BCE=0.6604) | Val: 0.042804 (MSE=0.009426 BCE=0.6676) | LR: 5.00e-05 | Best: 0.042344 (ep 7)
[17:03:01] Early stopping at epoch 17 (no improvement for 10 epochs)
[17:03:02] Factor 24 done — best val loss: 0.042344 at epoch 7
[17:03:02] 
Best factor: 10 (val loss 0.042181)
[17:03:02] Training done. Best factor=10, val_loss=0.042181
[17:05:36] Building validation dataset...
[17:05:36] Building features: 0% (1/175846)
[17:05:37] Building features: 5% (8793/175846)
[17:05:37] Building features: 10% (17585/175846)
[17:05:38] Building features: 15% (26377/175846)
[17:05:38] Building features: 20% (35169/175846)
[17:05:39] Building features: 25% (43961/175846)
[17:05:39] Building features: 30% (52753/175846)
[17:05:40] Building features: 35% (61545/175846)
[17:05:40] Building features: 40% (70337/175846)
[17:05:41] Building features: 45% (79129/175846)
[17:05:41] Building features: 50% (87921/175846)
[17:05:42] Building features: 55% (96713/175846)
[17:05:42] Building features: 60% (105505/175846)
[17:05:43] Building features: 65% (114297/175846)
[17:05:43] Building features: 70% (123089/175846)
[17:05:44] Building features: 75% (131881/175846)
[17:05:45] Building features: 80% (140673/175846)
[17:05:45] Building features: 85% (149465/175846)
[17:05:46] Building features: 90% (158257/175846)
[17:05:46] Building features: 95% (167049/175846)
[17:05:47] Building features: 100% (175841/175846)
[17:05:47] Computing Hurst exponent...
[17:05:52] Computing market regimes (GMM)...
[17:06:00] Running backtest...
[17:06:00] Backtest complete: 7660 trades (2448L/5212S), WR=48.7%, PF=0.94
[17:07:06] Training started.
[17:07:06] 
============================================================
[17:07:06] STF Factor 5 of [5..10]
[17:07:06] ============================================================
[17:07:06] Building features: 0% (1/175846)
[17:07:07] Building features: 5% (8793/175846)
[17:07:07] Building features: 10% (17585/175846)
[17:07:08] Building features: 15% (26377/175846)
[17:07:08] Building features: 20% (35169/175846)
[17:07:09] Building features: 25% (43961/175846)
[17:07:09] Building features: 30% (52753/175846)
[17:07:10] Building features: 35% (61545/175846)
[17:07:10] Building features: 40% (70337/175846)
[17:07:11] Building features: 45% (79129/175846)
[17:07:11] Building features: 50% (87921/175846)
[17:07:12] Building features: 55% (96713/175846)
[17:07:12] Building features: 60% (105505/175846)
[17:07:13] Building features: 65% (114297/175846)
[17:07:13] Building features: 70% (123089/175846)
[17:07:14] Building features: 75% (131881/175846)
[17:07:14] Building features: 80% (140673/175846)
[17:07:15] Building features: 85% (149465/175846)
[17:07:15] Building features: 90% (158257/175846)
[17:07:16] Building features: 95% (167049/175846)
[17:07:16] Building features: 100% (175841/175846)
[17:07:16] Computing Hurst exponent...
[17:07:17] Stop requested...
[17:07:21] Computing market regimes (GMM)...
[17:07:28] Factor 5: 175824 samples, 79 features
[17:07:29] Batch stats — Input:  mean=0.0306 std=0.2134 min=-7.0610 max=16.4110
[17:07:29] Batch stats — Target: mean=0.0052 std=0.0737 min=-0.4720 max=0.4134
[17:07:29] Batch stats — Cls:    pos_long=112/256 pos_short=86/256
[17:07:29] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:07:29] Training stopped by user.
[17:07:30] Factor 5 done — best val loss: inf at epoch 0
[17:07:30] 
Best factor: 5 (val loss inf)
[17:07:30] Training done. Best factor=5, val_loss=inf
[17:07:37] Training started.
[17:07:37] 
============================================================
[17:07:37] STF Factor 5 of [5..10]
[17:07:37] ============================================================
[17:07:37] Building features: 0% (1/175846)
[17:07:38] Building features: 5% (8793/175846)
[17:07:38] Building features: 10% (17585/175846)
[17:07:39] Building features: 15% (26377/175846)
[17:07:39] Building features: 20% (35169/175846)
[17:07:40] Building features: 25% (43961/175846)
[17:07:40] Building features: 30% (52753/175846)
[17:07:41] Building features: 35% (61545/175846)
[17:07:41] Building features: 40% (70337/175846)
[17:07:42] Building features: 45% (79129/175846)
[17:07:43] Building features: 50% (87921/175846)
[17:07:43] Building features: 55% (96713/175846)
[17:07:44] Building features: 60% (105505/175846)
[17:07:44] Building features: 65% (114297/175846)
[17:07:45] Building features: 70% (123089/175846)
[17:07:45] Building features: 75% (131881/175846)
[17:07:46] Building features: 80% (140673/175846)
[17:07:46] Building features: 85% (149465/175846)
[17:07:47] Building features: 90% (158257/175846)
[17:07:48] Building features: 95% (167049/175846)
[17:07:48] Building features: 100% (175841/175846)
[17:07:48] Computing Hurst exponent...
[17:07:54] Computing market regimes (GMM)...
[17:08:01] Factor 5: 175804 samples, 79 features
[17:08:03] Batch stats — Input:  mean=0.0295 std=0.2150 min=-5.5995 max=60.4783
[17:08:03] Batch stats — Target: mean=0.0008 std=0.0640 min=-0.4589 max=0.4134
[17:08:03] Batch stats — Cls:    pos_long=103/256 pos_short=98/256
[17:08:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:08:08] Epoch 1/100 | Train: 0.036793 (MSE=0.003551 BCE=0.6648) | Val: 0.044431 (MSE=0.011092 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044431 (ep 1)
[17:08:11] Epoch 2/100 | Train: 0.036173 (MSE=0.003087 BCE=0.6617) | Val: 0.043458 (MSE=0.010151 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043458 (ep 2)
[17:08:14] Epoch 3/100 | Train: 0.036104 (MSE=0.003039 BCE=0.6613) | Val: 0.043136 (MSE=0.009845 BCE=0.6658) | LR: 1.00e-04 | Best: 0.043136 (ep 3)
[17:08:17] Epoch 4/100 | Train: 0.036074 (MSE=0.003013 BCE=0.6612) | Val: 0.043042 (MSE=0.009737 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043042 (ep 4)
[17:08:20] Epoch 5/100 | Train: 0.036044 (MSE=0.002992 BCE=0.6610) | Val: 0.042767 (MSE=0.009478 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042767 (ep 5)
[17:08:23] Epoch 6/100 | Train: 0.036024 (MSE=0.002971 BCE=0.6611) | Val: 0.042474 (MSE=0.009185 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042474 (ep 6)
[17:08:26] Epoch 7/100 | Train: 0.036005 (MSE=0.002961 BCE=0.6609) | Val: 0.042545 (MSE=0.009256 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042474 (ep 6)
[17:08:28] Epoch 8/100 | Train: 0.035991 (MSE=0.002947 BCE=0.6609) | Val: 0.042410 (MSE=0.009124 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042410 (ep 8)
[17:08:31] Epoch 9/100 | Train: 0.035978 (MSE=0.002938 BCE=0.6608) | Val: 0.042330 (MSE=0.009044 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042330 (ep 9)
[17:08:33] Epoch 10/100 | Train: 0.035960 (MSE=0.002926 BCE=0.6607) | Val: 0.042342 (MSE=0.009055 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042330 (ep 9)
[17:08:36] Epoch 11/100 | Train: 0.035959 (MSE=0.002920 BCE=0.6608) | Val: 0.042278 (MSE=0.008992 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042278 (ep 11)
[17:08:38] Epoch 12/100 | Train: 0.035947 (MSE=0.002914 BCE=0.6607) | Val: 0.042269 (MSE=0.008982 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042269 (ep 12)
[17:08:41] Epoch 13/100 | Train: 0.035939 (MSE=0.002908 BCE=0.6606) | Val: 0.042247 (MSE=0.008959 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042247 (ep 13)
[17:08:43] Epoch 14/100 | Train: 0.035929 (MSE=0.002902 BCE=0.6605) | Val: 0.042297 (MSE=0.009001 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042247 (ep 13)
[17:08:46] Epoch 15/100 | Train: 0.035924 (MSE=0.002896 BCE=0.6606) | Val: 0.042334 (MSE=0.009043 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042247 (ep 13)
[17:08:49] Epoch 16/100 | Train: 0.035912 (MSE=0.002893 BCE=0.6604) | Val: 0.042234 (MSE=0.008941 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:08:52] Epoch 17/100 | Train: 0.035911 (MSE=0.002886 BCE=0.6605) | Val: 0.042279 (MSE=0.008978 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:08:55] Epoch 18/100 | Train: 0.035903 (MSE=0.002883 BCE=0.6604) | Val: 0.042268 (MSE=0.008968 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:08:58] Epoch 19/100 | Train: 0.035893 (MSE=0.002876 BCE=0.6603) | Val: 0.042338 (MSE=0.009049 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:09:01] Epoch 20/100 | Train: 0.035890 (MSE=0.002877 BCE=0.6603) | Val: 0.042338 (MSE=0.009043 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:09:04] Epoch 21/100 | Train: 0.035889 (MSE=0.002872 BCE=0.6604) | Val: 0.042459 (MSE=0.009165 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042234 (ep 16)
[17:09:07] Epoch 22/100 | Train: 0.035881 (MSE=0.002866 BCE=0.6603) | Val: 0.042390 (MSE=0.009088 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042234 (ep 16)
[17:09:10] Epoch 23/100 | Train: 0.035862 (MSE=0.002855 BCE=0.6601) | Val: 0.042522 (MSE=0.009233 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042234 (ep 16)
[17:09:13] Epoch 24/100 | Train: 0.035858 (MSE=0.002853 BCE=0.6601) | Val: 0.042430 (MSE=0.009124 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042234 (ep 16)
[17:09:16] Epoch 25/100 | Train: 0.035852 (MSE=0.002851 BCE=0.6600) | Val: 0.042463 (MSE=0.009145 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042234 (ep 16)
[17:09:19] Epoch 26/100 | Train: 0.035853 (MSE=0.002851 BCE=0.6600) | Val: 0.042509 (MSE=0.009211 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042234 (ep 16)
[17:09:19] Early stopping at epoch 26 (no improvement for 10 epochs)
[17:09:20] Factor 5 done — best val loss: 0.042234 at epoch 16
[17:09:20] 
============================================================
[17:09:20] STF Factor 6 of [5..10]
[17:09:20] ============================================================
[17:09:20] Building features: 0% (1/175846)
[17:09:21] Building features: 5% (8793/175846)
[17:09:21] Building features: 10% (17585/175846)
[17:09:22] Building features: 15% (26377/175846)
[17:09:23] Building features: 20% (35169/175846)
[17:09:23] Building features: 25% (43961/175846)
[17:09:24] Building features: 30% (52753/175846)
[17:09:24] Building features: 35% (61545/175846)
[17:09:25] Building features: 40% (70337/175846)
[17:09:25] Building features: 45% (79129/175846)
[17:09:26] Building features: 50% (87921/175846)
[17:09:27] Building features: 55% (96713/175846)
[17:09:27] Building features: 60% (105505/175846)
[17:09:28] Building features: 65% (114297/175846)
[17:09:28] Building features: 70% (123089/175846)
[17:09:29] Building features: 75% (131881/175846)
[17:09:29] Building features: 80% (140673/175846)
[17:09:30] Building features: 85% (149465/175846)
[17:09:31] Building features: 90% (158257/175846)
[17:09:31] Building features: 95% (167049/175846)
[17:09:32] Building features: 100% (175841/175846)
[17:09:32] Computing Hurst exponent...
[17:09:37] Computing market regimes (GMM)...
[17:09:45] Factor 6: 175804 samples, 79 features
[17:09:46] Batch stats — Input:  mean=0.0324 std=0.2066 min=-5.3639 max=10.0390
[17:09:46] Batch stats — Target: mean=0.0019 std=0.0665 min=-0.4156 max=0.3478
[17:09:46] Batch stats — Cls:    pos_long=105/256 pos_short=86/256
[17:09:46] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:09:51] Epoch 1/100 | Train: 0.036913 (MSE=0.003613 BCE=0.6660) | Val: 0.044396 (MSE=0.011043 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044396 (ep 1)
[17:09:54] Epoch 2/100 | Train: 0.036178 (MSE=0.003091 BCE=0.6617) | Val: 0.043513 (MSE=0.010213 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043513 (ep 2)
[17:09:57] Epoch 3/100 | Train: 0.036107 (MSE=0.003039 BCE=0.6614) | Val: 0.043088 (MSE=0.009791 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043088 (ep 3)
[17:10:00] Epoch 4/100 | Train: 0.036074 (MSE=0.003012 BCE=0.6612) | Val: 0.042999 (MSE=0.009702 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042999 (ep 4)
[17:10:03] Epoch 5/100 | Train: 0.036053 (MSE=0.002996 BCE=0.6611) | Val: 0.042857 (MSE=0.009553 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042857 (ep 5)
[17:10:06] Epoch 6/100 | Train: 0.036032 (MSE=0.002978 BCE=0.6611) | Val: 0.042531 (MSE=0.009241 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042531 (ep 6)
[17:10:09] Epoch 7/100 | Train: 0.036008 (MSE=0.002963 BCE=0.6609) | Val: 0.042528 (MSE=0.009230 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042528 (ep 7)
[17:10:12] Epoch 8/100 | Train: 0.035996 (MSE=0.002952 BCE=0.6609) | Val: 0.042441 (MSE=0.009147 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042441 (ep 8)
[17:10:15] Epoch 9/100 | Train: 0.035976 (MSE=0.002940 BCE=0.6607) | Val: 0.042313 (MSE=0.009011 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042313 (ep 9)
[17:10:18] Epoch 10/100 | Train: 0.035967 (MSE=0.002931 BCE=0.6607) | Val: 0.042399 (MSE=0.009104 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042313 (ep 9)
[17:10:20] Epoch 11/100 | Train: 0.035962 (MSE=0.002924 BCE=0.6608) | Val: 0.042275 (MSE=0.008970 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042275 (ep 11)
[17:10:23] Epoch 12/100 | Train: 0.035952 (MSE=0.002916 BCE=0.6607) | Val: 0.042238 (MSE=0.008928 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042238 (ep 12)
[17:10:26] Epoch 13/100 | Train: 0.035941 (MSE=0.002910 BCE=0.6606) | Val: 0.042276 (MSE=0.008960 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042238 (ep 12)
[17:10:29] Epoch 14/100 | Train: 0.035932 (MSE=0.002903 BCE=0.6606) | Val: 0.042179 (MSE=0.008878 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042179 (ep 14)
[17:10:32] Epoch 15/100 | Train: 0.035922 (MSE=0.002897 BCE=0.6605) | Val: 0.042220 (MSE=0.008888 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042179 (ep 14)
[17:10:35] Epoch 16/100 | Train: 0.035919 (MSE=0.002894 BCE=0.6605) | Val: 0.042149 (MSE=0.008858 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:38] Epoch 17/100 | Train: 0.035909 (MSE=0.002888 BCE=0.6604) | Val: 0.042188 (MSE=0.008875 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:41] Epoch 18/100 | Train: 0.035908 (MSE=0.002884 BCE=0.6605) | Val: 0.042168 (MSE=0.008865 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:43] Epoch 19/100 | Train: 0.035898 (MSE=0.002882 BCE=0.6603) | Val: 0.042261 (MSE=0.008968 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:46] Epoch 20/100 | Train: 0.035894 (MSE=0.002880 BCE=0.6603) | Val: 0.042292 (MSE=0.008994 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:49] Epoch 21/100 | Train: 0.035887 (MSE=0.002874 BCE=0.6603) | Val: 0.042233 (MSE=0.008932 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042149 (ep 16)
[17:10:52] Epoch 22/100 | Train: 0.035886 (MSE=0.002871 BCE=0.6603) | Val: 0.042336 (MSE=0.009041 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042149 (ep 16)
[17:10:55] Epoch 23/100 | Train: 0.035866 (MSE=0.002861 BCE=0.6601) | Val: 0.042312 (MSE=0.009008 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042149 (ep 16)
[17:10:58] Epoch 24/100 | Train: 0.035860 (MSE=0.002858 BCE=0.6600) | Val: 0.042279 (MSE=0.008980 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042149 (ep 16)
[17:11:01] Epoch 25/100 | Train: 0.035860 (MSE=0.002856 BCE=0.6601) | Val: 0.042350 (MSE=0.009052 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042149 (ep 16)
[17:11:04] Epoch 26/100 | Train: 0.035853 (MSE=0.002854 BCE=0.6600) | Val: 0.042370 (MSE=0.009059 BCE=0.6662) | LR: 5.00e-05 | Best: 0.042149 (ep 16)
[17:11:04] Early stopping at epoch 26 (no improvement for 10 epochs)
[17:11:05] Factor 6 done — best val loss: 0.042149 at epoch 16
[17:11:05] 
============================================================
[17:11:05] STF Factor 7 of [5..10]
[17:11:05] ============================================================
[17:11:05] Building features: 0% (1/175846)
[17:11:06] Building features: 5% (8793/175846)
[17:11:06] Building features: 10% (17585/175846)
[17:11:07] Building features: 15% (26377/175846)
[17:11:07] Building features: 20% (35169/175846)
[17:11:08] Building features: 25% (43961/175846)
[17:11:08] Building features: 30% (52753/175846)
[17:11:09] Building features: 35% (61545/175846)
[17:11:09] Building features: 40% (70337/175846)
[17:11:10] Building features: 45% (79129/175846)
[17:11:10] Building features: 50% (87921/175846)
[17:11:11] Building features: 55% (96713/175846)
[17:11:12] Building features: 60% (105505/175846)
[17:11:12] Building features: 65% (114297/175846)
[17:11:13] Building features: 70% (123089/175846)
[17:11:13] Building features: 75% (131881/175846)
[17:11:14] Building features: 80% (140673/175846)
[17:11:14] Building features: 85% (149465/175846)
[17:11:15] Building features: 90% (158257/175846)
[17:11:15] Building features: 95% (167049/175846)
[17:11:16] Building features: 100% (175841/175846)
[17:11:16] Computing Hurst exponent...
[17:11:21] Computing market regimes (GMM)...
[17:11:28] Factor 7: 175804 samples, 79 features
[17:11:30] Batch stats — Input:  mean=0.0309 std=0.2044 min=-4.2131 max=12.6954
[17:11:30] Batch stats — Target: mean=-0.0022 std=0.0643 min=-0.4720 max=0.4134
[17:11:30] Batch stats — Cls:    pos_long=96/256 pos_short=110/256
[17:11:30] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:11:35] Epoch 1/100 | Train: 0.036813 (MSE=0.003543 BCE=0.6654) | Val: 0.044431 (MSE=0.011102 BCE=0.6666) | LR: 1.00e-04 | Best: 0.044431 (ep 1)
[17:11:38] Epoch 2/100 | Train: 0.036170 (MSE=0.003087 BCE=0.6617) | Val: 0.043629 (MSE=0.010324 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043629 (ep 2)
[17:11:41] Epoch 3/100 | Train: 0.036107 (MSE=0.003038 BCE=0.6614) | Val: 0.043272 (MSE=0.009966 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043272 (ep 3)
[17:11:43] Epoch 4/100 | Train: 0.036075 (MSE=0.003015 BCE=0.6612) | Val: 0.043055 (MSE=0.009751 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043055 (ep 4)
[17:11:46] Epoch 5/100 | Train: 0.036055 (MSE=0.002996 BCE=0.6612) | Val: 0.042903 (MSE=0.009605 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042903 (ep 5)
[17:11:48] Epoch 6/100 | Train: 0.036034 (MSE=0.002979 BCE=0.6611) | Val: 0.042606 (MSE=0.009310 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042606 (ep 6)
[17:11:51] Epoch 7/100 | Train: 0.036019 (MSE=0.002966 BCE=0.6611) | Val: 0.042541 (MSE=0.009251 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042541 (ep 7)
[17:11:53] Epoch 8/100 | Train: 0.036000 (MSE=0.002952 BCE=0.6610) | Val: 0.042423 (MSE=0.009128 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042423 (ep 8)
[17:11:56] Epoch 9/100 | Train: 0.035984 (MSE=0.002940 BCE=0.6609) | Val: 0.042354 (MSE=0.009052 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042354 (ep 9)
[17:11:58] Epoch 10/100 | Train: 0.035973 (MSE=0.002933 BCE=0.6608) | Val: 0.042302 (MSE=0.009006 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042302 (ep 10)
[17:12:01] Epoch 11/100 | Train: 0.035966 (MSE=0.002925 BCE=0.6608) | Val: 0.042301 (MSE=0.009003 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042301 (ep 11)
[17:12:03] Epoch 12/100 | Train: 0.035955 (MSE=0.002919 BCE=0.6607) | Val: 0.042258 (MSE=0.008965 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042258 (ep 12)
[17:12:07] Epoch 13/100 | Train: 0.035946 (MSE=0.002912 BCE=0.6607) | Val: 0.042170 (MSE=0.008870 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:10] Epoch 14/100 | Train: 0.035939 (MSE=0.002905 BCE=0.6607) | Val: 0.042268 (MSE=0.008949 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:13] Epoch 15/100 | Train: 0.035933 (MSE=0.002904 BCE=0.6606) | Val: 0.042247 (MSE=0.008945 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:16] Epoch 16/100 | Train: 0.035928 (MSE=0.002898 BCE=0.6606) | Val: 0.042235 (MSE=0.008936 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:19] Epoch 17/100 | Train: 0.035919 (MSE=0.002894 BCE=0.6605) | Val: 0.042228 (MSE=0.008935 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:22] Epoch 18/100 | Train: 0.035914 (MSE=0.002890 BCE=0.6605) | Val: 0.042265 (MSE=0.008953 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042170 (ep 13)
[17:12:25] Epoch 19/100 | Train: 0.035909 (MSE=0.002887 BCE=0.6604) | Val: 0.042285 (MSE=0.008971 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042170 (ep 13)
[17:12:28] Epoch 20/100 | Train: 0.035895 (MSE=0.002878 BCE=0.6603) | Val: 0.042211 (MSE=0.008918 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042170 (ep 13)
[17:12:31] Epoch 21/100 | Train: 0.035888 (MSE=0.002874 BCE=0.6603) | Val: 0.042250 (MSE=0.008939 BCE=0.6662) | LR: 5.00e-05 | Best: 0.042170 (ep 13)
[17:12:34] Epoch 22/100 | Train: 0.035885 (MSE=0.002873 BCE=0.6603) | Val: 0.042228 (MSE=0.008928 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042170 (ep 13)
[17:12:37] Epoch 23/100 | Train: 0.035888 (MSE=0.002875 BCE=0.6603) | Val: 0.042204 (MSE=0.008895 BCE=0.6662) | LR: 5.00e-05 | Best: 0.042170 (ep 13)
[17:12:37] Early stopping at epoch 23 (no improvement for 10 epochs)
[17:12:38] Factor 7 done — best val loss: 0.042170 at epoch 13
[17:12:38] 
============================================================
[17:12:38] STF Factor 8 of [5..10]
[17:12:38] ============================================================
[17:12:38] Building features: 0% (1/175846)
[17:12:39] Building features: 5% (8793/175846)
[17:12:39] Building features: 10% (17585/175846)
[17:12:40] Building features: 15% (26377/175846)
[17:12:41] Building features: 20% (35169/175846)
[17:12:41] Building features: 25% (43961/175846)
[17:12:42] Building features: 30% (52753/175846)
[17:12:42] Building features: 35% (61545/175846)
[17:12:43] Building features: 40% (70337/175846)
[17:12:44] Building features: 45% (79129/175846)
[17:12:44] Building features: 50% (87921/175846)
[17:12:45] Building features: 55% (96713/175846)
[17:12:45] Building features: 60% (105505/175846)
[17:12:46] Building features: 65% (114297/175846)
[17:12:46] Building features: 70% (123089/175846)
[17:12:47] Building features: 75% (131881/175846)
[17:12:48] Building features: 80% (140673/175846)
[17:12:48] Building features: 85% (149465/175846)
[17:12:49] Building features: 90% (158257/175846)
[17:12:49] Building features: 95% (167049/175846)
[17:12:50] Building features: 100% (175841/175846)
[17:12:50] Computing Hurst exponent...
[17:12:56] Computing market regimes (GMM)...
[17:13:03] Factor 8: 175804 samples, 79 features
[17:13:05] Batch stats — Input:  mean=0.0308 std=0.2039 min=-3.4467 max=12.2195
[17:13:05] Batch stats — Target: mean=0.0013 std=0.0716 min=-0.4720 max=0.4134
[17:13:05] Batch stats — Cls:    pos_long=102/256 pos_short=95/256
[17:13:05] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:13:10] Epoch 1/100 | Train: 0.036750 (MSE=0.003527 BCE=0.6644) | Val: 0.044222 (MSE=0.010880 BCE=0.6668) | LR: 1.00e-04 | Best: 0.044222 (ep 1)
[17:13:13] Epoch 2/100 | Train: 0.036159 (MSE=0.003079 BCE=0.6616) | Val: 0.043455 (MSE=0.010143 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043455 (ep 2)
[17:13:16] Epoch 3/100 | Train: 0.036100 (MSE=0.003031 BCE=0.6614) | Val: 0.043192 (MSE=0.009894 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043192 (ep 3)
[17:13:20] Epoch 4/100 | Train: 0.036071 (MSE=0.003007 BCE=0.6613) | Val: 0.042812 (MSE=0.009515 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042812 (ep 4)
[17:13:23] Epoch 5/100 | Train: 0.036042 (MSE=0.002986 BCE=0.6611) | Val: 0.042756 (MSE=0.009457 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042756 (ep 5)
[17:13:26] Epoch 6/100 | Train: 0.036020 (MSE=0.002969 BCE=0.6610) | Val: 0.042591 (MSE=0.009301 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042591 (ep 6)
[17:13:29] Epoch 7/100 | Train: 0.036005 (MSE=0.002954 BCE=0.6610) | Val: 0.042470 (MSE=0.009176 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042470 (ep 7)
[17:13:32] Epoch 8/100 | Train: 0.035989 (MSE=0.002945 BCE=0.6609) | Val: 0.042456 (MSE=0.009161 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042456 (ep 8)
[17:13:35] Epoch 9/100 | Train: 0.035977 (MSE=0.002935 BCE=0.6608) | Val: 0.042340 (MSE=0.009040 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042340 (ep 9)
[17:13:38] Epoch 10/100 | Train: 0.035973 (MSE=0.002928 BCE=0.6609) | Val: 0.042313 (MSE=0.009014 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:42] Epoch 11/100 | Train: 0.035962 (MSE=0.002921 BCE=0.6608) | Val: 0.042400 (MSE=0.009096 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:45] Epoch 12/100 | Train: 0.035951 (MSE=0.002915 BCE=0.6607) | Val: 0.042400 (MSE=0.009089 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:48] Epoch 13/100 | Train: 0.035945 (MSE=0.002908 BCE=0.6608) | Val: 0.042405 (MSE=0.009095 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:51] Epoch 14/100 | Train: 0.035934 (MSE=0.002903 BCE=0.6606) | Val: 0.042517 (MSE=0.009219 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:55] Epoch 15/100 | Train: 0.035930 (MSE=0.002899 BCE=0.6606) | Val: 0.042324 (MSE=0.009033 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042313 (ep 10)
[17:13:58] Epoch 16/100 | Train: 0.035917 (MSE=0.002893 BCE=0.6605) | Val: 0.042451 (MSE=0.009146 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042313 (ep 10)
[17:14:01] Epoch 17/100 | Train: 0.035911 (MSE=0.002882 BCE=0.6606) | Val: 0.042439 (MSE=0.009133 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042313 (ep 10)
[17:14:04] Epoch 18/100 | Train: 0.035898 (MSE=0.002880 BCE=0.6604) | Val: 0.042382 (MSE=0.009084 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042313 (ep 10)
[17:14:07] Epoch 19/100 | Train: 0.035896 (MSE=0.002879 BCE=0.6603) | Val: 0.042443 (MSE=0.009142 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042313 (ep 10)
[17:14:10] Epoch 20/100 | Train: 0.035895 (MSE=0.002879 BCE=0.6603) | Val: 0.042409 (MSE=0.009119 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042313 (ep 10)
[17:14:10] Early stopping at epoch 20 (no improvement for 10 epochs)
[17:14:11] Factor 8 done — best val loss: 0.042313 at epoch 10
[17:14:11] 
============================================================
[17:14:11] STF Factor 9 of [5..10]
[17:14:11] ============================================================
[17:14:11] Building features: 0% (1/175846)
[17:14:12] Building features: 5% (8793/175846)
[17:14:13] Building features: 10% (17585/175846)
[17:14:13] Building features: 15% (26377/175846)
[17:14:14] Building features: 20% (35169/175846)
[17:14:15] Building features: 25% (43961/175846)
[17:14:16] Building features: 30% (52753/175846)
[17:14:16] Building features: 35% (61545/175846)
[17:14:17] Building features: 40% (70337/175846)
[17:14:18] Building features: 45% (79129/175846)
[17:14:18] Building features: 50% (87921/175846)
[17:14:19] Building features: 55% (96713/175846)
[17:14:20] Building features: 60% (105505/175846)
[17:14:20] Building features: 65% (114297/175846)
[17:14:21] Building features: 70% (123089/175846)
[17:14:21] Building features: 75% (131881/175846)
[17:14:22] Building features: 80% (140673/175846)
[17:14:22] Building features: 85% (149465/175846)
[17:14:23] Building features: 90% (158257/175846)
[17:14:23] Building features: 95% (167049/175846)
[17:14:24] Building features: 100% (175841/175846)
[17:14:24] Computing Hurst exponent...
[17:14:29] Computing market regimes (GMM)...
[17:14:36] Factor 9: 175804 samples, 79 features
[17:14:37] Batch stats — Input:  mean=0.0279 std=0.2033 min=-2.7872 max=6.9471
[17:14:37] Batch stats — Target: mean=-0.0009 std=0.0684 min=-0.3564 max=0.4134
[17:14:37] Batch stats — Cls:    pos_long=102/256 pos_short=87/256
[17:14:37] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:14:42] Epoch 1/100 | Train: 0.036981 (MSE=0.003684 BCE=0.6659) | Val: 0.044521 (MSE=0.011185 BCE=0.6667) | LR: 1.00e-04 | Best: 0.044521 (ep 1)
[17:14:46] Epoch 2/100 | Train: 0.036189 (MSE=0.003098 BCE=0.6618) | Val: 0.043794 (MSE=0.010483 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043794 (ep 2)
[17:14:49] Epoch 3/100 | Train: 0.036115 (MSE=0.003046 BCE=0.6614) | Val: 0.043294 (MSE=0.009999 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043294 (ep 3)
[17:14:52] Epoch 4/100 | Train: 0.036081 (MSE=0.003020 BCE=0.6612) | Val: 0.043079 (MSE=0.009774 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043079 (ep 4)
[17:14:55] Epoch 5/100 | Train: 0.036060 (MSE=0.003004 BCE=0.6611) | Val: 0.042895 (MSE=0.009598 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042895 (ep 5)
[17:14:58] Epoch 6/100 | Train: 0.036041 (MSE=0.002988 BCE=0.6611) | Val: 0.042781 (MSE=0.009482 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042781 (ep 6)
[17:15:01] Epoch 7/100 | Train: 0.036016 (MSE=0.002971 BCE=0.6609) | Val: 0.042605 (MSE=0.009311 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042605 (ep 7)
[17:15:04] Epoch 8/100 | Train: 0.036006 (MSE=0.002959 BCE=0.6609) | Val: 0.042552 (MSE=0.009258 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042552 (ep 8)
[17:15:08] Epoch 9/100 | Train: 0.035985 (MSE=0.002948 BCE=0.6607) | Val: 0.042366 (MSE=0.009066 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042366 (ep 9)
[17:15:11] Epoch 10/100 | Train: 0.035978 (MSE=0.002936 BCE=0.6608) | Val: 0.042432 (MSE=0.009140 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042366 (ep 9)
[17:15:14] Epoch 11/100 | Train: 0.035965 (MSE=0.002929 BCE=0.6607) | Val: 0.042346 (MSE=0.009054 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042346 (ep 11)
[17:15:17] Epoch 12/100 | Train: 0.035955 (MSE=0.002920 BCE=0.6607) | Val: 0.042329 (MSE=0.009032 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042329 (ep 12)
[17:15:20] Epoch 13/100 | Train: 0.035945 (MSE=0.002914 BCE=0.6606) | Val: 0.042230 (MSE=0.008940 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:23] Epoch 14/100 | Train: 0.035936 (MSE=0.002907 BCE=0.6606) | Val: 0.042308 (MSE=0.009020 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:26] Epoch 15/100 | Train: 0.035935 (MSE=0.002904 BCE=0.6606) | Val: 0.042297 (MSE=0.009010 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:30] Epoch 16/100 | Train: 0.035924 (MSE=0.002897 BCE=0.6605) | Val: 0.042342 (MSE=0.009048 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:33] Epoch 17/100 | Train: 0.035915 (MSE=0.002893 BCE=0.6604) | Val: 0.042292 (MSE=0.009009 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:36] Epoch 18/100 | Train: 0.035910 (MSE=0.002887 BCE=0.6605) | Val: 0.042315 (MSE=0.009028 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042230 (ep 13)
[17:15:39] Epoch 19/100 | Train: 0.035904 (MSE=0.002884 BCE=0.6604) | Val: 0.042410 (MSE=0.009122 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[17:15:42] Epoch 20/100 | Train: 0.035887 (MSE=0.002874 BCE=0.6603) | Val: 0.042470 (MSE=0.009180 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[17:15:45] Epoch 21/100 | Train: 0.035881 (MSE=0.002872 BCE=0.6602) | Val: 0.042398 (MSE=0.009112 BCE=0.6657) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[17:15:48] Epoch 22/100 | Train: 0.035878 (MSE=0.002872 BCE=0.6601) | Val: 0.042442 (MSE=0.009156 BCE=0.6657) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[17:15:52] Epoch 23/100 | Train: 0.035879 (MSE=0.002870 BCE=0.6602) | Val: 0.042476 (MSE=0.009181 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042230 (ep 13)
[17:15:52] Early stopping at epoch 23 (no improvement for 10 epochs)
[17:15:53] Factor 9 done — best val loss: 0.042230 at epoch 13
[17:15:53] 
============================================================
[17:15:53] STF Factor 10 of [5..10]
[17:15:53] ============================================================
[17:15:53] Building features: 0% (1/175846)
[17:15:53] Building features: 5% (8793/175846)
[17:15:54] Building features: 10% (17585/175846)
[17:15:55] Building features: 15% (26377/175846)
[17:15:55] Building features: 20% (35169/175846)
[17:15:56] Building features: 25% (43961/175846)
[17:15:56] Building features: 30% (52753/175846)
[17:15:57] Building features: 35% (61545/175846)
[17:15:57] Building features: 40% (70337/175846)
[17:15:58] Building features: 45% (79129/175846)
[17:15:59] Building features: 50% (87921/175846)
[17:15:59] Building features: 55% (96713/175846)
[17:16:00] Building features: 60% (105505/175846)
[17:16:00] Building features: 65% (114297/175846)
[17:16:01] Building features: 70% (123089/175846)
[17:16:02] Building features: 75% (131881/175846)
[17:16:02] Building features: 80% (140673/175846)
[17:16:03] Building features: 85% (149465/175846)
[17:16:04] Building features: 90% (158257/175846)
[17:16:04] Building features: 95% (167049/175846)
[17:16:05] Building features: 100% (175841/175846)
[17:16:05] Computing Hurst exponent...
[17:16:10] Computing market regimes (GMM)...
[17:16:18] Factor 10: 175804 samples, 79 features
[17:16:20] Batch stats — Input:  mean=0.0311 std=0.2010 min=-3.0219 max=12.6954
[17:16:20] Batch stats — Target: mean=0.0009 std=0.0664 min=-0.3453 max=0.4134
[17:16:20] Batch stats — Cls:    pos_long=89/256 pos_short=106/256
[17:16:20] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[17:16:24] Epoch 1/100 | Train: 0.036636 (MSE=0.003449 BCE=0.6637) | Val: 0.044405 (MSE=0.011090 BCE=0.6663) | LR: 1.00e-04 | Best: 0.044405 (ep 1)
[17:16:27] Epoch 2/100 | Train: 0.036154 (MSE=0.003074 BCE=0.6616) | Val: 0.043572 (MSE=0.010255 BCE=0.6663) | LR: 1.00e-04 | Best: 0.043572 (ep 2)
[17:16:30] Epoch 3/100 | Train: 0.036100 (MSE=0.003031 BCE=0.6614) | Val: 0.043094 (MSE=0.009793 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043094 (ep 3)
[17:16:32] Epoch 4/100 | Train: 0.036067 (MSE=0.003009 BCE=0.6612) | Val: 0.042960 (MSE=0.009663 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042960 (ep 4)
[17:16:35] Epoch 5/100 | Train: 0.036047 (MSE=0.002991 BCE=0.6611) | Val: 0.042955 (MSE=0.009653 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042955 (ep 5)
[17:16:38] Epoch 6/100 | Train: 0.036020 (MSE=0.002974 BCE=0.6609) | Val: 0.042819 (MSE=0.009518 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042819 (ep 6)
[17:16:42] Epoch 7/100 | Train: 0.036010 (MSE=0.002963 BCE=0.6609) | Val: 0.042519 (MSE=0.009224 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042519 (ep 7)
[17:16:45] Epoch 8/100 | Train: 0.035990 (MSE=0.002952 BCE=0.6608) | Val: 0.042591 (MSE=0.009299 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042519 (ep 7)
[17:16:48] Epoch 9/100 | Train: 0.035981 (MSE=0.002942 BCE=0.6608) | Val: 0.042428 (MSE=0.009130 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042428 (ep 9)
[17:16:51] Epoch 10/100 | Train: 0.035967 (MSE=0.002929 BCE=0.6608) | Val: 0.042372 (MSE=0.009075 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042372 (ep 10)
[17:16:55] Epoch 11/100 | Train: 0.035962 (MSE=0.002923 BCE=0.6608) | Val: 0.042377 (MSE=0.009083 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042372 (ep 10)
[17:16:58] Epoch 12/100 | Train: 0.035951 (MSE=0.002917 BCE=0.6607) | Val: 0.042330 (MSE=0.009036 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042330 (ep 12)
[17:17:01] Epoch 13/100 | Train: 0.035936 (MSE=0.002910 BCE=0.6605) | Val: 0.042223 (MSE=0.008925 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042223 (ep 13)
[17:17:04] Epoch 14/100 | Train: 0.035936 (MSE=0.002907 BCE=0.6606) | Val: 0.042168 (MSE=0.008876 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:07] Epoch 15/100 | Train: 0.035930 (MSE=0.002899 BCE=0.6606) | Val: 0.042306 (MSE=0.009003 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:10] Epoch 16/100 | Train: 0.035917 (MSE=0.002893 BCE=0.6605) | Val: 0.042315 (MSE=0.009016 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:14] Epoch 17/100 | Train: 0.035913 (MSE=0.002891 BCE=0.6604) | Val: 0.042195 (MSE=0.008908 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:17] Epoch 18/100 | Train: 0.035909 (MSE=0.002887 BCE=0.6604) | Val: 0.042257 (MSE=0.008969 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:20] Epoch 19/100 | Train: 0.035905 (MSE=0.002880 BCE=0.6605) | Val: 0.042288 (MSE=0.008993 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042168 (ep 14)
[17:17:23] Epoch 20/100 | Train: 0.035895 (MSE=0.002877 BCE=0.6603) | Val: 0.042331 (MSE=0.009049 BCE=0.6656) | LR: 5.00e-05 | Best: 0.042168 (ep 14)
[17:17:26] Epoch 21/100 | Train: 0.035878 (MSE=0.002867 BCE=0.6602) | Val: 0.042324 (MSE=0.009027 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042168 (ep 14)
[17:17:29] Epoch 22/100 | Train: 0.035874 (MSE=0.002867 BCE=0.6602) | Val: 0.042336 (MSE=0.009041 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042168 (ep 14)
[17:17:32] Epoch 23/100 | Train: 0.035873 (MSE=0.002865 BCE=0.6602) | Val: 0.042345 (MSE=0.009048 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042168 (ep 14)
[17:17:36] Epoch 24/100 | Train: 0.035868 (MSE=0.002861 BCE=0.6601) | Val: 0.042359 (MSE=0.009066 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042168 (ep 14)
[17:17:36] Early stopping at epoch 24 (no improvement for 10 epochs)
[17:17:37] Factor 10 done — best val loss: 0.042168 at epoch 14
[17:17:37] 
Best factor: 6 (val loss 0.042149)
[17:17:37] Training done. Best factor=6, val_loss=0.042149
[17:19:18] Building validation dataset...
[17:19:18] Building features: 0% (1/175846)
[17:19:18] Building features: 5% (8793/175846)
[17:19:19] Building features: 10% (17585/175846)
[17:19:19] Building features: 15% (26377/175846)
[17:19:20] Building features: 20% (35169/175846)
[17:19:20] Building features: 25% (43961/175846)
[17:19:21] Building features: 30% (52753/175846)
[17:19:21] Building features: 35% (61545/175846)
[17:19:22] Building features: 40% (70337/175846)
[17:19:22] Building features: 45% (79129/175846)
[17:19:23] Building features: 50% (87921/175846)
[17:19:23] Building features: 55% (96713/175846)
[17:19:24] Building features: 60% (105505/175846)
[17:19:24] Building features: 65% (114297/175846)
[17:19:25] Building features: 70% (123089/175846)
[17:19:25] Building features: 75% (131881/175846)
[17:19:26] Building features: 80% (140673/175846)
[17:19:26] Building features: 85% (149465/175846)
[17:19:27] Building features: 90% (158257/175846)
[17:19:27] Building features: 95% (167049/175846)
[17:19:28] Building features: 100% (175841/175846)
[17:19:28] Computing Hurst exponent...
[17:19:34] Computing market regimes (GMM)...
[17:19:42] Running backtest...
[17:19:42] Backtest complete: 7965 trades (3488L/4477S), WR=48.4%, PF=0.93
[18:08:39] NTCP initialized.
[18:08:57] Loaded 175846 M5 bars.
[18:09:28] Training started.
[18:09:28] 
============================================================
[18:09:28] STF Factor 5 of [5..6]
[18:09:28] ============================================================
[18:09:28] Building features: 0% (1/175846)
[18:09:29] Building features: 5% (8793/175846)
[18:09:29] Building features: 10% (17585/175846)
[18:09:30] Building features: 15% (26377/175846)
[18:09:30] Building features: 20% (35169/175846)
[18:09:31] Building features: 25% (43961/175846)
[18:09:31] Building features: 30% (52753/175846)
[18:09:32] Building features: 35% (61545/175846)
[18:09:32] Building features: 40% (70337/175846)
[18:09:33] Building features: 45% (79129/175846)
[18:09:33] Building features: 50% (87921/175846)
[18:09:34] Building features: 55% (96713/175846)
[18:09:34] Building features: 60% (105505/175846)
[18:09:35] Building features: 65% (114297/175846)
[18:09:35] Building features: 70% (123089/175846)
[18:09:35] Building features: 75% (131881/175846)
[18:09:36] Building features: 80% (140673/175846)
[18:09:36] Building features: 85% (149465/175846)
[18:09:37] Building features: 90% (158257/175846)
[18:09:37] Building features: 95% (167049/175846)
[18:09:38] Building features: 100% (175841/175846)
[18:09:38] Skipping market regimes (group unchecked).
[18:09:42] Factor 5: 175804 samples, 79 features
[18:09:43] Batch stats — Input:  mean=0.0291 std=0.2178 min=-7.0610 max=60.4783
[18:09:43] Batch stats — Target: mean=-0.0029 std=0.0615 min=-0.4720 max=0.4134
[18:09:43] Batch stats — Cls:    pos_long=105/256 pos_short=94/256
[18:09:43] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:09:48] Epoch 1/100 | Train: 0.036751 (MSE=0.003514 BCE=0.6647) | Val: 0.044452 (MSE=0.011139 BCE=0.6663) | LR: 1.00e-04 | Best: 0.044452 (ep 1)
[18:09:51] Epoch 2/100 | Train: 0.036150 (MSE=0.003075 BCE=0.6615) | Val: 0.043588 (MSE=0.010286 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043588 (ep 2)
[18:09:53] Epoch 3/100 | Train: 0.036099 (MSE=0.003031 BCE=0.6614) | Val: 0.043213 (MSE=0.009920 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043213 (ep 3)
[18:09:55] Epoch 4/100 | Train: 0.036071 (MSE=0.003008 BCE=0.6613) | Val: 0.042936 (MSE=0.009640 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042936 (ep 4)
[18:09:58] Epoch 5/100 | Train: 0.036047 (MSE=0.002989 BCE=0.6612) | Val: 0.042800 (MSE=0.009504 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042800 (ep 5)
[18:10:00] Epoch 6/100 | Train: 0.036023 (MSE=0.002970 BCE=0.6611) | Val: 0.042664 (MSE=0.009369 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042664 (ep 6)
[18:10:03] Epoch 7/100 | Train: 0.036007 (MSE=0.002958 BCE=0.6610) | Val: 0.042446 (MSE=0.009149 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042446 (ep 7)
[18:10:06] Epoch 8/100 | Train: 0.035993 (MSE=0.002945 BCE=0.6610) | Val: 0.042426 (MSE=0.009133 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042426 (ep 8)
[18:10:09] Epoch 9/100 | Train: 0.035980 (MSE=0.002935 BCE=0.6609) | Val: 0.042427 (MSE=0.009137 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042426 (ep 8)
[18:10:11] Epoch 10/100 | Train: 0.035959 (MSE=0.002923 BCE=0.6607) | Val: 0.042310 (MSE=0.009019 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042310 (ep 10)
[18:10:14] Epoch 11/100 | Train: 0.035961 (MSE=0.002920 BCE=0.6608) | Val: 0.042358 (MSE=0.009061 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042310 (ep 10)
[18:10:17] Epoch 12/100 | Train: 0.035948 (MSE=0.002913 BCE=0.6607) | Val: 0.042322 (MSE=0.009028 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042310 (ep 10)
[18:10:20] Epoch 13/100 | Train: 0.035939 (MSE=0.002905 BCE=0.6607) | Val: 0.042378 (MSE=0.009095 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042310 (ep 10)
[18:10:23] Epoch 14/100 | Train: 0.035933 (MSE=0.002901 BCE=0.6606) | Val: 0.042306 (MSE=0.009017 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042306 (ep 14)
[18:10:26] Epoch 15/100 | Train: 0.035923 (MSE=0.002897 BCE=0.6605) | Val: 0.042315 (MSE=0.009010 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042306 (ep 14)
[18:10:29] Epoch 16/100 | Train: 0.035914 (MSE=0.002891 BCE=0.6605) | Val: 0.042319 (MSE=0.009027 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:32] Epoch 17/100 | Train: 0.035904 (MSE=0.002884 BCE=0.6604) | Val: 0.042378 (MSE=0.009095 BCE=0.6657) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:35] Epoch 18/100 | Train: 0.035903 (MSE=0.002878 BCE=0.6605) | Val: 0.042344 (MSE=0.009056 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:38] Epoch 19/100 | Train: 0.035896 (MSE=0.002878 BCE=0.6604) | Val: 0.042388 (MSE=0.009103 BCE=0.6657) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:40] Epoch 20/100 | Train: 0.035893 (MSE=0.002873 BCE=0.6604) | Val: 0.042475 (MSE=0.009181 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:42] Epoch 21/100 | Train: 0.035893 (MSE=0.002874 BCE=0.6604) | Val: 0.042435 (MSE=0.009155 BCE=0.6656) | LR: 5.00e-05 | Best: 0.042306 (ep 14)
[18:10:45] Epoch 22/100 | Train: 0.035884 (MSE=0.002869 BCE=0.6603) | Val: 0.042557 (MSE=0.009265 BCE=0.6659) | LR: 2.50e-05 | Best: 0.042306 (ep 14)
[18:10:48] Epoch 23/100 | Train: 0.035879 (MSE=0.002866 BCE=0.6603) | Val: 0.042486 (MSE=0.009195 BCE=0.6658) | LR: 2.50e-05 | Best: 0.042306 (ep 14)
[18:10:51] Epoch 24/100 | Train: 0.035874 (MSE=0.002864 BCE=0.6602) | Val: 0.042569 (MSE=0.009273 BCE=0.6659) | LR: 2.50e-05 | Best: 0.042306 (ep 14)
[18:10:51] Early stopping at epoch 24 (no improvement for 10 epochs)
[18:10:52] Factor 5 done — best val loss: 0.042306 at epoch 14
[18:10:52] 
============================================================
[18:10:52] STF Factor 6 of [5..6]
[18:10:52] ============================================================
[18:10:52] Building features: 0% (1/175846)
[18:10:52] Building features: 5% (8793/175846)
[18:10:53] Building features: 10% (17585/175846)
[18:10:53] Building features: 15% (26377/175846)
[18:10:54] Building features: 20% (35169/175846)
[18:10:55] Building features: 25% (43961/175846)
[18:10:55] Building features: 30% (52753/175846)
[18:10:56] Building features: 35% (61545/175846)
[18:10:56] Building features: 40% (70337/175846)
[18:10:57] Building features: 45% (79129/175846)
[18:10:57] Building features: 50% (87921/175846)
[18:10:58] Building features: 55% (96713/175846)
[18:10:58] Building features: 60% (105505/175846)
[18:10:59] Building features: 65% (114297/175846)
[18:11:00] Building features: 70% (123089/175846)
[18:11:00] Building features: 75% (131881/175846)
[18:11:01] Building features: 80% (140673/175846)
[18:11:01] Building features: 85% (149465/175846)
[18:11:02] Building features: 90% (158257/175846)
[18:11:02] Building features: 95% (167049/175846)
[18:11:03] Building features: 100% (175841/175846)
[18:11:03] Skipping market regimes (group unchecked).
[18:11:07] Factor 6: 175804 samples, 79 features
[18:11:09] Batch stats — Input:  mean=0.0293 std=0.2029 min=-3.3455 max=10.0671
[18:11:09] Batch stats — Target: mean=-0.0025 std=0.0661 min=-0.4720 max=0.4134
[18:11:09] Batch stats — Cls:    pos_long=100/256 pos_short=100/256
[18:11:09] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:11:13] Epoch 1/100 | Train: 0.036813 (MSE=0.003587 BCE=0.6645) | Val: 0.044440 (MSE=0.011122 BCE=0.6664) | LR: 1.00e-04 | Best: 0.044440 (ep 1)
[18:11:16] Epoch 2/100 | Train: 0.036165 (MSE=0.003088 BCE=0.6615) | Val: 0.043961 (MSE=0.010639 BCE=0.6664) | LR: 1.00e-04 | Best: 0.043961 (ep 2)
[18:11:19] Epoch 3/100 | Train: 0.036107 (MSE=0.003039 BCE=0.6614) | Val: 0.043266 (MSE=0.009964 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043266 (ep 3)
[18:11:22] Epoch 4/100 | Train: 0.036075 (MSE=0.003012 BCE=0.6613) | Val: 0.043049 (MSE=0.009751 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043049 (ep 4)
[18:11:25] Epoch 5/100 | Train: 0.036046 (MSE=0.002993 BCE=0.6611) | Val: 0.042978 (MSE=0.009686 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042978 (ep 5)
[18:11:28] Epoch 6/100 | Train: 0.036028 (MSE=0.002977 BCE=0.6610) | Val: 0.042775 (MSE=0.009478 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042775 (ep 6)
[18:11:31] Epoch 7/100 | Train: 0.036012 (MSE=0.002962 BCE=0.6610) | Val: 0.042716 (MSE=0.009430 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042716 (ep 7)
[18:11:34] Epoch 8/100 | Train: 0.035995 (MSE=0.002953 BCE=0.6608) | Val: 0.042502 (MSE=0.009214 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042502 (ep 8)
[18:11:37] Epoch 9/100 | Train: 0.035984 (MSE=0.002942 BCE=0.6608) | Val: 0.042476 (MSE=0.009183 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042476 (ep 9)
[18:11:40] Epoch 10/100 | Train: 0.035973 (MSE=0.002935 BCE=0.6608) | Val: 0.042346 (MSE=0.009063 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042346 (ep 10)
[18:11:43] Epoch 11/100 | Train: 0.035963 (MSE=0.002926 BCE=0.6607) | Val: 0.042299 (MSE=0.009005 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042299 (ep 11)
[18:11:46] Epoch 12/100 | Train: 0.035951 (MSE=0.002919 BCE=0.6606) | Val: 0.042301 (MSE=0.008995 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042299 (ep 11)
[18:11:48] Epoch 13/100 | Train: 0.035945 (MSE=0.002913 BCE=0.6606) | Val: 0.042192 (MSE=0.008896 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:11:51] Epoch 14/100 | Train: 0.035938 (MSE=0.002907 BCE=0.6606) | Val: 0.042226 (MSE=0.008928 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:11:54] Epoch 15/100 | Train: 0.035925 (MSE=0.002901 BCE=0.6605) | Val: 0.042264 (MSE=0.008960 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:11:57] Epoch 16/100 | Train: 0.035925 (MSE=0.002897 BCE=0.6606) | Val: 0.042215 (MSE=0.008920 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:12:00] Epoch 17/100 | Train: 0.035914 (MSE=0.002891 BCE=0.6604) | Val: 0.042289 (MSE=0.008998 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:12:03] Epoch 18/100 | Train: 0.035909 (MSE=0.002888 BCE=0.6604) | Val: 0.042289 (MSE=0.008984 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042192 (ep 13)
[18:12:06] Epoch 19/100 | Train: 0.035903 (MSE=0.002885 BCE=0.6604) | Val: 0.042243 (MSE=0.008960 BCE=0.6657) | LR: 5.00e-05 | Best: 0.042192 (ep 13)
[18:12:09] Epoch 20/100 | Train: 0.035892 (MSE=0.002876 BCE=0.6603) | Val: 0.042330 (MSE=0.009037 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042192 (ep 13)
[18:12:12] Epoch 21/100 | Train: 0.035883 (MSE=0.002873 BCE=0.6602) | Val: 0.042281 (MSE=0.008988 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042192 (ep 13)
[18:12:15] Epoch 22/100 | Train: 0.035877 (MSE=0.002872 BCE=0.6601) | Val: 0.042331 (MSE=0.009038 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042192 (ep 13)
[18:12:17] Epoch 23/100 | Train: 0.035877 (MSE=0.002870 BCE=0.6601) | Val: 0.042337 (MSE=0.009045 BCE=0.6658) | LR: 5.00e-05 | Best: 0.042192 (ep 13)
[18:12:17] Early stopping at epoch 23 (no improvement for 10 epochs)
[18:12:18] Factor 6 done — best val loss: 0.042192 at epoch 13
[18:12:18] 
Best factor: 6 (val loss 0.042192)
[18:12:18] Training done. Best factor=6, val_loss=0.042192
[18:15:53] Building validation dataset...
[18:15:53] Building features: 0% (1/175846)
[18:15:53] Building features: 5% (8793/175846)
[18:15:54] Building features: 10% (17585/175846)
[18:15:54] Building features: 15% (26377/175846)
[18:15:55] Building features: 20% (35169/175846)
[18:15:55] Building features: 25% (43961/175846)
[18:15:56] Building features: 30% (52753/175846)
[18:15:56] Building features: 35% (61545/175846)
[18:15:57] Building features: 40% (70337/175846)
[18:15:57] Building features: 45% (79129/175846)
[18:15:58] Building features: 50% (87921/175846)
[18:15:58] Building features: 55% (96713/175846)
[18:15:59] Building features: 60% (105505/175846)
[18:15:59] Building features: 65% (114297/175846)
[18:16:00] Building features: 70% (123089/175846)
[18:16:00] Building features: 75% (131881/175846)
[18:16:01] Building features: 80% (140673/175846)
[18:16:01] Building features: 85% (149465/175846)
[18:16:02] Building features: 90% (158257/175846)
[18:16:02] Building features: 95% (167049/175846)
[18:16:03] Building features: 100% (175841/175846)
[18:16:03] Skipping market regimes (group unchecked).
[18:16:07] Running backtest...
[18:16:07] Backtest complete: 8171 trades (5491L/2680S), WR=49.1%, PF=1.01
[18:16:44] Training started.
[18:16:44] 
============================================================
[18:16:44] STF Factor 5 of [5..6]
[18:16:44] ============================================================
[18:16:44] Building features: 0% (1/175846)
[18:16:45] Building features: 5% (8793/175846)
[18:16:45] Building features: 10% (17585/175846)
[18:16:46] Building features: 15% (26377/175846)
[18:16:46] Building features: 20% (35169/175846)
[18:16:47] Building features: 25% (43961/175846)
[18:16:47] Building features: 30% (52753/175846)
[18:16:48] Building features: 35% (61545/175846)
[18:16:48] Building features: 40% (70337/175846)
[18:16:49] Building features: 45% (79129/175846)
[18:16:49] Building features: 50% (87921/175846)
[18:16:50] Building features: 55% (96713/175846)
[18:16:50] Building features: 60% (105505/175846)
[18:16:51] Building features: 65% (114297/175846)
[18:16:52] Building features: 70% (123089/175846)
[18:16:52] Building features: 75% (131881/175846)
[18:16:53] Building features: 80% (140673/175846)
[18:16:53] Building features: 85% (149465/175846)
[18:16:54] Building features: 90% (158257/175846)
[18:16:54] Building features: 95% (167049/175846)
[18:16:55] Building features: 100% (175841/175846)
[18:16:55] Computing M5 Hurst exponent...
[18:16:58] Computing market regimes (GMM)...
[18:17:03] Computing STF Hurst exponent...
[18:17:09] Factor 5: 175704 samples, 92 features
[18:17:11] Batch stats — Input:  mean=0.0544 std=0.2660 min=-5.4479 max=18.3862
[18:17:11] Batch stats — Target: mean=0.0017 std=0.0639 min=-0.4318 max=0.4134
[18:17:11] Batch stats — Cls:    pos_long=98/256 pos_short=99/256
[18:17:11] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:17:16] Epoch 1/100 | Train: 0.037137 (MSE=0.003964 BCE=0.6635) | Val: 0.044582 (MSE=0.011215 BCE=0.6673) | LR: 1.00e-04 | Best: 0.044582 (ep 1)
[18:17:19] Epoch 2/100 | Train: 0.036201 (MSE=0.003120 BCE=0.6616) | Val: 0.043298 (MSE=0.009947 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043298 (ep 2)
[18:17:22] Epoch 3/100 | Train: 0.036117 (MSE=0.003051 BCE=0.6613) | Val: 0.042667 (MSE=0.009312 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042667 (ep 3)
[18:17:25] Epoch 4/100 | Train: 0.036080 (MSE=0.003018 BCE=0.6612) | Val: 0.042492 (MSE=0.009165 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042492 (ep 4)
[18:17:27] Epoch 5/100 | Train: 0.036047 (MSE=0.002992 BCE=0.6611) | Val: 0.042417 (MSE=0.009073 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042417 (ep 5)
[18:17:30] Epoch 6/100 | Train: 0.036022 (MSE=0.002973 BCE=0.6610) | Val: 0.042339 (MSE=0.009018 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042339 (ep 6)
[18:17:33] Epoch 7/100 | Train: 0.036000 (MSE=0.002959 BCE=0.6608) | Val: 0.042413 (MSE=0.009083 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042339 (ep 6)
[18:17:36] Epoch 8/100 | Train: 0.035987 (MSE=0.002949 BCE=0.6608) | Val: 0.042325 (MSE=0.009003 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042325 (ep 8)
[18:17:39] Epoch 9/100 | Train: 0.035982 (MSE=0.002943 BCE=0.6608) | Val: 0.042334 (MSE=0.008994 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042325 (ep 8)
[18:17:42] Epoch 10/100 | Train: 0.035965 (MSE=0.002930 BCE=0.6607) | Val: 0.042282 (MSE=0.008933 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042282 (ep 10)
[18:17:44] Epoch 11/100 | Train: 0.035955 (MSE=0.002924 BCE=0.6606) | Val: 0.042296 (MSE=0.008955 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042282 (ep 10)
[18:17:46] Epoch 12/100 | Train: 0.035940 (MSE=0.002913 BCE=0.6605) | Val: 0.042311 (MSE=0.008982 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042282 (ep 10)
[18:17:49] Epoch 13/100 | Train: 0.035935 (MSE=0.002910 BCE=0.6605) | Val: 0.042227 (MSE=0.008889 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042227 (ep 13)
[18:17:51] Epoch 14/100 | Train: 0.035922 (MSE=0.002900 BCE=0.6604) | Val: 0.042314 (MSE=0.008993 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042227 (ep 13)
[18:17:54] Epoch 15/100 | Train: 0.035920 (MSE=0.002897 BCE=0.6605) | Val: 0.042214 (MSE=0.008885 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:17:56] Epoch 16/100 | Train: 0.035908 (MSE=0.002890 BCE=0.6604) | Val: 0.042278 (MSE=0.008938 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:17:58] Epoch 17/100 | Train: 0.035900 (MSE=0.002884 BCE=0.6603) | Val: 0.042259 (MSE=0.008918 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:18:01] Epoch 18/100 | Train: 0.035887 (MSE=0.002880 BCE=0.6601) | Val: 0.042382 (MSE=0.009035 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:18:03] Epoch 19/100 | Train: 0.035882 (MSE=0.002873 BCE=0.6602) | Val: 0.042520 (MSE=0.009159 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:18:05] Epoch 20/100 | Train: 0.035875 (MSE=0.002869 BCE=0.6601) | Val: 0.042460 (MSE=0.009109 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042214 (ep 15)
[18:18:07] Epoch 21/100 | Train: 0.035865 (MSE=0.002867 BCE=0.6600) | Val: 0.042367 (MSE=0.008997 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042214 (ep 15)
[18:18:10] Epoch 22/100 | Train: 0.035845 (MSE=0.002856 BCE=0.6598) | Val: 0.042724 (MSE=0.009364 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042214 (ep 15)
[18:18:12] Epoch 23/100 | Train: 0.035846 (MSE=0.002853 BCE=0.6599) | Val: 0.042652 (MSE=0.009305 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042214 (ep 15)
[18:18:15] Epoch 24/100 | Train: 0.035843 (MSE=0.002851 BCE=0.6598) | Val: 0.042428 (MSE=0.009083 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042214 (ep 15)
[18:18:17] Epoch 25/100 | Train: 0.035838 (MSE=0.002851 BCE=0.6597) | Val: 0.042737 (MSE=0.009385 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042214 (ep 15)
[18:18:17] Early stopping at epoch 25 (no improvement for 10 epochs)
[18:18:18] Factor 5 done — best val loss: 0.042214 at epoch 15
[18:18:18] 
============================================================
[18:18:18] STF Factor 6 of [5..6]
[18:18:18] ============================================================
[18:18:18] Building features: 0% (1/175846)
[18:18:18] Building features: 5% (8793/175846)
[18:18:19] Building features: 10% (17585/175846)
[18:18:19] Building features: 15% (26377/175846)
[18:18:20] Building features: 20% (35169/175846)
[18:18:20] Building features: 25% (43961/175846)
[18:18:21] Building features: 30% (52753/175846)
[18:18:21] Building features: 35% (61545/175846)
[18:18:22] Building features: 40% (70337/175846)
[18:18:22] Building features: 45% (79129/175846)
[18:18:23] Building features: 50% (87921/175846)
[18:18:23] Building features: 55% (96713/175846)
[18:18:24] Building features: 60% (105505/175846)
[18:18:24] Building features: 65% (114297/175846)
[18:18:25] Building features: 70% (123089/175846)
[18:18:25] Building features: 75% (131881/175846)
[18:18:26] Building features: 80% (140673/175846)
[18:18:26] Building features: 85% (149465/175846)
[18:18:27] Building features: 90% (158257/175846)
[18:18:27] Building features: 95% (167049/175846)
[18:18:28] Building features: 100% (175841/175846)
[18:18:28] Computing M5 Hurst exponent...
[18:18:30] Computing market regimes (GMM)...
[18:18:33] Computing STF Hurst exponent...
[18:18:40] Factor 6: 175704 samples, 92 features
[18:18:41] Batch stats — Input:  mean=0.0549 std=0.2688 min=-5.7502 max=12.6954
[18:18:41] Batch stats — Target: mean=-0.0073 std=0.0697 min=-0.4720 max=0.2734
[18:18:41] Batch stats — Cls:    pos_long=101/256 pos_short=103/256
[18:18:41] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:18:46] Epoch 1/100 | Train: 0.036975 (MSE=0.003725 BCE=0.6650) | Val: 0.043553 (MSE=0.010203 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043553 (ep 1)
[18:18:49] Epoch 2/100 | Train: 0.036182 (MSE=0.003092 BCE=0.6618) | Val: 0.042796 (MSE=0.009443 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042796 (ep 2)
[18:18:52] Epoch 3/100 | Train: 0.036113 (MSE=0.003039 BCE=0.6615) | Val: 0.042583 (MSE=0.009244 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042583 (ep 3)
[18:18:55] Epoch 4/100 | Train: 0.036081 (MSE=0.003009 BCE=0.6614) | Val: 0.042573 (MSE=0.009231 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042573 (ep 4)
[18:18:57] Epoch 5/100 | Train: 0.036041 (MSE=0.002982 BCE=0.6612) | Val: 0.042421 (MSE=0.009083 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042421 (ep 5)
[18:19:00] Epoch 6/100 | Train: 0.036016 (MSE=0.002963 BCE=0.6610) | Val: 0.042411 (MSE=0.009074 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042411 (ep 6)
[18:19:03] Epoch 7/100 | Train: 0.036001 (MSE=0.002948 BCE=0.6611) | Val: 0.042332 (MSE=0.008996 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042332 (ep 7)
[18:19:06] Epoch 8/100 | Train: 0.035987 (MSE=0.002941 BCE=0.6609) | Val: 0.042329 (MSE=0.008990 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042329 (ep 8)
[18:19:09] Epoch 9/100 | Train: 0.035976 (MSE=0.002929 BCE=0.6609) | Val: 0.042283 (MSE=0.008950 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:12] Epoch 10/100 | Train: 0.035961 (MSE=0.002924 BCE=0.6607) | Val: 0.042316 (MSE=0.008979 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:14] Epoch 11/100 | Train: 0.035953 (MSE=0.002916 BCE=0.6607) | Val: 0.042288 (MSE=0.008956 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:17] Epoch 12/100 | Train: 0.035938 (MSE=0.002906 BCE=0.6606) | Val: 0.042456 (MSE=0.009129 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:20] Epoch 13/100 | Train: 0.035930 (MSE=0.002902 BCE=0.6606) | Val: 0.042591 (MSE=0.009252 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:23] Epoch 14/100 | Train: 0.035921 (MSE=0.002893 BCE=0.6606) | Val: 0.042496 (MSE=0.009155 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042283 (ep 9)
[18:19:26] Epoch 15/100 | Train: 0.035916 (MSE=0.002891 BCE=0.6605) | Val: 0.042461 (MSE=0.009112 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[18:19:29] Epoch 16/100 | Train: 0.035898 (MSE=0.002878 BCE=0.6604) | Val: 0.042515 (MSE=0.009175 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[18:19:32] Epoch 17/100 | Train: 0.035893 (MSE=0.002876 BCE=0.6603) | Val: 0.042567 (MSE=0.009232 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[18:19:34] Epoch 18/100 | Train: 0.035890 (MSE=0.002873 BCE=0.6603) | Val: 0.042554 (MSE=0.009214 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[18:19:37] Epoch 19/100 | Train: 0.035881 (MSE=0.002869 BCE=0.6602) | Val: 0.042611 (MSE=0.009274 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042283 (ep 9)
[18:19:37] Early stopping at epoch 19 (no improvement for 10 epochs)
[18:19:38] Factor 6 done — best val loss: 0.042283 at epoch 9
[18:19:38] 
Best factor: 5 (val loss 0.042214)
[18:19:38] Training done. Best factor=5, val_loss=0.042214
[18:21:45] Building validation dataset...
[18:21:45] Building features: 0% (1/175846)
[18:21:45] Building features: 5% (8793/175846)
[18:21:46] Building features: 10% (17585/175846)
[18:21:46] Building features: 15% (26377/175846)
[18:21:47] Building features: 20% (35169/175846)
[18:21:47] Building features: 25% (43961/175846)
[18:21:48] Building features: 30% (52753/175846)
[18:21:48] Building features: 35% (61545/175846)
[18:21:49] Building features: 40% (70337/175846)
[18:21:50] Building features: 45% (79129/175846)
[18:21:50] Building features: 50% (87921/175846)
[18:21:51] Building features: 55% (96713/175846)
[18:21:51] Building features: 60% (105505/175846)
[18:21:52] Building features: 65% (114297/175846)
[18:21:52] Building features: 70% (123089/175846)
[18:21:53] Building features: 75% (131881/175846)
[18:21:53] Building features: 80% (140673/175846)
[18:21:54] Building features: 85% (149465/175846)
[18:21:54] Building features: 90% (158257/175846)
[18:21:55] Building features: 95% (167049/175846)
[18:21:55] Building features: 100% (175841/175846)
[18:21:55] Computing M5 Hurst exponent...
[18:21:58] Computing market regimes (GMM)...
[18:22:01] Computing STF Hurst exponent...
[18:22:07] Running backtest...
[18:22:08] Backtest complete: 10037 trades (8196L/1841S), WR=48.4%, PF=0.95
[18:22:46] Training started.
[18:22:46] 
============================================================
[18:22:46] STF Factor 5 of [5..6]
[18:22:46] ============================================================
[18:22:46] Building features: 0% (1/175846)
[18:22:46] Building features: 5% (8793/175846)
[18:22:47] Building features: 10% (17585/175846)
[18:22:47] Building features: 15% (26377/175846)
[18:22:48] Building features: 20% (35169/175846)
[18:22:48] Building features: 25% (43961/175846)
[18:22:49] Building features: 30% (52753/175846)
[18:22:50] Building features: 35% (61545/175846)
[18:22:50] Building features: 40% (70337/175846)
[18:22:51] Building features: 45% (79129/175846)
[18:22:51] Building features: 50% (87921/175846)
[18:22:52] Building features: 55% (96713/175846)
[18:22:52] Building features: 60% (105505/175846)
[18:22:53] Building features: 65% (114297/175846)
[18:22:54] Building features: 70% (123089/175846)
[18:22:54] Building features: 75% (131881/175846)
[18:22:55] Building features: 80% (140673/175846)
[18:22:55] Building features: 85% (149465/175846)
[18:22:56] Building features: 90% (158257/175846)
[18:22:57] Building features: 95% (167049/175846)
[18:22:57] Building features: 100% (175841/175846)
[18:22:57] Skipping market regimes (group unchecked).
[18:23:01] Factor 5: 175804 samples, 73 features
[18:23:03] Batch stats — Input:  mean=0.0277 std=0.1874 min=-1.0000 max=1.0000
[18:23:03] Batch stats — Target: mean=0.0020 std=0.0689 min=-0.4720 max=0.4134
[18:23:03] Batch stats — Cls:    pos_long=109/256 pos_short=84/256
[18:23:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:23:08] Epoch 1/100 | Train: 0.036769 (MSE=0.003495 BCE=0.6655) | Val: 0.044565 (MSE=0.011244 BCE=0.6664) | LR: 1.00e-04 | Best: 0.044565 (ep 1)
[18:23:11] Epoch 2/100 | Train: 0.036170 (MSE=0.003097 BCE=0.6615) | Val: 0.043836 (MSE=0.010527 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043836 (ep 2)
[18:23:14] Epoch 3/100 | Train: 0.036108 (MSE=0.003048 BCE=0.6612) | Val: 0.043626 (MSE=0.010320 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043626 (ep 3)
[18:23:17] Epoch 4/100 | Train: 0.036082 (MSE=0.003025 BCE=0.6612) | Val: 0.043614 (MSE=0.010308 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043614 (ep 4)
[18:23:20] Epoch 5/100 | Train: 0.036071 (MSE=0.003013 BCE=0.6612) | Val: 0.043437 (MSE=0.010134 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043437 (ep 5)
[18:23:23] Epoch 6/100 | Train: 0.036051 (MSE=0.002999 BCE=0.6611) | Val: 0.043362 (MSE=0.010061 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043362 (ep 6)
[18:23:26] Epoch 7/100 | Train: 0.036042 (MSE=0.002989 BCE=0.6611) | Val: 0.043386 (MSE=0.010089 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043362 (ep 6)
[18:23:29] Epoch 8/100 | Train: 0.036027 (MSE=0.002979 BCE=0.6610) | Val: 0.043334 (MSE=0.010041 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043334 (ep 8)
[18:23:32] Epoch 9/100 | Train: 0.036015 (MSE=0.002970 BCE=0.6609) | Val: 0.043246 (MSE=0.009947 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043246 (ep 9)
[18:23:34] Epoch 10/100 | Train: 0.036009 (MSE=0.002964 BCE=0.6609) | Val: 0.043136 (MSE=0.009838 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043136 (ep 10)
[18:23:37] Epoch 11/100 | Train: 0.035997 (MSE=0.002958 BCE=0.6608) | Val: 0.043076 (MSE=0.009782 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043076 (ep 11)
[18:23:40] Epoch 12/100 | Train: 0.035991 (MSE=0.002954 BCE=0.6607) | Val: 0.043055 (MSE=0.009768 BCE=0.6657) | LR: 1.00e-04 | Best: 0.043055 (ep 12)
[18:23:43] Epoch 13/100 | Train: 0.035985 (MSE=0.002946 BCE=0.6608) | Val: 0.042974 (MSE=0.009691 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042974 (ep 13)
[18:23:46] Epoch 14/100 | Train: 0.035978 (MSE=0.002943 BCE=0.6607) | Val: 0.042843 (MSE=0.009546 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042843 (ep 14)
[18:23:49] Epoch 15/100 | Train: 0.035970 (MSE=0.002937 BCE=0.6607) | Val: 0.042988 (MSE=0.009703 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042843 (ep 14)
[18:23:52] Epoch 16/100 | Train: 0.035964 (MSE=0.002932 BCE=0.6606) | Val: 0.042848 (MSE=0.009557 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042843 (ep 14)
[18:23:55] Epoch 17/100 | Train: 0.035960 (MSE=0.002928 BCE=0.6607) | Val: 0.042768 (MSE=0.009483 BCE=0.6657) | LR: 1.00e-04 | Best: 0.042768 (ep 17)
[18:23:58] Epoch 18/100 | Train: 0.035955 (MSE=0.002924 BCE=0.6606) | Val: 0.042765 (MSE=0.009475 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042765 (ep 18)
[18:24:01] Epoch 19/100 | Train: 0.035951 (MSE=0.002922 BCE=0.6606) | Val: 0.042696 (MSE=0.009400 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042696 (ep 19)
[18:24:04] Epoch 20/100 | Train: 0.035946 (MSE=0.002919 BCE=0.6605) | Val: 0.042659 (MSE=0.009365 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042659 (ep 20)
[18:24:07] Epoch 21/100 | Train: 0.035940 (MSE=0.002915 BCE=0.6605) | Val: 0.042667 (MSE=0.009374 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042659 (ep 20)
[18:24:10] Epoch 22/100 | Train: 0.035935 (MSE=0.002913 BCE=0.6604) | Val: 0.042646 (MSE=0.009355 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042646 (ep 22)
[18:24:13] Epoch 23/100 | Train: 0.035930 (MSE=0.002907 BCE=0.6605) | Val: 0.042608 (MSE=0.009314 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042608 (ep 23)
[18:24:16] Epoch 24/100 | Train: 0.035926 (MSE=0.002906 BCE=0.6604) | Val: 0.042592 (MSE=0.009292 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042592 (ep 24)
[18:24:19] Epoch 25/100 | Train: 0.035922 (MSE=0.002901 BCE=0.6604) | Val: 0.042597 (MSE=0.009305 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042592 (ep 24)
[18:24:22] Epoch 26/100 | Train: 0.035918 (MSE=0.002899 BCE=0.6604) | Val: 0.042605 (MSE=0.009305 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042592 (ep 24)
[18:24:25] Epoch 27/100 | Train: 0.035914 (MSE=0.002896 BCE=0.6604) | Val: 0.042516 (MSE=0.009200 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042516 (ep 27)
[18:24:28] Epoch 28/100 | Train: 0.035904 (MSE=0.002889 BCE=0.6603) | Val: 0.042573 (MSE=0.009267 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042516 (ep 27)
[18:24:31] Epoch 29/100 | Train: 0.035904 (MSE=0.002887 BCE=0.6603) | Val: 0.042556 (MSE=0.009243 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042516 (ep 27)
[18:24:34] Epoch 30/100 | Train: 0.035894 (MSE=0.002883 BCE=0.6602) | Val: 0.042458 (MSE=0.009149 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:37] Epoch 31/100 | Train: 0.035888 (MSE=0.002879 BCE=0.6602) | Val: 0.042463 (MSE=0.009150 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:40] Epoch 32/100 | Train: 0.035881 (MSE=0.002875 BCE=0.6601) | Val: 0.042592 (MSE=0.009249 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:43] Epoch 33/100 | Train: 0.035882 (MSE=0.002874 BCE=0.6602) | Val: 0.042590 (MSE=0.009269 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:46] Epoch 34/100 | Train: 0.035876 (MSE=0.002869 BCE=0.6601) | Val: 0.042636 (MSE=0.009307 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:48] Epoch 35/100 | Train: 0.035864 (MSE=0.002865 BCE=0.6600) | Val: 0.042565 (MSE=0.009233 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042458 (ep 30)
[18:24:51] Epoch 36/100 | Train: 0.035858 (MSE=0.002860 BCE=0.6600) | Val: 0.042695 (MSE=0.009367 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042458 (ep 30)
[18:24:54] Epoch 37/100 | Train: 0.035848 (MSE=0.002853 BCE=0.6599) | Val: 0.042638 (MSE=0.009300 BCE=0.6668) | LR: 5.00e-05 | Best: 0.042458 (ep 30)
[18:24:57] Epoch 38/100 | Train: 0.035845 (MSE=0.002851 BCE=0.6599) | Val: 0.042652 (MSE=0.009322 BCE=0.6666) | LR: 5.00e-05 | Best: 0.042458 (ep 30)
[18:25:00] Epoch 39/100 | Train: 0.035839 (MSE=0.002849 BCE=0.6598) | Val: 0.042676 (MSE=0.009339 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042458 (ep 30)
[18:25:03] Epoch 40/100 | Train: 0.035839 (MSE=0.002849 BCE=0.6598) | Val: 0.042628 (MSE=0.009285 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042458 (ep 30)
[18:25:03] Early stopping at epoch 40 (no improvement for 10 epochs)
[18:25:04] Factor 5 done — best val loss: 0.042458 at epoch 30
[18:25:04] 
============================================================
[18:25:04] STF Factor 6 of [5..6]
[18:25:04] ============================================================
[18:25:05] Building features: 0% (1/175846)
[18:25:05] Building features: 5% (8793/175846)
[18:25:06] Building features: 10% (17585/175846)
[18:25:06] Building features: 15% (26377/175846)
[18:25:07] Building features: 20% (35169/175846)
[18:25:08] Building features: 25% (43961/175846)
[18:25:08] Building features: 30% (52753/175846)
[18:25:09] Building features: 35% (61545/175846)
[18:25:10] Building features: 40% (70337/175846)
[18:25:10] Building features: 45% (79129/175846)
[18:25:11] Building features: 50% (87921/175846)
[18:25:12] Building features: 55% (96713/175846)
[18:25:12] Building features: 60% (105505/175846)
[18:25:13] Building features: 65% (114297/175846)
[18:25:14] Building features: 70% (123089/175846)
[18:25:14] Building features: 75% (131881/175846)
[18:25:15] Building features: 80% (140673/175846)
[18:25:15] Building features: 85% (149465/175846)
[18:25:16] Building features: 90% (158257/175846)
[18:25:17] Building features: 95% (167049/175846)
[18:25:17] Building features: 100% (175841/175846)
[18:25:17] Skipping market regimes (group unchecked).
[18:25:21] Factor 6: 175804 samples, 73 features
[18:25:23] Batch stats — Input:  mean=0.0267 std=0.1876 min=-1.0000 max=1.0000
[18:25:23] Batch stats — Target: mean=-0.0030 std=0.0639 min=-0.4720 max=0.3520
[18:25:23] Batch stats — Cls:    pos_long=95/256 pos_short=83/256
[18:25:23] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:25:28] Epoch 1/100 | Train: 0.036760 (MSE=0.003467 BCE=0.6659) | Val: 0.044456 (MSE=0.011126 BCE=0.6666) | LR: 1.00e-04 | Best: 0.044456 (ep 1)
[18:25:31] Epoch 2/100 | Train: 0.036172 (MSE=0.003095 BCE=0.6615) | Val: 0.043895 (MSE=0.010587 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043895 (ep 2)
[18:25:34] Epoch 3/100 | Train: 0.036110 (MSE=0.003046 BCE=0.6613) | Val: 0.043619 (MSE=0.010310 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043619 (ep 3)
[18:25:37] Epoch 4/100 | Train: 0.036088 (MSE=0.003024 BCE=0.6613) | Val: 0.043405 (MSE=0.010102 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043405 (ep 4)
[18:25:40] Epoch 5/100 | Train: 0.036068 (MSE=0.003010 BCE=0.6611) | Val: 0.043332 (MSE=0.010037 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043332 (ep 5)
[18:25:43] Epoch 6/100 | Train: 0.036051 (MSE=0.002997 BCE=0.6611) | Val: 0.043345 (MSE=0.010047 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043332 (ep 5)
[18:25:46] Epoch 7/100 | Train: 0.036038 (MSE=0.002986 BCE=0.6610) | Val: 0.043300 (MSE=0.010005 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043300 (ep 7)
[18:25:49] Epoch 8/100 | Train: 0.036026 (MSE=0.002977 BCE=0.6610) | Val: 0.043231 (MSE=0.009924 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043231 (ep 8)
[18:25:52] Epoch 9/100 | Train: 0.036013 (MSE=0.002969 BCE=0.6609) | Val: 0.043151 (MSE=0.009855 BCE=0.6659) | LR: 1.00e-04 | Best: 0.043151 (ep 9)
[18:25:55] Epoch 10/100 | Train: 0.036004 (MSE=0.002963 BCE=0.6608) | Val: 0.043136 (MSE=0.009845 BCE=0.6658) | LR: 1.00e-04 | Best: 0.043136 (ep 10)
[18:25:58] Epoch 11/100 | Train: 0.035996 (MSE=0.002957 BCE=0.6608) | Val: 0.043073 (MSE=0.009776 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043073 (ep 11)
[18:26:01] Epoch 12/100 | Train: 0.035993 (MSE=0.002952 BCE=0.6608) | Val: 0.043102 (MSE=0.009802 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043073 (ep 11)
[18:26:04] Epoch 13/100 | Train: 0.035988 (MSE=0.002948 BCE=0.6608) | Val: 0.043057 (MSE=0.009756 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043057 (ep 13)
[18:26:06] Epoch 14/100 | Train: 0.035979 (MSE=0.002943 BCE=0.6607) | Val: 0.042947 (MSE=0.009656 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042947 (ep 14)
[18:26:09] Epoch 15/100 | Train: 0.035972 (MSE=0.002939 BCE=0.6607) | Val: 0.043015 (MSE=0.009720 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042947 (ep 14)
[18:26:13] Epoch 16/100 | Train: 0.035969 (MSE=0.002935 BCE=0.6607) | Val: 0.043014 (MSE=0.009721 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042947 (ep 14)
[18:26:15] Epoch 17/100 | Train: 0.035965 (MSE=0.002932 BCE=0.6607) | Val: 0.042889 (MSE=0.009591 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042889 (ep 17)
[18:26:18] Epoch 18/100 | Train: 0.035960 (MSE=0.002926 BCE=0.6607) | Val: 0.042897 (MSE=0.009603 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042889 (ep 17)
[18:26:21] Epoch 19/100 | Train: 0.035955 (MSE=0.002926 BCE=0.6606) | Val: 0.042887 (MSE=0.009595 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042887 (ep 19)
[18:26:24] Epoch 20/100 | Train: 0.035947 (MSE=0.002919 BCE=0.6606) | Val: 0.042855 (MSE=0.009562 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042855 (ep 20)
[18:26:27] Epoch 21/100 | Train: 0.035949 (MSE=0.002920 BCE=0.6606) | Val: 0.042857 (MSE=0.009560 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042855 (ep 20)
[18:26:30] Epoch 22/100 | Train: 0.035945 (MSE=0.002916 BCE=0.6606) | Val: 0.042787 (MSE=0.009492 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042787 (ep 22)
[18:26:33] Epoch 23/100 | Train: 0.035933 (MSE=0.002909 BCE=0.6605) | Val: 0.042735 (MSE=0.009428 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042735 (ep 23)
[18:26:36] Epoch 24/100 | Train: 0.035929 (MSE=0.002908 BCE=0.6604) | Val: 0.042727 (MSE=0.009432 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042727 (ep 24)
[18:26:39] Epoch 25/100 | Train: 0.035924 (MSE=0.002902 BCE=0.6604) | Val: 0.042747 (MSE=0.009446 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042727 (ep 24)
[18:26:42] Epoch 26/100 | Train: 0.035915 (MSE=0.002900 BCE=0.6603) | Val: 0.042708 (MSE=0.009408 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042708 (ep 26)
[18:26:45] Epoch 27/100 | Train: 0.035919 (MSE=0.002896 BCE=0.6605) | Val: 0.042634 (MSE=0.009339 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042634 (ep 27)
[18:26:48] Epoch 28/100 | Train: 0.035908 (MSE=0.002892 BCE=0.6603) | Val: 0.042679 (MSE=0.009379 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042634 (ep 27)
[18:26:50] Epoch 29/100 | Train: 0.035902 (MSE=0.002887 BCE=0.6603) | Val: 0.042647 (MSE=0.009323 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042634 (ep 27)
[18:26:53] Epoch 30/100 | Train: 0.035897 (MSE=0.002885 BCE=0.6602) | Val: 0.042571 (MSE=0.009273 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042571 (ep 30)
[18:26:56] Epoch 31/100 | Train: 0.035892 (MSE=0.002880 BCE=0.6602) | Val: 0.042733 (MSE=0.009431 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042571 (ep 30)
[18:26:59] Epoch 32/100 | Train: 0.035893 (MSE=0.002878 BCE=0.6603) | Val: 0.042566 (MSE=0.009254 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:02] Epoch 33/100 | Train: 0.035881 (MSE=0.002875 BCE=0.6601) | Val: 0.042632 (MSE=0.009313 BCE=0.6664) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:05] Epoch 34/100 | Train: 0.035877 (MSE=0.002870 BCE=0.6601) | Val: 0.042645 (MSE=0.009335 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:08] Epoch 35/100 | Train: 0.035867 (MSE=0.002865 BCE=0.6600) | Val: 0.042627 (MSE=0.009281 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:10] Epoch 36/100 | Train: 0.035860 (MSE=0.002862 BCE=0.6600) | Val: 0.042756 (MSE=0.009424 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:13] Epoch 37/100 | Train: 0.035857 (MSE=0.002859 BCE=0.6600) | Val: 0.042696 (MSE=0.009387 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042566 (ep 32)
[18:27:15] Epoch 38/100 | Train: 0.035855 (MSE=0.002854 BCE=0.6600) | Val: 0.042738 (MSE=0.009419 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042566 (ep 32)
[18:27:18] Epoch 39/100 | Train: 0.035834 (MSE=0.002845 BCE=0.6598) | Val: 0.042768 (MSE=0.009449 BCE=0.6664) | LR: 5.00e-05 | Best: 0.042566 (ep 32)
[18:27:20] Epoch 40/100 | Train: 0.035829 (MSE=0.002841 BCE=0.6598) | Val: 0.042829 (MSE=0.009502 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042566 (ep 32)
[18:27:22] Epoch 41/100 | Train: 0.035822 (MSE=0.002839 BCE=0.6597) | Val: 0.043023 (MSE=0.009697 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042566 (ep 32)
[18:27:25] Epoch 42/100 | Train: 0.035824 (MSE=0.002836 BCE=0.6598) | Val: 0.042944 (MSE=0.009619 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042566 (ep 32)
[18:27:25] Early stopping at epoch 42 (no improvement for 10 epochs)
[18:27:26] Factor 6 done — best val loss: 0.042566 at epoch 32
[18:27:26] 
Best factor: 5 (val loss 0.042458)
[18:27:26] Training done. Best factor=5, val_loss=0.042458
[18:27:31] Building validation dataset...
[18:27:31] Building features: 0% (1/175846)
[18:27:32] Building features: 5% (8793/175846)
[18:27:32] Building features: 10% (17585/175846)
[18:27:33] Building features: 15% (26377/175846)
[18:27:33] Building features: 20% (35169/175846)
[18:27:34] Building features: 25% (43961/175846)
[18:27:34] Building features: 30% (52753/175846)
[18:27:35] Building features: 35% (61545/175846)
[18:27:35] Building features: 40% (70337/175846)
[18:27:36] Building features: 45% (79129/175846)
[18:27:36] Building features: 50% (87921/175846)
[18:27:37] Building features: 55% (96713/175846)
[18:27:37] Building features: 60% (105505/175846)
[18:27:38] Building features: 65% (114297/175846)
[18:27:38] Building features: 70% (123089/175846)
[18:27:39] Building features: 75% (131881/175846)
[18:27:39] Building features: 80% (140673/175846)
[18:27:40] Building features: 85% (149465/175846)
[18:27:41] Building features: 90% (158257/175846)
[18:27:41] Building features: 95% (167049/175846)
[18:27:42] Building features: 100% (175841/175846)
[18:27:42] Skipping market regimes (group unchecked).
[18:27:46] Running backtest...
[18:27:46] Backtest complete: 8146 trades (4433L/3713S), WR=48.3%, PF=0.96
[18:29:51] Training started.
[18:29:51] 
============================================================
[18:29:51] STF Factor 5 of [5..6]
[18:29:51] ============================================================
[18:29:51] Building features: 0% (1/175846)
[18:29:52] Building features: 5% (8793/175846)
[18:29:52] Building features: 10% (17585/175846)
[18:29:53] Building features: 15% (26377/175846)
[18:29:53] Building features: 20% (35169/175846)
[18:29:54] Building features: 25% (43961/175846)
[18:29:54] Building features: 30% (52753/175846)
[18:29:55] Building features: 35% (61545/175846)
[18:29:55] Building features: 40% (70337/175846)
[18:29:56] Building features: 45% (79129/175846)
[18:29:57] Building features: 50% (87921/175846)
[18:29:57] Building features: 55% (96713/175846)
[18:29:58] Building features: 60% (105505/175846)
[18:29:58] Building features: 65% (114297/175846)
[18:29:59] Building features: 70% (123089/175846)
[18:29:59] Building features: 75% (131881/175846)
[18:30:00] Building features: 80% (140673/175846)
[18:30:01] Building features: 85% (149465/175846)
[18:30:01] Building features: 90% (158257/175846)
[18:30:02] Building features: 95% (167049/175846)
[18:30:02] Building features: 100% (175841/175846)
[18:30:02] Skipping market regimes (group unchecked).
[18:30:06] Factor 5: 175804 samples, 82 features
[18:30:08] Batch stats — Input:  mean=0.0203 std=0.2150 min=-4.3918 max=6.4875
[18:30:08] Batch stats — Target: mean=0.0027 std=0.0597 min=-0.4720 max=0.3067
[18:30:08] Batch stats — Cls:    pos_long=114/256 pos_short=81/256
[18:30:08] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:30:14] Epoch 1/100 | Train: 0.036774 (MSE=0.003537 BCE=0.6648) | Val: 0.044320 (MSE=0.011010 BCE=0.6662) | LR: 1.00e-04 | Best: 0.044320 (ep 1)
[18:30:16] Epoch 2/100 | Train: 0.036159 (MSE=0.003079 BCE=0.6616) | Val: 0.043545 (MSE=0.010231 BCE=0.6663) | LR: 1.00e-04 | Best: 0.043545 (ep 2)
[18:30:18] Epoch 3/100 | Train: 0.036096 (MSE=0.003030 BCE=0.6613) | Val: 0.043119 (MSE=0.009815 BCE=0.6661) | LR: 1.00e-04 | Best: 0.043119 (ep 3)
[18:30:21] Epoch 4/100 | Train: 0.036059 (MSE=0.003002 BCE=0.6611) | Val: 0.042923 (MSE=0.009626 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042923 (ep 4)
[18:30:24] Epoch 5/100 | Train: 0.036037 (MSE=0.002980 BCE=0.6612) | Val: 0.042683 (MSE=0.009385 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042683 (ep 5)
[18:30:27] Epoch 6/100 | Train: 0.036017 (MSE=0.002963 BCE=0.6611) | Val: 0.042522 (MSE=0.009223 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042522 (ep 6)
[18:30:30] Epoch 7/100 | Train: 0.035996 (MSE=0.002948 BCE=0.6610) | Val: 0.042406 (MSE=0.009099 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042406 (ep 7)
[18:30:33] Epoch 8/100 | Train: 0.035988 (MSE=0.002939 BCE=0.6610) | Val: 0.042339 (MSE=0.009024 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042339 (ep 8)
[18:30:36] Epoch 9/100 | Train: 0.035972 (MSE=0.002929 BCE=0.6609) | Val: 0.042202 (MSE=0.008905 BCE=0.6659) | LR: 1.00e-04 | Best: 0.042202 (ep 9)
[18:30:39] Epoch 10/100 | Train: 0.035960 (MSE=0.002921 BCE=0.6608) | Val: 0.042131 (MSE=0.008841 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042131 (ep 10)
[18:30:42] Epoch 11/100 | Train: 0.035958 (MSE=0.002914 BCE=0.6609) | Val: 0.042129 (MSE=0.008829 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042129 (ep 11)
[18:30:45] Epoch 12/100 | Train: 0.035947 (MSE=0.002910 BCE=0.6607) | Val: 0.042172 (MSE=0.008867 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042129 (ep 11)
[18:30:48] Epoch 13/100 | Train: 0.035936 (MSE=0.002901 BCE=0.6607) | Val: 0.042169 (MSE=0.008881 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042129 (ep 11)
[18:30:51] Epoch 14/100 | Train: 0.035930 (MSE=0.002900 BCE=0.6606) | Val: 0.042152 (MSE=0.008852 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042129 (ep 11)
[18:30:55] Epoch 15/100 | Train: 0.035928 (MSE=0.002894 BCE=0.6607) | Val: 0.042161 (MSE=0.008862 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042129 (ep 11)
[18:30:58] Epoch 16/100 | Train: 0.035916 (MSE=0.002890 BCE=0.6605) | Val: 0.042252 (MSE=0.008956 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:01] Epoch 17/100 | Train: 0.035902 (MSE=0.002882 BCE=0.6604) | Val: 0.042204 (MSE=0.008897 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:04] Epoch 18/100 | Train: 0.035897 (MSE=0.002879 BCE=0.6603) | Val: 0.042240 (MSE=0.008940 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:07] Epoch 19/100 | Train: 0.035896 (MSE=0.002877 BCE=0.6604) | Val: 0.042290 (MSE=0.008973 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:10] Epoch 20/100 | Train: 0.035897 (MSE=0.002878 BCE=0.6604) | Val: 0.042244 (MSE=0.008941 BCE=0.6661) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:13] Epoch 21/100 | Train: 0.035896 (MSE=0.002875 BCE=0.6604) | Val: 0.042329 (MSE=0.009032 BCE=0.6659) | LR: 5.00e-05 | Best: 0.042129 (ep 11)
[18:31:13] Early stopping at epoch 21 (no improvement for 10 epochs)
[18:31:14] Factor 5 done — best val loss: 0.042129 at epoch 11
[18:31:14] 
============================================================
[18:31:14] STF Factor 6 of [5..6]
[18:31:14] ============================================================
[18:31:15] Building features: 0% (1/175846)
[18:31:15] Building features: 5% (8793/175846)
[18:31:16] Building features: 10% (17585/175846)
[18:31:16] Building features: 15% (26377/175846)
[18:31:17] Building features: 20% (35169/175846)
[18:31:18] Building features: 25% (43961/175846)
[18:31:19] Building features: 30% (52753/175846)
[18:31:19] Building features: 35% (61545/175846)
[18:31:20] Building features: 40% (70337/175846)
[18:31:20] Building features: 45% (79129/175846)
[18:31:21] Building features: 50% (87921/175846)
[18:31:22] Building features: 55% (96713/175846)
[18:31:23] Building features: 60% (105505/175846)
[18:31:23] Building features: 65% (114297/175846)
[18:31:24] Building features: 70% (123089/175846)
[18:31:25] Building features: 75% (131881/175846)
[18:31:25] Building features: 80% (140673/175846)
[18:31:26] Building features: 85% (149465/175846)
[18:31:27] Building features: 90% (158257/175846)
[18:31:27] Building features: 95% (167049/175846)
[18:31:28] Building features: 100% (175841/175846)
[18:31:28] Skipping market regimes (group unchecked).
[18:31:32] Factor 6: 175804 samples, 82 features
[18:31:34] Batch stats — Input:  mean=0.0218 std=0.2157 min=-3.9629 max=9.4604
[18:31:34] Batch stats — Target: mean=-0.0019 std=0.0622 min=-0.4027 max=0.3508
[18:31:34] Batch stats — Cls:    pos_long=99/256 pos_short=102/256
[18:31:34] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:31:40] Epoch 1/100 | Train: 0.036858 (MSE=0.003615 BCE=0.6649) | Val: 0.044399 (MSE=0.011055 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044399 (ep 1)
[18:31:43] Epoch 2/100 | Train: 0.036175 (MSE=0.003089 BCE=0.6617) | Val: 0.043536 (MSE=0.010228 BCE=0.6662) | LR: 1.00e-04 | Best: 0.043536 (ep 2)
[18:31:46] Epoch 3/100 | Train: 0.036112 (MSE=0.003041 BCE=0.6614) | Val: 0.043047 (MSE=0.009746 BCE=0.6660) | LR: 1.00e-04 | Best: 0.043047 (ep 3)
[18:31:49] Epoch 4/100 | Train: 0.036073 (MSE=0.003013 BCE=0.6612) | Val: 0.042923 (MSE=0.009617 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042923 (ep 4)
[18:31:52] Epoch 5/100 | Train: 0.036043 (MSE=0.002987 BCE=0.6611) | Val: 0.042489 (MSE=0.009197 BCE=0.6658) | LR: 1.00e-04 | Best: 0.042489 (ep 5)
[18:31:55] Epoch 6/100 | Train: 0.036025 (MSE=0.002970 BCE=0.6611) | Val: 0.042335 (MSE=0.009032 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042335 (ep 6)
[18:31:58] Epoch 7/100 | Train: 0.036006 (MSE=0.002954 BCE=0.6610) | Val: 0.042192 (MSE=0.008889 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042192 (ep 7)
[18:32:00] Epoch 8/100 | Train: 0.035986 (MSE=0.002942 BCE=0.6609) | Val: 0.042247 (MSE=0.008932 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042192 (ep 7)
[18:32:03] Epoch 9/100 | Train: 0.035974 (MSE=0.002932 BCE=0.6608) | Val: 0.042110 (MSE=0.008810 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042110 (ep 9)
[18:32:05] Epoch 10/100 | Train: 0.035966 (MSE=0.002925 BCE=0.6608) | Val: 0.042115 (MSE=0.008816 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042110 (ep 9)
[18:32:08] Epoch 11/100 | Train: 0.035956 (MSE=0.002916 BCE=0.6608) | Val: 0.042113 (MSE=0.008815 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042110 (ep 9)
[18:32:10] Epoch 12/100 | Train: 0.035950 (MSE=0.002914 BCE=0.6607) | Val: 0.042082 (MSE=0.008782 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:13] Epoch 13/100 | Train: 0.035939 (MSE=0.002907 BCE=0.6607) | Val: 0.042088 (MSE=0.008786 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:16] Epoch 14/100 | Train: 0.035936 (MSE=0.002905 BCE=0.6606) | Val: 0.042135 (MSE=0.008822 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:19] Epoch 15/100 | Train: 0.035932 (MSE=0.002900 BCE=0.6606) | Val: 0.042136 (MSE=0.008828 BCE=0.6662) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:22] Epoch 16/100 | Train: 0.035926 (MSE=0.002895 BCE=0.6606) | Val: 0.042098 (MSE=0.008801 BCE=0.6660) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:25] Epoch 17/100 | Train: 0.035917 (MSE=0.002892 BCE=0.6605) | Val: 0.042242 (MSE=0.008936 BCE=0.6661) | LR: 1.00e-04 | Best: 0.042082 (ep 12)
[18:32:28] Epoch 18/100 | Train: 0.035911 (MSE=0.002890 BCE=0.6604) | Val: 0.042152 (MSE=0.008851 BCE=0.6660) | LR: 5.00e-05 | Best: 0.042082 (ep 12)
[18:32:31] Epoch 19/100 | Train: 0.035903 (MSE=0.002881 BCE=0.6604) | Val: 0.042170 (MSE=0.008857 BCE=0.6663) | LR: 5.00e-05 | Best: 0.042082 (ep 12)
[18:32:35] Epoch 20/100 | Train: 0.035899 (MSE=0.002878 BCE=0.6604) | Val: 0.042167 (MSE=0.008857 BCE=0.6662) | LR: 5.00e-05 | Best: 0.042082 (ep 12)
[18:32:38] Epoch 21/100 | Train: 0.035889 (MSE=0.002874 BCE=0.6603) | Val: 0.042183 (MSE=0.008860 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042082 (ep 12)
[18:32:41] Epoch 22/100 | Train: 0.035893 (MSE=0.002876 BCE=0.6603) | Val: 0.042265 (MSE=0.008938 BCE=0.6665) | LR: 5.00e-05 | Best: 0.042082 (ep 12)
[18:32:41] Early stopping at epoch 22 (no improvement for 10 epochs)
[18:32:42] Factor 6 done — best val loss: 0.042082 at epoch 12
[18:32:42] 
Best factor: 6 (val loss 0.042082)
[18:32:42] Training done. Best factor=6, val_loss=0.042082
[18:33:03] Building validation dataset...
[18:33:03] Building features: 0% (1/175846)
[18:33:03] Building features: 5% (8793/175846)
[18:33:04] Building features: 10% (17585/175846)
[18:33:04] Building features: 15% (26377/175846)
[18:33:05] Building features: 20% (35169/175846)
[18:33:05] Building features: 25% (43961/175846)
[18:33:06] Building features: 30% (52753/175846)
[18:33:06] Building features: 35% (61545/175846)
[18:33:07] Building features: 40% (70337/175846)
[18:33:07] Building features: 45% (79129/175846)
[18:33:08] Building features: 50% (87921/175846)
[18:33:08] Building features: 55% (96713/175846)
[18:33:09] Building features: 60% (105505/175846)
[18:33:09] Building features: 65% (114297/175846)
[18:33:10] Building features: 70% (123089/175846)
[18:33:10] Building features: 75% (131881/175846)
[18:33:11] Building features: 80% (140673/175846)
[18:33:11] Building features: 85% (149465/175846)
[18:33:12] Building features: 90% (158257/175846)
[18:33:13] Building features: 95% (167049/175846)
[18:33:13] Building features: 100% (175841/175846)
[18:33:13] Skipping market regimes (group unchecked).
[18:33:17] Running backtest...
[18:33:17] Backtest complete: 10254 trades (6577L/3677S), WR=48.0%, PF=0.92
[18:34:19] Training started.
[18:34:19] 
============================================================
[18:34:19] STF Factor 5 of [5..6]
[18:34:19] ============================================================
[18:34:19] Building features: 0% (1/175846)
[18:34:20] Building features: 5% (8793/175846)
[18:34:20] Building features: 10% (17585/175846)
[18:34:21] Building features: 15% (26377/175846)
[18:34:21] Building features: 20% (35169/175846)
[18:34:22] Building features: 25% (43961/175846)
[18:34:22] Building features: 30% (52753/175846)
[18:34:23] Building features: 35% (61545/175846)
[18:34:23] Building features: 40% (70337/175846)
[18:34:24] Building features: 45% (79129/175846)
[18:34:24] Building features: 50% (87921/175846)
[18:34:25] Building features: 55% (96713/175846)
[18:34:25] Building features: 60% (105505/175846)
[18:34:26] Building features: 65% (114297/175846)
[18:34:26] Building features: 70% (123089/175846)
[18:34:27] Building features: 75% (131881/175846)
[18:34:27] Building features: 80% (140673/175846)
[18:34:28] Building features: 85% (149465/175846)
[18:34:28] Building features: 90% (158257/175846)
[18:34:29] Building features: 95% (167049/175846)
[18:34:29] Building features: 100% (175841/175846)
[18:34:29] Computing M5 Hurst exponent...
[18:34:32] Computing market regimes (GMM)...
[18:34:35] Computing STF Hurst exponent...
[18:34:41] Factor 5: 175644 samples, 92 features
[18:34:43] Batch stats — Input:  mean=0.0565 std=0.2664 min=-7.0610 max=22.9822
[18:34:43] Batch stats — Target: mean=-0.0038 std=0.0638 min=-0.4720 max=0.4117
[18:34:43] Batch stats — Cls:    pos_long=88/256 pos_short=98/256
[18:34:43] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:34:48] Epoch 1/100 | Train: 0.037106 (MSE=0.003879 BCE=0.6645) | Val: 0.043993 (MSE=0.010634 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043993 (ep 1)
[18:34:51] Epoch 2/100 | Train: 0.036196 (MSE=0.003106 BCE=0.6618) | Val: 0.042825 (MSE=0.009473 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042825 (ep 2)
[18:34:54] Epoch 3/100 | Train: 0.036116 (MSE=0.003043 BCE=0.6615) | Val: 0.042633 (MSE=0.009289 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042633 (ep 3)
[18:34:57] Epoch 4/100 | Train: 0.036073 (MSE=0.003012 BCE=0.6612) | Val: 0.042390 (MSE=0.009039 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042390 (ep 4)
[18:35:00] Epoch 5/100 | Train: 0.036045 (MSE=0.002984 BCE=0.6612) | Val: 0.042416 (MSE=0.009080 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042390 (ep 4)
[18:35:03] Epoch 6/100 | Train: 0.036017 (MSE=0.002965 BCE=0.6610) | Val: 0.042339 (MSE=0.009008 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042339 (ep 6)
[18:35:06] Epoch 7/100 | Train: 0.035994 (MSE=0.002951 BCE=0.6609) | Val: 0.042426 (MSE=0.009082 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042339 (ep 6)
[18:35:09] Epoch 8/100 | Train: 0.035987 (MSE=0.002941 BCE=0.6609) | Val: 0.042295 (MSE=0.008949 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042295 (ep 8)
[18:35:12] Epoch 9/100 | Train: 0.035973 (MSE=0.002929 BCE=0.6609) | Val: 0.042360 (MSE=0.009028 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042295 (ep 8)
[18:35:15] Epoch 10/100 | Train: 0.035962 (MSE=0.002920 BCE=0.6609) | Val: 0.042268 (MSE=0.008927 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042268 (ep 10)
[18:35:18] Epoch 11/100 | Train: 0.035952 (MSE=0.002916 BCE=0.6607) | Val: 0.042244 (MSE=0.008897 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:21] Epoch 12/100 | Train: 0.035944 (MSE=0.002911 BCE=0.6607) | Val: 0.042292 (MSE=0.008958 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:25] Epoch 13/100 | Train: 0.035925 (MSE=0.002901 BCE=0.6605) | Val: 0.042344 (MSE=0.009008 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:28] Epoch 14/100 | Train: 0.035928 (MSE=0.002897 BCE=0.6606) | Val: 0.042326 (MSE=0.008984 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:31] Epoch 15/100 | Train: 0.035921 (MSE=0.002890 BCE=0.6606) | Val: 0.042437 (MSE=0.009075 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:34] Epoch 16/100 | Train: 0.035914 (MSE=0.002889 BCE=0.6605) | Val: 0.042416 (MSE=0.009079 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042244 (ep 11)
[18:35:37] Epoch 17/100 | Train: 0.035904 (MSE=0.002883 BCE=0.6604) | Val: 0.042363 (MSE=0.009011 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042244 (ep 11)
[18:35:40] Epoch 18/100 | Train: 0.035881 (MSE=0.002872 BCE=0.6602) | Val: 0.042396 (MSE=0.009050 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042244 (ep 11)
[18:35:43] Epoch 19/100 | Train: 0.035873 (MSE=0.002866 BCE=0.6602) | Val: 0.042472 (MSE=0.009124 BCE=0.6670) | LR: 5.00e-05 | Best: 0.042244 (ep 11)
[18:35:46] Epoch 20/100 | Train: 0.035876 (MSE=0.002868 BCE=0.6602) | Val: 0.042539 (MSE=0.009205 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042244 (ep 11)
[18:35:49] Epoch 21/100 | Train: 0.035872 (MSE=0.002862 BCE=0.6602) | Val: 0.042492 (MSE=0.009155 BCE=0.6667) | LR: 5.00e-05 | Best: 0.042244 (ep 11)
[18:35:49] Early stopping at epoch 21 (no improvement for 10 epochs)
[18:35:50] Factor 5 done — best val loss: 0.042244 at epoch 11
[18:35:50] 
============================================================
[18:35:50] STF Factor 6 of [5..6]
[18:35:50] ============================================================
[18:35:50] Building features: 0% (1/175846)
[18:35:51] Building features: 5% (8793/175846)
[18:35:51] Building features: 10% (17585/175846)
[18:35:52] Building features: 15% (26377/175846)
[18:35:52] Building features: 20% (35169/175846)
[18:35:53] Building features: 25% (43961/175846)
[18:35:53] Building features: 30% (52753/175846)
[18:35:54] Building features: 35% (61545/175846)
[18:35:54] Building features: 40% (70337/175846)
[18:35:55] Building features: 45% (79129/175846)
[18:35:55] Building features: 50% (87921/175846)
[18:35:56] Building features: 55% (96713/175846)
[18:35:56] Building features: 60% (105505/175846)
[18:35:57] Building features: 65% (114297/175846)
[18:35:57] Building features: 70% (123089/175846)
[18:35:58] Building features: 75% (131881/175846)
[18:35:58] Building features: 80% (140673/175846)
[18:35:59] Building features: 85% (149465/175846)
[18:35:59] Building features: 90% (158257/175846)
[18:36:00] Building features: 95% (167049/175846)
[18:36:00] Building features: 100% (175841/175846)
[18:36:00] Computing M5 Hurst exponent...
[18:36:03] Computing market regimes (GMM)...
[18:36:06] Computing STF Hurst exponent...
[18:36:12] Factor 6: 175644 samples, 92 features
[18:36:14] Batch stats — Input:  mean=0.0529 std=0.2736 min=-5.4479 max=60.4783
[18:36:14] Batch stats — Target: mean=0.0017 std=0.0690 min=-0.4720 max=0.4134
[18:36:14] Batch stats — Cls:    pos_long=99/256 pos_short=92/256
[18:36:14] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:36:18] Epoch 1/100 | Train: 0.037278 (MSE=0.004006 BCE=0.6654) | Val: 0.044340 (MSE=0.010995 BCE=0.6669) | LR: 1.00e-04 | Best: 0.044340 (ep 1)
[18:36:22] Epoch 2/100 | Train: 0.036204 (MSE=0.003120 BCE=0.6617) | Val: 0.043077 (MSE=0.009752 BCE=0.6665) | LR: 1.00e-04 | Best: 0.043077 (ep 2)
[18:36:25] Epoch 3/100 | Train: 0.036133 (MSE=0.003062 BCE=0.6614) | Val: 0.042722 (MSE=0.009380 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042722 (ep 3)
[18:36:28] Epoch 4/100 | Train: 0.036088 (MSE=0.003031 BCE=0.6612) | Val: 0.042651 (MSE=0.009314 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042651 (ep 4)
[18:36:31] Epoch 5/100 | Train: 0.036063 (MSE=0.003006 BCE=0.6611) | Val: 0.042523 (MSE=0.009175 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042523 (ep 5)
[18:36:34] Epoch 6/100 | Train: 0.036037 (MSE=0.002981 BCE=0.6611) | Val: 0.042575 (MSE=0.009229 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042523 (ep 5)
[18:36:37] Epoch 7/100 | Train: 0.036013 (MSE=0.002963 BCE=0.6610) | Val: 0.042575 (MSE=0.009231 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042523 (ep 5)
[18:36:40] Epoch 8/100 | Train: 0.035999 (MSE=0.002948 BCE=0.6610) | Val: 0.042479 (MSE=0.009134 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042479 (ep 8)
[18:36:43] Epoch 9/100 | Train: 0.035980 (MSE=0.002936 BCE=0.6609) | Val: 0.042539 (MSE=0.009177 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042479 (ep 8)
[18:36:46] Epoch 10/100 | Train: 0.035974 (MSE=0.002931 BCE=0.6609) | Val: 0.042466 (MSE=0.009106 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042466 (ep 10)
[18:36:49] Epoch 11/100 | Train: 0.035958 (MSE=0.002920 BCE=0.6607) | Val: 0.042420 (MSE=0.009077 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:36:52] Epoch 12/100 | Train: 0.035952 (MSE=0.002913 BCE=0.6608) | Val: 0.042481 (MSE=0.009131 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:36:55] Epoch 13/100 | Train: 0.035939 (MSE=0.002903 BCE=0.6607) | Val: 0.042569 (MSE=0.009208 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:36:58] Epoch 14/100 | Train: 0.035928 (MSE=0.002899 BCE=0.6606) | Val: 0.042669 (MSE=0.009295 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:37:02] Epoch 15/100 | Train: 0.035923 (MSE=0.002894 BCE=0.6606) | Val: 0.042652 (MSE=0.009299 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:37:05] Epoch 16/100 | Train: 0.035912 (MSE=0.002890 BCE=0.6604) | Val: 0.042743 (MSE=0.009387 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042420 (ep 11)
[18:37:08] Epoch 17/100 | Train: 0.035902 (MSE=0.002884 BCE=0.6604) | Val: 0.042641 (MSE=0.009285 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042420 (ep 11)
[18:37:11] Epoch 18/100 | Train: 0.035884 (MSE=0.002874 BCE=0.6602) | Val: 0.042699 (MSE=0.009341 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042420 (ep 11)
[18:37:14] Epoch 19/100 | Train: 0.035879 (MSE=0.002871 BCE=0.6602) | Val: 0.042753 (MSE=0.009368 BCE=0.6677) | LR: 5.00e-05 | Best: 0.042420 (ep 11)
[18:37:17] Epoch 20/100 | Train: 0.035884 (MSE=0.002873 BCE=0.6602) | Val: 0.042843 (MSE=0.009476 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042420 (ep 11)
[18:37:20] Epoch 21/100 | Train: 0.035870 (MSE=0.002866 BCE=0.6601) | Val: 0.042872 (MSE=0.009496 BCE=0.6675) | LR: 5.00e-05 | Best: 0.042420 (ep 11)
[18:37:20] Early stopping at epoch 21 (no improvement for 10 epochs)
[18:37:21] Factor 6 done — best val loss: 0.042420 at epoch 11
[18:37:21] 
Best factor: 5 (val loss 0.042244)
[18:37:21] Training done. Best factor=5, val_loss=0.042244
[18:37:30] Building validation dataset...
[18:37:30] Building features: 0% (1/175846)
[18:37:30] Building features: 5% (8793/175846)
[18:37:31] Building features: 10% (17585/175846)
[18:37:31] Building features: 15% (26377/175846)
[18:37:32] Building features: 20% (35169/175846)
[18:37:32] Building features: 25% (43961/175846)
[18:37:33] Building features: 30% (52753/175846)
[18:37:33] Building features: 35% (61545/175846)
[18:37:34] Building features: 40% (70337/175846)
[18:37:35] Building features: 45% (79129/175846)
[18:37:35] Building features: 50% (87921/175846)
[18:37:36] Building features: 55% (96713/175846)
[18:37:36] Building features: 60% (105505/175846)
[18:37:37] Building features: 65% (114297/175846)
[18:37:37] Building features: 70% (123089/175846)
[18:37:38] Building features: 75% (131881/175846)
[18:37:39] Building features: 80% (140673/175846)
[18:37:39] Building features: 85% (149465/175846)
[18:37:40] Building features: 90% (158257/175846)
[18:37:40] Building features: 95% (167049/175846)
[18:37:41] Building features: 100% (175841/175846)
[18:37:41] Computing M5 Hurst exponent...
[18:37:44] Computing market regimes (GMM)...
[18:37:47] Computing STF Hurst exponent...
[18:37:54] Running backtest...
[18:37:54] Backtest complete: 7364 trades (2640L/4724S), WR=49.0%, PF=0.93
[18:39:14] Training started.
[18:39:14] 
============================================================
[18:39:14] STF Factor 15 of [15..16]
[18:39:14] ============================================================
[18:39:14] Building features: 0% (1/175846)
[18:39:15] Building features: 5% (8793/175846)
[18:39:15] Building features: 10% (17585/175846)
[18:39:16] Building features: 15% (26377/175846)
[18:39:16] Building features: 20% (35169/175846)
[18:39:17] Building features: 25% (43961/175846)
[18:39:17] Building features: 30% (52753/175846)
[18:39:18] Building features: 35% (61545/175846)
[18:39:18] Building features: 40% (70337/175846)
[18:39:19] Building features: 45% (79129/175846)
[18:39:19] Building features: 50% (87921/175846)
[18:39:20] Building features: 55% (96713/175846)
[18:39:20] Building features: 60% (105505/175846)
[18:39:21] Building features: 65% (114297/175846)
[18:39:21] Building features: 70% (123089/175846)
[18:39:22] Building features: 75% (131881/175846)
[18:39:22] Building features: 80% (140673/175846)
[18:39:23] Building features: 85% (149465/175846)
[18:39:23] Building features: 90% (158257/175846)
[18:39:24] Building features: 95% (167049/175846)
[18:39:24] Building features: 100% (175841/175846)
[18:39:24] Computing M5 Hurst exponent...
[18:39:27] Computing market regimes (GMM)...
[18:39:31] Computing STF Hurst exponent...
[18:39:37] Factor 15: 175644 samples, 92 features
[18:39:39] Batch stats — Input:  mean=0.0525 std=0.2694 min=-5.4479 max=60.4783
[18:39:39] Batch stats — Target: mean=-0.0035 std=0.0655 min=-0.4720 max=0.4134
[18:39:39] Batch stats — Cls:    pos_long=95/256 pos_short=95/256
[18:39:39] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:39:46] Epoch 1/100 | Train: 0.037193 (MSE=0.003993 BCE=0.6640) | Val: 0.044076 (MSE=0.010721 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044076 (ep 1)
[18:39:49] Epoch 2/100 | Train: 0.036212 (MSE=0.003132 BCE=0.6616) | Val: 0.042913 (MSE=0.009561 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042913 (ep 2)
[18:39:53] Epoch 3/100 | Train: 0.036140 (MSE=0.003073 BCE=0.6613) | Val: 0.042671 (MSE=0.009313 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042671 (ep 3)
[18:39:57] Epoch 4/100 | Train: 0.036107 (MSE=0.003044 BCE=0.6613) | Val: 0.042585 (MSE=0.009248 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042585 (ep 4)
[18:40:00] Epoch 5/100 | Train: 0.036067 (MSE=0.003013 BCE=0.6611) | Val: 0.042464 (MSE=0.009130 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042464 (ep 5)
[18:40:04] Epoch 6/100 | Train: 0.036031 (MSE=0.002987 BCE=0.6609) | Val: 0.042447 (MSE=0.009110 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042447 (ep 6)
[18:40:08] Epoch 7/100 | Train: 0.036008 (MSE=0.002965 BCE=0.6608) | Val: 0.042366 (MSE=0.009037 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042366 (ep 7)
[18:40:11] Epoch 8/100 | Train: 0.035985 (MSE=0.002946 BCE=0.6608) | Val: 0.042314 (MSE=0.008987 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042314 (ep 8)
[18:40:15] Epoch 9/100 | Train: 0.035976 (MSE=0.002938 BCE=0.6608) | Val: 0.042310 (MSE=0.008973 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042310 (ep 9)
[18:40:19] Epoch 10/100 | Train: 0.035961 (MSE=0.002928 BCE=0.6607) | Val: 0.042299 (MSE=0.008965 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042299 (ep 10)
[18:40:23] Epoch 11/100 | Train: 0.035945 (MSE=0.002917 BCE=0.6606) | Val: 0.042283 (MSE=0.008951 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042283 (ep 11)
[18:40:26] Epoch 12/100 | Train: 0.035933 (MSE=0.002907 BCE=0.6605) | Val: 0.042382 (MSE=0.009050 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042283 (ep 11)
[18:40:30] Epoch 13/100 | Train: 0.035927 (MSE=0.002901 BCE=0.6605) | Val: 0.042432 (MSE=0.009080 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042283 (ep 11)
[18:40:34] Epoch 14/100 | Train: 0.035919 (MSE=0.002896 BCE=0.6605) | Val: 0.042249 (MSE=0.008906 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:37] Epoch 15/100 | Train: 0.035906 (MSE=0.002889 BCE=0.6603) | Val: 0.042392 (MSE=0.009047 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:40] Epoch 16/100 | Train: 0.035897 (MSE=0.002883 BCE=0.6603) | Val: 0.042553 (MSE=0.009194 BCE=0.6672) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:44] Epoch 17/100 | Train: 0.035896 (MSE=0.002880 BCE=0.6603) | Val: 0.042308 (MSE=0.008942 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:47] Epoch 18/100 | Train: 0.035883 (MSE=0.002872 BCE=0.6602) | Val: 0.042602 (MSE=0.009229 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:50] Epoch 19/100 | Train: 0.035876 (MSE=0.002865 BCE=0.6602) | Val: 0.042599 (MSE=0.009247 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042249 (ep 14)
[18:40:54] Epoch 20/100 | Train: 0.035864 (MSE=0.002862 BCE=0.6600) | Val: 0.042485 (MSE=0.009114 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042249 (ep 14)
[18:40:58] Epoch 21/100 | Train: 0.035846 (MSE=0.002850 BCE=0.6599) | Val: 0.042477 (MSE=0.009120 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042249 (ep 14)
[18:41:01] Epoch 22/100 | Train: 0.035841 (MSE=0.002848 BCE=0.6599) | Val: 0.042651 (MSE=0.009285 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042249 (ep 14)
[18:41:05] Epoch 23/100 | Train: 0.035835 (MSE=0.002846 BCE=0.6598) | Val: 0.042625 (MSE=0.009260 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042249 (ep 14)
[18:41:09] Epoch 24/100 | Train: 0.035830 (MSE=0.002841 BCE=0.6598) | Val: 0.042680 (MSE=0.009319 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042249 (ep 14)
[18:41:09] Early stopping at epoch 24 (no improvement for 10 epochs)
[18:41:10] Factor 15 done — best val loss: 0.042249 at epoch 14
[18:41:10] 
============================================================
[18:41:10] STF Factor 16 of [15..16]
[18:41:10] ============================================================
[18:41:10] Building features: 0% (1/175846)
[18:41:10] Building features: 5% (8793/175846)
[18:41:11] Building features: 10% (17585/175846)
[18:41:12] Building features: 15% (26377/175846)
[18:41:12] Building features: 20% (35169/175846)
[18:41:13] Building features: 25% (43961/175846)
[18:41:13] Building features: 30% (52753/175846)
[18:41:14] Building features: 35% (61545/175846)
[18:41:14] Building features: 40% (70337/175846)
[18:41:15] Building features: 45% (79129/175846)
[18:41:16] Building features: 50% (87921/175846)
[18:41:16] Building features: 55% (96713/175846)
[18:41:17] Building features: 60% (105505/175846)
[18:41:17] Building features: 65% (114297/175846)
[18:41:18] Building features: 70% (123089/175846)
[18:41:18] Building features: 75% (131881/175846)
[18:41:19] Building features: 80% (140673/175846)
[18:41:19] Building features: 85% (149465/175846)
[18:41:20] Building features: 90% (158257/175846)
[18:41:21] Building features: 95% (167049/175846)
[18:41:21] Building features: 100% (175841/175846)
[18:41:21] Computing M5 Hurst exponent...
[18:41:24] Computing market regimes (GMM)...
[18:41:27] Computing STF Hurst exponent...
[18:41:34] Factor 16: 175644 samples, 92 features
[18:41:35] Batch stats — Input:  mean=0.0534 std=0.2714 min=-7.0610 max=22.9822
[18:41:35] Batch stats — Target: mean=-0.0037 std=0.0701 min=-0.4720 max=0.3949
[18:41:35] Batch stats — Cls:    pos_long=95/256 pos_short=98/256
[18:41:35] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:41:40] Epoch 1/100 | Train: 0.037136 (MSE=0.003882 BCE=0.6651) | Val: 0.044774 (MSE=0.011422 BCE=0.6671) | LR: 1.00e-04 | Best: 0.044774 (ep 1)
[18:41:43] Epoch 2/100 | Train: 0.036206 (MSE=0.003118 BCE=0.6618) | Val: 0.043286 (MSE=0.009963 BCE=0.6665) | LR: 1.00e-04 | Best: 0.043286 (ep 2)
[18:41:46] Epoch 3/100 | Train: 0.036128 (MSE=0.003062 BCE=0.6613) | Val: 0.042770 (MSE=0.009443 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042770 (ep 3)
[18:41:50] Epoch 4/100 | Train: 0.036099 (MSE=0.003034 BCE=0.6613) | Val: 0.042590 (MSE=0.009264 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042590 (ep 4)
[18:41:54] Epoch 5/100 | Train: 0.036053 (MSE=0.003002 BCE=0.6610) | Val: 0.042447 (MSE=0.009134 BCE=0.6663) | LR: 1.00e-04 | Best: 0.042447 (ep 5)
[18:41:57] Epoch 6/100 | Train: 0.036026 (MSE=0.002978 BCE=0.6610) | Val: 0.042521 (MSE=0.009197 BCE=0.6665) | LR: 1.00e-04 | Best: 0.042447 (ep 5)
[18:42:01] Epoch 7/100 | Train: 0.036011 (MSE=0.002959 BCE=0.6610) | Val: 0.042467 (MSE=0.009137 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042447 (ep 5)
[18:42:04] Epoch 8/100 | Train: 0.035990 (MSE=0.002946 BCE=0.6609) | Val: 0.042420 (MSE=0.009086 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042420 (ep 8)
[18:42:08] Epoch 9/100 | Train: 0.035969 (MSE=0.002935 BCE=0.6607) | Val: 0.042379 (MSE=0.009038 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[18:42:12] Epoch 10/100 | Train: 0.035955 (MSE=0.002926 BCE=0.6606) | Val: 0.042405 (MSE=0.009069 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[18:42:16] Epoch 11/100 | Train: 0.035947 (MSE=0.002918 BCE=0.6606) | Val: 0.042386 (MSE=0.009053 BCE=0.6666) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[18:42:19] Epoch 12/100 | Train: 0.035940 (MSE=0.002909 BCE=0.6606) | Val: 0.042441 (MSE=0.009096 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042379 (ep 9)
[18:42:23] Epoch 13/100 | Train: 0.035921 (MSE=0.002903 BCE=0.6604) | Val: 0.042369 (MSE=0.009018 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:27] Epoch 14/100 | Train: 0.035912 (MSE=0.002899 BCE=0.6603) | Val: 0.042434 (MSE=0.009062 BCE=0.6674) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:31] Epoch 15/100 | Train: 0.035917 (MSE=0.002894 BCE=0.6605) | Val: 0.042399 (MSE=0.009022 BCE=0.6675) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:34] Epoch 16/100 | Train: 0.035901 (MSE=0.002889 BCE=0.6602) | Val: 0.042456 (MSE=0.009104 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:38] Epoch 17/100 | Train: 0.035899 (MSE=0.002880 BCE=0.6604) | Val: 0.042418 (MSE=0.009077 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:42] Epoch 18/100 | Train: 0.035885 (MSE=0.002876 BCE=0.6602) | Val: 0.042566 (MSE=0.009209 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042369 (ep 13)
[18:42:46] Epoch 19/100 | Train: 0.035876 (MSE=0.002867 BCE=0.6602) | Val: 0.042507 (MSE=0.009160 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042369 (ep 13)
[18:42:49] Epoch 20/100 | Train: 0.035855 (MSE=0.002857 BCE=0.6600) | Val: 0.042563 (MSE=0.009216 BCE=0.6669) | LR: 5.00e-05 | Best: 0.042369 (ep 13)
[18:42:53] Epoch 21/100 | Train: 0.035854 (MSE=0.002858 BCE=0.6599) | Val: 0.042637 (MSE=0.009283 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042369 (ep 13)
[18:42:57] Epoch 22/100 | Train: 0.035846 (MSE=0.002855 BCE=0.6598) | Val: 0.042680 (MSE=0.009314 BCE=0.6673) | LR: 5.00e-05 | Best: 0.042369 (ep 13)
[18:43:01] Epoch 23/100 | Train: 0.035838 (MSE=0.002852 BCE=0.6597) | Val: 0.042624 (MSE=0.009263 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042369 (ep 13)
[18:43:01] Early stopping at epoch 23 (no improvement for 10 epochs)
[18:43:02] Factor 16 done — best val loss: 0.042369 at epoch 13
[18:43:02] 
Best factor: 15 (val loss 0.042249)
[18:43:02] Training done. Best factor=15, val_loss=0.042249
[18:43:55] Building validation dataset...
[18:43:55] Building features: 0% (1/175846)
[18:43:55] Building features: 5% (8793/175846)
[18:43:56] Building features: 10% (17585/175846)
[18:43:56] Building features: 15% (26377/175846)
[18:43:57] Building features: 20% (35169/175846)
[18:43:57] Building features: 25% (43961/175846)
[18:43:58] Building features: 30% (52753/175846)
[18:43:58] Building features: 35% (61545/175846)
[18:43:59] Building features: 40% (70337/175846)
[18:43:59] Building features: 45% (79129/175846)
[18:44:00] Building features: 50% (87921/175846)
[18:44:01] Building features: 55% (96713/175846)
[18:44:01] Building features: 60% (105505/175846)
[18:44:02] Building features: 65% (114297/175846)
[18:44:02] Building features: 70% (123089/175846)
[18:44:03] Building features: 75% (131881/175846)
[18:44:04] Building features: 80% (140673/175846)
[18:44:04] Building features: 85% (149465/175846)
[18:44:05] Building features: 90% (158257/175846)
[18:44:06] Building features: 95% (167049/175846)
[18:44:06] Building features: 100% (175841/175846)
[18:44:06] Computing M5 Hurst exponent...
[18:44:09] Computing market regimes (GMM)...
[18:44:12] Computing STF Hurst exponent...
[18:44:19] Running backtest...
[18:44:20] Backtest complete: 9390 trades (2605L/6785S), WR=49.6%, PF=0.93
[18:45:32] NTCP initialized.
[18:45:49] Loaded 175846 M5 bars.
[18:46:43] Training started.
[18:46:43] 
============================================================
[18:46:43] STF Factor 5 of [5..5]
[18:46:43] ============================================================
[18:46:43] Building features: 0% (1/175846)
[18:46:44] Building features: 5% (8793/175846)
[18:46:44] Building features: 10% (17585/175846)
[18:46:45] Building features: 15% (26377/175846)
[18:46:45] Building features: 20% (35169/175846)
[18:46:46] Building features: 25% (43961/175846)
[18:46:46] Building features: 30% (52753/175846)
[18:46:47] Building features: 35% (61545/175846)
[18:46:47] Building features: 40% (70337/175846)
[18:46:48] Building features: 45% (79129/175846)
[18:46:48] Building features: 50% (87921/175846)
[18:46:49] Building features: 55% (96713/175846)
[18:46:49] Building features: 60% (105505/175846)
[18:46:50] Building features: 65% (114297/175846)
[18:46:51] Building features: 70% (123089/175846)
[18:46:51] Building features: 75% (131881/175846)
[18:46:52] Building features: 80% (140673/175846)
[18:46:52] Building features: 85% (149465/175846)
[18:46:53] Building features: 90% (158257/175846)
[18:46:53] Building features: 95% (167049/175846)
[18:46:54] Building features: 100% (175841/175846)
[18:46:54] Computing M5 Hurst exponent...
[18:46:56] Computing market regimes (GMM)...
[18:47:02] Computing STF Hurst exponent...
[18:47:07] Factor 5: 175626 samples, 92 features
[18:47:09] Batch stats — Input:  mean=0.0550 std=0.2681 min=-6.3104 max=9.5638
[18:47:09] Batch stats — Target: mean=0.0046 std=0.1576 min=-1.6304 max=1.0781
[18:47:09] Batch stats — Cls:    pos_long=2/256 pos_short=0/256
[18:47:09] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:47:14] Epoch 1/100 | Train: 0.026150 (MSE=0.021060 BCE=0.1018) | Val: 0.079516 (MSE=0.077745 BCE=0.0354) | LR: 1.00e-04 | Best: 0.079516 (ep 1)
[18:47:17] Epoch 2/100 | Train: 0.020865 (MSE=0.019123 BCE=0.0348) | Val: 0.066080 (MSE=0.064312 BCE=0.0354) | LR: 1.00e-04 | Best: 0.066080 (ep 2)
[18:47:19] Epoch 3/100 | Train: 0.020368 (MSE=0.018622 BCE=0.0349) | Val: 0.064765 (MSE=0.063012 BCE=0.0351) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:22] Epoch 4/100 | Train: 0.020107 (MSE=0.018380 BCE=0.0345) | Val: 0.065967 (MSE=0.064217 BCE=0.0350) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:24] Epoch 5/100 | Train: 0.019882 (MSE=0.018167 BCE=0.0343) | Val: 0.065513 (MSE=0.063767 BCE=0.0349) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:27] Epoch 6/100 | Train: 0.019712 (MSE=0.017993 BCE=0.0344) | Val: 0.068609 (MSE=0.066879 BCE=0.0346) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:29] Epoch 7/100 | Train: 0.019506 (MSE=0.017809 BCE=0.0339) | Val: 0.071393 (MSE=0.069662 BCE=0.0346) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:32] Epoch 8/100 | Train: 0.019271 (MSE=0.017591 BCE=0.0336) | Val: 0.075799 (MSE=0.074091 BCE=0.0342) | LR: 1.00e-04 | Best: 0.064765 (ep 3)
[18:47:34] Epoch 9/100 | Train: 0.019070 (MSE=0.017423 BCE=0.0330) | Val: 0.079173 (MSE=0.077494 BCE=0.0336) | LR: 5.00e-05 | Best: 0.064765 (ep 3)
[18:47:37] Epoch 10/100 | Train: 0.018816 (MSE=0.017203 BCE=0.0323) | Val: 0.079392 (MSE=0.077738 BCE=0.0331) | LR: 5.00e-05 | Best: 0.064765 (ep 3)
[18:47:40] Epoch 11/100 | Train: 0.018685 (MSE=0.017101 BCE=0.0317) | Val: 0.080577 (MSE=0.078929 BCE=0.0330) | LR: 5.00e-05 | Best: 0.064765 (ep 3)
[18:47:42] Epoch 12/100 | Train: 0.018543 (MSE=0.016982 BCE=0.0312) | Val: 0.083201 (MSE=0.081555 BCE=0.0329) | LR: 5.00e-05 | Best: 0.064765 (ep 3)
[18:47:45] Epoch 13/100 | Train: 0.018447 (MSE=0.016908 BCE=0.0308) | Val: 0.084849 (MSE=0.083210 BCE=0.0328) | LR: 5.00e-05 | Best: 0.064765 (ep 3)
[18:47:45] Early stopping at epoch 13 (no improvement for 10 epochs)
[18:47:46] Factor 5 done — best val loss: 0.064765 at epoch 3
[18:47:46] 
Best factor: 5 (val loss 0.064765)
[18:47:46] Training done. Best factor=5, val_loss=0.064765
[18:47:54] Building validation dataset...
[18:47:54] Building features: 0% (1/175846)
[18:47:54] Building features: 5% (8793/175846)
[18:47:55] Building features: 10% (17585/175846)
[18:47:55] Building features: 15% (26377/175846)
[18:47:56] Building features: 20% (35169/175846)
[18:47:56] Building features: 25% (43961/175846)
[18:47:57] Building features: 30% (52753/175846)
[18:47:58] Building features: 35% (61545/175846)
[18:47:58] Building features: 40% (70337/175846)
[18:47:59] Building features: 45% (79129/175846)
[18:47:59] Building features: 50% (87921/175846)
[18:48:00] Building features: 55% (96713/175846)
[18:48:01] Building features: 60% (105505/175846)
[18:48:01] Building features: 65% (114297/175846)
[18:48:02] Building features: 70% (123089/175846)
[18:48:03] Building features: 75% (131881/175846)
[18:48:03] Building features: 80% (140673/175846)
[18:48:04] Building features: 85% (149465/175846)
[18:48:04] Building features: 90% (158257/175846)
[18:48:05] Building features: 95% (167049/175846)
[18:48:06] Building features: 100% (175841/175846)
[18:48:06] Computing M5 Hurst exponent...
[18:48:08] Computing market regimes (GMM)...
[18:48:12] Computing STF Hurst exponent...
[18:48:18] Running backtest...
[18:48:18] Backtest complete: 8280 trades (8280L/0S), WR=48.8%, PF=0.92
[18:51:31] Training started.
[18:51:31] 
============================================================
[18:51:31] STF Factor 5 of [5..5]
[18:51:31] ============================================================
[18:51:31] Building features: 0% (1/175846)
[18:51:31] Building features: 5% (8793/175846)
[18:51:32] Building features: 10% (17585/175846)
[18:51:33] Building features: 15% (26377/175846)
[18:51:33] Building features: 20% (35169/175846)
[18:51:34] Building features: 25% (43961/175846)
[18:51:35] Building features: 30% (52753/175846)
[18:51:35] Building features: 35% (61545/175846)
[18:51:36] Building features: 40% (70337/175846)
[18:51:36] Building features: 45% (79129/175846)
[18:51:37] Building features: 50% (87921/175846)
[18:51:38] Building features: 55% (96713/175846)
[18:51:38] Building features: 60% (105505/175846)
[18:51:39] Building features: 65% (114297/175846)
[18:51:40] Building features: 70% (123089/175846)
[18:51:40] Building features: 75% (131881/175846)
[18:51:41] Building features: 80% (140673/175846)
[18:51:42] Building features: 85% (149465/175846)
[18:51:43] Building features: 90% (158257/175846)
[18:51:43] Building features: 95% (167049/175846)
[18:51:44] Building features: 100% (175841/175846)
[18:51:44] Computing M5 Hurst exponent...
[18:51:47] Computing market regimes (GMM)...
[18:51:50] Computing STF Hurst exponent...
[18:51:56] Factor 5: 175626 samples, 92 features
[18:51:58] Batch stats — Input:  mean=0.0541 std=0.2660 min=-4.0825 max=15.9549
[18:51:58] Batch stats — Target: mean=-0.0007 std=0.1573 min=-1.3219 max=1.0392
[18:51:58] Batch stats — Cls:    pos_long=0/256 pos_short=0/256
[18:51:58] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:52:03] Epoch 1/100 | Train: 0.024786 (MSE=0.020917 BCE=0.0774) | Val: 0.079934 (MSE=0.079923 BCE=0.0002) | LR: 1.00e-04 | Best: 0.079934 (ep 1)
[18:52:06] Epoch 2/100 | Train: 0.019122 (MSE=0.019111 BCE=0.0002) | Val: 0.062765 (MSE=0.062761 BCE=0.0001) | LR: 1.00e-04 | Best: 0.062765 (ep 2)
[18:52:09] Epoch 3/100 | Train: 0.018681 (MSE=0.018674 BCE=0.0001) | Val: 0.062055 (MSE=0.062052 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:11] Epoch 4/100 | Train: 0.018435 (MSE=0.018430 BCE=0.0001) | Val: 0.062843 (MSE=0.062841 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:14] Epoch 5/100 | Train: 0.018269 (MSE=0.018265 BCE=0.0001) | Val: 0.063917 (MSE=0.063915 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:16] Epoch 6/100 | Train: 0.018107 (MSE=0.018104 BCE=0.0001) | Val: 0.064788 (MSE=0.064786 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:19] Epoch 7/100 | Train: 0.017942 (MSE=0.017940 BCE=0.0000) | Val: 0.066984 (MSE=0.066979 BCE=0.0001) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:21] Epoch 8/100 | Train: 0.017777 (MSE=0.017775 BCE=0.0000) | Val: 0.067917 (MSE=0.067908 BCE=0.0002) | LR: 1.00e-04 | Best: 0.062055 (ep 3)
[18:52:24] Epoch 9/100 | Train: 0.017582 (MSE=0.017581 BCE=0.0000) | Val: 0.069609 (MSE=0.069600 BCE=0.0002) | LR: 5.00e-05 | Best: 0.062055 (ep 3)
[18:52:27] Epoch 10/100 | Train: 0.017397 (MSE=0.017397 BCE=0.0000) | Val: 0.070732 (MSE=0.070726 BCE=0.0001) | LR: 5.00e-05 | Best: 0.062055 (ep 3)
[18:52:31] Epoch 11/100 | Train: 0.017272 (MSE=0.017272 BCE=0.0000) | Val: 0.072009 (MSE=0.072004 BCE=0.0001) | LR: 5.00e-05 | Best: 0.062055 (ep 3)
[18:52:34] Epoch 12/100 | Train: 0.017172 (MSE=0.017172 BCE=0.0000) | Val: 0.074207 (MSE=0.074204 BCE=0.0001) | LR: 5.00e-05 | Best: 0.062055 (ep 3)
[18:52:37] Epoch 13/100 | Train: 0.017055 (MSE=0.017055 BCE=0.0000) | Val: 0.076220 (MSE=0.076217 BCE=0.0001) | LR: 5.00e-05 | Best: 0.062055 (ep 3)
[18:52:37] Early stopping at epoch 13 (no improvement for 10 epochs)
[18:52:38] Factor 5 done — best val loss: 0.062055 at epoch 3
[18:52:38] 
Best factor: 5 (val loss 0.062055)
[18:52:38] Training done. Best factor=5, val_loss=0.062055
[18:53:34] Building validation dataset...
[18:53:34] Building features: 0% (1/175846)
[18:53:34] Building features: 5% (8793/175846)
[18:53:35] Building features: 10% (17585/175846)
[18:53:35] Building features: 15% (26377/175846)
[18:53:36] Building features: 20% (35169/175846)
[18:53:36] Building features: 25% (43961/175846)
[18:53:37] Building features: 30% (52753/175846)
[18:53:37] Building features: 35% (61545/175846)
[18:53:38] Building features: 40% (70337/175846)
[18:53:38] Building features: 45% (79129/175846)
[18:53:39] Building features: 50% (87921/175846)
[18:53:39] Building features: 55% (96713/175846)
[18:53:40] Building features: 60% (105505/175846)
[18:53:41] Building features: 65% (114297/175846)
[18:53:41] Building features: 70% (123089/175846)
[18:53:42] Building features: 75% (131881/175846)
[18:53:42] Building features: 80% (140673/175846)
[18:53:43] Building features: 85% (149465/175846)
[18:53:44] Building features: 90% (158257/175846)
[18:53:44] Building features: 95% (167049/175846)
[18:53:45] Building features: 100% (175841/175846)
[18:53:45] Computing M5 Hurst exponent...
[18:53:48] Computing market regimes (GMM)...
[18:53:51] Computing STF Hurst exponent...
[18:53:58] Running backtest...
[18:53:58] Backtest complete: 7416 trades (3327L/4089S), WR=49.0%, PF=0.97
[18:54:41] Training started.
[18:54:41] 
============================================================
[18:54:41] STF Factor 15 of [15..15]
[18:54:41] ============================================================
[18:54:41] Building features: 0% (1/175846)
[18:54:42] Building features: 5% (8793/175846)
[18:54:42] Building features: 10% (17585/175846)
[18:54:43] Building features: 15% (26377/175846)
[18:54:43] Building features: 20% (35169/175846)
[18:54:44] Building features: 25% (43961/175846)
[18:54:44] Building features: 30% (52753/175846)
[18:54:45] Building features: 35% (61545/175846)
[18:54:45] Building features: 40% (70337/175846)
[18:54:46] Building features: 45% (79129/175846)
[18:54:46] Building features: 50% (87921/175846)
[18:54:47] Building features: 55% (96713/175846)
[18:54:48] Building features: 60% (105505/175846)
[18:54:48] Building features: 65% (114297/175846)
[18:54:49] Building features: 70% (123089/175846)
[18:54:49] Building features: 75% (131881/175846)
[18:54:50] Building features: 80% (140673/175846)
[18:54:51] Building features: 85% (149465/175846)
[18:54:51] Building features: 90% (158257/175846)
[18:54:52] Building features: 95% (167049/175846)
[18:54:52] Building features: 100% (175841/175846)
[18:54:52] Computing M5 Hurst exponent...
[18:54:55] Computing market regimes (GMM)...
[18:54:58] Computing STF Hurst exponent...
[18:55:05] Factor 15: 175626 samples, 92 features
[18:55:07] Batch stats — Input:  mean=0.0522 std=0.2693 min=-4.2128 max=9.9344
[18:55:07] Batch stats — Target: mean=0.0060 std=0.1652 min=-1.8057 max=1.3001
[18:55:07] Batch stats — Cls:    pos_long=0/256 pos_short=0/256
[18:55:07] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:55:12] Epoch 1/100 | Train: 0.024442 (MSE=0.021116 BCE=0.0665) | Val: 0.081212 (MSE=0.081206 BCE=0.0001) | LR: 1.00e-04 | Best: 0.081212 (ep 1)
[18:55:15] Epoch 2/100 | Train: 0.019163 (MSE=0.019155 BCE=0.0002) | Val: 0.069124 (MSE=0.069122 BCE=0.0000) | LR: 1.00e-04 | Best: 0.069124 (ep 2)
[18:55:18] Epoch 3/100 | Train: 0.018733 (MSE=0.018729 BCE=0.0001) | Val: 0.063711 (MSE=0.063709 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:21] Epoch 4/100 | Train: 0.018385 (MSE=0.018382 BCE=0.0001) | Val: 0.063833 (MSE=0.063833 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:24] Epoch 5/100 | Train: 0.018137 (MSE=0.018135 BCE=0.0000) | Val: 0.065418 (MSE=0.065418 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:27] Epoch 6/100 | Train: 0.017922 (MSE=0.017921 BCE=0.0000) | Val: 0.068309 (MSE=0.068309 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:30] Epoch 7/100 | Train: 0.017720 (MSE=0.017719 BCE=0.0000) | Val: 0.070934 (MSE=0.070934 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:34] Epoch 8/100 | Train: 0.017530 (MSE=0.017529 BCE=0.0000) | Val: 0.079041 (MSE=0.079041 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063711 (ep 3)
[18:55:37] Epoch 9/100 | Train: 0.017309 (MSE=0.017309 BCE=0.0000) | Val: 0.084509 (MSE=0.084509 BCE=0.0000) | LR: 5.00e-05 | Best: 0.063711 (ep 3)
[18:55:40] Epoch 10/100 | Train: 0.017068 (MSE=0.017068 BCE=0.0000) | Val: 0.083665 (MSE=0.083665 BCE=0.0000) | LR: 5.00e-05 | Best: 0.063711 (ep 3)
[18:55:43] Epoch 11/100 | Train: 0.016948 (MSE=0.016948 BCE=0.0000) | Val: 0.085935 (MSE=0.085935 BCE=0.0000) | LR: 5.00e-05 | Best: 0.063711 (ep 3)
[18:55:46] Epoch 12/100 | Train: 0.016820 (MSE=0.016820 BCE=0.0000) | Val: 0.084411 (MSE=0.084411 BCE=0.0000) | LR: 5.00e-05 | Best: 0.063711 (ep 3)
[18:55:49] Epoch 13/100 | Train: 0.016714 (MSE=0.016714 BCE=0.0000) | Val: 0.087594 (MSE=0.087594 BCE=0.0000) | LR: 5.00e-05 | Best: 0.063711 (ep 3)
[18:55:49] Early stopping at epoch 13 (no improvement for 10 epochs)
[18:55:50] Factor 15 done — best val loss: 0.063711 at epoch 3
[18:55:50] 
Best factor: 15 (val loss 0.063711)
[18:55:50] Training done. Best factor=15, val_loss=0.063711
[18:55:56] Building validation dataset...
[18:55:56] Building features: 0% (1/175846)
[18:55:57] Building features: 5% (8793/175846)
[18:55:57] Building features: 10% (17585/175846)
[18:55:58] Building features: 15% (26377/175846)
[18:55:58] Building features: 20% (35169/175846)
[18:55:59] Building features: 25% (43961/175846)
[18:55:59] Building features: 30% (52753/175846)
[18:56:00] Building features: 35% (61545/175846)
[18:56:00] Building features: 40% (70337/175846)
[18:56:01] Building features: 45% (79129/175846)
[18:56:01] Building features: 50% (87921/175846)
[18:56:02] Building features: 55% (96713/175846)
[18:56:02] Building features: 60% (105505/175846)
[18:56:03] Building features: 65% (114297/175846)
[18:56:03] Building features: 70% (123089/175846)
[18:56:04] Building features: 75% (131881/175846)
[18:56:04] Building features: 80% (140673/175846)
[18:56:05] Building features: 85% (149465/175846)
[18:56:05] Building features: 90% (158257/175846)
[18:56:06] Building features: 95% (167049/175846)
[18:56:06] Building features: 100% (175841/175846)
[18:56:06] Computing M5 Hurst exponent...
[18:56:09] Computing market regimes (GMM)...
[18:56:12] Computing STF Hurst exponent...
[18:56:18] Running backtest...
[18:56:18] Backtest complete: 12771 trades (12771L/0S), WR=49.6%, PF=0.95
[18:57:01] Training started.
[18:57:01] 
============================================================
[18:57:01] STF Factor 60 of [60..60]
[18:57:01] ============================================================
[18:57:01] Building features: 0% (1/175846)
[18:57:01] Building features: 5% (8793/175846)
[18:57:02] Building features: 10% (17585/175846)
[18:57:03] Building features: 15% (26377/175846)
[18:57:03] Building features: 20% (35169/175846)
[18:57:04] Building features: 25% (43961/175846)
[18:57:04] Building features: 30% (52753/175846)
[18:57:05] Building features: 35% (61545/175846)
[18:57:05] Building features: 40% (70337/175846)
[18:57:06] Building features: 45% (79129/175846)
[18:57:06] Building features: 50% (87921/175846)
[18:57:07] Building features: 55% (96713/175846)
[18:57:07] Building features: 60% (105505/175846)
[18:57:08] Building features: 65% (114297/175846)
[18:57:08] Building features: 70% (123089/175846)
[18:57:09] Building features: 75% (131881/175846)
[18:57:09] Building features: 80% (140673/175846)
[18:57:10] Building features: 85% (149465/175846)
[18:57:11] Building features: 90% (158257/175846)
[18:57:11] Building features: 95% (167049/175846)
[18:57:12] Building features: 100% (175841/175846)
[18:57:12] Computing M5 Hurst exponent...
[18:57:14] Computing market regimes (GMM)...
[18:57:18] Computing STF Hurst exponent...
[18:57:24] Factor 60: 175626 samples, 92 features
[18:57:26] Batch stats — Input:  mean=0.0497 std=0.2754 min=-4.1165 max=8.2644
[18:57:26] Batch stats — Target: mean=-0.0032 std=0.1749 min=-1.9124 max=1.1077
[18:57:26] Batch stats — Cls:    pos_long=0/256 pos_short=0/256
[18:57:26] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[18:57:30] Epoch 1/100 | Train: 0.024170 (MSE=0.020853 BCE=0.0663) | Val: 0.075082 (MSE=0.075069 BCE=0.0003) | LR: 1.00e-04 | Best: 0.075082 (ep 1)
[18:57:33] Epoch 2/100 | Train: 0.019121 (MSE=0.019107 BCE=0.0003) | Val: 0.064444 (MSE=0.064439 BCE=0.0001) | LR: 1.00e-04 | Best: 0.064444 (ep 2)
[18:57:36] Epoch 3/100 | Train: 0.018723 (MSE=0.018717 BCE=0.0001) | Val: 0.062236 (MSE=0.062233 BCE=0.0001) | LR: 1.00e-04 | Best: 0.062236 (ep 3)
[18:57:38] Epoch 4/100 | Train: 0.018397 (MSE=0.018393 BCE=0.0001) | Val: 0.062217 (MSE=0.062215 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:41] Epoch 5/100 | Train: 0.018157 (MSE=0.018153 BCE=0.0001) | Val: 0.064358 (MSE=0.064357 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:43] Epoch 6/100 | Train: 0.017868 (MSE=0.017865 BCE=0.0001) | Val: 0.068870 (MSE=0.068869 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:46] Epoch 7/100 | Train: 0.017517 (MSE=0.017514 BCE=0.0001) | Val: 0.075660 (MSE=0.075659 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:48] Epoch 8/100 | Train: 0.017274 (MSE=0.017272 BCE=0.0000) | Val: 0.083853 (MSE=0.083853 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:51] Epoch 9/100 | Train: 0.017044 (MSE=0.017042 BCE=0.0000) | Val: 0.083709 (MSE=0.083709 BCE=0.0000) | LR: 1.00e-04 | Best: 0.062217 (ep 4)
[18:57:53] Epoch 10/100 | Train: 0.016855 (MSE=0.016853 BCE=0.0000) | Val: 0.096586 (MSE=0.096586 BCE=0.0000) | LR: 5.00e-05 | Best: 0.062217 (ep 4)
[18:57:55] Epoch 11/100 | Train: 0.016561 (MSE=0.016560 BCE=0.0000) | Val: 0.096661 (MSE=0.096661 BCE=0.0000) | LR: 5.00e-05 | Best: 0.062217 (ep 4)
[18:57:58] Epoch 12/100 | Train: 0.016454 (MSE=0.016452 BCE=0.0000) | Val: 0.097935 (MSE=0.097935 BCE=0.0000) | LR: 5.00e-05 | Best: 0.062217 (ep 4)
[18:58:00] Epoch 13/100 | Train: 0.016319 (MSE=0.016318 BCE=0.0000) | Val: 0.099085 (MSE=0.099085 BCE=0.0000) | LR: 5.00e-05 | Best: 0.062217 (ep 4)
[18:58:03] Epoch 14/100 | Train: 0.016218 (MSE=0.016217 BCE=0.0000) | Val: 0.101457 (MSE=0.101457 BCE=0.0000) | LR: 5.00e-05 | Best: 0.062217 (ep 4)
[18:58:03] Early stopping at epoch 14 (no improvement for 10 epochs)
[18:58:04] Factor 60 done — best val loss: 0.062217 at epoch 4
[18:58:04] 
Best factor: 60 (val loss 0.062217)
[18:58:04] Training done. Best factor=60, val_loss=0.062217
[18:58:14] Building validation dataset...
[18:58:14] Building features: 0% (1/175846)
[18:58:14] Building features: 5% (8793/175846)
[18:58:15] Building features: 10% (17585/175846)
[18:58:16] Building features: 15% (26377/175846)
[18:58:16] Building features: 20% (35169/175846)
[18:58:17] Building features: 25% (43961/175846)
[18:58:17] Building features: 30% (52753/175846)
[18:58:18] Building features: 35% (61545/175846)
[18:58:18] Building features: 40% (70337/175846)
[18:58:19] Building features: 45% (79129/175846)
[18:58:20] Building features: 50% (87921/175846)
[18:58:20] Building features: 55% (96713/175846)
[18:58:21] Building features: 60% (105505/175846)
[18:58:21] Building features: 65% (114297/175846)
[18:58:22] Building features: 70% (123089/175846)
[18:58:23] Building features: 75% (131881/175846)
[18:58:23] Building features: 80% (140673/175846)
[18:58:24] Building features: 85% (149465/175846)
[18:58:24] Building features: 90% (158257/175846)
[18:58:25] Building features: 95% (167049/175846)
[18:58:26] Building features: 100% (175841/175846)
[18:58:26] Computing M5 Hurst exponent...
[18:58:28] Computing market regimes (GMM)...
[18:58:32] Computing STF Hurst exponent...
[18:58:38] Running backtest...
[18:58:38] Backtest complete: 18823 trades (187L/18636S), WR=45.4%, PF=0.84
[18:59:37] Training started.
[18:59:37] 
============================================================
[18:59:37] STF Factor 5 of [5..5]
[18:59:37] ============================================================
[18:59:37] Building features: 0% (1/175846)
[18:59:38] Building features: 5% (8793/175846)
[18:59:38] Building features: 10% (17585/175846)
[18:59:39] Building features: 15% (26377/175846)
[18:59:39] Building features: 20% (35169/175846)
[18:59:40] Building features: 25% (43961/175846)
[18:59:40] Building features: 30% (52753/175846)
[18:59:41] Building features: 35% (61545/175846)
[18:59:41] Building features: 40% (70337/175846)
[18:59:42] Building features: 45% (79129/175846)
[18:59:42] Building features: 50% (87921/175846)
[18:59:43] Building features: 55% (96713/175846)
[18:59:44] Building features: 60% (105505/175846)
[18:59:44] Building features: 65% (114297/175846)
[18:59:45] Building features: 70% (123089/175846)
[18:59:45] Building features: 75% (131881/175846)
[18:59:46] Building features: 80% (140673/175846)
[18:59:47] Building features: 85% (149465/175846)
[18:59:47] Building features: 90% (158257/175846)
[18:59:48] Building features: 95% (167049/175846)
[18:59:48] Building features: 100% (175841/175846)
[18:59:48] Computing M5 Hurst exponent...
[18:59:51] Computing market regimes (GMM)...
[18:59:54] Computing STF Hurst exponent...
[19:00:01] Factor 5: 175646 samples, 92 features
[19:00:03] Batch stats — Input:  mean=0.0546 std=0.2648 min=-4.2131 max=12.2195
[19:00:03] Batch stats — Target: mean=0.0000 std=0.1715 min=-1.9124 max=0.9539
[19:00:03] Batch stats — Cls:    pos_long=0/256 pos_short=0/256
[19:00:03] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[19:00:08] Epoch 1/100 | Train: 0.023603 (MSE=0.020706 BCE=0.0580) | Val: 0.077671 (MSE=0.077660 BCE=0.0002) | LR: 1.00e-04 | Best: 0.077671 (ep 1)
[19:00:10] Epoch 2/100 | Train: 0.019269 (MSE=0.019257 BCE=0.0002) | Val: 0.066627 (MSE=0.066623 BCE=0.0001) | LR: 1.00e-04 | Best: 0.066627 (ep 2)
[19:00:13] Epoch 3/100 | Train: 0.018756 (MSE=0.018752 BCE=0.0001) | Val: 0.063047 (MSE=0.063046 BCE=0.0000) | LR: 1.00e-04 | Best: 0.063047 (ep 3)
[19:00:16] Epoch 4/100 | Train: 0.018488 (MSE=0.018485 BCE=0.0000) | Val: 0.061987 (MSE=0.061987 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:19] Epoch 5/100 | Train: 0.018326 (MSE=0.018324 BCE=0.0000) | Val: 0.062259 (MSE=0.062259 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:22] Epoch 6/100 | Train: 0.018196 (MSE=0.018195 BCE=0.0000) | Val: 0.062941 (MSE=0.062941 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:24] Epoch 7/100 | Train: 0.018050 (MSE=0.018050 BCE=0.0000) | Val: 0.064939 (MSE=0.064939 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:27] Epoch 8/100 | Train: 0.017933 (MSE=0.017932 BCE=0.0000) | Val: 0.071704 (MSE=0.071704 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:30] Epoch 9/100 | Train: 0.017808 (MSE=0.017807 BCE=0.0000) | Val: 0.079374 (MSE=0.079374 BCE=0.0000) | LR: 1.00e-04 | Best: 0.061987 (ep 4)
[19:00:33] Epoch 10/100 | Train: 0.017645 (MSE=0.017645 BCE=0.0000) | Val: 0.093826 (MSE=0.093826 BCE=0.0000) | LR: 5.00e-05 | Best: 0.061987 (ep 4)
[19:00:36] Epoch 11/100 | Train: 0.017470 (MSE=0.017470 BCE=0.0000) | Val: 0.100599 (MSE=0.100599 BCE=0.0000) | LR: 5.00e-05 | Best: 0.061987 (ep 4)
[19:00:39] Epoch 12/100 | Train: 0.017363 (MSE=0.017362 BCE=0.0000) | Val: 0.108199 (MSE=0.108199 BCE=0.0000) | LR: 5.00e-05 | Best: 0.061987 (ep 4)
[19:00:41] Epoch 13/100 | Train: 0.017277 (MSE=0.017277 BCE=0.0000) | Val: 0.116185 (MSE=0.116185 BCE=0.0000) | LR: 5.00e-05 | Best: 0.061987 (ep 4)
[19:00:44] Epoch 14/100 | Train: 0.017192 (MSE=0.017192 BCE=0.0000) | Val: 0.121725 (MSE=0.121725 BCE=0.0000) | LR: 5.00e-05 | Best: 0.061987 (ep 4)
[19:00:44] Early stopping at epoch 14 (no improvement for 10 epochs)
[19:00:45] Factor 5 done — best val loss: 0.061987 at epoch 4
[19:00:45] 
Best factor: 5 (val loss 0.061987)
[19:00:45] Training done. Best factor=5, val_loss=0.061987
[19:00:55] Building validation dataset...
[19:00:55] Building features: 0% (1/175846)
[19:00:56] Building features: 5% (8793/175846)
[19:00:56] Building features: 10% (17585/175846)
[19:00:57] Building features: 15% (26377/175846)
[19:00:57] Building features: 20% (35169/175846)
[19:00:58] Building features: 25% (43961/175846)
[19:00:58] Building features: 30% (52753/175846)
[19:00:59] Building features: 35% (61545/175846)
[19:00:59] Building features: 40% (70337/175846)
[19:01:00] Building features: 45% (79129/175846)
[19:01:00] Building features: 50% (87921/175846)
[19:01:01] Building features: 55% (96713/175846)
[19:01:01] Building features: 60% (105505/175846)
[19:01:02] Building features: 65% (114297/175846)
[19:01:02] Building features: 70% (123089/175846)
[19:01:03] Building features: 75% (131881/175846)
[19:01:03] Building features: 80% (140673/175846)
[19:01:04] Building features: 85% (149465/175846)
[19:01:04] Building features: 90% (158257/175846)
[19:01:05] Building features: 95% (167049/175846)
[19:01:05] Building features: 100% (175841/175846)
[19:01:05] Computing M5 Hurst exponent...
[19:01:08] Computing market regimes (GMM)...
[19:01:11] Computing STF Hurst exponent...
[19:01:17] Running backtest...
[19:01:17] Backtest complete: 13876 trades (724L/13152S), WR=45.0%, PF=0.79
[19:02:39] NTCP initialized.
[19:02:50] Loaded 175846 M5 bars.
[19:03:55] Training started.
[19:03:55] 
============================================================
[19:03:55] STF Factor 5 of [5..5]
[19:03:55] ============================================================
[19:03:56] Building features: 0% (1/175846)
[19:03:56] Building features: 5% (8793/175846)
[19:03:57] Building features: 10% (17585/175846)
[19:03:57] Building features: 15% (26377/175846)
[19:03:58] Building features: 20% (35169/175846)
[19:03:58] Building features: 25% (43961/175846)
[19:03:59] Building features: 30% (52753/175846)
[19:03:59] Building features: 35% (61545/175846)
[19:04:00] Building features: 40% (70337/175846)
[19:04:01] Building features: 45% (79129/175846)
[19:04:01] Building features: 50% (87921/175846)
[19:04:02] Building features: 55% (96713/175846)
[19:04:02] Building features: 60% (105505/175846)
[19:04:03] Building features: 65% (114297/175846)
[19:04:03] Building features: 70% (123089/175846)
[19:04:04] Building features: 75% (131881/175846)
[19:04:05] Building features: 80% (140673/175846)
[19:04:05] Building features: 85% (149465/175846)
[19:04:06] Building features: 90% (158257/175846)
[19:04:06] Building features: 95% (167049/175846)
[19:04:07] Building features: 100% (175841/175846)
[19:04:07] Skipping market regimes (group unchecked).
[19:04:11] Factor 5: 175824 samples, 70 features
[19:04:13] Batch stats — Input:  mean=0.0183 std=0.1711 min=-1.0000 max=1.0000
[19:04:13] Batch stats — Target: mean=-0.0027 std=0.0570 min=-0.4572 max=0.3343
[19:04:13] Batch stats — Cls:    pos_long=87/256 pos_short=100/256
[19:04:13] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[19:04:18] Epoch 1/100 | Train: 0.036823 (MSE=0.003482 BCE=0.6668) | Val: 0.044607 (MSE=0.011226 BCE=0.6676) | LR: 1.00e-04 | Best: 0.044607 (ep 1)
[19:04:21] Epoch 2/100 | Train: 0.036252 (MSE=0.003134 BCE=0.6624) | Val: 0.043934 (MSE=0.010575 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043934 (ep 2)
[19:04:24] Epoch 3/100 | Train: 0.036199 (MSE=0.003091 BCE=0.6622) | Val: 0.043662 (MSE=0.010318 BCE=0.6669) | LR: 1.00e-04 | Best: 0.043662 (ep 3)
[19:04:26] Epoch 4/100 | Train: 0.036172 (MSE=0.003071 BCE=0.6620) | Val: 0.043498 (MSE=0.010149 BCE=0.6670) | LR: 1.00e-04 | Best: 0.043498 (ep 4)
[19:04:29] Epoch 5/100 | Train: 0.036150 (MSE=0.003054 BCE=0.6619) | Val: 0.043463 (MSE=0.010125 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043463 (ep 5)
[19:04:32] Epoch 6/100 | Train: 0.036140 (MSE=0.003040 BCE=0.6620) | Val: 0.043469 (MSE=0.010128 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043463 (ep 5)
[19:04:35] Epoch 7/100 | Train: 0.036127 (MSE=0.003030 BCE=0.6619) | Val: 0.043396 (MSE=0.010035 BCE=0.6672) | LR: 1.00e-04 | Best: 0.043396 (ep 7)
[19:04:37] Epoch 8/100 | Train: 0.036118 (MSE=0.003023 BCE=0.6619) | Val: 0.043347 (MSE=0.010012 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043347 (ep 8)
[19:04:40] Epoch 9/100 | Train: 0.036104 (MSE=0.003016 BCE=0.6618) | Val: 0.043360 (MSE=0.010028 BCE=0.6666) | LR: 1.00e-04 | Best: 0.043347 (ep 8)
[19:04:43] Epoch 10/100 | Train: 0.036096 (MSE=0.003010 BCE=0.6617) | Val: 0.043318 (MSE=0.009975 BCE=0.6669) | LR: 1.00e-04 | Best: 0.043318 (ep 10)
[19:04:46] Epoch 11/100 | Train: 0.036095 (MSE=0.003005 BCE=0.6618) | Val: 0.043329 (MSE=0.009997 BCE=0.6666) | LR: 1.00e-04 | Best: 0.043318 (ep 10)
[19:04:48] Epoch 12/100 | Train: 0.036082 (MSE=0.002997 BCE=0.6617) | Val: 0.043273 (MSE=0.009937 BCE=0.6667) | LR: 1.00e-04 | Best: 0.043273 (ep 12)
[19:04:51] Epoch 13/100 | Train: 0.036078 (MSE=0.002994 BCE=0.6617) | Val: 0.043207 (MSE=0.009868 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043207 (ep 13)
[19:04:54] Epoch 14/100 | Train: 0.036064 (MSE=0.002985 BCE=0.6616) | Val: 0.043065 (MSE=0.009726 BCE=0.6668) | LR: 1.00e-04 | Best: 0.043065 (ep 14)
[19:04:57] Epoch 15/100 | Train: 0.036053 (MSE=0.002976 BCE=0.6615) | Val: 0.042878 (MSE=0.009534 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042878 (ep 15)
[19:05:00] Epoch 16/100 | Train: 0.036045 (MSE=0.002968 BCE=0.6615) | Val: 0.042835 (MSE=0.009497 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042835 (ep 16)
[19:05:02] Epoch 17/100 | Train: 0.036033 (MSE=0.002960 BCE=0.6615) | Val: 0.042741 (MSE=0.009408 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042741 (ep 17)
[19:05:05] Epoch 18/100 | Train: 0.036022 (MSE=0.002949 BCE=0.6615) | Val: 0.042750 (MSE=0.009410 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042741 (ep 17)
[19:05:08] Epoch 19/100 | Train: 0.036011 (MSE=0.002939 BCE=0.6614) | Val: 0.042643 (MSE=0.009302 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042643 (ep 19)
[19:05:11] Epoch 20/100 | Train: 0.035996 (MSE=0.002925 BCE=0.6614) | Val: 0.042577 (MSE=0.009242 BCE=0.6667) | LR: 1.00e-04 | Best: 0.042577 (ep 20)
[19:05:13] Epoch 21/100 | Train: 0.035980 (MSE=0.002914 BCE=0.6613) | Val: 0.042559 (MSE=0.009211 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042559 (ep 21)
[19:05:15] Epoch 22/100 | Train: 0.035968 (MSE=0.002905 BCE=0.6613) | Val: 0.042494 (MSE=0.009156 BCE=0.6668) | LR: 1.00e-04 | Best: 0.042494 (ep 22)
[19:05:18] Epoch 23/100 | Train: 0.035959 (MSE=0.002896 BCE=0.6613) | Val: 0.042506 (MSE=0.009163 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042494 (ep 22)
[19:05:20] Epoch 24/100 | Train: 0.035952 (MSE=0.002891 BCE=0.6612) | Val: 0.042444 (MSE=0.009079 BCE=0.6673) | LR: 1.00e-04 | Best: 0.042444 (ep 24)
[19:05:22] Epoch 25/100 | Train: 0.035940 (MSE=0.002882 BCE=0.6612) | Val: 0.042431 (MSE=0.009084 BCE=0.6669) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:25] Epoch 26/100 | Train: 0.035935 (MSE=0.002878 BCE=0.6611) | Val: 0.042481 (MSE=0.009131 BCE=0.6670) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:28] Epoch 27/100 | Train: 0.035928 (MSE=0.002872 BCE=0.6611) | Val: 0.042530 (MSE=0.009177 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:31] Epoch 28/100 | Train: 0.035919 (MSE=0.002865 BCE=0.6611) | Val: 0.042514 (MSE=0.009160 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:34] Epoch 29/100 | Train: 0.035914 (MSE=0.002863 BCE=0.6610) | Val: 0.042459 (MSE=0.009105 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:36] Epoch 30/100 | Train: 0.035913 (MSE=0.002861 BCE=0.6610) | Val: 0.042542 (MSE=0.009188 BCE=0.6671) | LR: 1.00e-04 | Best: 0.042431 (ep 25)
[19:05:39] Epoch 31/100 | Train: 0.035903 (MSE=0.002854 BCE=0.6610) | Val: 0.042604 (MSE=0.009234 BCE=0.6674) | LR: 5.00e-05 | Best: 0.042431 (ep 25)
[19:05:42] Epoch 32/100 | Train: 0.035896 (MSE=0.002847 BCE=0.6610) | Val: 0.042450 (MSE=0.009090 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042431 (ep 25)
[19:05:44] Epoch 33/100 | Train: 0.035893 (MSE=0.002846 BCE=0.6609) | Val: 0.042500 (MSE=0.009145 BCE=0.6671) | LR: 5.00e-05 | Best: 0.042431 (ep 25)
[19:05:46] Epoch 34/100 | Train: 0.035890 (MSE=0.002844 BCE=0.6609) | Val: 0.042503 (MSE=0.009143 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042431 (ep 25)
[19:05:49] Epoch 35/100 | Train: 0.035884 (MSE=0.002841 BCE=0.6609) | Val: 0.042492 (MSE=0.009133 BCE=0.6672) | LR: 5.00e-05 | Best: 0.042431 (ep 25)
[19:05:49] Early stopping at epoch 35 (no improvement for 10 epochs)
[19:05:50] Factor 5 done — best val loss: 0.042431 at epoch 25
[19:05:50] 
Best factor: 5 (val loss 0.042431)
[19:05:50] Training done. Best factor=5, val_loss=0.042431
[19:05:59] Building validation dataset...
[19:05:59] Building features: 0% (1/175846)
[19:06:00] Building features: 5% (8793/175846)
[19:06:00] Building features: 10% (17585/175846)
[19:06:01] Building features: 15% (26377/175846)
[19:06:01] Building features: 20% (35169/175846)
[19:06:02] Building features: 25% (43961/175846)
[19:06:02] Building features: 30% (52753/175846)
[19:06:03] Building features: 35% (61545/175846)
[19:06:03] Building features: 40% (70337/175846)
[19:06:04] Building features: 45% (79129/175846)
[19:06:04] Building features: 50% (87921/175846)
[19:06:05] Building features: 55% (96713/175846)
[19:06:05] Building features: 60% (105505/175846)
[19:06:06] Building features: 65% (114297/175846)
[19:06:06] Building features: 70% (123089/175846)
[19:06:07] Building features: 75% (131881/175846)
[19:06:07] Building features: 80% (140673/175846)
[19:06:08] Building features: 85% (149465/175846)
[19:06:08] Building features: 90% (158257/175846)
[19:06:09] Building features: 95% (167049/175846)
[19:06:09] Building features: 100% (175841/175846)
[19:06:09] Skipping market regimes (group unchecked).
[19:06:13] Running backtest...
[19:06:13] Backtest complete: 10648 trades (8986L/1662S), WR=46.7%, PF=0.89
[19:07:26] Training started.
[19:07:26] 
============================================================
[19:07:26] STF Factor 5 of [5..5]
[19:07:26] ============================================================
[19:07:27] Building features: 0% (1/175846)
[19:07:27] Building features: 5% (8793/175846)
[19:07:28] Building features: 10% (17585/175846)
[19:07:28] Building features: 15% (26377/175846)
[19:07:29] Building features: 20% (35169/175846)
[19:07:29] Building features: 25% (43961/175846)
[19:07:30] Building features: 30% (52753/175846)
[19:07:31] Building features: 35% (61545/175846)
[19:07:31] Building features: 40% (70337/175846)
[19:07:32] Building features: 45% (79129/175846)
[19:07:32] Building features: 50% (87921/175846)
[19:07:33] Building features: 55% (96713/175846)
[19:07:34] Building features: 60% (105505/175846)
[19:07:34] Building features: 65% (114297/175846)
[19:07:35] Building features: 70% (123089/175846)
[19:07:36] Building features: 75% (131881/175846)
[19:07:36] Building features: 80% (140673/175846)
[19:07:37] Building features: 85% (149465/175846)
[19:07:37] Building features: 90% (158257/175846)
[19:07:38] Building features: 95% (167049/175846)
[19:07:38] Building features: 100% (175841/175846)
[19:07:38] Skipping market regimes (group unchecked).
[19:07:42] Factor 5: 175746 samples, 70 features
[19:07:44] Batch stats — Input:  mean=0.0179 std=0.1713 min=-1.0000 max=1.0000
[19:07:44] Batch stats — Target: mean=-0.0042 std=0.1751 min=-1.9124 max=1.0903
[19:07:44] Batch stats — Cls:    pos_long=0/256 pos_short=0/256
[19:07:44] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[19:07:48] Epoch 1/100 | Train: 0.026515 (MSE=0.020855 BCE=0.1132) | Val: 0.078851 (MSE=0.078848 BCE=0.0001) | LR: 1.00e-04 | Best: 0.078851 (ep 1)
[19:07:51] Epoch 2/100 | Train: 0.019348 (MSE=0.019339 BCE=0.0002) | Val: 0.075582 (MSE=0.075581 BCE=0.0000) | LR: 1.00e-04 | Best: 0.075582 (ep 2)
[19:07:54] Epoch 3/100 | Train: 0.019021 (MSE=0.019016 BCE=0.0001) | Val: 0.073962 (MSE=0.073961 BCE=0.0000) | LR: 1.00e-04 | Best: 0.073962 (ep 3)
[19:07:57] Epoch 4/100 | Train: 0.018854 (MSE=0.018851 BCE=0.0001) | Val: 0.071856 (MSE=0.071855 BCE=0.0000) | LR: 1.00e-04 | Best: 0.071856 (ep 4)
[19:08:00] Epoch 5/100 | Train: 0.018705 (MSE=0.018701 BCE=0.0001) | Val: 0.070991 (MSE=0.070989 BCE=0.0000) | LR: 1.00e-04 | Best: 0.070991 (ep 5)
[19:08:02] Epoch 6/100 | Train: 0.018538 (MSE=0.018535 BCE=0.0001) | Val: 0.069550 (MSE=0.069529 BCE=0.0004) | LR: 1.00e-04 | Best: 0.069550 (ep 6)
[19:08:05] Epoch 7/100 | Train: 0.018364 (MSE=0.018362 BCE=0.0000) | Val: 0.069262 (MSE=0.069242 BCE=0.0004) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:08] Epoch 8/100 | Train: 0.018239 (MSE=0.018238 BCE=0.0000) | Val: 0.069952 (MSE=0.069933 BCE=0.0004) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:10] Epoch 9/100 | Train: 0.018115 (MSE=0.018114 BCE=0.0000) | Val: 0.070113 (MSE=0.070105 BCE=0.0002) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:13] Epoch 10/100 | Train: 0.018018 (MSE=0.018017 BCE=0.0000) | Val: 0.072213 (MSE=0.072207 BCE=0.0001) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:16] Epoch 11/100 | Train: 0.017920 (MSE=0.017919 BCE=0.0000) | Val: 0.073965 (MSE=0.073957 BCE=0.0002) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:19] Epoch 12/100 | Train: 0.017821 (MSE=0.017820 BCE=0.0000) | Val: 0.075191 (MSE=0.075189 BCE=0.0001) | LR: 1.00e-04 | Best: 0.069262 (ep 7)
[19:08:21] Epoch 13/100 | Train: 0.017708 (MSE=0.017707 BCE=0.0000) | Val: 0.075385 (MSE=0.075383 BCE=0.0000) | LR: 5.00e-05 | Best: 0.069262 (ep 7)
[19:08:24] Epoch 14/100 | Train: 0.017537 (MSE=0.017536 BCE=0.0000) | Val: 0.076013 (MSE=0.076011 BCE=0.0000) | LR: 5.00e-05 | Best: 0.069262 (ep 7)
[19:08:27] Epoch 15/100 | Train: 0.017476 (MSE=0.017476 BCE=0.0000) | Val: 0.077761 (MSE=0.077759 BCE=0.0000) | LR: 5.00e-05 | Best: 0.069262 (ep 7)
[19:08:30] Epoch 16/100 | Train: 0.017407 (MSE=0.017407 BCE=0.0000) | Val: 0.077788 (MSE=0.077786 BCE=0.0000) | LR: 5.00e-05 | Best: 0.069262 (ep 7)
[19:08:32] Epoch 17/100 | Train: 0.017332 (MSE=0.017332 BCE=0.0000) | Val: 0.079733 (MSE=0.079732 BCE=0.0000) | LR: 5.00e-05 | Best: 0.069262 (ep 7)
[19:08:32] Early stopping at epoch 17 (no improvement for 10 epochs)
[19:08:33] Factor 5 done — best val loss: 0.069262 at epoch 7
[19:08:33] 
Best factor: 5 (val loss 0.069262)
[19:08:33] Training done. Best factor=5, val_loss=0.069262
[19:10:08] Building validation dataset...
[19:10:08] Building features: 0% (1/175846)
[19:10:09] Building features: 5% (8793/175846)
[19:10:09] Building features: 10% (17585/175846)
[19:10:10] Building features: 15% (26377/175846)
[19:10:10] Building features: 20% (35169/175846)
[19:10:11] Building features: 25% (43961/175846)
[19:10:11] Building features: 30% (52753/175846)
[19:10:12] Building features: 35% (61545/175846)
[19:10:12] Building features: 40% (70337/175846)
[19:10:13] Building features: 45% (79129/175846)
[19:10:13] Building features: 50% (87921/175846)
[19:10:14] Building features: 55% (96713/175846)
[19:10:14] Building features: 60% (105505/175846)
[19:10:15] Building features: 65% (114297/175846)
[19:10:15] Building features: 70% (123089/175846)
[19:10:16] Building features: 75% (131881/175846)
[19:10:16] Building features: 80% (140673/175846)
[19:10:17] Building features: 85% (149465/175846)
[19:10:17] Building features: 90% (158257/175846)
[19:10:18] Building features: 95% (167049/175846)
[19:10:18] Building features: 100% (175841/175846)
[19:10:18] Skipping market regimes (group unchecked).
[19:10:21] Running backtest...
[19:10:21] Building validation dataset...
[19:10:22] Building features: 0% (1/175846)
[19:10:22] Building features: 5% (8793/175846)
[19:10:23] Building features: 10% (17585/175846)
[19:10:23] Building features: 15% (26377/175846)
[19:10:24] Building features: 20% (35169/175846)
[19:10:24] Building features: 25% (43961/175846)
[19:10:25] Building features: 30% (52753/175846)
[19:10:25] Building features: 35% (61545/175846)
[19:10:26] Building features: 40% (70337/175846)
[19:10:26] Building features: 45% (79129/175846)
[19:10:27] Building features: 50% (87921/175846)
[19:10:27] Building features: 55% (96713/175846)
[19:10:28] Building features: 60% (105505/175846)
[19:10:28] Building features: 65% (114297/175846)
[19:10:29] Building features: 70% (123089/175846)
[19:10:30] Building features: 75% (131881/175846)
[19:10:30] Building features: 80% (140673/175846)
[19:10:31] Building features: 85% (149465/175846)
[19:10:31] Building features: 90% (158257/175846)
[19:10:32] Building features: 95% (167049/175846)
[19:10:32] Building features: 100% (175841/175846)
[19:10:32] Skipping market regimes (group unchecked).
[19:10:35] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[19:10:35] Running backtest...
[19:10:36] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[21:14:11] NTCP initialized.
[21:14:25] Loaded 175846 M5 bars.
[21:15:58] Training started.
[21:15:58] 
============================================================
[21:15:58] STF Factor 6 of [6..24]
[21:15:58] ============================================================
[21:15:58] Building features: 0% (1/175846)
[21:15:59] Building features: 5% (8793/175846)
[21:16:00] Building features: 10% (17585/175846)
[21:16:00] Building features: 15% (26377/175846)
[21:16:01] Building features: 20% (35169/175846)
[21:16:02] Building features: 25% (43961/175846)
[21:16:03] Building features: 30% (52753/175846)
[21:16:03] Building features: 35% (61545/175846)
[21:16:04] Building features: 40% (70337/175846)
[21:16:05] Building features: 45% (79129/175846)
[21:16:06] Building features: 50% (87921/175846)
[21:16:07] Building features: 55% (96713/175846)
[21:16:08] Building features: 60% (105505/175846)
[21:16:09] Building features: 65% (114297/175846)
[21:16:09] Building features: 70% (123089/175846)
[21:16:10] Building features: 75% (131881/175846)
[21:16:11] Building features: 80% (140673/175846)
[21:16:12] Building features: 85% (149465/175846)
[21:16:13] Building features: 90% (158257/175846)
[21:16:14] Building features: 95% (167049/175846)
[21:16:14] Building features: 100% (175841/175846)
[21:16:14] Computing M5 Hurst exponent...
[21:16:17] Computing market regimes (GMM)...
[21:16:24] Computing STF Hurst exponent...
[21:16:33] Factor 6: 175646 samples, 146 features
[21:16:35] Batch stats — Input:  mean=0.0392 std=0.2144 min=-3.5931 max=7.2034
[21:16:35] Batch stats — Target: mean=-0.0101 std=0.1738 min=-1.9124 max=0.8057
[21:16:35] Batch stats — Cls:    pos_long=21/256 pos_short=13/256
[21:16:35] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[21:16:41] Epoch 1/100 | Train: 0.034550 (MSE=0.021193 BCE=0.2671) | Val: 0.083839 (MSE=0.074524 BCE=0.1863) | LR: 1.00e-04 | Best: 0.083839 (ep 1)
[21:16:44] Epoch 2/100 | Train: 0.028225 (MSE=0.019320 BCE=0.1781) | Val: 0.072224 (MSE=0.063596 BCE=0.1726) | LR: 1.00e-04 | Best: 0.072224 (ep 2)
[21:16:46] Epoch 3/100 | Train: 0.027413 (MSE=0.018776 BCE=0.1727) | Val: 0.074395 (MSE=0.065833 BCE=0.1712) | LR: 1.00e-04 | Best: 0.072224 (ep 2)
[21:16:49] Epoch 4/100 | Train: 0.027007 (MSE=0.018487 BCE=0.1704) | Val: 0.070799 (MSE=0.062361 BCE=0.1688) | LR: 1.00e-04 | Best: 0.070799 (ep 4)
[21:16:52] Epoch 5/100 | Train: 0.026727 (MSE=0.018326 BCE=0.1680) | Val: 0.069197 (MSE=0.060857 BCE=0.1668) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:16:55] Epoch 6/100 | Train: 0.026466 (MSE=0.018175 BCE=0.1658) | Val: 0.070457 (MSE=0.062169 BCE=0.1658) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:16:57] Epoch 7/100 | Train: 0.026226 (MSE=0.018018 BCE=0.1642) | Val: 0.072034 (MSE=0.063804 BCE=0.1646) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:17:00] Epoch 8/100 | Train: 0.025996 (MSE=0.017882 BCE=0.1623) | Val: 0.075022 (MSE=0.066810 BCE=0.1642) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:17:03] Epoch 9/100 | Train: 0.025769 (MSE=0.017747 BCE=0.1604) | Val: 0.081543 (MSE=0.073301 BCE=0.1648) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:17:06] Epoch 10/100 | Train: 0.025561 (MSE=0.017608 BCE=0.1591) | Val: 0.091591 (MSE=0.083342 BCE=0.1650) | LR: 1.00e-04 | Best: 0.069197 (ep 5)
[21:17:08] Epoch 11/100 | Train: 0.025393 (MSE=0.017490 BCE=0.1581) | Val: 0.104730 (MSE=0.096375 BCE=0.1671) | LR: 5.00e-05 | Best: 0.069197 (ep 5)
[21:17:11] Epoch 12/100 | Train: 0.025141 (MSE=0.017306 BCE=0.1567) | Val: 0.109530 (MSE=0.101141 BCE=0.1678) | LR: 5.00e-05 | Best: 0.069197 (ep 5)
[21:17:14] Epoch 13/100 | Train: 0.025041 (MSE=0.017238 BCE=0.1561) | Val: 0.113316 (MSE=0.104969 BCE=0.1669) | LR: 5.00e-05 | Best: 0.069197 (ep 5)
[21:17:17] Epoch 14/100 | Train: 0.024994 (MSE=0.017215 BCE=0.1556) | Val: 0.118346 (MSE=0.109933 BCE=0.1683) | LR: 5.00e-05 | Best: 0.069197 (ep 5)
[21:17:20] Epoch 15/100 | Train: 0.024873 (MSE=0.017132 BCE=0.1548) | Val: 0.121649 (MSE=0.113173 BCE=0.1695) | LR: 5.00e-05 | Best: 0.069197 (ep 5)
[21:17:20] Early stopping at epoch 15 (no improvement for 10 epochs)
[21:17:21] Factor 6 done — best val loss: 0.069197 at epoch 5
[21:17:21] 
============================================================
[21:17:21] STF Factor 7 of [6..24]
[21:17:21] ============================================================
[21:17:21] Building features: 0% (1/175846)
[21:17:22] Building features: 5% (8793/175846)
[21:17:23] Building features: 10% (17585/175846)
[21:17:23] Building features: 15% (26377/175846)
[21:17:24] Building features: 20% (35169/175846)
[21:17:25] Building features: 25% (43961/175846)
[21:17:26] Stop requested...
[21:17:26] Building features: 30% (52753/175846)
[21:17:27] Building features: 35% (61545/175846)
[21:17:27] Building features: 40% (70337/175846)
[21:17:28] Building features: 45% (79129/175846)
[21:17:29] Building features: 50% (87921/175846)
[21:17:30] Building features: 55% (96713/175846)
[21:17:30] Building features: 60% (105505/175846)
[21:17:31] Building features: 65% (114297/175846)
[21:17:32] Building features: 70% (123089/175846)
[21:17:33] Building features: 75% (131881/175846)
[21:17:33] Building features: 80% (140673/175846)
[21:17:34] Building features: 85% (149465/175846)
[21:17:35] Building features: 90% (158257/175846)
[21:17:36] Building features: 95% (167049/175846)
[21:17:36] Building features: 100% (175841/175846)
[21:17:36] Computing M5 Hurst exponent...
[21:17:39] Computing market regimes (GMM)...
[21:17:44] Computing STF Hurst exponent...
[21:17:52] Factor 7: 175646 samples, 146 features
[21:17:53] Batch stats — Input:  mean=0.0405 std=0.2129 min=-3.9503 max=5.7365
[21:17:53] Batch stats — Target: mean=-0.0002 std=0.1792 min=-1.8007 max=1.4136
[21:17:53] Batch stats — Cls:    pos_long=14/256 pos_short=16/256
[21:17:53] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[21:17:53] Training stopped by user.
[21:17:54] Factor 7 done — best val loss: inf at epoch 0
[21:17:54] 
Best factor: 6 (val loss 0.069197)
[21:17:54] Training done. Best factor=6, val_loss=0.069197
[21:18:00] Training started.
[21:18:00] 
============================================================
[21:18:00] STF Factor 5 of [5..5]
[21:18:00] ============================================================
[21:18:00] Building features: 0% (1/175846)
[21:18:01] Building features: 5% (8793/175846)
[21:18:01] Building features: 10% (17585/175846)
[21:18:02] Building features: 15% (26377/175846)
[21:18:03] Building features: 20% (35169/175846)
[21:18:04] Building features: 25% (43961/175846)
[21:18:05] Building features: 30% (52753/175846)
[21:18:05] Building features: 35% (61545/175846)
[21:18:06] Building features: 40% (70337/175846)
[21:18:07] Building features: 45% (79129/175846)
[21:18:08] Building features: 50% (87921/175846)
[21:18:08] Building features: 55% (96713/175846)
[21:18:09] Building features: 60% (105505/175846)
[21:18:10] Building features: 65% (114297/175846)
[21:18:11] Building features: 70% (123089/175846)
[21:18:11] Building features: 75% (131881/175846)
[21:18:12] Building features: 80% (140673/175846)
[21:18:13] Building features: 85% (149465/175846)
[21:18:14] Building features: 90% (158257/175846)
[21:18:14] Building features: 95% (167049/175846)
[21:18:15] Building features: 100% (175841/175846)
[21:18:15] Computing M5 Hurst exponent...
[21:18:18] Computing market regimes (GMM)...
[21:18:22] Computing STF Hurst exponent...
[21:18:30] Factor 5: 175646 samples, 146 features
[21:18:32] Batch stats — Input:  mean=0.0400 std=0.2134 min=-4.1147 max=27.8570
[21:18:32] Batch stats — Target: mean=0.0046 std=0.1605 min=-1.6668 max=0.8713
[21:18:32] Batch stats — Cls:    pos_long=13/256 pos_short=11/256
[21:18:32] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[21:18:37] Epoch 1/100 | Train: 0.033989 (MSE=0.020831 BCE=0.2632) | Val: 0.085256 (MSE=0.075417 BCE=0.1968) | LR: 1.00e-04 | Best: 0.085256 (ep 1)
[21:18:40] Epoch 2/100 | Train: 0.028226 (MSE=0.019225 BCE=0.1800) | Val: 0.072852 (MSE=0.063908 BCE=0.1789) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:43] Epoch 3/100 | Train: 0.027382 (MSE=0.018722 BCE=0.1732) | Val: 0.077597 (MSE=0.068631 BCE=0.1793) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:46] Epoch 4/100 | Train: 0.026933 (MSE=0.018424 BCE=0.1702) | Val: 0.079691 (MSE=0.070934 BCE=0.1751) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:48] Epoch 5/100 | Train: 0.026602 (MSE=0.018208 BCE=0.1679) | Val: 0.077939 (MSE=0.069266 BCE=0.1735) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:51] Epoch 6/100 | Train: 0.026321 (MSE=0.018043 BCE=0.1656) | Val: 0.082634 (MSE=0.074058 BCE=0.1715) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:54] Epoch 7/100 | Train: 0.026074 (MSE=0.017900 BCE=0.1635) | Val: 0.092453 (MSE=0.083903 BCE=0.1710) | LR: 1.00e-04 | Best: 0.072852 (ep 2)
[21:18:57] Epoch 8/100 | Train: 0.025914 (MSE=0.017808 BCE=0.1621) | Val: 0.103821 (MSE=0.095318 BCE=0.1701) | LR: 5.00e-05 | Best: 0.072852 (ep 2)
[21:19:00] Epoch 9/100 | Train: 0.025676 (MSE=0.017646 BCE=0.1606) | Val: 0.117687 (MSE=0.109250 BCE=0.1687) | LR: 5.00e-05 | Best: 0.072852 (ep 2)
[21:19:02] Epoch 10/100 | Train: 0.025591 (MSE=0.017580 BCE=0.1602) | Val: 0.129472 (MSE=0.121072 BCE=0.1680) | LR: 5.00e-05 | Best: 0.072852 (ep 2)
[21:19:05] Epoch 11/100 | Train: 0.025500 (MSE=0.017515 BCE=0.1597) | Val: 0.134727 (MSE=0.126290 BCE=0.1687) | LR: 5.00e-05 | Best: 0.072852 (ep 2)
[21:19:08] Epoch 12/100 | Train: 0.025394 (MSE=0.017434 BCE=0.1592) | Val: 0.139429 (MSE=0.130995 BCE=0.1687) | LR: 5.00e-05 | Best: 0.072852 (ep 2)
[21:19:08] Early stopping at epoch 12 (no improvement for 10 epochs)
[21:19:09] Factor 5 done — best val loss: 0.072852 at epoch 2
[21:19:09] 
Best factor: 5 (val loss 0.072852)
[21:19:09] Training done. Best factor=5, val_loss=0.072852
[21:19:40] Building validation dataset...
[21:19:40] Building features: 0% (1/175846)
[21:19:41] Building features: 5% (8793/175846)
[21:19:42] Building features: 10% (17585/175846)
[21:19:43] Building features: 15% (26377/175846)
[21:19:44] Building features: 20% (35169/175846)
[21:19:45] Building features: 25% (43961/175846)
[21:19:45] Building features: 30% (52753/175846)
[21:19:46] Building features: 35% (61545/175846)
[21:19:47] Building features: 40% (70337/175846)
[21:19:48] Building features: 45% (79129/175846)
[21:19:49] Building features: 50% (87921/175846)
[21:19:50] Building features: 55% (96713/175846)
[21:19:51] Building features: 60% (105505/175846)
[21:19:51] Building features: 65% (114297/175846)
[21:19:52] Building features: 70% (123089/175846)
[21:19:53] Building features: 75% (131881/175846)
[21:19:54] Building features: 80% (140673/175846)
[21:19:55] Building features: 85% (149465/175846)
[21:19:56] Building features: 90% (158257/175846)
[21:19:57] Building features: 95% (167049/175846)
[21:19:58] Building features: 100% (175841/175846)
[21:19:58] Computing M5 Hurst exponent...
[21:20:00] Computing market regimes (GMM)...
[21:20:05] Computing STF Hurst exponent...
[21:20:14] Running backtest...
[21:20:14] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[21:57:26] NTCP initialized.
[21:57:36] Loaded 175846 M5 bars.
[21:58:51] Training started.
[21:58:51] 
============================================================
[21:58:51] STF Factor 5 of [5..5]
[21:58:51] ============================================================
[21:58:51] Building features: 0% (1/175846)
[21:58:51] Building features: 5% (8793/175846)
[21:58:52] Building features: 10% (17585/175846)
[21:58:52] Building features: 15% (26377/175846)
[21:58:53] Building features: 20% (35169/175846)
[21:58:53] Building features: 25% (43961/175846)
[21:58:54] Building features: 30% (52753/175846)
[21:58:54] Building features: 35% (61545/175846)
[21:58:55] Building features: 40% (70337/175846)
[21:58:55] Building features: 45% (79129/175846)
[21:58:56] Building features: 50% (87921/175846)
[21:58:57] Building features: 55% (96713/175846)
[21:58:57] Building features: 60% (105505/175846)
[21:58:58] Building features: 65% (114297/175846)
[21:58:58] Building features: 70% (123089/175846)
[21:58:59] Building features: 75% (131881/175846)
[21:58:59] Building features: 80% (140673/175846)
[21:59:00] Building features: 85% (149465/175846)
[21:59:00] Building features: 90% (158257/175846)
[21:59:01] Building features: 95% (167049/175846)
[21:59:01] Building features: 100% (175841/175846)
[21:59:01] Computing M5 Hurst exponent...
[21:59:04] Computing market regimes (GMM)...
[21:59:09] Computing STF Hurst exponent...
[21:59:16] Factor 5: 175646 samples, 92 features
[21:59:18] Batch stats — Input:  mean=0.0514 std=0.2648 min=-3.7241 max=6.0317
[21:59:18] Batch stats — Target: mean=-0.0067 std=0.1752 min=-1.9124 max=0.9560
[21:59:18] Batch stats — Cls:    pos_long=2/256 pos_short=4/256
[21:59:18] Using CUDA: NVIDIA GeForce RTX 5080 (TF32 enabled)
[21:59:24] Epoch 1/100 | Train: 0.027658 (MSE=0.020922 BCE=0.1347) | Val: 0.083824 (MSE=0.080513 BCE=0.0662) | LR: 1.00e-04 | Best: 0.083824 (ep 1)
[21:59:27] Epoch 2/100 | Train: 0.022688 (MSE=0.019288 BCE=0.0680) | Val: 0.069308 (MSE=0.066047 BCE=0.0652) | LR: 1.00e-04 | Best: 0.069308 (ep 2)
[21:59:29] Epoch 3/100 | Train: 0.022000 (MSE=0.018723 BCE=0.0655) | Val: 0.072913 (MSE=0.069774 BCE=0.0628) | LR: 1.00e-04 | Best: 0.069308 (ep 2)
[21:59:32] Epoch 4/100 | Train: 0.021352 (MSE=0.018404 BCE=0.0590) | Val: 0.074245 (MSE=0.071423 BCE=0.0564) | LR: 1.00e-04 | Best: 0.069308 (ep 2)
[21:59:35] Epoch 5/100 | Train: 0.020943 (MSE=0.018201 BCE=0.0548) | Val: 0.068590 (MSE=0.065824 BCE=0.0553) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:37] Epoch 6/100 | Train: 0.020711 (MSE=0.018029 BCE=0.0536) | Val: 0.071464 (MSE=0.068743 BCE=0.0544) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:40] Epoch 7/100 | Train: 0.020557 (MSE=0.017878 BCE=0.0536) | Val: 0.080751 (MSE=0.078000 BCE=0.0550) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:43] Epoch 8/100 | Train: 0.020400 (MSE=0.017738 BCE=0.0532) | Val: 0.096797 (MSE=0.094025 BCE=0.0554) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:45] Epoch 9/100 | Train: 0.020224 (MSE=0.017586 BCE=0.0527) | Val: 0.102424 (MSE=0.099646 BCE=0.0556) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:48] Epoch 10/100 | Train: 0.020093 (MSE=0.017482 BCE=0.0522) | Val: 0.124715 (MSE=0.121941 BCE=0.0555) | LR: 1.00e-04 | Best: 0.068590 (ep 5)
[21:59:51] Epoch 11/100 | Train: 0.019954 (MSE=0.017353 BCE=0.0520) | Val: 0.132527 (MSE=0.129759 BCE=0.0554) | LR: 5.00e-05 | Best: 0.068590 (ep 5)
[21:59:53] Epoch 12/100 | Train: 0.019763 (MSE=0.017172 BCE=0.0518) | Val: 0.150669 (MSE=0.147909 BCE=0.0552) | LR: 5.00e-05 | Best: 0.068590 (ep 5)
[21:59:56] Epoch 13/100 | Train: 0.019683 (MSE=0.017101 BCE=0.0516) | Val: 0.139852 (MSE=0.137125 BCE=0.0545) | LR: 5.00e-05 | Best: 0.068590 (ep 5)
[21:59:59] Epoch 14/100 | Train: 0.019611 (MSE=0.017042 BCE=0.0514) | Val: 0.152990 (MSE=0.150216 BCE=0.0555) | LR: 5.00e-05 | Best: 0.068590 (ep 5)
[22:00:02] Epoch 15/100 | Train: 0.019537 (MSE=0.016961 BCE=0.0515) | Val: 0.150415 (MSE=0.147683 BCE=0.0546) | LR: 5.00e-05 | Best: 0.068590 (ep 5)
[22:00:02] Early stopping at epoch 15 (no improvement for 10 epochs)
[22:00:03] Factor 5 done — best val loss: 0.068590 at epoch 5
[22:00:03] 
Best factor: 5 (val loss 0.068590)
[22:00:03] Training done. Best factor=5, val_loss=0.068590
[22:00:08] Building validation dataset...
[22:00:08] Building features: 0% (1/175846)
[22:00:09] Building features: 5% (8793/175846)
[22:00:09] Building features: 10% (17585/175846)
[22:00:10] Building features: 15% (26377/175846)
[22:00:10] Building features: 20% (35169/175846)
[22:00:11] Building features: 25% (43961/175846)
[22:00:11] Building features: 30% (52753/175846)
[22:00:12] Building features: 35% (61545/175846)
[22:00:12] Building features: 40% (70337/175846)
[22:00:13] Building features: 45% (79129/175846)
[22:00:14] Building features: 50% (87921/175846)
[22:00:14] Building features: 55% (96713/175846)
[22:00:15] Building features: 60% (105505/175846)
[22:00:15] Building features: 65% (114297/175846)
[22:00:16] Building features: 70% (123089/175846)
[22:00:16] Building features: 75% (131881/175846)
[22:00:17] Building features: 80% (140673/175846)
[22:00:17] Building features: 85% (149465/175846)
[22:00:18] Building features: 90% (158257/175846)
[22:00:18] Building features: 95% (167049/175846)
[22:00:19] Building features: 100% (175841/175846)
[22:00:19] Computing M5 Hurst exponent...
[22:00:21] Computing market regimes (GMM)...
[22:00:25] Computing STF Hurst exponent...
[22:00:31] Running backtest...
[22:00:32] Backtest complete: 0 trades (0L/0S), WR=0.0%, PF=0.00
[23:19:13] NTCP initialized.
